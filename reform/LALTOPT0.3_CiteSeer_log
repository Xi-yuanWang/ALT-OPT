[I 2023-06-11 23:21:26,030] A new study created in RDB with name: CiteSeer_ALTOPT
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.001856802849567028
weight_decay:  0.010437315921839154
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4546640219632536
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 02
None time:  1.008440773934126
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  0.6260821809992194
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.1385254859924316
total time:  4.711661738809198
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.47 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 68.20 ± 0.70
[I 2023-06-11 23:21:31,275] Trial 0 finished with value: 69.46666717529297 and parameters: {'Fwd': 0.024252614499677055, 'K': 8, 'alpha': 0.5, 'dropout': 0.1, 'gnnepoch': 30, 'lambda1': 0.6000000000000001, 'lambda2': 1.4947964571746175, 'loop': 2, 'loss': 'MSE', 'lr': 0.001856802849567028, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.010437315921839154, 'weightedloss': True}. Best is trial 0 with value: 69.46666717529297.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.7000000000000001
lr:  0.00014002617410517948
weight_decay:  4.027233645450561e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.35262805689126253
None Run 01:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 45.70
Split: 01, Run: 02
None time:  0.4782988908700645
None Run 02:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 99.17
   Final Test: 62.70
Split: 01, Run: 03
None time:  0.47538122721016407
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 97.50
   Final Test: 64.20
run time now: 1.3535451889038086
total time:  1.4133982271887362
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.87 ± 11.50
  Final Train: 98.89 ± 1.27
   Final Test: 57.53 ± 10.28
[I 2023-06-11 23:21:33,026] Trial 1 finished with value: 59.866668701171875 and parameters: {'Fwd': 0.006784717247072782, 'K': 6, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 1.3571727617581564, 'loop': 1, 'loss': 'CE', 'lr': 0.00014002617410517948, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.027233645450561e-05, 'weightedloss': False}. Best is trial 0 with value: 69.46666717529297.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.35000000000000003
lr:  0.000433428526276257
weight_decay:  1.4346207779730118e-06
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.49765209294855595
None Run 01:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 45.60
Split: 01, Run: 02
None time:  0.5844270640518516
None Run 02:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 03
None time:  0.8487285699229687
None Run 03:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 53.40
run time now: 1.9680914878845215
total time:  2.011580026941374
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.67 ± 4.56
  Final Train: 100.00 ± 0.00
   Final Test: 50.17 ± 4.07
[I 2023-06-11 23:21:35,364] Trial 2 finished with value: 51.66666793823242 and parameters: {'Fwd': 0.00021072958487887251, 'K': 6, 'alpha': 0.35000000000000003, 'dropout': 0.0, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 0.5601743389344982, 'loop': 1, 'loss': 'MSE', 'lr': 0.000433428526276257, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4346207779730118e-06, 'weightedloss': True}. Best is trial 0 with value: 69.46666717529297.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.00016513637254898217
weight_decay:  6.057189957966733e-05
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.2679332890547812
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.40
Split: 01, Run: 02
None time:  0.8887391479220241
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 91.67
   Final Test: 67.10
Split: 01, Run: 03
None time:  0.386515585007146
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 93.33
   Final Test: 63.80
run time now: 1.5826926231384277
total time:  1.6396971070207655
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.13 ± 10.69
  Final Train: 95.00 ± 4.41
   Final Test: 59.10 ± 11.12
[I 2023-06-11 23:21:37,316] Trial 3 finished with value: 59.13333511352539 and parameters: {'Fwd': 0.06316541696865646, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.0, 'gnnepoch': 20, 'lambda1': 0.4, 'lambda2': 0.977905165337829, 'loop': 2, 'loss': 'CE', 'lr': 0.00016513637254898217, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.057189957966733e-05, 'weightedloss': True}. Best is trial 0 with value: 69.46666717529297.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.0004800362319249094
weight_decay:  0.012582779436389979
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7875857390463352
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 02
None time:  0.9565131939016283
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  0.8459520449396223
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.40
run time now: 2.621682643890381
total time:  2.66817124793306
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.40 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 66.73 ± 0.35
[I 2023-06-11 23:21:40,343] Trial 4 finished with value: 68.4000015258789 and parameters: {'Fwd': 3.1097790956890324e-06, 'K': 1, 'alpha': 0.4, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 8.145106976561962, 'loop': 1, 'loss': 'CE', 'lr': 0.0004800362319249094, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.012582779436389979, 'weightedloss': True}. Best is trial 0 with value: 69.46666717529297.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.65
lr:  0.0019177808510439914
weight_decay:  0.00011403726458847238
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8939046419691294
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.8482444880064577
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.867189162876457
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 2.648247003555298
total time:  2.7025736609939486
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.21
[I 2023-06-11 23:21:43,407] Trial 5 finished with value: 71.0 and parameters: {'Fwd': 0.0007161169001932046, 'K': 6, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 2.69333188017253, 'loop': 1, 'loss': 'CE', 'lr': 0.0019177808510439914, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011403726458847238, 'weightedloss': False}. Best is trial 5 with value: 71.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.2
lr:  0.00107959170639809
weight_decay:  0.001082496457948407
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6794367609545588
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 81.67
   Final Test: 70.30
Split: 01, Run: 02
None time:  0.6019228450022638
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.6117633038666099
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.9306015968322754
total time:  3.0164879597723484
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.61
  Final Train: 93.89 ± 10.58
   Final Test: 70.57 ± 0.64
[I 2023-06-11 23:21:46,749] Trial 6 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.00020916623070637498, 'K': 5, 'alpha': 0.2, 'dropout': 0.1, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 2.674225551454137, 'loop': 2, 'loss': 'CE', 'lr': 0.00107959170639809, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001082496457948407, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.0007679021380332803
weight_decay:  0.061227763436356615
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.531367972958833
None Run 01:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 54.00
Split: 01, Run: 02
None time:  0.6210419500712305
None Run 02:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 53.60
Split: 01, Run: 03
None time:  0.36350875603966415
None Run 03:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 36.20
run time now: 1.5505270957946777
total time:  1.6221111179329455
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 48.33 ± 9.94
  Final Train: 100.00 ± 0.00
   Final Test: 47.93 ± 10.16
[I 2023-06-11 23:21:48,714] Trial 7 finished with value: 48.33333206176758 and parameters: {'Fwd': 0.07048361793024657, 'K': 3, 'alpha': 0.25, 'dropout': 0.5, 'gnnepoch': 20, 'lambda1': 0.9500000000000001, 'lambda2': 8.226975040948997, 'loop': 1, 'loss': 'MSE', 'lr': 0.0007679021380332803, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.061227763436356615, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.15000000000000002
lr:  0.0024470714036407223
weight_decay:  0.00026008624332664673
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.20% Test: 66.50%
Split: 01, Run: 01
None time:  0.9091645190492272
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.20% Test: 68.70%
Split: 01, Run: 02
None time:  0.9499562850687653
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.40% Test: 69.10%
Split: 01, Run: 03
None time:  0.9419330100063235
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.8368542194366455
total time:  2.888211081037298
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.93 ± 1.62
  Final Train: 100.00 ± 0.00
   Final Test: 68.13 ± 1.53
[I 2023-06-11 23:21:51,954] Trial 8 finished with value: 65.9333267211914 and parameters: {'Fwd': 1.2825129606282566e-06, 'K': 5, 'alpha': 0.15000000000000002, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 7.298536959247012, 'loop': 0, 'loss': 'MSE', 'lr': 0.0024470714036407223, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00026008624332664673, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0034365142317319725
weight_decay:  1.2346879711973835e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1163126560859382
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0635, Train: 100.00%, Valid: 70.60% Test: 71.00%
Split: 01, Run: 02
None time:  2.4487989221233875
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.644070188049227
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.80
run time now: 5.251619338989258
total time:  5.2960060951299965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.47 ± 0.58
[I 2023-06-11 23:21:57,628] Trial 9 finished with value: 70.33333587646484 and parameters: {'Fwd': 2.86954432767055e-06, 'K': 10, 'alpha': 0.55, 'dropout': 0.30000000000000004, 'gnnepoch': 120, 'lambda1': 0.25, 'lambda2': 9.738579250623044, 'loop': 2, 'loss': 'MSE', 'lr': 0.0034365142317319725, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2346879711973835e-05, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.008614001511659341
weight_decay:  0.001350791917970191
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3186153550632298
None Run 01:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 48.20
Split: 01, Run: 02
None time:  0.36377415899187326
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 95.83
   Final Test: 66.60
Split: 01, Run: 03
None time:  0.3524048610124737
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 66.00
run time now: 1.0698602199554443
total time:  1.1302899648435414
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.53 ± 11.05
  Final Train: 98.33 ± 2.20
   Final Test: 60.27 ± 10.45
[I 2023-06-11 23:21:59,189] Trial 10 finished with value: 62.5333366394043 and parameters: {'Fwd': 5.2588152166708364e-05, 'K': 3, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 1.0, 'lambda2': 4.511915808040719, 'loop': 0, 'loss': 'CE', 'lr': 0.008614001511659341, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.001350791917970191, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  1.0
lr:  0.001815620438961864
weight_decay:  0.0008081935224171034
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5200731637887657
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.60
Split: 01, Run: 02
None time:  1.4952099591027945
None Run 02:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.60
Split: 01, Run: 03
None time:  1.5794588918797672
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.60
run time now: 4.630714654922485
total time:  4.684537066845223
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.60 ± 0.00
[I 2023-06-11 23:22:04,318] Trial 11 finished with value: 51.40000534057617 and parameters: {'Fwd': 0.0013720446081474157, 'K': 4, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.0, 'lambda2': 3.5707396273420997, 'loop': 2, 'loss': 'CE', 'lr': 0.001815620438961864, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0008081935224171034, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.001081501715816602
weight_decay:  0.00020310336701966729
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0339707068633288
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.9936322399880737
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.115948547841981
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.183539628982544
total time:  3.2488378109410405
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.61
[I 2023-06-11 23:22:07,999] Trial 12 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.0009829961797844994, 'K': 7, 'alpha': 0.65, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.440356331055556, 'loop': 0, 'loss': 'CE', 'lr': 0.001081501715816602, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00020310336701966729, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.000713423340150338
weight_decay:  0.00088526404470787
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.962992416927591
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.028370387852192
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.9937763689085841
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.0252609252929688
total time:  3.0796611590776592
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.55
[I 2023-06-11 23:22:11,507] Trial 13 finished with value: 70.80000305175781 and parameters: {'Fwd': 6.2770223571208e-05, 'K': 8, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.8249054639394835, 'loop': 0, 'loss': 'CE', 'lr': 0.000713423340150338, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00088526404470787, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.0010107291218251322
weight_decay:  0.00266741069405433
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5736106890253723
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 61.50
Split: 01, Run: 02
None time:  0.4622247579973191
None Run 02:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 97.50
   Final Test: 54.70
Split: 01, Run: 03
None time:  0.5100356771145016
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 97.50
   Final Test: 63.10
run time now: 1.5902233123779297
total time:  1.6550057458225638
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.40 ± 6.88
  Final Train: 98.33 ± 1.44
   Final Test: 59.77 ± 4.46
[I 2023-06-11 23:22:13,638] Trial 14 finished with value: 60.399993896484375 and parameters: {'Fwd': 0.002663934198797851, 'K': 10, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 3.272809921943396, 'loop': 0, 'loss': 'CE', 'lr': 0.0010107291218251322, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00266741069405433, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.30000000000000004
lr:  0.0003438641642403041
weight_decay:  0.000225916388511797
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6121936370618641
None Run 01:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 51.60
Split: 01, Run: 02
None time:  0.15959832281805575
None Run 02:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 50.20
Split: 01, Run: 03
None time:  0.42434851196594536
None Run 03:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 55.40
run time now: 1.2421448230743408
total time:  1.2962011320050806
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.07 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 52.40 ± 2.69
[I 2023-06-11 23:22:15,380] Trial 15 finished with value: 53.06666564941406 and parameters: {'Fwd': 0.0002755560029216279, 'K': 7, 'alpha': 0.30000000000000004, 'dropout': 0.1, 'gnnepoch': 0, 'lambda1': 0.6000000000000001, 'lambda2': 2.4091019852193662, 'loop': 0, 'loss': 'CE', 'lr': 0.0003438641642403041, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000225916388511797, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.0011845380661480664
weight_decay:  0.0031643945519815894
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1158770848996937
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.218281903071329
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.145319937961176
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.5157833099365234
total time:  3.581486660055816
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.15
[I 2023-06-11 23:22:19,367] Trial 16 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.005480056814453059, 'K': 4, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 5.746568316966854, 'loop': 2, 'loss': 'CE', 'lr': 0.0011845380661480664, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0031643945519815894, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00023093677651011944
weight_decay:  0.00046488304581389383
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1847003251314163
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 94.17
   Final Test: 68.10
Split: 01, Run: 02
None time:  0.7213439450133592
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.7877819167915732
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 68.70
run time now: 2.725376605987549
total time:  2.785740887047723
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 0.70
  Final Train: 97.50 ± 3.00
   Final Test: 68.37 ± 0.31
[I 2023-06-11 23:22:22,582] Trial 17 finished with value: 69.13333129882812 and parameters: {'Fwd': 0.0006748865659046962, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 2.1434225812950967, 'loop': 1, 'loss': 'CE', 'lr': 0.00023093677651011944, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00046488304581389383, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0006468261745885941
weight_decay:  4.1723657921266173e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6969555530231446
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 90.83
   Final Test: 68.50
Split: 01, Run: 02
None time:  0.6725795730017126
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 90.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.6635870400350541
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 91.67
   Final Test: 68.40
run time now: 2.0751514434814453
total time:  2.126605562167242
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 0.72
  Final Train: 90.83 ± 0.83
   Final Test: 68.93 ± 0.84
[I 2023-06-11 23:22:25,144] Trial 18 finished with value: 69.79999542236328 and parameters: {'Fwd': 6.484847301914175e-05, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 3.805875629336062, 'loop': 2, 'loss': 'CE', 'lr': 0.0006468261745885941, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.1723657921266173e-05, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.45
lr:  0.0002729971201463768
weight_decay:  0.00032936992773427377
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.44978127791546285
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 95.83
   Final Test: 64.50
Split: 01, Run: 02
None time:  0.47961489600129426
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 91.67
   Final Test: 68.10
Split: 01, Run: 03
None time:  0.6091721390839666
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 90.00
   Final Test: 67.60
run time now: 1.5803637504577637
total time:  1.642515657003969
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.53 ± 1.45
  Final Train: 92.50 ± 3.00
   Final Test: 66.73 ± 1.95
[I 2023-06-11 23:22:27,226] Trial 19 finished with value: 68.53333282470703 and parameters: {'Fwd': 0.010087061330767508, 'K': 5, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 0.01160826824479777, 'loop': 0, 'loss': 'CE', 'lr': 0.0002729971201463768, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00032936992773427377, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.15000000000000002
lr:  0.00010430735852803162
weight_decay:  1.8223242098874302e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2860571818891913
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 02
None time:  1.1965137959923595
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  1.395982241956517
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.50
run time now: 3.9166882038116455
total time:  3.957589292898774
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.60 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 66.37 ± 1.63
[I 2023-06-11 23:22:31,687] Trial 20 finished with value: 66.5999984741211 and parameters: {'Fwd': 0.0021263235243104434, 'K': 7, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.5, 'lambda2': 1.9197677750808304, 'loop': 1, 'loss': 'CE', 'lr': 0.00010430735852803162, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8223242098874302e-05, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.001119571116693451
weight_decay:  0.003049400372641805
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.170405853074044
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.3388440920971334
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.1771387590561062
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.20
run time now: 3.7274982929229736
total time:  3.79564720694907
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.33 ± 0.15
[I 2023-06-11 23:22:36,069] Trial 21 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.006234534779550612, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 5.747295565528696, 'loop': 2, 'loss': 'CE', 'lr': 0.001119571116693451, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.003049400372641805, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.8
lr:  0.0014017165253577281
weight_decay:  0.0022707241187924225
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0341304619796574
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.2048889640718699
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.1846854980103672
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.4590518474578857
total time:  3.5218601517844945
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.38
[I 2023-06-11 23:22:39,972] Trial 22 finished with value: 70.93333435058594 and parameters: {'Fwd': 0.0006924687527079932, 'K': 3, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 5.756909497346384, 'loop': 2, 'loss': 'CE', 'lr': 0.0014017165253577281, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0022707241187924225, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.0010651567545640218
weight_decay:  0.006936739400391876
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0162808171007782
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.078653406118974
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1310555920936167
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.261570453643799
total time:  3.3051182460039854
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.26
[I 2023-06-11 23:22:43,688] Trial 23 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.0037510100654815095, 'K': 4, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 4.13300609000236, 'loop': 2, 'loss': 'CE', 'lr': 0.0010651567545640218, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.006936739400391876, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.65
lr:  0.0007540427136572629
weight_decay:  0.008007774006053547
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0338082308880985
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.022270721849054
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.9574157078750432
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.20
run time now: 3.047689914703369
total time:  3.0968520999886096
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 1.19
[I 2023-06-11 23:22:47,184] Trial 24 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.002100240914530609, 'K': 2, 'alpha': 0.65, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 1.0, 'lambda2': 3.0064226749207847, 'loop': 2, 'loss': 'CE', 'lr': 0.0007540427136572629, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.008007774006053547, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.45
lr:  0.0005201551005725884
weight_decay:  0.02892674562452339
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9295030620414764
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0043216310441494
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.9540946809574962
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.9267730712890625
total time:  2.978134882869199
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.06
[I 2023-06-11 23:22:50,563] Trial 25 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.01986467585350006, 'K': 5, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.215273006102622, 'loop': 1, 'loss': 'CE', 'lr': 0.0005201551005725884, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.02892674562452339, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.25
lr:  0.0005292166723263522
weight_decay:  0.056255354174582876
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0030571050010622
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 95.83
   Final Test: 65.20
Split: 01, Run: 02
None time:  0.708601722959429
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 03
None time:  0.7420608920510858
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 65.60
run time now: 2.491154193878174
total time:  2.547871921909973
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.00 ± 0.53
  Final Train: 98.61 ± 2.41
   Final Test: 65.67 ± 0.50
[I 2023-06-11 23:22:53,542] Trial 26 finished with value: 65.00000762939453 and parameters: {'Fwd': 0.014771437703522213, 'K': 5, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.9500000000000001, 'lambda2': 4.232496898212476, 'loop': 1, 'loss': 'CE', 'lr': 0.0005292166723263522, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.056255354174582876, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.45
lr:  0.00036738227444745535
weight_decay:  0.013673741184274663
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0201, Train: 100.00%, Valid: 57.00% Test: 57.10%
Split: 01, Run: 01
None time:  1.7932198408525437
None Run 01:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 02
None time:  1.0517260420601815
None Run 02:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 58.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0207, Train: 100.00%, Valid: 53.40% Test: 52.70%
Split: 01, Run: 03
None time:  1.8901498119812459
None Run 03:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 51.50
run time now: 4.7703447341918945
total time:  4.821137397084385
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.33 ± 1.81
  Final Train: 100.00 ± 0.00
   Final Test: 55.57 ± 3.57
[I 2023-06-11 23:22:58,759] Trial 27 finished with value: 55.33333206176758 and parameters: {'Fwd': 0.03153111495690476, 'K': 4, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 1.0, 'lambda2': 4.133653938364789, 'loop': 1, 'loss': 'MSE', 'lr': 0.00036738227444745535, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.013673741184274663, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.35000000000000003
lr:  0.0005673003694202422
weight_decay:  0.026337562175641233
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5231660029385239
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 94.17
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.7689176490530372
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 97.50
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.8367513020057231
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 69.60
run time now: 3.1763317584991455
total time:  3.243954516015947
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.80
  Final Train: 96.11 ± 1.73
   Final Test: 70.60 ± 0.89
[I 2023-06-11 23:23:02,407] Trial 28 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.034663888192136, 'K': 5, 'alpha': 0.35000000000000003, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 4.8509237675663845, 'loop': 2, 'loss': 'CE', 'lr': 0.0005673003694202422, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.026337562175641233, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.5
lr:  0.0006827172747842742
weight_decay:  0.0062618009752769994
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.296440528007224
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 62.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.3059, Train: 100.00%, Valid: 62.60% Test: 60.00%
Split: 01, Run: 02
None time:  2.5520932120271027
None Run 02:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 59.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.2695, Train: 100.00%, Valid: 28.80% Test: 29.10%
Split: 01, Run: 03
None time:  2.6007125889882445
None Run 03:
Highest Train: 100.00
Highest Valid: 28.80
  Final Train: 100.00
   Final Test: 28.60
run time now: 7.485333442687988
total time:  7.534197787987068
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.93 ± 20.05
  Final Train: 100.00 ± 0.00
   Final Test: 50.40 ± 18.95
[I 2023-06-11 23:23:10,438] Trial 29 finished with value: 51.93333435058594 and parameters: {'Fwd': 0.09855044033661274, 'K': 2, 'alpha': 0.5, 'dropout': 0.2, 'gnnepoch': 40, 'lambda1': 0.9, 'lambda2': 1.776438037038906, 'loop': 2, 'loss': 'MSE', 'lr': 0.0006827172747842742, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0062618009752769994, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.25
lr:  0.0008527808925368099
weight_decay:  0.09331299209274034
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0375714788679034
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1590752911288291
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.0785946450196207
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.3153910636901855
total time:  3.373605438042432
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.55
[I 2023-06-11 23:23:14,256] Trial 30 finished with value: 71.0 and parameters: {'Fwd': 0.018893601619122482, 'K': 6, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.55, 'lambda2': 2.516126028845464, 'loop': 2, 'loss': 'CE', 'lr': 0.0008527808925368099, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.09331299209274034, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0009607344223738349
weight_decay:  0.027694647437740673
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7784326809924096
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.9038316060323268
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.8773130171466619
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.5995686054229736
total time:  2.651328400010243
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.40
[I 2023-06-11 23:23:17,328] Trial 31 finished with value: 70.73332977294922 and parameters: {'Fwd': 0.005055976958096755, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 3.270906335729973, 'loop': 0, 'loss': 'CE', 'lr': 0.0009607344223738349, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.027694647437740673, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.0013735172950410013
weight_decay:  0.006372795716697229
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.061709696892649
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0963621861301363
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.0245904268231243
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.2213523387908936
total time:  3.275215680943802
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.20
[I 2023-06-11 23:23:21,045] Trial 32 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.008972044243888333, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 3.763062923447154, 'loop': 1, 'loss': 'CE', 'lr': 0.0013735172950410013, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.006372795716697229, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.45
lr:  0.0005177110789250033
weight_decay:  0.0016053087840028697
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9024040820077062
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.9764481610618532
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.9319257950410247
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.10
run time now: 2.8482165336608887
total time:  2.9051011949777603
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.98
[I 2023-06-11 23:23:24,386] Trial 33 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.003421571378781322, 'K': 6, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 2.8970336351026575, 'loop': 2, 'loss': 'CE', 'lr': 0.0005177110789250033, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0016053087840028697, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.65
lr:  0.0008661736697605719
weight_decay:  0.004967588295911895
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1658399319276214
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.093681458150968
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.182825676864013
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 70.70
run time now: 3.4795033931732178
total time:  3.521790402010083
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.20
  Final Train: 98.61 ± 1.73
   Final Test: 69.90 ± 0.80
[I 2023-06-11 23:23:28,423] Trial 34 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.014311727706967306, 'K': 5, 'alpha': 0.65, 'dropout': 0.1, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 1.25924692264604, 'loop': 1, 'loss': 'CE', 'lr': 0.0008661736697605719, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.004967588295911895, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.35000000000000003
lr:  0.0004417825076467259
weight_decay:  0.016230380094768192
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.385842656949535
None Run 01:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 48.70
Split: 01, Run: 02
None time:  0.845666540088132
None Run 02:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 90.00
   Final Test: 63.70
Split: 01, Run: 03
None time:  0.5234630699269474
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 99.17
   Final Test: 64.10
run time now: 1.7930145263671875
total time:  1.8465239580255002
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.33 ± 8.95
  Final Train: 96.39 ± 5.55
   Final Test: 58.83 ± 8.78
[I 2023-06-11 23:23:30,685] Trial 35 finished with value: 59.33333206176758 and parameters: {'Fwd': 0.03694175641645962, 'K': 6, 'alpha': 0.35000000000000003, 'dropout': 0.0, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 3.985852458089506, 'loop': 1, 'loss': 'CE', 'lr': 0.0004417825076467259, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.016230380094768192, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.9500000000000001
lr:  0.0013634110429366988
weight_decay:  0.0006167488293027485
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0427523248363286
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.3200402909424156
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.2420128399971873
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 97.50
   Final Test: 69.10
run time now: 3.6414122581481934
total time:  3.703309669159353
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.20
  Final Train: 99.17 ± 1.44
   Final Test: 69.30 ± 0.20
[I 2023-06-11 23:23:34,821] Trial 36 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.00015861469667571054, 'K': 4, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 1.4150160286456104, 'loop': 2, 'loss': 'CE', 'lr': 0.0013634110429366988, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0006167488293027485, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.000915565159781727
weight_decay:  0.0013062739349648694
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7198251897934824
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.20
Split: 01, Run: 02
None time:  1.3652594659943134
None Run 02:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.40
Split: 01, Run: 03
None time:  0.788759624119848
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.60
run time now: 2.9303369522094727
total time:  2.990137414075434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.53 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 66.07 ± 2.27
[I 2023-06-11 23:23:38,211] Trial 37 finished with value: 67.53333282470703 and parameters: {'Fwd': 0.0012204382343583328, 'K': 8, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 2.7286876499410853, 'loop': 1, 'loss': 'MSE', 'lr': 0.000915565159781727, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0013062739349648694, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.6000000000000001
lr:  0.000621769786516601
weight_decay:  0.009761841615448711
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5872287598904222
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.6113581520039588
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.5897851809859276
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 67.90
run time now: 1.8238024711608887
total time:  1.8791086850687861
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 68.93 ± 0.93
[I 2023-06-11 23:23:40,523] Trial 38 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.00042499763827041795, 'K': 3, 'alpha': 0.6000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.205204847609556, 'loop': 0, 'loss': 'CE', 'lr': 0.000621769786516601, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.009761841615448711, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.0004209175587576527
weight_decay:  0.0048284605636615355
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7058983680326492
None Run 01:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 52.60
Split: 01, Run: 02
None time:  1.1580347018316388
None Run 02:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 55.50
Split: 01, Run: 03
None time:  0.5282094259746373
None Run 03:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 48.90
run time now: 2.43554949760437
total time:  2.4798684760462493
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.53 ± 1.42
  Final Train: 100.00 ± 0.00
   Final Test: 52.33 ± 3.31
[I 2023-06-11 23:23:43,457] Trial 39 finished with value: 52.5333366394043 and parameters: {'Fwd': 0.0035035357515196854, 'K': 9, 'alpha': 0.4, 'dropout': 0.6000000000000001, 'gnnepoch': 30, 'lambda1': 0.75, 'lambda2': 3.1997696774623425, 'loop': 1, 'loss': 'MSE', 'lr': 0.0004209175587576527, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0048284605636615355, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.05
lr:  0.0017072801185493397
weight_decay:  0.00014639694017546163
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8222301809582859
None Run 01:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 51.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0143, Train: 83.33%, Valid: 68.60% Test: 68.50%
Split: 01, Run: 02
None time:  2.2881561419926584
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 84.17
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.8135163460392505
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 67.40
run time now: 3.962590217590332
total time:  4.006097289966419
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.87 ± 12.19
  Final Train: 94.44 ± 8.91
   Final Test: 62.77 ± 9.54
[I 2023-06-11 23:23:47,868] Trial 40 finished with value: 61.86666488647461 and parameters: {'Fwd': 0.0014281585778552828, 'K': 6, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 2.1246866530240607, 'loop': 2, 'loss': 'CE', 'lr': 0.0017072801185493397, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00014639694017546163, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.0011734113791966605
weight_decay:  0.0023806277676531873
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1099327330011874
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1629246319644153
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.1634552630130202
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.472727060317993
total time:  3.5290828021243215
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.12
[I 2023-06-11 23:23:51,832] Trial 41 finished with value: 71.0 and parameters: {'Fwd': 0.006038367474022367, 'K': 4, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 4.4680126478745885, 'loop': 2, 'loss': 'CE', 'lr': 0.0011734113791966605, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0023806277676531873, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.5
lr:  0.00115633450196351
weight_decay:  0.003950431436374869
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1994205098599195
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 02
None time:  1.196274712216109
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.2569445639383048
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.6896796226501465
total time:  3.732475870056078
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.07 ± 0.47
[I 2023-06-11 23:23:55,958] Trial 42 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.008382019943872422, 'K': 5, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 5.313281404021755, 'loop': 2, 'loss': 'CE', 'lr': 0.00115633450196351, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.003950431436374869, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.0008455525959026454
weight_decay:  0.0007112208714522451
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1510400720871985
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.1137048359960318
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1567897421773523
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.80
run time now: 3.458496570587158
total time:  3.5145937509369105
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 1.75
  Final Train: 100.00 ± 0.00
   Final Test: 68.33 ± 2.21
[I 2023-06-11 23:23:59,946] Trial 43 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.004179548832461367, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 3.695372271623976, 'loop': 2, 'loss': 'CE', 'lr': 0.0008455525959026454, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0007112208714522451, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.7000000000000001
lr:  0.002213722821635535
weight_decay:  0.0013270097781780195
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9276484230067581
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0185128438752145
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.9970003550406545
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.97812557220459
total time:  3.0331387030892074
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.64
[I 2023-06-11 23:24:03,410] Trial 44 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.019473208797738745, 'K': 3, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 6.270856446704429, 'loop': 2, 'loss': 'CE', 'lr': 0.002213722821635535, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0013270097781780195, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.55
lr:  0.0015298775905972183
weight_decay:  0.00044695808234803395
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1423872120212764
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.1529017409775406
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.2121294178068638
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.540364980697632
total time:  3.5961228301748633
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.61
[I 2023-06-11 23:24:07,402] Trial 45 finished with value: 71.06666564941406 and parameters: {'Fwd': 0.0009676391550321997, 'K': 2, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.603689968339337, 'loop': 2, 'loss': 'CE', 'lr': 0.0015298775905972183, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00044695808234803395, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.4
lr:  0.0020931120170893302
weight_decay:  0.0033198321505243356
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6877867670264095
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 98.33
   Final Test: 65.40
Split: 01, Run: 02
None time:  0.6350118929985911
None Run 02:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.60
Split: 01, Run: 03
None time:  0.7608797329012305
None Run 03:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 55.10
run time now: 2.1188573837280273
total time:  2.1656892800237983
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.67 ± 6.11
  Final Train: 99.44 ± 0.96
   Final Test: 59.70 ± 5.24
[I 2023-06-11 23:24:09,975] Trial 46 finished with value: 59.66666793823242 and parameters: {'Fwd': 0.002286128081619696, 'K': 4, 'alpha': 0.4, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 3.4095148767833208, 'loop': 0, 'loss': 'CE', 'lr': 0.0020931120170893302, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0033198321505243356, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.75
lr:  0.0030692134257570163
weight_decay:  9.168458721435514e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9418800650164485
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.154935209080577
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.9259913710411638
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.0598278045654297
total time:  3.118456050986424
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.53
  Final Train: 99.44 ± 0.96
   Final Test: 69.13 ± 0.49
[I 2023-06-11 23:24:13,515] Trial 47 finished with value: 71.0 and parameters: {'Fwd': 0.00046613367668265395, 'K': 5, 'alpha': 0.75, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 4.120148367985587, 'loop': 2, 'loss': 'CE', 'lr': 0.0030692134257570163, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.168458721435514e-05, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0011229623994397893
weight_decay:  0.010124476892775194
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.23306288989260793
None Run 01:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 46.10
Split: 01, Run: 02
None time:  0.17941337497904897
None Run 02:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 46.10
Split: 01, Run: 03
None time:  0.21053023589774966
None Run 03:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 46.10
run time now: 0.663074254989624
total time:  0.7182658740784973
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 46.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 46.10 ± 0.00
[I 2023-06-11 23:24:14,654] Trial 48 finished with value: 46.39999771118164 and parameters: {'Fwd': 0.0001948597371741555, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.0, 'gnnepoch': 0, 'lambda1': 0.35000000000000003, 'lambda2': 4.410960685105729, 'loop': 1, 'loss': 'MSE', 'lr': 0.0011229623994397893, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.010124476892775194, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.2
lr:  0.001738992807608647
weight_decay:  0.00018829567937017486
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7797068490181118
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 86.67
   Final Test: 67.40
Split: 01, Run: 02
None time:  0.6896835460793227
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.7476832219399512
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 68.50
run time now: 2.253493070602417
total time:  2.3089622468687594
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 2.53
  Final Train: 94.17 ± 6.61
   Final Test: 68.30 ± 0.82
[I 2023-06-11 23:24:17,402] Trial 49 finished with value: 70.06666564941406 and parameters: {'Fwd': 0.010310478065200726, 'K': 5, 'alpha': 0.2, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 2.579666504971737, 'loop': 2, 'loss': 'CE', 'lr': 0.001738992807608647, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00018829567937017486, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.7000000000000001
lr:  0.0006820386669679401
weight_decay:  0.0011253065891636991
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.40% Test: 59.70%
Split: 01, Run: 01
None time:  0.8041619688738137
None Run 01:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 59.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 62.20% Test: 63.60%
Split: 01, Run: 02
None time:  0.8760847360827029
None Run 02:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 63.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 59.80% Test: 62.40%
Split: 01, Run: 03
None time:  0.8358474359847605
None Run 03:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 62.30
run time now: 2.5544846057891846
total time:  2.6164410039782524
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.80 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 61.77 ± 1.86
[I 2023-06-11 23:24:20,465] Trial 50 finished with value: 60.79999923706055 and parameters: {'Fwd': 0.05648898653698167, 'K': 6, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 10, 'lambda1': 0.6000000000000001, 'lambda2': 3.535814176582826, 'loop': 0, 'loss': 'CE', 'lr': 0.0006820386669679401, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0011253065891636991, 'weightedloss': True}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.5
lr:  0.0011054718199446322
weight_decay:  0.0038017720069834504
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.218166918028146
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 02
None time:  1.273165772901848
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.2370808210689574
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.76609206199646
total time:  3.8163625460583717
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 68.97 ± 0.25
[I 2023-06-11 23:24:24,706] Trial 51 finished with value: 70.93334197998047 and parameters: {'Fwd': 0.0077533032903158465, 'K': 5, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 5.218704384773342, 'loop': 2, 'loss': 'CE', 'lr': 0.0011054718199446322, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0038017720069834504, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.0009978780363261047
weight_decay:  0.001961530298669602
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0969905480742455
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1289464950095862
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.1582153218332678
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.80
run time now: 3.4198076725006104
total time:  3.470097801880911
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.23 ± 0.40
[I 2023-06-11 23:24:28,590] Trial 52 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.004195718489479473, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 4.9289556243955, 'loop': 2, 'loss': 'CE', 'lr': 0.0009978780363261047, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.001961530298669602, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.5
lr:  0.0012371146212090622
weight_decay:  0.00366903079225019
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.825065751094371
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  2.0766692738980055
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 03
None time:  1.815192328998819
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
run time now: 5.754272937774658
total time:  5.7967519701924175
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.30 ± 0.00
[I 2023-06-11 23:24:34,855] Trial 53 finished with value: 51.20000076293945 and parameters: {'Fwd': 0.011935191838324125, 'K': 5, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.0, 'lambda2': 5.545177090015455, 'loop': 2, 'loss': 'CE', 'lr': 0.0012371146212090622, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00366903079225019, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.0015353666756826212
weight_decay:  0.0010064582238019646
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1909451140090823
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.2188265821896493
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.3803028881084174
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.8306353092193604
total time:  3.887654914986342
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.40
[I 2023-06-11 23:24:39,180] Trial 54 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.00669051096521923, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 6.660591607524228, 'loop': 2, 'loss': 'CE', 'lr': 0.0015353666756826212, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0010064582238019646, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.0016306746757120438
weight_decay:  0.0009522650370267514
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1751763781066984
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.0670459179673344
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.2138090669177473
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.497671604156494
total time:  3.5533055879641324
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.17
[I 2023-06-11 23:24:43,164] Trial 55 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.0017574063129324729, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 6.284022394294625, 'loop': 2, 'loss': 'CE', 'lr': 0.0016306746757120438, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0009522650370267514, 'weightedloss': False}. Best is trial 6 with value: 71.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.0015988493791180593
weight_decay:  0.0003975635718945405
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0553343081846833
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.0416769119910896
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.0696618519723415
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.2005553245544434
total time:  3.2604764860589057
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.35
[I 2023-06-11 23:24:46,847] Trial 56 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0017541959709468143, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 6.548110596375791, 'loop': 2, 'loss': 'CE', 'lr': 0.0015988493791180593, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003975635718945405, 'weightedloss': False}. Best is trial 56 with value: 71.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.0017034864364181724
weight_decay:  0.0003163224809785667
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.041931230807677
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0325398950371891
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.178108470980078
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.287768602371216
total time:  3.3414185610599816
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.35
[I 2023-06-11 23:24:50,618] Trial 57 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.001777485681989555, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 6.758752822358639, 'loop': 2, 'loss': 'CE', 'lr': 0.0017034864364181724, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003163224809785667, 'weightedloss': False}. Best is trial 57 with value: 71.60000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0014817500352084848
weight_decay:  0.0003009255028000841
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6750284831505269
None Run 01:
Highest Train: 100.00
Highest Valid: 40.40
  Final Train: 100.00
   Final Test: 42.70
Split: 01, Run: 02
None time:  0.6681965051684529
None Run 02:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 37.60
Split: 01, Run: 03
None time:  0.5636545869056135
None Run 03:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 35.30
run time now: 1.9410979747772217
total time:  1.9986285180784762
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 38.40 ± 2.36
  Final Train: 100.00 ± 0.00
   Final Test: 38.53 ± 3.79
[I 2023-06-11 23:24:53,072] Trial 58 finished with value: 38.39999771118164 and parameters: {'Fwd': 0.002459985096935264, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 7.261989631115192, 'loop': 2, 'loss': 'CE', 'lr': 0.0014817500352084848, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003009255028000841, 'weightedloss': False}. Best is trial 57 with value: 71.60000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.0026534051431396145
weight_decay:  0.0006517377174185078
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4197868460323662
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.717028568033129
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.5430014291778207
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 4.714747667312622
total time:  4.763228310039267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.21
[I 2023-06-11 23:24:58,240] Trial 59 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.003006712908288001, 'K': 3, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 6.75942296968398, 'loop': 2, 'loss': 'CE', 'lr': 0.0026534051431396145, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0006517377174185078, 'weightedloss': True}. Best is trial 57 with value: 71.60000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.002478689461534006
weight_decay:  0.0005577382784963652
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1424158359877765
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.1316, Train: 100.00%, Valid: 70.20% Test: 70.30%
Split: 01, Run: 02
None time:  3.0269851570483297
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.3240057982038707
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.90
run time now: 5.543220520019531
total time:  5.601471605943516
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.74
[I 2023-06-11 23:25:04,249] Trial 60 finished with value: 69.33333587646484 and parameters: {'Fwd': 0.0030332148522991707, 'K': 3, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 7.078392838694919, 'loop': 2, 'loss': 'MSE', 'lr': 0.002478689461534006, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005577382784963652, 'weightedloss': True}. Best is trial 57 with value: 71.60000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0018884404943302468
weight_decay:  0.0003592007267062464
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.180511036887765
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  2.383936352096498
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.434416573960334
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.031366348266602
total time:  6.086149919778109
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.71
[I 2023-06-11 23:25:10,716] Trial 61 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.001587101811214164, 'K': 1, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.8440573964817855, 'loop': 2, 'loss': 'CE', 'lr': 0.0018884404943302468, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003592007267062464, 'weightedloss': True}. Best is trial 57 with value: 71.60000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0019314407230989741
weight_decay:  0.00040543585135462715
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0714026249479502
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0781762688420713
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  1.290367861976847
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.474224805831909
total time:  3.526119118090719
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.46
[I 2023-06-11 23:25:14,658] Trial 62 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.0013370229251207625, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 7.810120215350878, 'loop': 2, 'loss': 'CE', 'lr': 0.0019314407230989741, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00040543585135462715, 'weightedloss': True}. Best is trial 57 with value: 71.60000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0025733671861125937
weight_decay:  0.00029464366377322647
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9990618680603802
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.197442278964445
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.5837859199382365
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.30
run time now: 3.8150222301483154
total time:  3.8733351971022785
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.47 ± 0.85
[I 2023-06-11 23:25:18,967] Trial 63 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0017919088811796367, 'K': 2, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 6.836122031179738, 'loop': 2, 'loss': 'CE', 'lr': 0.0025733671861125937, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00029464366377322647, 'weightedloss': True}. Best is trial 57 with value: 71.60000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0027127905503229023
weight_decay:  0.0002701511632706244
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3096381830982864
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.757731445133686
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.604866661131382
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 4.706191062927246
total time:  4.752453353954479
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.33 ± 0.35
[I 2023-06-11 23:25:24,247] Trial 64 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.000980364732079023, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 6.837118895280871, 'loop': 2, 'loss': 'CE', 'lr': 0.0027127905503229023, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002701511632706244, 'weightedloss': True}. Best is trial 57 with value: 71.60000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.002688003234175839
weight_decay:  0.00029575345826821873
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.027379886014387
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.7973851431161165
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 03
None time:  1.7509901120793074
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.607861280441284
total time:  3.65872671501711
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 68.37 ± 2.05
[I 2023-06-11 23:25:28,328] Trial 65 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.000886267410134777, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.1, 'lambda2': 7.733722473896073, 'loop': 2, 'loss': 'CE', 'lr': 0.002688003234175839, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00029575345826821873, 'weightedloss': True}. Best is trial 57 with value: 71.60000610351562.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.003336334418622564
weight_decay:  0.00021526675812185794
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1207900778390467
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.7909767490345985
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  1.3838922081049532
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.00
run time now: 4.33470606803894
total time:  4.378914515022188
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 70.67 ± 0.67
[I 2023-06-11 23:25:33,089] Trial 66 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.0017382706331724375, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 8.497226384014843, 'loop': 2, 'loss': 'CE', 'lr': 0.003336334418622564, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021526675812185794, 'weightedloss': True}. Best is trial 66 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0047881751513736606
weight_decay:  0.00017242121331529224
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0842642970383167
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  0.6428641360253096
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.7013837599661201
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.20
run time now: 2.4619340896606445
total time:  2.5081420179922134
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 1.22
  Final Train: 99.72 ± 0.48
   Final Test: 70.53 ± 1.65
[I 2023-06-11 23:25:36,011] Trial 67 finished with value: 72.4000015258789 and parameters: {'Fwd': 0.0007386615301344076, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 8.507299281264721, 'loop': 2, 'loss': 'CE', 'lr': 0.0047881751513736606, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00017242121331529224, 'weightedloss': True}. Best is trial 67 with value: 72.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.003948502578517208
weight_decay:  0.00010880720626828991
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5021945438347757
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.6914729119744152
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  0.6916729521472007
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.40
run time now: 2.917905569076538
total time:  2.967196370009333
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 68.77 ± 1.29
[I 2023-06-11 23:25:39,456] Trial 68 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0005800972087213903, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 8.622228224905442, 'loop': 2, 'loss': 'CE', 'lr': 0.003948502578517208, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010880720626828991, 'weightedloss': True}. Best is trial 67 with value: 72.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.004270853362933674
weight_decay:  0.0002291810227506512
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8025093730539083
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.8509514159522951
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.5957031860016286
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.70
run time now: 3.2845537662506104
total time:  3.3538933640811592
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.47 ± 1.60
  Final Train: 100.00 ± 0.00
   Final Test: 70.43 ± 1.17
[I 2023-06-11 23:25:43,217] Trial 69 finished with value: 72.46666717529297 and parameters: {'Fwd': 0.0008228329561948027, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.05, 'lambda2': 8.374918859146023, 'loop': 2, 'loss': 'CE', 'lr': 0.004270853362933674, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002291810227506512, 'weightedloss': True}. Best is trial 69 with value: 72.46666717529297.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.004416349295260373
weight_decay:  0.0001991534790335912
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2838981859385967
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 02
None time:  1.2444935759995133
None Run 02:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 03
None time:  1.2388114870991558
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
run time now: 3.8013834953308105
total time:  3.8483485348988324
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.50 ± 0.00
[I 2023-06-11 23:25:47,511] Trial 70 finished with value: 51.40000534057617 and parameters: {'Fwd': 0.0003258313920877525, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.0, 'lambda2': 8.714921800849863, 'loop': 2, 'loss': 'CE', 'lr': 0.004416349295260373, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001991534790335912, 'weightedloss': True}. Best is trial 69 with value: 72.46666717529297.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.004929582373443951
weight_decay:  0.00043117017137624895
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.287360757123679
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  1.4807592967990786
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.7552626600954682
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.40
run time now: 3.5569331645965576
total time:  3.6086003999225795
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.20 ± 1.39
[I 2023-06-11 23:25:51,548] Trial 71 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.0009002968771335159, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.05, 'lambda2': 7.602551761992865, 'loop': 2, 'loss': 'CE', 'lr': 0.004929582373443951, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00043117017137624895, 'weightedloss': True}. Best is trial 69 with value: 72.46666717529297.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0035112463721847253
weight_decay:  0.00016600601716943133
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3892612759955227
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.6374995189253241
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.5918201128952205
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.652012586593628
total time:  2.6985723162069917
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.33 ± 0.31
  Final Train: 99.72 ± 0.48
   Final Test: 70.50 ± 0.44
[I 2023-06-11 23:25:54,756] Trial 72 finished with value: 73.33333587646484 and parameters: {'Fwd': 0.0006863636758126659, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 8.283499330774147, 'loop': 2, 'loss': 'CE', 'lr': 0.0035112463721847253, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00016600601716943133, 'weightedloss': True}. Best is trial 72 with value: 73.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.005639674086031381
weight_decay:  0.00014735799146486757
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0475340019911528
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.7686636890284717
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.5629338170401752
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.10
run time now: 2.4124670028686523
total time:  2.4663165870588273
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.17 ± 1.20
[I 2023-06-11 23:25:57,648] Trial 73 finished with value: 70.93334197998047 and parameters: {'Fwd': 0.000582462145212767, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.05, 'lambda2': 8.64577822563557, 'loop': 2, 'loss': 'CE', 'lr': 0.005639674086031381, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00014735799146486757, 'weightedloss': True}. Best is trial 72 with value: 73.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.003255229860645179
weight_decay:  6.83828231455465e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6368973080534488
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.60
Split: 01, Run: 02
None time:  0.8156962099019438
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.6738389041274786
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.10
run time now: 2.1587181091308594
total time:  2.2246097738388926
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.00 ± 2.80
  Final Train: 100.00 ± 0.00
   Final Test: 67.40 ± 2.44
[I 2023-06-11 23:26:00,267] Trial 74 finished with value: 69.0 and parameters: {'Fwd': 0.0010580969981351645, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.3751835147329, 'loop': 2, 'loss': 'CE', 'lr': 0.003255229860645179, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.83828231455465e-05, 'weightedloss': True}. Best is trial 72 with value: 73.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.003860603923562026
weight_decay:  0.00023778327169659552
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2071072089020163
None Run 01:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 02
None time:  0.6701097041368484
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  0.7496084659360349
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.6605758666992188
total time:  2.7137376158498228
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.07 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 2.86
[I 2023-06-11 23:26:03,385] Trial 75 finished with value: 74.0666732788086 and parameters: {'Fwd': 0.0008714031075641993, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.204291220952793, 'loop': 2, 'loss': 'CE', 'lr': 0.003860603923562026, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00023778327169659552, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0034317059001628594
weight_decay:  0.00017353594625266905
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0846961080096662
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.80
Split: 01, Run: 02
None time:  0.8043558308854699
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.6585164158605039
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 69.10
run time now: 2.5799384117126465
total time:  2.6267782980576158
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 70.57 ± 1.97
[I 2023-06-11 23:26:06,458] Trial 76 finished with value: 72.79999542236328 and parameters: {'Fwd': 0.000788909504374928, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.203141622071673, 'loop': 2, 'loss': 'CE', 'lr': 0.0034317059001628594, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00017353594625266905, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.003621240286962428
weight_decay:  0.00016381089130311065
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0900450269691646
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 99.17
   Final Test: 62.00
Split: 01, Run: 02
None time:  1.3632954328786582
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.7511001308448613
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.239529609680176
total time:  3.2933199810795486
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.73 ± 3.29
  Final Train: 99.44 ± 0.48
   Final Test: 66.87 ± 4.23
[I 2023-06-11 23:26:10,282] Trial 77 finished with value: 68.73333740234375 and parameters: {'Fwd': 0.0006799495617049347, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.15701626336896, 'loop': 2, 'loss': 'CE', 'lr': 0.003621240286962428, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00016381089130311065, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.005778464400636271
weight_decay:  0.00020830312168293647
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.201783511089161
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 66.90
Split: 01, Run: 02
None time:  0.7735882380511612
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.6676349849440157
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.00
run time now: 2.6760048866271973
total time:  2.724561810027808
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 1.11
  Final Train: 99.72 ± 0.48
   Final Test: 67.93 ± 1.70
[I 2023-06-11 23:26:13,416] Trial 78 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.0013440336252931214, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 9.428519735013715, 'loop': 2, 'loss': 'CE', 'lr': 0.005778464400636271, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00020830312168293647, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0037590986492173147
weight_decay:  0.0001212434369514986
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5788548199925572
None Run 01:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 54.20
Split: 01, Run: 02
None time:  1.1571714060846716
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 03
None time:  0.6260261929128319
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.20
run time now: 2.394988775253296
total time:  2.46281302603893
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.40 ± 5.37
  Final Train: 100.00 ± 0.00
   Final Test: 61.33 ± 6.22
[I 2023-06-11 23:26:16,315] Trial 79 finished with value: 62.39999771118164 and parameters: {'Fwd': 0.00036466691134906006, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.08448277653312, 'loop': 2, 'loss': 'MSE', 'lr': 0.0037590986492173147, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0001212434369514986, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.003280477997611614
weight_decay:  8.926980326837182e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6642742049880326
None Run 01:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 46.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.1420, Train: 90.83%, Valid: 68.00% Test: 69.20%
Split: 01, Run: 02
None time:  2.0164288331288844
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 91.67
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.6952847549691796
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.409975290298462
total time:  3.4643450351431966
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.60 ± 13.68
  Final Train: 97.22 ± 4.81
   Final Test: 61.50 ± 13.44
[I 2023-06-11 23:26:20,212] Trial 80 finished with value: 60.60000228881836 and parameters: {'Fwd': 0.0005389865417961587, 'K': 3, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 9.81135376988844, 'loop': 2, 'loss': 'CE', 'lr': 0.003280477997611614, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.926980326837182e-05, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0029801893338126622
weight_decay:  0.0002374853662408658
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6257168471347541
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.50
Split: 01, Run: 02
None time:  1.373265135101974
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  0.9896052549593151
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.70
run time now: 3.0216777324676514
total time:  3.0757608821149915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 5.10
  Final Train: 100.00 ± 0.00
   Final Test: 69.07 ± 4.82
[I 2023-06-11 23:26:23,707] Trial 81 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.0008222959127429136, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 9.115807108577158, 'loop': 2, 'loss': 'CE', 'lr': 0.0029801893338126622, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002374853662408658, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.004050172385358592
weight_decay:  0.00023489422872223324
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9370011789724231
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.5876081201713532
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.6270522100385278
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.1876981258392334
total time:  2.248028571018949
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 2.03
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 1.25
[I 2023-06-11 23:26:26,352] Trial 82 finished with value: 72.0 and parameters: {'Fwd': 0.0011631053505407076, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.234884572310207, 'loop': 2, 'loss': 'CE', 'lr': 0.004050172385358592, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00023489422872223324, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.004137527735762814
weight_decay:  0.00013648557455930553
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7827005088329315
None Run 01:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 55.40
Split: 01, Run: 02
None time:  0.9842010631691664
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.6963375338818878
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.498166561126709
total time:  2.5529377749189734
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.60 ± 6.08
  Final Train: 99.72 ± 0.48
   Final Test: 65.73 ± 8.96
[I 2023-06-11 23:26:29,453] Trial 83 finished with value: 67.5999984741211 and parameters: {'Fwd': 0.0018737841686896665, 'K': 2, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 8.247112120469842, 'loop': 2, 'loss': 'CE', 'lr': 0.004137527735762814, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00013648557455930553, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.004349353899256831
weight_decay:  0.0005121497015933604
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.49665351188741624
None Run 01:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 54.50
Split: 01, Run: 02
None time:  1.0549039971083403
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 99.17
   Final Test: 67.30
Split: 01, Run: 03
None time:  0.5144866879563779
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.10516357421875
total time:  2.161165145924315
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.53 ± 8.13
  Final Train: 99.72 ± 0.48
   Final Test: 64.13 ± 8.50
[I 2023-06-11 23:26:32,054] Trial 84 finished with value: 65.53333282470703 and parameters: {'Fwd': 0.0007027898809198755, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.15000000000000002, 'lambda2': 8.96315969156587, 'loop': 2, 'loss': 'CE', 'lr': 0.004349353899256831, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005121497015933604, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0035249835604414946
weight_decay:  0.00019279451142943118
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6143276649527252
None Run 01:
Highest Train: 100.00
Highest Valid: 31.60
  Final Train: 100.00
   Final Test: 34.00
Split: 01, Run: 02
None time:  0.6680693631060421
None Run 02:
Highest Train: 100.00
Highest Valid: 21.80
  Final Train: 100.00
   Final Test: 25.80
Split: 01, Run: 03
None time:  0.6004037200473249
None Run 03:
Highest Train: 100.00
Highest Valid: 31.40
  Final Train: 100.00
   Final Test: 32.80
run time now: 1.914625644683838
total time:  1.9687670720741153
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 28.27 ± 5.60
  Final Train: 100.00 ± 0.00
   Final Test: 30.87 ± 4.43
[I 2023-06-11 23:26:34,434] Trial 85 finished with value: 28.26666831970215 and parameters: {'Fwd': 0.00115402438504348, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.496080138741396, 'loop': 2, 'loss': 'CE', 'lr': 0.0035249835604414946, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019279451142943118, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.00230259765045612
weight_decay:  5.93907602449555e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8883688058704138
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 02
None time:  0.660600685980171
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  0.5530758849345148
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 66.90
run time now: 2.137401580810547
total time:  2.195719789015129
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 67.40 ± 0.46
[I 2023-06-11 23:26:37,034] Trial 86 finished with value: 69.86666870117188 and parameters: {'Fwd': 0.00048082591299095437, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 8.411146795439798, 'loop': 2, 'loss': 'CE', 'lr': 0.00230259765045612, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.93907602449555e-05, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.1
lr:  0.002970131740304469
weight_decay:  0.000250674165849032
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4080509091727436
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 99.17
   Final Test: 64.20
Split: 01, Run: 02
None time:  0.5995954088866711
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 03
None time:  0.6863680901005864
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.60
run time now: 2.727529764175415
total time:  2.777537555899471
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.60 ± 1.64
  Final Train: 99.72 ± 0.48
   Final Test: 66.13 ± 2.25
[I 2023-06-11 23:26:40,226] Trial 87 finished with value: 67.5999984741211 and parameters: {'Fwd': 0.0022896467144833577, 'K': 3, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.048934140374271, 'loop': 2, 'loss': 'CE', 'lr': 0.002970131740304469, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000250674165849032, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.00473940847559778
weight_decay:  0.00035383191137072014
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.320807856041938
None Run 01:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 95.00
   Final Test: 58.80
Split: 01, Run: 02
None time:  0.5731697459705174
None Run 02:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 59.90
Split: 01, Run: 03
None time:  0.721244327025488
None Run 03:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 64.20
run time now: 2.654233694076538
total time:  2.707822215044871
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.27 ± 1.72
  Final Train: 98.33 ± 2.89
   Final Test: 60.97 ± 2.85
[I 2023-06-11 23:26:43,428] Trial 88 finished with value: 60.26666259765625 and parameters: {'Fwd': 0.0002525589628073656, 'K': 2, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 8.920271708125375, 'loop': 2, 'loss': 'CE', 'lr': 0.00473940847559778, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00035383191137072014, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.0038708235091684576
weight_decay:  0.0007666831885517429
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.101722976192832
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 02
None time:  0.5577260998543352
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.6372703830711544
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.20
run time now: 2.3320887088775635
total time:  2.3834037960041314
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 71.77 ± 0.67
[I 2023-06-11 23:26:46,260] Trial 89 finished with value: 73.53333282470703 and parameters: {'Fwd': 0.0004058574669637431, 'K': 3, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.979491892781478, 'loop': 2, 'loss': 'CE', 'lr': 0.0038708235091684576, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007666831885517429, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00358699206268929
weight_decay:  0.0008134597145382737
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5956808270420879
None Run 01:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 48.80
Split: 01, Run: 02
None time:  0.5988530840259045
None Run 02:
Highest Train: 100.00
Highest Valid: 41.80
  Final Train: 100.00
   Final Test: 44.40
Split: 01, Run: 03
None time:  0.5430980040691793
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 54.60
run time now: 1.7703948020935059
total time:  1.813328537158668
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 47.13 ± 4.83
  Final Train: 100.00 ± 0.00
   Final Test: 49.27 ± 5.12
[I 2023-06-11 23:26:48,515] Trial 90 finished with value: 47.13333511352539 and parameters: {'Fwd': 0.00035754078277550717, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.932823412578387, 'loop': 2, 'loss': 'CE', 'lr': 0.00358699206268929, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008134597145382737, 'weightedloss': True}. Best is trial 75 with value: 74.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.00562035086674343
weight_decay:  0.00016264921469095437
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8123779469169676
None Run 01:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 02
None time:  0.6726619601249695
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  0.6123797290492803
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.00
run time now: 3.1312694549560547
total time:  3.1879308570642024
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 71.83 ± 0.67
[I 2023-06-11 23:26:52,171] Trial 91 finished with value: 74.5999984741211 and parameters: {'Fwd': 0.0008018213982014878, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 9.536804654909846, 'loop': 2, 'loss': 'CE', 'lr': 0.00562035086674343, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00016264921469095437, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006011855196423247
weight_decay:  0.00017611109777453292
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3303994801826775
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  1.1257581529207528
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 03
None time:  0.7639906979165971
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.70
run time now: 3.2556588649749756
total time:  3.2997254279907793
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 71.90 ± 1.14
[I 2023-06-11 23:26:55,874] Trial 92 finished with value: 72.26666259765625 and parameters: {'Fwd': 0.0007195660285075133, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 9.619981981956414, 'loop': 2, 'loss': 'CE', 'lr': 0.006011855196423247, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00017611109777453292, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006377686317517458
weight_decay:  0.00017464967659084637
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.719871980138123
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.90
Split: 01, Run: 02
None time:  0.8880410331767052
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.6185711740981787
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.2599120140075684
total time:  2.318149333121255
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 3.38
  Final Train: 100.00 ± 0.00
   Final Test: 67.77 ± 2.51
[I 2023-06-11 23:26:58,629] Trial 93 finished with value: 69.33333587646484 and parameters: {'Fwd': 0.00042286141834961126, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 9.569424633060413, 'loop': 2, 'loss': 'CE', 'lr': 0.006377686317517458, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00017464967659084637, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0076047317143039
weight_decay:  0.00011851634951532459
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0928165370132774
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.8582074840087444
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  0.7192114328499883
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.90
run time now: 2.7035250663757324
total time:  2.7517995869275182
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 71.07 ± 0.29
[I 2023-06-11 23:27:01,833] Trial 94 finished with value: 73.26666259765625 and parameters: {'Fwd': 0.0007481169972068995, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.05, 'lambda2': 9.31227658558722, 'loop': 2, 'loss': 'CE', 'lr': 0.0076047317143039, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011851634951532459, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.007680887003222381
weight_decay:  0.00011913102261889915
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2271939059719443
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 67.70
Split: 01, Run: 02
None time:  0.5908570131286979
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.5709341049659997
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.422682285308838
total time:  2.468487264122814
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 1.59
  Final Train: 99.72 ± 0.48
   Final Test: 69.93 ± 2.04
[I 2023-06-11 23:27:04,832] Trial 95 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.000803615226060465, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.15000000000000002, 'lambda2': 9.311100471234722, 'loop': 2, 'loss': 'CE', 'lr': 0.007680887003222381, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011913102261889915, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.005077958297691528
weight_decay:  8.544281077721441e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3335614269599319
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  1.3986632490996271
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 03
None time:  1.383070187177509
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
run time now: 4.147417306900024
total time:  4.20441484102048
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.30 ± 0.00
[I 2023-06-11 23:27:09,472] Trial 96 finished with value: 51.20000076293945 and parameters: {'Fwd': 0.0006450666838556873, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.0, 'lambda2': 9.757618935125098, 'loop': 2, 'loss': 'MSE', 'lr': 0.005077958297691528, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.544281077721441e-05, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007212591031397024
weight_decay:  0.00011050349101265998
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5658173949923366
None Run 01:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 52.20
Split: 01, Run: 02
None time:  0.5970807590056211
None Run 02:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 47.00
Split: 01, Run: 03
None time:  0.6098681089933962
None Run 03:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 99.17
   Final Test: 39.60
run time now: 1.8131375312805176
total time:  1.8824153100140393
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.20 ± 3.47
  Final Train: 99.72 ± 0.48
   Final Test: 46.27 ± 6.33
[I 2023-06-11 23:27:11,766] Trial 97 finished with value: 49.20000076293945 and parameters: {'Fwd': 0.001112455275480943, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.720650427977692, 'loop': 2, 'loss': 'CE', 'lr': 0.007212591031397024, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00011050349101265998, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.003923556905423186
weight_decay:  0.00014382208339944094
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3751511930022389
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.5661264040973037
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.48121829610317945
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.459162950515747
total time:  2.5141582910437137
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 70.83 ± 0.85
[I 2023-06-11 23:27:14,701] Trial 98 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.0002861328047981699, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.1, 'lambda2': 9.234656477234806, 'loop': 2, 'loss': 'CE', 'lr': 0.003923556905423186, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00014382208339944094, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.008863646586470996
weight_decay:  0.0001535464464536402
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9924144300166517
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 02
None time:  1.06017133500427
None Run 02:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 03
None time:  1.015782950911671
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
run time now: 3.1027400493621826
total time:  3.160629655001685
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.50 ± 0.00
[I 2023-06-11 23:27:18,310] Trial 99 finished with value: 51.40000534057617 and parameters: {'Fwd': 0.00023833067554473303, 'K': 3, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.0, 'lambda2': 9.281583423493093, 'loop': 2, 'loss': 'CE', 'lr': 0.008863646586470996, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001535464464536402, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.009458520850188681
weight_decay:  6.347611465705433e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4251872058957815
None Run 01:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 54.60
Split: 01, Run: 02
None time:  1.131641963031143
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.5017770200502127
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.80
run time now: 2.0932979583740234
total time:  2.1582739481236786
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.33 ± 10.88
  Final Train: 100.00 ± 0.00
   Final Test: 65.30 ± 9.34
[I 2023-06-11 23:27:20,905] Trial 100 finished with value: 65.33333587646484 and parameters: {'Fwd': 0.00029804176164976065, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.1, 'lambda2': 9.968869701322163, 'loop': 2, 'loss': 'CE', 'lr': 0.009458520850188681, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.347611465705433e-05, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.004156540082251711
weight_decay:  0.0001459062528010997
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1101783378981054
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.8727723020128906
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 03
None time:  0.5805906620807946
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.5961503982543945
total time:  2.649008992826566
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 1.20
  Final Train: 100.00 ± 0.00
   Final Test: 71.40 ± 0.40
[I 2023-06-11 23:27:24,006] Trial 101 finished with value: 72.79999542236328 and parameters: {'Fwd': 0.00048551358909821007, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 8.85965323429279, 'loop': 2, 'loss': 'CE', 'lr': 0.004156540082251711, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001459062528010997, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.004590985856845676
weight_decay:  4.6454613011469866e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.429540250916034
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.565560036804527
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  1.2500853000674397
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.278564691543579
total time:  3.327269553905353
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 70.27 ± 0.81
[I 2023-06-11 23:27:27,867] Trial 102 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.0004791076928836118, 'K': 3, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.05, 'lambda2': 8.87660308631272, 'loop': 2, 'loss': 'CE', 'lr': 0.004590985856845676, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.6454613011469866e-05, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.003898022739415106
weight_decay:  0.0001517007565595335
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5676161360461265
None Run 01:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 46.70
Split: 01, Run: 02
None time:  0.9269443249795586
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.6739726238884032
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.2052595615386963
total time:  2.2623487119562924
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.87 ± 13.76
  Final Train: 100.00 ± 0.00
   Final Test: 62.73 ± 13.89
[I 2023-06-11 23:27:30,577] Trial 103 finished with value: 62.866668701171875 and parameters: {'Fwd': 0.0007465135511308108, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 40, 'lambda1': 0.2, 'lambda2': 9.576883802063685, 'loop': 2, 'loss': 'CE', 'lr': 0.003898022739415106, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001517007565595335, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.00542583059800052
weight_decay:  9.871509974195297e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3767300541512668
None Run 01:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 53.40
Split: 01, Run: 02
None time:  0.7011349510867149
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.5138752690982074
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 67.90
run time now: 1.629883050918579
total time:  1.679478476056829
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.40 ± 10.39
  Final Train: 100.00 ± 0.00
   Final Test: 63.50 ± 8.77
[I 2023-06-11 23:27:32,662] Trial 104 finished with value: 65.4000015258789 and parameters: {'Fwd': 0.00040279829661722384, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.1, 'lambda2': 9.285179057215219, 'loop': 2, 'loss': 'CE', 'lr': 0.00542583059800052, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.871509974195297e-05, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.005044130595786773
weight_decay:  7.977902210548684e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4213410478550941
None Run 01:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 43.70
Split: 01, Run: 02
None time:  0.9462237309198827
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 99.17
   Final Test: 66.90
Split: 01, Run: 03
None time:  0.4703225221019238
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 1.8723728656768799
total time:  1.922636189032346
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.13 ± 13.84
  Final Train: 99.72 ± 0.48
   Final Test: 59.97 ± 14.14
[I 2023-06-11 23:27:35,064] Trial 105 finished with value: 61.133331298828125 and parameters: {'Fwd': 0.0005216905596679521, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 40, 'lambda1': 0.2, 'lambda2': 9.077251605287952, 'loop': 2, 'loss': 'CE', 'lr': 0.005044130595786773, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.977902210548684e-05, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.006255639326734491
weight_decay:  0.00012048653553617899
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1028135030064732
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 02
None time:  1.1014107880182564
None Run 02:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 03
None time:  1.0687363019678742
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
run time now: 3.3079919815063477
total time:  3.351805367041379
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.50 ± 0.00
[I 2023-06-11 23:27:38,909] Trial 106 finished with value: 51.40000534057617 and parameters: {'Fwd': 0.00015679500967069206, 'K': 3, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.0, 'lambda2': 8.886140793354805, 'loop': 2, 'loss': 'CE', 'lr': 0.006255639326734491, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012048653553617899, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.004096181923486854
weight_decay:  0.00017956354878976376
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9266918641515076
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.5990210468880832
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 03
None time:  0.5339007198344916
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.20
run time now: 2.093122959136963
total time:  2.1388838368002325
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.58
  Final Train: 99.72 ± 0.48
   Final Test: 68.03 ± 0.96
[I 2023-06-11 23:27:41,484] Trial 107 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.0006012725954006101, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.380065945768914, 'loop': 2, 'loss': 'CE', 'lr': 0.004096181923486854, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00017956354878976376, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.004313676067475021
weight_decay:  0.0004905946245603642
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6177651660982519
None Run 01:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 41.30
Split: 01, Run: 02
None time:  0.7450952520594001
None Run 02:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 38.20
Split: 01, Run: 03
None time:  0.6838789461180568
None Run 03:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 41.80
run time now: 2.0798254013061523
total time:  2.143277922878042
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 38.73 ± 3.93
  Final Train: 100.00 ± 0.00
   Final Test: 40.43 ± 1.95
[I 2023-06-11 23:27:44,014] Trial 108 finished with value: 38.733333587646484 and parameters: {'Fwd': 0.0008836329362885897, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 8.728728437677498, 'loop': 2, 'loss': 'CE', 'lr': 0.004313676067475021, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004905946245603642, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.004652164945599265
weight_decay:  0.0002647789606729579
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7978370569180697
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.5453368991147727
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 03
None time:  0.608518613036722
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 67.30
run time now: 1.9862580299377441
total time:  2.0302340369671583
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 67.93 ± 1.93
[I 2023-06-11 23:27:46,449] Trial 109 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.00030132785636398536, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 9.136939769090011, 'loop': 2, 'loss': 'CE', 'lr': 0.004652164945599265, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002647789606729579, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.006247655879070088
weight_decay:  0.0001305491641520419
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5211766781285405
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.30
Split: 01, Run: 02
None time:  0.631772531894967
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.7184024131856859
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 65.50
run time now: 2.9109878540039062
total time:  2.957954165060073
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 1.81
  Final Train: 100.00 ± 0.00
   Final Test: 67.10 ± 2.12
[I 2023-06-11 23:27:49,804] Trial 110 finished with value: 69.93333435058594 and parameters: {'Fwd': 0.000735492883685693, 'K': 1, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.15000000000000002, 'lambda2': 9.70655187007769, 'loop': 2, 'loss': 'MSE', 'lr': 0.006247655879070088, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001305491641520419, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.003811420726253579
weight_decay:  0.0002263226989107708
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.71076178108342
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 02
None time:  0.6013298500329256
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.6068499069660902
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.955483913421631
total time:  3.013355053961277
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.27 ± 0.74
[I 2023-06-11 23:27:53,281] Trial 111 finished with value: 72.0 and parameters: {'Fwd': 0.0011670770578171576, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 9.502591966960905, 'loop': 2, 'loss': 'CE', 'lr': 0.003811420726253579, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002263226989107708, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.005191659205746243
weight_decay:  0.0003523753390142191
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6413735749665648
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.6092274109832942
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.6509364179801196
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.9359960556030273
total time:  2.988306761952117
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.20
  Final Train: 99.72 ± 0.48
   Final Test: 69.77 ± 0.25
[I 2023-06-11 23:27:56,693] Trial 112 finished with value: 72.0 and parameters: {'Fwd': 0.0014265799400949232, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.524937827172673, 'loop': 2, 'loss': 'CE', 'lr': 0.005191659205746243, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003523753390142191, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.00469922913869719
weight_decay:  0.00023344368947379878
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.60012510092929
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 72.10
Split: 01, Run: 02
None time:  0.6624205831903964
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.6529675708152354
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.9498627185821533
total time:  3.0033070410136133
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 0.53
  Final Train: 99.72 ± 0.48
   Final Test: 70.70 ± 1.35
[I 2023-06-11 23:28:00,159] Trial 113 finished with value: 72.5999984741211 and parameters: {'Fwd': 0.00039786132122129734, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.972114886915678, 'loop': 2, 'loss': 'CE', 'lr': 0.00469922913869719, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00023344368947379878, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.004540488250500237
weight_decay:  0.0001562289361455688
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8930196918081492
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 02
None time:  0.7351193448994309
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  0.6893126929644495
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 65.90
run time now: 2.3542704582214355
total time:  2.402566167060286
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 66.80 ± 1.01
[I 2023-06-11 23:28:03,004] Trial 114 finished with value: 69.13333129882812 and parameters: {'Fwd': 0.00039232367216048757, 'K': 3, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.899871626777928, 'loop': 2, 'loss': 'CE', 'lr': 0.004540488250500237, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001562289361455688, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.005553919008461031
weight_decay:  9.595920794900007e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0344870218541473
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.7037034628447145
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.6386466280091554
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.4131405353546143
total time:  2.4724298771470785
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 1.22
[I 2023-06-11 23:28:06,009] Trial 115 finished with value: 73.26666259765625 and parameters: {'Fwd': 0.0005378673881342857, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 9.676837189882459, 'loop': 2, 'loss': 'CE', 'lr': 0.005553919008461031, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.595920794900007e-05, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.005215016175301338
weight_decay:  7.867915087269972e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.696346856886521
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.10
Split: 01, Run: 02
None time:  0.7063121348619461
None Run 02:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 58.20
Split: 01, Run: 03
None time:  0.568954722955823
None Run 03:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 99.17
   Final Test: 54.40
run time now: 2.006683826446533
total time:  2.0707555091939867
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.93 ± 4.50
  Final Train: 99.72 ± 0.48
   Final Test: 59.23 ± 5.42
[I 2023-06-11 23:28:08,487] Trial 116 finished with value: 59.9333381652832 and parameters: {'Fwd': 0.0005365021648711126, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 9.680033594248751, 'loop': 2, 'loss': 'CE', 'lr': 0.005215016175301338, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.867915087269972e-05, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.005920651903869521
weight_decay:  0.00010171513041676522
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1613151610363275
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.6722196519840509
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.6602817268576473
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.90
run time now: 2.5293331146240234
total time:  2.586166311055422
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 0.60
  Final Train: 99.72 ± 0.48
   Final Test: 70.20 ± 1.21
[I 2023-06-11 23:28:11,482] Trial 117 finished with value: 73.0 and parameters: {'Fwd': 0.0009248268190715669, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 9.434987397775128, 'loop': 2, 'loss': 'CE', 'lr': 0.005920651903869521, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010171513041676522, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.006898986339227934
weight_decay:  9.898624651896947e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4434430168475956
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 99.17
   Final Test: 64.90
Split: 01, Run: 02
None time:  0.9319633720442653
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.665464609162882
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.0762219429016113
total time:  3.132149034878239
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 1.63
  Final Train: 99.44 ± 0.48
   Final Test: 67.57 ± 2.31
[I 2023-06-11 23:28:15,056] Trial 118 finished with value: 68.46666717529297 and parameters: {'Fwd': 0.0009828100133968314, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 9.437899740011932, 'loop': 2, 'loss': 'CE', 'lr': 0.006898986339227934, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.898624651896947e-05, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0054715835175175274
weight_decay:  3.160959234851206e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6518444241955876
None Run 01:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 44.40
Split: 01, Run: 02
None time:  0.6456403231713921
None Run 02:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 43.20
Split: 01, Run: 03
None time:  1.0107730359304696
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 69.30
run time now: 2.3458759784698486
total time:  2.3925065950024873
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.53 ± 17.28
  Final Train: 99.72 ± 0.48
   Final Test: 52.30 ± 14.73
[I 2023-06-11 23:28:17,940] Trial 119 finished with value: 52.533329010009766 and parameters: {'Fwd': 0.0004784634985366072, 'K': 1, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 8.809074052580753, 'loop': 2, 'loss': 'CE', 'lr': 0.0054715835175175274, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.160959234851206e-05, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.005691881983373732
weight_decay:  0.0006059584296512727
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1632657567970455
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.6754749941173941
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.6394733949564397
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.520160675048828
total time:  2.5851848600432277
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.53
  Final Train: 99.72 ± 0.48
   Final Test: 69.20 ± 0.44
[I 2023-06-11 23:28:20,956] Trial 120 finished with value: 71.0 and parameters: {'Fwd': 0.00020230123155034425, 'K': 3, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 9.036632320999574, 'loop': 2, 'loss': 'CE', 'lr': 0.005691881983373732, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006059584296512727, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008033136098279112
weight_decay:  0.00018229731795714972
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8934042751789093
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 02
None time:  0.6238771739881486
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  0.7144345541018993
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.2650392055511475
total time:  2.3169421888887882
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 71.77 ± 0.68
[I 2023-06-11 23:28:23,728] Trial 121 finished with value: 74.26666259765625 and parameters: {'Fwd': 0.0006545667092239694, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.989659131204517, 'loop': 2, 'loss': 'CE', 'lr': 0.008033136098279112, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00018229731795714972, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008034543186604428
weight_decay:  0.00028191558792695326
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9862274001352489
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.7239711668808013
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.6962623971048743
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.4402194023132324
total time:  2.503096306929365
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 70.47 ± 1.02
[I 2023-06-11 23:28:26,638] Trial 122 finished with value: 72.0666732788086 and parameters: {'Fwd': 0.0006308421574108843, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.999132397997267, 'loop': 2, 'loss': 'CE', 'lr': 0.008034543186604428, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00028191558792695326, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006793848385640096
weight_decay:  0.00010323822993976055
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0823544769082218
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.6401508408598602
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.6227719001471996
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.20
run time now: 2.3780875205993652
total time:  2.428751887055114
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.59
[I 2023-06-11 23:28:29,488] Trial 123 finished with value: 73.79999542236328 and parameters: {'Fwd': 0.0008167540495326309, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.78946102316234, 'loop': 2, 'loss': 'CE', 'lr': 0.006793848385640096, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010323822993976055, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0072617922958444
weight_decay:  0.00011304306206517498
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1268365590367466
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 02
None time:  0.5849505851510912
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.6735962280072272
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.4188530445098877
total time:  2.475047369953245
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.87 ± 0.80
[I 2023-06-11 23:28:32,394] Trial 124 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.0009445044627251262, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.763723874524484, 'loop': 2, 'loss': 'CE', 'lr': 0.0072617922958444, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011304306206517498, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007008680743608692
weight_decay:  7.239306392702244e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9721067880745977
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 02
None time:  0.6088954389560968
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  0.685075992019847
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.300091028213501
total time:  2.3645649279933423
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 71.23 ± 0.42
[I 2023-06-11 23:28:35,192] Trial 125 finished with value: 73.39999389648438 and parameters: {'Fwd': 0.0014604737272200666, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.8070917116192, 'loop': 2, 'loss': 'CE', 'lr': 0.007008680743608692, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.239306392702244e-05, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.006865265387177199
weight_decay:  5.188884035732353e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8398395711556077
None Run 01:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 55.40
Split: 01, Run: 02
None time:  1.0432415180839598
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 99.17
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.6179458370897919
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.5368053913116455
total time:  2.596355063142255
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.87 ± 6.96
  Final Train: 99.72 ± 0.48
   Final Test: 64.43 ± 7.86
[I 2023-06-11 23:28:38,314] Trial 126 finished with value: 65.86666870117188 and parameters: {'Fwd': 0.0013799619209565771, 'K': 1, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.752738747620551, 'loop': 2, 'loss': 'CE', 'lr': 0.006865265387177199, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.188884035732353e-05, 'weightedloss': True}. Best is trial 91 with value: 74.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008189195938875484
weight_decay:  6.792188987087839e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9042117330245674
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 72.60
Split: 01, Run: 02
None time:  0.5346135161817074
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  0.6315726949833333
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 71.20
run time now: 2.103837490081787
total time:  2.1556369508616626
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.80 ± 0.92
  Final Train: 99.72 ± 0.48
   Final Test: 71.57 ± 0.91
[I 2023-06-11 23:28:40,923] Trial 127 finished with value: 74.79999542236328 and parameters: {'Fwd': 0.0014934669385102929, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.37019604993161, 'loop': 2, 'loss': 'CE', 'lr': 0.008189195938875484, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.792188987087839e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.008399452596965284
weight_decay:  7.124675116048066e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9818730859551579
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.10
Split: 01, Run: 02
None time:  0.6844485918991268
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 03
None time:  0.5821282770484686
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.00
run time now: 2.2831361293792725
total time:  2.3334354581311345
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.80 ± 0.72
  Final Train: 99.72 ± 0.48
   Final Test: 71.73 ± 0.55
[I 2023-06-11 23:28:43,679] Trial 128 finished with value: 73.79999542236328 and parameters: {'Fwd': 0.0023385020294807665, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.486237855373636, 'loop': 2, 'loss': 'CE', 'lr': 0.008399452596965284, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.124675116048066e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.008405934018075722
weight_decay:  7.025327267731877e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.045091147068888
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 95.83
   Final Test: 67.50
Split: 01, Run: 02
None time:  0.6528468101751059
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.6249783490784466
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 66.70
run time now: 2.3619749546051025
total time:  2.412041728850454
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.20
  Final Train: 98.33 ± 2.20
   Final Test: 67.53 ± 0.85
[I 2023-06-11 23:28:46,504] Trial 129 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.0023827976451172117, 'K': 3, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 9.589410465171914, 'loop': 2, 'loss': 'CE', 'lr': 0.008405934018075722, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.025327267731877e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.007753376632055937
weight_decay:  5.60479016614474e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8902410680893809
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 02
None time:  0.6149074309505522
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.6237712618894875
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 73.00
run time now: 2.163935899734497
total time:  2.2342151149641722
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 0.92
  Final Train: 99.72 ± 0.48
   Final Test: 71.43 ± 1.40
[I 2023-06-11 23:28:49,178] Trial 130 finished with value: 73.0 and parameters: {'Fwd': 0.0015547611812543084, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.377392576005425, 'loop': 2, 'loss': 'CE', 'lr': 0.007753376632055937, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.60479016614474e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.15000000000000002
lr:  0.00747496083324609
weight_decay:  3.785140546995484e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8120969159062952
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.6379704810678959
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.5694887831341475
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.0561296939849854
total time:  2.1115528668742627
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.73 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 70.43 ± 0.76
[I 2023-06-11 23:28:51,736] Trial 131 finished with value: 72.73332977294922 and parameters: {'Fwd': 0.0014491298076351078, 'K': 4, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.387233216414067, 'loop': 2, 'loss': 'CE', 'lr': 0.00747496083324609, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.785140546995484e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.009812337795580096
weight_decay:  6.281389414360747e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.94537508697249
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.651298132026568
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.6131798708811402
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.80
run time now: 2.2440061569213867
total time:  2.2974360920488834
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.81
  Final Train: 99.72 ± 0.48
   Final Test: 70.43 ± 1.35
[I 2023-06-11 23:28:54,505] Trial 132 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0027368101571801006, 'K': 3, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.775131710823032, 'loop': 2, 'loss': 'CE', 'lr': 0.009812337795580096, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.281389414360747e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.008067169311663694
weight_decay:  5.361327433223566e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0408497068565339
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.6349023929797113
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  0.6442367839626968
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.3658154010772705
total time:  2.4179912619292736
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.07 ± 0.92
  Final Train: 99.72 ± 0.48
   Final Test: 70.77 ± 1.12
[I 2023-06-11 23:28:57,465] Trial 133 finished with value: 73.0666732788086 and parameters: {'Fwd': 0.0020654052809511935, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.489862957110871, 'loop': 2, 'loss': 'CE', 'lr': 0.008067169311663694, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.361327433223566e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.008412996024695366
weight_decay:  9.350299159387801e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.904089936055243
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.5965425611939281
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.5502866010647267
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.90
run time now: 2.0852673053741455
total time:  2.143008128972724
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.80 ± 1.35
[I 2023-06-11 23:29:00,073] Trial 134 finished with value: 72.33333587646484 and parameters: {'Fwd': 0.001935676438109926, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.572242481044588, 'loop': 2, 'loss': 'CE', 'lr': 0.008412996024695366, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.350299159387801e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.006760042655662624
weight_decay:  7.749160659113555e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0099846459925175
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.6617691370192915
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.6456613929476589
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.352001667022705
total time:  2.398437200114131
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 0.40
  Final Train: 99.72 ± 0.48
   Final Test: 70.40 ± 0.53
[I 2023-06-11 23:29:02,931] Trial 135 finished with value: 72.19999694824219 and parameters: {'Fwd': 0.0009801299966111477, 'K': 3, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.780262521747483, 'loop': 2, 'loss': 'CE', 'lr': 0.006760042655662624, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.749160659113555e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.2
lr:  0.009075730152282252
weight_decay:  4.364112377017486e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5348146660253406
None Run 01:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 52.10
Split: 01, Run: 02
None time:  0.6277857669629157
None Run 02:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 59.60
Split: 01, Run: 03
None time:  0.6018579420633614
None Run 03:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 63.00
run time now: 1.7992568016052246
total time:  1.8524566001724452
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.80 ± 5.52
  Final Train: 100.00 ± 0.00
   Final Test: 58.23 ± 5.58
[I 2023-06-11 23:29:05,223] Trial 136 finished with value: 57.79999923706055 and parameters: {'Fwd': 0.001190460099996907, 'K': 4, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.084677703180569, 'loop': 2, 'loss': 'MSE', 'lr': 0.009075730152282252, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.364112377017486e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.007276338970120533
weight_decay:  3.2959596251882605e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5820130759384483
None Run 01:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 54.20
Split: 01, Run: 02
None time:  0.6333936110604554
None Run 02:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 57.10
Split: 01, Run: 03
None time:  0.659787226933986
None Run 03:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 99.17
   Final Test: 54.80
run time now: 1.9251439571380615
total time:  1.9812342489603907
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.07 ± 0.83
  Final Train: 99.72 ± 0.48
   Final Test: 55.37 ± 1.53
[I 2023-06-11 23:29:07,669] Trial 137 finished with value: 55.06666564941406 and parameters: {'Fwd': 0.003455107330836038, 'K': 2, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.949997292550265, 'loop': 2, 'loss': 'CE', 'lr': 0.007276338970120533, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.2959596251882605e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.008121455426875528
weight_decay:  9.393616272160482e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8424132808577269
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.5836315688211471
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.5492319709155709
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.00
run time now: 2.009136199951172
total time:  2.0605954250786453
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 1.45
  Final Train: 100.00 ± 0.00
   Final Test: 70.60 ± 1.31
[I 2023-06-11 23:29:10,198] Trial 138 finished with value: 72.86666870117188 and parameters: {'Fwd': 0.002406397511678592, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.49760573119268, 'loop': 2, 'loss': 'CE', 'lr': 0.008121455426875528, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.393616272160482e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.15000000000000002
lr:  0.006754800309193123
weight_decay:  0.00011620083871812875
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8184238569810987
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 02
None time:  0.6447294428944588
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.6756845351774246
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
run time now: 2.1825809478759766
total time:  2.2413485781289637
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 68.40 ± 0.70
[I 2023-06-11 23:29:12,863] Trial 139 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.0020841060286725236, 'K': 4, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.325220323005018, 'loop': 2, 'loss': 'CE', 'lr': 0.006754800309193123, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011620083871812875, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.00987766934055978
weight_decay:  7.244887230160917e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0412291600368917
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.640764384996146
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.5695082310121506
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.286073684692383
total time:  2.3381818050984293
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.64
  Final Train: 99.72 ± 0.48
   Final Test: 69.73 ± 0.75
[I 2023-06-11 23:29:15,688] Trial 140 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.0009329319238752591, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 9.736263822598678, 'loop': 2, 'loss': 'CE', 'lr': 0.00987766934055978, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.244887230160917e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.0077725756187498225
weight_decay:  5.489151164849115e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7247538329102099
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  0.6677791469264776
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  0.5934116248972714
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.0198464393615723
total time:  2.0607614328619093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.13 ± 1.17
  Final Train: 100.00 ± 0.00
   Final Test: 71.43 ± 0.60
[I 2023-06-11 23:29:18,323] Trial 141 finished with value: 74.13333129882812 and parameters: {'Fwd': 0.001586861228988206, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.367648796120108, 'loop': 2, 'loss': 'CE', 'lr': 0.0077725756187498225, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.489151164849115e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.008948478976570327
weight_decay:  6.163190339737444e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9195175061468035
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.641241546953097
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.6087439369875938
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.30
run time now: 2.2041144371032715
total time:  2.255582731915638
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 0.80
  Final Train: 99.72 ± 0.48
   Final Test: 70.47 ± 0.97
[I 2023-06-11 23:29:20,974] Trial 142 finished with value: 72.39999389648438 and parameters: {'Fwd': 0.001177834659975726, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.155421161716792, 'loop': 2, 'loss': 'CE', 'lr': 0.008948478976570327, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.163190339737444e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.006337656982663893
weight_decay:  4.952791880330981e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7360634841024876
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.6096787299029529
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.6065946789458394
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.00
run time now: 1.9856584072113037
total time:  2.03828386310488
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 1.01
[I 2023-06-11 23:29:23,442] Trial 143 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.0015135798882596949, 'K': 3, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.551261183431, 'loop': 2, 'loss': 'CE', 'lr': 0.006337656982663893, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.952791880330981e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.007675784572077923
weight_decay:  0.00012375333851699608
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9634907098952681
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.7483999328687787
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.5875769858248532
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.3380367755889893
total time:  2.3799048129003495
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.12
  Final Train: 99.72 ± 0.48
   Final Test: 70.13 ± 0.42
[I 2023-06-11 23:29:26,234] Trial 144 finished with value: 72.33332824707031 and parameters: {'Fwd': 0.004378729862502057, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.5, 'lambda2': 9.990836903718648, 'loop': 2, 'loss': 'CE', 'lr': 0.007675784572077923, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012375333851699608, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.008465833685624749
weight_decay:  0.0001005842857286607
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0980336838401854
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 93.33
   Final Test: 63.00
Split: 01, Run: 02
None time:  0.6073912570718676
None Run 02:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 63.40
Split: 01, Run: 03
None time:  0.7692944151349366
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 98.33
   Final Test: 66.20
run time now: 2.5176126956939697
total time:  2.566621684934944
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.13 ± 1.81
  Final Train: 97.22 ± 3.47
   Final Test: 64.20 ± 1.74
[I 2023-06-11 23:29:29,240] Trial 145 finished with value: 64.13333129882812 and parameters: {'Fwd': 0.002790972987079764, 'K': 2, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 8.996868985975228, 'loop': 2, 'loss': 'CE', 'lr': 0.008465833685624749, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001005842857286607, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.007270524265685795
weight_decay:  5.463169521302905e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9746202619280666
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 68.40
Split: 01, Run: 02
None time:  0.6626082938164473
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.6373918598983437
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.309453248977661
total time:  2.366973607102409
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 0.40
  Final Train: 99.72 ± 0.48
   Final Test: 69.63 ± 1.10
[I 2023-06-11 23:29:32,046] Trial 146 finished with value: 73.0 and parameters: {'Fwd': 0.0018548242032954125, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.291625024196525, 'loop': 2, 'loss': 'CE', 'lr': 0.007270524265685795, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.463169521302905e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.2
lr:  0.005946072307841442
weight_decay:  3.5773733355330284e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8273216770030558
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.6196689559146762
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  0.7462273568380624
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.20
run time now: 2.244748830795288
total time:  2.301222976995632
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.73 ± 1.46
[I 2023-06-11 23:29:34,759] Trial 147 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.0010209323829548514, 'K': 10, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.788377531700771, 'loop': 2, 'loss': 'CE', 'lr': 0.005946072307841442, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.5773733355330284e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0067196576569218125
weight_decay:  2.573882968567151e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0790729019790888
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.6598696389701217
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.7573077490087599
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 72.30
run time now: 2.5297834873199463
total time:  2.5845478910487145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.87
  Final Train: 99.17 ± 0.83
   Final Test: 71.27 ± 1.05
[I 2023-06-11 23:29:37,793] Trial 148 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.0006743066914691451, 'K': 2, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.582958161463361, 'loop': 2, 'loss': 'CE', 'lr': 0.0067196576569218125, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.573882968567151e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008984185806653847
weight_decay:  4.4575573105053756e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0255860299803317
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.562338741030544
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.5085951050277799
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.1321732997894287
total time:  2.186377908103168
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.87 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 70.63 ± 0.99
[I 2023-06-11 23:29:40,451] Trial 149 finished with value: 73.86666870117188 and parameters: {'Fwd': 0.0013712155954223113, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.36116330736745, 'loop': 2, 'loss': 'CE', 'lr': 0.008984185806653847, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.4575573105053756e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.008634087471877225
weight_decay:  4.788912569572385e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8759034390095621
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 65.50
Split: 01, Run: 02
None time:  0.4900532129686326
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.592688110889867
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.90
run time now: 1.9929823875427246
total time:  2.046351236058399
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 1.70
  Final Train: 100.00 ± 0.00
   Final Test: 67.47 ± 1.76
[I 2023-06-11 23:29:42,929] Trial 150 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.001413854644588089, 'K': 3, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.207412958303086, 'loop': 2, 'loss': 'CE', 'lr': 0.008634087471877225, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.788912569572385e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007980351070034353
weight_decay:  7.391165148748526e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9997933260165155
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.5308465471025556
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  0.6115015749819577
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.40
run time now: 2.1753780841827393
total time:  2.2212334300857037
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 71.90 ± 0.56
[I 2023-06-11 23:29:45,571] Trial 151 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.0007948327667099417, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.46660268876313, 'loop': 2, 'loss': 'CE', 'lr': 0.007980351070034353, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.391165148748526e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007748133829972435
weight_decay:  7.092869831692273e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9639297400135547
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.5575620541349053
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.6100630410946906
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.90
run time now: 2.169379234313965
total time:  2.2148859361186624
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 1.86
  Final Train: 100.00 ± 0.00
   Final Test: 70.73 ± 0.67
[I 2023-06-11 23:29:48,188] Trial 152 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.0006317007262337857, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.816484148767849, 'loop': 2, 'loss': 'CE', 'lr': 0.007748133829972435, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.092869831692273e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.009263681690218292
weight_decay:  8.365781042687875e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0263883019797504
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.5513180638663471
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  0.4667800741735846
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.083791971206665
total time:  2.137598439119756
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 68.87 ± 1.01
[I 2023-06-11 23:29:50,791] Trial 153 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.0007865001111101009, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.2, 'lambda2': 9.709295876831538, 'loop': 2, 'loss': 'CE', 'lr': 0.009263681690218292, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.365781042687875e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007398930276645875
weight_decay:  6.817998549872693e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9427271541208029
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.5615630089305341
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.6811219120863825
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.2200257778167725
total time:  2.280051195062697
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.25
[I 2023-06-11 23:29:53,536] Trial 154 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.0005652764863139287, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.880343997044234, 'loop': 2, 'loss': 'CE', 'lr': 0.007398930276645875, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.817998549872693e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.009859352929193767
weight_decay:  7.322501067677319e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6746571930125356
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  0.6236715649720281
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.5401726060081273
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 1.871744155883789
total time:  1.9256781300064176
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 1.29
  Final Train: 100.00 ± 0.00
   Final Test: 70.67 ± 0.47
[I 2023-06-11 23:29:55,900] Trial 155 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.0006149533313411211, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.001604194970657, 'loop': 2, 'loss': 'CE', 'lr': 0.009859352929193767, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.322501067677319e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.009640749412893078
weight_decay:  7.35164799710632e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1647481301333755
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.4764558160677552
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.45989097910933197
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.1344919204711914
total time:  2.1869862051680684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.20 ± 1.06
  Final Train: 99.72 ± 0.48
   Final Test: 70.67 ± 0.95
[I 2023-06-11 23:29:58,565] Trial 156 finished with value: 73.20000457763672 and parameters: {'Fwd': 0.001279534916909529, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 8.78238499541587, 'loop': 2, 'loss': 'CE', 'lr': 0.009640749412893078, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.35164799710632e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.008810946688772208
weight_decay:  2.806460847497178e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2625245309900492
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.727642048150301
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.6161177491303533
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.6432831287384033
total time:  2.69871971802786
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 70.30 ± 0.61
[I 2023-06-11 23:30:01,686] Trial 157 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.0006494267876521501, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 9.059042329547523, 'loop': 2, 'loss': 'CE', 'lr': 0.008810946688772208, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.806460847497178e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.00788260234795058
weight_decay:  4.2825607205704314e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0466827508062124
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 02
None time:  0.6336360019631684
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.6825219648890197
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.20
run time now: 2.397958278656006
total time:  2.455352823017165
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 68.77 ± 1.99
[I 2023-06-11 23:30:04,583] Trial 158 finished with value: 71.13333129882812 and parameters: {'Fwd': 0.0010899295005016272, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.287853990594993, 'loop': 2, 'loss': 'CE', 'lr': 0.00788260234795058, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.2825607205704314e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006584532338984005
weight_decay:  0.00012541115408706263
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9702801238745451
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.90
Split: 01, Run: 02
None time:  0.7880926239304245
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.9017789948266
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.30
run time now: 2.6929452419281006
total time:  2.748787307878956
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.93 ± 3.14
  Final Train: 100.00 ± 0.00
   Final Test: 66.00 ± 2.96
[I 2023-06-11 23:30:07,777] Trial 159 finished with value: 67.93333435058594 and parameters: {'Fwd': 0.0008396288024502035, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 8.920857150053077, 'loop': 2, 'loss': 'MSE', 'lr': 0.006584532338984005, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012541115408706263, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.009874836823826292
weight_decay:  7.732611124159541e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5738219690974802
None Run 01:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 58.40
Split: 01, Run: 02
None time:  0.5064422201830894
None Run 02:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 53.80
Split: 01, Run: 03
None time:  0.5938061140477657
None Run 03:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 99.17
   Final Test: 52.20
run time now: 1.7083747386932373
total time:  1.763960335869342
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.80 ± 3.82
  Final Train: 99.72 ± 0.48
   Final Test: 54.80 ± 3.22
[I 2023-06-11 23:30:09,967] Trial 160 finished with value: 56.80000305175781 and parameters: {'Fwd': 0.00035881125509197825, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 9.444664240796003, 'loop': 2, 'loss': 'CE', 'lr': 0.009874836823826292, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.732611124159541e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.007510679423008571
weight_decay:  9.969483527652347e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9711958130355924
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.5872136470861733
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.60
Split: 01, Run: 03
None time:  0.5259230120573193
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.1185262203216553
total time:  2.1821017239708453
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 0.42
  Final Train: 99.72 ± 0.48
   Final Test: 71.20 ± 1.45
[I 2023-06-11 23:30:12,572] Trial 161 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.0005145365759883936, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.9862794768428, 'loop': 2, 'loss': 'CE', 'lr': 0.007510679423008571, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.969483527652347e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.007388887487241585
weight_decay:  0.00011402538603339768
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0263159067835659
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.5754605380352587
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.5320950350724161
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.90
run time now: 2.1737613677978516
total time:  2.2280435629654676
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 1.56
  Final Train: 100.00 ± 0.00
   Final Test: 70.30 ± 1.83
[I 2023-06-11 23:30:15,247] Trial 162 finished with value: 72.79999542236328 and parameters: {'Fwd': 0.0006265140416515779, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.802198756740664, 'loop': 2, 'loss': 'CE', 'lr': 0.007388887487241585, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011402538603339768, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.008920340913974393
weight_decay:  4.1550550975145906e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1678457320667803
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.48008764209225774
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.49946447601541877
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 68.70
run time now: 2.1897213459014893
total time:  2.250275795115158
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.33 ± 0.76
  Final Train: 99.72 ± 0.48
   Final Test: 69.93 ± 1.37
[I 2023-06-11 23:30:17,906] Trial 163 finished with value: 73.33332824707031 and parameters: {'Fwd': 0.0004429102395232432, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 9.963860610192581, 'loop': 2, 'loss': 'CE', 'lr': 0.008920340913974393, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.1550550975145906e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.008683153046715806
weight_decay:  4.314933898686377e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1250610479619354
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.4870769858825952
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.49169319006614387
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.1382551193237305
total time:  2.1979743130505085
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.60
  Final Train: 99.72 ± 0.48
   Final Test: 70.60 ± 0.36
[I 2023-06-11 23:30:20,611] Trial 164 finished with value: 73.39999389648438 and parameters: {'Fwd': 0.0004648751826044592, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 9.984936498980385, 'loop': 2, 'loss': 'CE', 'lr': 0.008683153046715806, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.314933898686377e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008248033937193285
weight_decay:  2.4090800251588175e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2701148760970682
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 99.17
   Final Test: 71.60
Split: 01, Run: 02
None time:  0.5293922221753746
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.5092467649374157
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.348684549331665
total time:  2.4021261010784656
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 0.42
  Final Train: 99.72 ± 0.48
   Final Test: 70.33 ± 1.21
[I 2023-06-11 23:30:23,466] Trial 165 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.0003357515073516448, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 9.99565163199953, 'loop': 2, 'loss': 'CE', 'lr': 0.008248033937193285, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.4090800251588175e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9500000000000001
lr:  0.008230431019073068
weight_decay:  2.6195738532045648e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4242050140164793
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.6529776179231703
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  0.6816160511225462
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.801201581954956
total time:  2.854826381895691
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 71.23 ± 0.29
[I 2023-06-11 23:30:26,762] Trial 166 finished with value: 72.86666107177734 and parameters: {'Fwd': 0.00033370838280104135, 'K': 1, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 9.61259131970216, 'loop': 2, 'loss': 'CE', 'lr': 0.008230431019073068, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.6195738532045648e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.009973083397857609
weight_decay:  1.619071024184737e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.359329974045977
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 97.50
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.4505986701697111
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.4731280121486634
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.3161044120788574
total time:  2.380290191154927
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 0.92
  Final Train: 99.17 ± 1.44
   Final Test: 71.10 ± 0.52
[I 2023-06-11 23:30:29,595] Trial 167 finished with value: 73.0 and parameters: {'Fwd': 0.0004658828692019907, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.30000000000000004, 'lambda2': 9.977487133592682, 'loop': 2, 'loss': 'CE', 'lr': 0.009973083397857609, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.619071024184737e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.006835074532737314
weight_decay:  6.209494386043404e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0114220508839935
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 71.50
Split: 01, Run: 02
None time:  0.5523980080615729
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.5996987321414053
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 72.20
run time now: 2.2188737392425537
total time:  2.267771186074242
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.00 ± 1.51
  Final Train: 99.72 ± 0.48
   Final Test: 71.33 ± 0.96
[I 2023-06-11 23:30:32,435] Trial 168 finished with value: 74.0 and parameters: {'Fwd': 0.00025178906489327927, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 9.822402303753833, 'loop': 2, 'loss': 'CE', 'lr': 0.006835074532737314, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.209494386043404e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006931709608761954
weight_decay:  5.6049328889276116e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7121370169334114
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.5576472161337733
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.4339570140000433
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 1.7369608879089355
total time:  1.7918670331127942
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.35
  Final Train: 99.44 ± 0.48
   Final Test: 69.70 ± 0.10
[I 2023-06-11 23:30:34,673] Trial 169 finished with value: 71.0 and parameters: {'Fwd': 0.0002873614750003439, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.4, 'lambda2': 9.762793479885508, 'loop': 1, 'loss': 'CE', 'lr': 0.006931709608761954, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.6049328889276116e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.006232876576787223
weight_decay:  6.384337390310836e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5139348809607327
None Run 01:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 50.20
Split: 01, Run: 02
None time:  0.8385275090113282
None Run 02:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 97.50
   Final Test: 55.60
Split: 01, Run: 03
None time:  0.5301178491208702
None Run 03:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 59.30
run time now: 1.9167561531066895
total time:  1.9721778850071132
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.20 ± 5.57
  Final Train: 99.17 ± 1.44
   Final Test: 55.03 ± 4.58
[I 2023-06-11 23:30:37,112] Trial 170 finished with value: 58.20000076293945 and parameters: {'Fwd': 0.00026331391967350504, 'K': 2, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 9.614371374629275, 'loop': 2, 'loss': 'CE', 'lr': 0.006232876576787223, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.384337390310836e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.008012674527113035
weight_decay:  3.5217847253585004e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9783740900456905
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.5618628810625523
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.50
Split: 01, Run: 03
None time:  0.5473481209482998
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.123008966445923
total time:  2.1740214449819177
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 2.20
  Final Train: 100.00 ± 0.00
   Final Test: 71.53 ± 2.06
[I 2023-06-11 23:30:39,761] Trial 171 finished with value: 73.53333282470703 and parameters: {'Fwd': 0.0003896491739247733, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 9.845756045168077, 'loop': 2, 'loss': 'CE', 'lr': 0.008012674527113035, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.5217847253585004e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.008038190463929442
weight_decay:  3.596802836295293e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9001759341917932
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 99.17
   Final Test: 67.30
Split: 01, Run: 02
None time:  0.5772896138951182
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.5105265181045979
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.50
run time now: 2.0294177532196045
total time:  2.0818115170113742
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.87 ± 0.46
  Final Train: 99.72 ± 0.48
   Final Test: 68.03 ± 0.64
[I 2023-06-11 23:30:42,261] Trial 172 finished with value: 68.86666870117188 and parameters: {'Fwd': 0.00017193271006690937, 'K': 9, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 9.778276038215948, 'loop': 2, 'loss': 'CE', 'lr': 0.008038190463929442, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.596802836295293e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0070295461622823414
weight_decay:  1.999785000166551e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9125213648658246
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.5224319789558649
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.6191770359873772
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.086669445037842
total time:  2.135332772973925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 1.25
[I 2023-06-11 23:30:44,854] Trial 173 finished with value: 72.26666259765625 and parameters: {'Fwd': 0.00022534928737670407, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.465997243957437, 'loop': 2, 'loss': 'CE', 'lr': 0.0070295461622823414, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.999785000166551e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0076219154524036275
weight_decay:  4.701158330670879e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8573251310735941
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.4546440669801086
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.5253371919970959
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.70
run time now: 1.8699555397033691
total time:  1.9252892350777984
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 1.83
  Final Train: 100.00 ± 0.00
   Final Test: 70.37 ± 1.16
[I 2023-06-11 23:30:47,311] Trial 174 finished with value: 72.79999542236328 and parameters: {'Fwd': 0.0003804785215909861, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 9.996634143896864, 'loop': 2, 'loss': 'CE', 'lr': 0.0076219154524036275, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.701158330670879e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.006460065886779125
weight_decay:  8.106680394989331e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8318006370682269
None Run 01:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 96.67
   Final Test: 50.40
Split: 01, Run: 02
None time:  0.59754628688097
None Run 02:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 99.17
   Final Test: 65.60
Split: 01, Run: 03
None time:  0.461710604140535
None Run 03:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.00
run time now: 1.9270131587982178
total time:  1.9828747818246484
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.07 ± 5.10
  Final Train: 98.61 ± 1.73
   Final Test: 59.33 ± 7.94
[I 2023-06-11 23:30:49,755] Trial 175 finished with value: 61.06666564941406 and parameters: {'Fwd': 0.0016162560807559466, 'K': 2, 'alpha': 0.2, 'dropout': 0.30000000000000004, 'gnnepoch': 50, 'lambda1': 0.45, 'lambda2': 9.650744983637152, 'loop': 2, 'loss': 'CE', 'lr': 0.006460065886779125, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.106680394989331e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.009025732983651965
weight_decay:  3.411018960973079e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7324535038787872
None Run 01:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  1.6847216868773103
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 93.33
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.4995147059671581
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 63.50
run time now: 2.9570655822753906
total time:  3.0142330729868263
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.33 ± 10.00
  Final Train: 97.78 ± 3.85
   Final Test: 61.40 ± 9.23
[I 2023-06-11 23:30:53,199] Trial 176 finished with value: 63.33333206176758 and parameters: {'Fwd': 0.0009266069864664126, 'K': 2, 'alpha': 0.1, 'dropout': 0.2, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.182273848420854, 'loop': 2, 'loss': 'CE', 'lr': 0.009025732983651965, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.411018960973079e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008185421271825815
weight_decay:  5.8471522600496e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9573472598567605
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 67.80
Split: 01, Run: 02
None time:  0.6247906831558794
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.5453250289428979
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 68.40
run time now: 2.162207841873169
total time:  2.206568355904892
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 1.15
  Final Train: 99.72 ± 0.48
   Final Test: 68.73 ± 1.14
[I 2023-06-11 23:30:55,809] Trial 177 finished with value: 72.53333282470703 and parameters: {'Fwd': 0.0006219261410245232, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.8182083825187, 'loop': 2, 'loss': 'CE', 'lr': 0.008185421271825815, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.8471522600496e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.007222032912035744
weight_decay:  8.368783609522134e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8254345890600234
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.9272323448676616
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 03
None time:  0.5612008210737258
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.345824718475342
total time:  2.400699202902615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 0.12
  Final Train: 99.72 ± 0.48
   Final Test: 71.00 ± 0.35
[I 2023-06-11 23:30:58,670] Trial 178 finished with value: 72.86666107177734 and parameters: {'Fwd': 0.0011729624427257212, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.43460522913064, 'loop': 2, 'loss': 'CE', 'lr': 0.007222032912035744, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.368783609522134e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0061075361395688645
weight_decay:  6.857400077809816e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.322202046168968
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.6433761599473655
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.5667380790691823
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.566774368286133
total time:  2.6215818310156465
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 0.31
  Final Train: 99.72 ± 0.48
   Final Test: 70.40 ± 0.79
[I 2023-06-11 23:31:01,801] Trial 179 finished with value: 72.86666107177734 and parameters: {'Fwd': 0.00034458291753155563, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.60642391420752, 'loop': 2, 'loss': 'CE', 'lr': 0.0061075361395688645, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.857400077809816e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.006850854213239517
weight_decay:  2.796304087674268e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8331204040441662
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 99.17
   Final Test: 66.10
Split: 01, Run: 02
None time:  0.5029780578333884
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.5570888130459934
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 1.9286892414093018
total time:  1.9832115229219198
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 2.31
  Final Train: 99.72 ± 0.48
   Final Test: 68.57 ± 2.19
[I 2023-06-11 23:31:04,283] Trial 180 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.0001428300220877216, 'K': 3, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 9.301703696619727, 'loop': 2, 'loss': 'CE', 'lr': 0.006850854213239517, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.796304087674268e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.008816570904492877
weight_decay:  4.7168216843224955e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.019544143928215
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.5095456319395453
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  0.5166955359745771
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.079397439956665
total time:  2.133691444993019
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 68.43 ± 1.33
[I 2023-06-11 23:31:06,836] Trial 181 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.0004519048620766128, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 9.833770906863798, 'loop': 2, 'loss': 'CE', 'lr': 0.008816570904492877, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.7168216843224955e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.008237709314880878
weight_decay:  3.954280853111102e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1869662669487298
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.499492019880563
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  0.5116437280084938
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.231440782546997
total time:  2.28178046294488
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 1.06
[I 2023-06-11 23:31:09,533] Trial 182 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.000509768215929196, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 9.978953333574324, 'loop': 2, 'loss': 'CE', 'lr': 0.008237709314880878, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.954280853111102e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.009316226385876846
weight_decay:  5.677344754605661e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9139241590164602
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.49087410094216466
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  0.47476347093470395
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.90
run time now: 1.9130611419677734
total time:  1.95981331798248
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.13 ± 0.23
  Final Train: 99.72 ± 0.48
   Final Test: 71.40 ± 0.50
[I 2023-06-11 23:31:12,034] Trial 183 finished with value: 73.13333129882812 and parameters: {'Fwd': 0.0008402411290893471, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 9.618546380701245, 'loop': 2, 'loss': 'CE', 'lr': 0.009316226385876846, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.677344754605661e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007697617177569785
weight_decay:  4.333840028772361e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.266624943818897
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  0.639168448979035
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  0.6932205418124795
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.6330997943878174
total time:  2.687092886073515
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.07 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 71.33 ± 0.76
[I 2023-06-11 23:31:15,170] Trial 184 finished with value: 74.0666732788086 and parameters: {'Fwd': 0.0006215200768398265, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.992294686713388, 'loop': 2, 'loss': 'CE', 'lr': 0.007697617177569785, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.333840028772361e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007527080117606003
weight_decay:  0.00010049531582495653
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8918461941648275
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 02
None time:  0.6556566080544144
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.6408992069773376
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.30
run time now: 2.2225725650787354
total time:  2.2660917460452765
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 71.37 ± 0.21
[I 2023-06-11 23:31:17,890] Trial 185 finished with value: 73.73332977294922 and parameters: {'Fwd': 0.0007655959697937393, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.78910558405707, 'loop': 2, 'loss': 'CE', 'lr': 0.007527080117606003, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010049531582495653, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.007644360099488627
weight_decay:  0.00010717525594221759
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.871323494007811
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 02
None time:  0.6562136090360582
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  0.6151741079520434
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.1762261390686035
total time:  2.2312444639392197
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 1.83
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 1.89
[I 2023-06-11 23:31:20,596] Trial 186 finished with value: 71.19998931884766 and parameters: {'Fwd': 0.0005970212498398722, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.459627438248468, 'loop': 2, 'loss': 'CE', 'lr': 0.007644360099488627, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010717525594221759, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.005671270357106537
weight_decay:  0.00013995906572109726
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0512008820660412
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.5782565390691161
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 03
None time:  0.5178311599884182
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 70.90
run time now: 2.180107355117798
total time:  2.2371103290934116
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 71.17 ± 0.46
[I 2023-06-11 23:31:23,400] Trial 187 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.0007999859249076609, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.08323665110017, 'loop': 2, 'loss': 'CE', 'lr': 0.005671270357106537, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00013995906572109726, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00582317668810475
weight_decay:  0.000148376328068757
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5596890840679407
None Run 01:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 44.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0289, Train: 100.00%, Valid: 69.40% Test: 67.60%
Split: 01, Run: 02
None time:  1.7913410840556026
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.40
Split: 01, Run: 03
None time:  1.0299724559299648
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.4133479595184326
total time:  3.4717049470636994
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.87 ± 14.95
  Final Train: 100.00 ± 0.00
   Final Test: 60.27 ± 13.76
[I 2023-06-11 23:31:27,340] Trial 188 finished with value: 60.866668701171875 and parameters: {'Fwd': 0.0007781875254298748, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.1, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.690344607311193, 'loop': 2, 'loss': 'CE', 'lr': 0.00582317668810475, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000148376328068757, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.006514313798773132
weight_decay:  0.00019392754844414404
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5847630549687892
None Run 01:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 54.50
Split: 01, Run: 02
None time:  0.6011053998954594
None Run 02:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 65.00
Split: 01, Run: 03
None time:  1.4514434698503464
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.90
run time now: 2.6738967895507812
total time:  2.7214358740020543
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.53 ± 4.47
  Final Train: 100.00 ± 0.00
   Final Test: 62.13 ± 6.68
[I 2023-06-11 23:31:30,506] Trial 189 finished with value: 62.5333366394043 and parameters: {'Fwd': 0.0010898223170151843, 'K': 3, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.026179527486875, 'loop': 2, 'loss': 'MSE', 'lr': 0.006514313798773132, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019392754844414404, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.005479018004308172
weight_decay:  1.0397436649782442e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.2371546388603747
None Run 01:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 42.70
Split: 01, Run: 02
None time:  0.33444180083461106
None Run 02:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 48.70
Split: 01, Run: 03
None time:  1.071976968087256
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 70.60
run time now: 1.676666021347046
total time:  1.7264190819114447
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.20 ± 14.87
  Final Train: 99.72 ± 0.48
   Final Test: 54.00 ± 14.69
[I 2023-06-11 23:31:32,659] Trial 190 finished with value: 55.20000076293945 and parameters: {'Fwd': 0.0009340558658238759, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 10, 'lambda1': 0.2, 'lambda2': 9.248066094067555, 'loop': 2, 'loss': 'CE', 'lr': 0.005479018004308172, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0397436649782442e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007828635955889406
weight_decay:  8.88802651812138e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3144062759820372
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.90
Split: 01, Run: 02
None time:  0.670002288883552
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 03
None time:  0.7005417549517006
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 72.00
run time now: 2.719839096069336
total time:  2.7647554220166057
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.93 ± 1.01
  Final Train: 99.44 ± 0.48
   Final Test: 72.10 ± 0.26
[I 2023-06-11 23:31:35,971] Trial 191 finished with value: 73.9333267211914 and parameters: {'Fwd': 0.0006567919976473274, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.704869487143856, 'loop': 2, 'loss': 'CE', 'lr': 0.007828635955889406, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.88802651812138e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008080182196326892
weight_decay:  0.00013678222779404088
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9194358428940177
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 02
None time:  0.6339089691173285
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  0.6452011670917273
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.30
run time now: 2.2324910163879395
total time:  2.28820667299442
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 2.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 2.54
[I 2023-06-11 23:31:38,789] Trial 192 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.0006830081264874453, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.604275165438656, 'loop': 2, 'loss': 'CE', 'lr': 0.008080182196326892, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00013678222779404088, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.009256010047701758
weight_decay:  9.222612660019526e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2674818220548332
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 02
None time:  0.5653741110581905
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  0.6220277820248157
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 72.30
run time now: 2.4882216453552246
total time:  2.564540029037744
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.80 ± 1.56
  Final Train: 100.00 ± 0.00
   Final Test: 71.73 ± 0.49
[I 2023-06-11 23:31:41,908] Trial 193 finished with value: 74.79999542236328 and parameters: {'Fwd': 0.0007968830252307148, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 9.38263262659491, 'loop': 2, 'loss': 'CE', 'lr': 0.009256010047701758, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.222612660019526e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.009989622256004579
weight_decay:  8.987960295918746e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0613202578388155
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.7790509229525924
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.5494998639915138
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.4432358741760254
total time:  2.5135510149411857
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.60 ± 0.20
[I 2023-06-11 23:31:44,872] Trial 194 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.0007988016792542691, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 9.38030941709344, 'loop': 2, 'loss': 'CE', 'lr': 0.009989622256004579, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.987960295918746e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.008804677618908059
weight_decay:  0.0001347437240050648
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1607486410066485
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 99.17
   Final Test: 61.90
Split: 01, Run: 02
None time:  0.6100902000907809
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 03
None time:  0.6486586451064795
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 67.70
run time now: 2.4530866146087646
total time:  2.511249122908339
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.00 ± 2.78
  Final Train: 99.72 ± 0.48
   Final Test: 65.60 ± 3.21
[I 2023-06-11 23:31:47,844] Trial 195 finished with value: 69.0 and parameters: {'Fwd': 0.0009714217162353901, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.12679363741945, 'loop': 2, 'loss': 'CE', 'lr': 0.008804677618908059, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001347437240050648, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.00637495312320526
weight_decay:  0.00016984097137720178
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5187164549715817
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.10
Split: 01, Run: 02
None time:  0.6419396421406418
None Run 02:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 53.20
Split: 01, Run: 03
None time:  0.6383965229615569
None Run 03:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 51.90
run time now: 1.8322639465332031
total time:  1.8757362640462816
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.93 ± 3.75
  Final Train: 100.00 ± 0.00
   Final Test: 55.73 ± 5.55
[I 2023-06-11 23:31:50,137] Trial 196 finished with value: 57.93333435058594 and parameters: {'Fwd': 0.0012892948471670358, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 9.475062259863131, 'loop': 2, 'loss': 'CE', 'lr': 0.00637495312320526, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00016984097137720178, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.009096870591762382
weight_decay:  9.220220475429213e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9227436631917953
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.5603573238477111
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.5932425770442933
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.114943742752075
total time:  2.162326875841245
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.91
[I 2023-06-11 23:31:52,718] Trial 197 finished with value: 72.66666412353516 and parameters: {'Fwd': 0.000383662089023378, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 8.982921221692465, 'loop': 2, 'loss': 'CE', 'lr': 0.009096870591762382, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.220220475429213e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.007168911544847464
weight_decay:  0.001435985838293173
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.881393251940608
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.6385232741013169
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  0.6852606821339577
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.2444119453430176
total time:  2.306784096872434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.80
[I 2023-06-11 23:31:55,532] Trial 198 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0005744326667994297, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 9.245696499725403, 'loop': 2, 'loss': 'CE', 'lr': 0.007168911544847464, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001435985838293173, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008286203285835828
weight_decay:  5.627181435554038e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9709963428322226
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 02
None time:  0.6015033770818263
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.5799200569745153
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.20
run time now: 2.185727596282959
total time:  2.2307271230965853
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 71.17 ± 0.75
[I 2023-06-11 23:31:58,262] Trial 199 finished with value: 73.9333267211914 and parameters: {'Fwd': 0.0017219831028069332, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.674418029595293, 'loop': 2, 'loss': 'CE', 'lr': 0.008286203285835828, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.627181435554038e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.008223635920895284
weight_decay:  5.195588033026677e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7617709711194038
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 66.70
Split: 01, Run: 02
None time:  0.7089453511871397
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.6130450430791825
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.1169707775115967
total time:  3.1755350111052394
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 0.70
  Final Train: 98.33 ± 2.89
   Final Test: 68.40 ± 1.47
[I 2023-06-11 23:32:01,961] Trial 200 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.001714347894878089, 'K': 1, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.572589063608854, 'loop': 2, 'loss': 'CE', 'lr': 0.008223635920895284, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.195588033026677e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008411462040764
weight_decay:  6.44035777816466e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0102270438801497
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 02
None time:  0.6341429960448295
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.6737247100099921
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.10
run time now: 2.3509912490844727
total time:  2.3970208619721234
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 71.87 ± 0.25
[I 2023-06-11 23:32:04,880] Trial 201 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.0011208912077230006, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.761972685259863, 'loop': 2, 'loss': 'CE', 'lr': 0.008411462040764, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.44035777816466e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.009995114147475634
weight_decay:  0.00011030919736876341
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0507430490106344
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 99.17
   Final Test: 67.70
Split: 01, Run: 02
None time:  0.6634460559580475
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.7064469591714442
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.4541919231414795
total time:  2.503753594821319
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 2.12
  Final Train: 99.72 ± 0.48
   Final Test: 69.53 ± 1.59
[I 2023-06-11 23:32:07,858] Trial 202 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.0007518385304335367, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.672177447327329, 'loop': 2, 'loss': 'CE', 'lr': 0.009995114147475634, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011030919736876341, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.007214629739357078
weight_decay:  8.60635424172787e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3995618391782045
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.6267070129979402
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.5890323289204389
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.6500725746154785
total time:  2.7020131039898843
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.81
  Final Train: 99.72 ± 0.48
   Final Test: 69.23 ± 0.90
[I 2023-06-11 23:32:11,072] Trial 203 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.0022449200336317897, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.42042203719602, 'loop': 2, 'loss': 'CE', 'lr': 0.007214629739357078, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.60635424172787e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0058234524557653905
weight_decay:  3.515087088137162e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5779170580208302
None Run 01:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 64.80
Split: 01, Run: 02
None time:  0.8884274859447032
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.5361541381571442
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.0429906845092773
total time:  2.1017602649517357
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.27 ± 5.28
  Final Train: 100.00 ± 0.00
   Final Test: 68.33 ± 3.06
[I 2023-06-11 23:32:13,649] Trial 204 finished with value: 69.26666259765625 and parameters: {'Fwd': 0.0013507465556412608, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 9.78605408124336, 'loop': 2, 'loss': 'CE', 'lr': 0.0058234524557653905, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.515087088137162e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.007761264518525991
weight_decay:  5.31309568659212e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1769671889487654
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 68.20
Split: 01, Run: 02
None time:  0.6391612149309367
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.6360904900357127
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 2.4891960620880127
total time:  2.546211634995416
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 1.51
  Final Train: 99.72 ± 0.48
   Final Test: 69.00 ± 1.22
[I 2023-06-11 23:32:16,653] Trial 205 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0009652113907386347, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 6.181576181734474, 'loop': 2, 'loss': 'CE', 'lr': 0.007761264518525991, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.31309568659212e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.00908831537146625
weight_decay:  6.884371811181069e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8884944301098585
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.6404778419528157
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.6086468920111656
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.40
run time now: 2.1715800762176514
total time:  2.225306770997122
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 1.17
  Final Train: 100.00 ± 0.00
   Final Test: 70.67 ± 1.66
[I 2023-06-11 23:32:19,358] Trial 206 finished with value: 72.0666732788086 and parameters: {'Fwd': 0.0017400286697801467, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.208319199773248, 'loop': 2, 'loss': 'CE', 'lr': 0.00908831537146625, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.884371811181069e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.005156091652102976
weight_decay:  0.000743967302232648
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.165536036947742
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.6453454240690917
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.6677998621016741
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.90
run time now: 2.5119469165802
total time:  2.5628634358290583
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.95
  Final Train: 99.72 ± 0.48
   Final Test: 70.07 ± 0.47
[I 2023-06-11 23:32:22,339] Trial 207 finished with value: 72.33333587646484 and parameters: {'Fwd': 0.0032882355174507763, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 9.533162403756032, 'loop': 2, 'loss': 'CE', 'lr': 0.005156091652102976, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000743967302232648, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006944778433612006
weight_decay:  0.0002186634760892357
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1207159969490021
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 02
None time:  0.5503272209316492
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.6708260709419847
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 72.70
run time now: 2.3755481243133545
total time:  2.431151033146307
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.27 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 70.97 ± 2.34
[I 2023-06-11 23:32:25,222] Trial 208 finished with value: 74.26666259765625 and parameters: {'Fwd': 0.0007843325612889435, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 8.956686664487352, 'loop': 2, 'loss': 'CE', 'lr': 0.006944778433612006, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002186634760892357, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.006723491496125284
weight_decay:  0.00021696659895344424
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5012, Train: 99.17%, Valid: 70.40% Test: 68.70%
Split: 01, Run: 01
None time:  1.828922110144049
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 68.80
Split: 01, Run: 02
None time:  0.584729541791603
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  0.5552398890722543
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 71.20
run time now: 3.0019545555114746
total time:  3.0571023300290108
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.40
  Final Train: 99.72 ± 0.48
   Final Test: 70.37 ± 1.36
[I 2023-06-11 23:32:28,727] Trial 209 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.0005472716093219747, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.615780314153776, 'loop': 2, 'loss': 'CE', 'lr': 0.006723491496125284, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00021696659895344424, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.00812603415880337
weight_decay:  0.0003330094068946542
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.433065177872777
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 52.10
Split: 01, Run: 02
None time:  1.083387935999781
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.4584004480857402
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.009178876876831
total time:  2.0550853891763836
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.53 ± 11.38
  Final Train: 99.72 ± 0.48
   Final Test: 64.43 ± 10.68
[I 2023-06-11 23:32:31,274] Trial 210 finished with value: 64.53333282470703 and parameters: {'Fwd': 0.0007785825669346077, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.2, 'lambda2': 8.843454459592916, 'loop': 2, 'loss': 'CE', 'lr': 0.00812603415880337, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003330094068946542, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.007227748850181648
weight_decay:  0.00012961544027366952
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.042285901028663
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 02
None time:  0.601170726120472
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.6386803078930825
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.20
run time now: 2.3160181045532227
total time:  2.3616178969386965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.87 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 71.17 ± 1.15
[I 2023-06-11 23:32:34,038] Trial 211 finished with value: 73.86666870117188 and parameters: {'Fwd': 0.0010981509363033875, 'K': 2, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.0432475634358, 'loop': 2, 'loss': 'CE', 'lr': 0.007227748850181648, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012961544027366952, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006277808410182734
weight_decay:  0.0001949353902120486
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1457466559950262
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.6216260760556906
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.6728268670849502
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.90
run time now: 2.475109338760376
total time:  2.5319326519966125
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 70.33 ± 1.40
[I 2023-06-11 23:32:37,122] Trial 212 finished with value: 72.86666107177734 and parameters: {'Fwd': 0.0012057262394289962, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.009030742416012, 'loop': 2, 'loss': 'CE', 'lr': 0.006277808410182734, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001949353902120486, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008703123252895836
weight_decay:  0.00015418918700959308
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5391283701173961
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.4674112251959741
None Run 02:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 61.70
Split: 01, Run: 03
None time:  0.5097132939845324
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 60.80
run time now: 1.549293041229248
total time:  1.611475721001625
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.73 ± 3.00
  Final Train: 100.00 ± 0.00
   Final Test: 63.80 ± 4.44
[I 2023-06-11 23:32:39,190] Trial 213 finished with value: 67.73333740234375 and parameters: {'Fwd': 0.000737229601006373, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 7.181186643454895, 'loop': 0, 'loss': 'CE', 'lr': 0.008703123252895836, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00015418918700959308, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.007624616700505234
weight_decay:  0.0010425892833740157
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7765144971199334
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.6957914722152054
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.668605487793684
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 72.10
run time now: 2.1742632389068604
total time:  2.2263882500119507
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 1.60
  Final Train: 100.00 ± 0.00
   Final Test: 71.13 ± 0.91
[I 2023-06-11 23:32:41,859] Trial 214 finished with value: 72.9333267211914 and parameters: {'Fwd': 0.0005822904718579616, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.155657776535733, 'loop': 2, 'loss': 'CE', 'lr': 0.007624616700505234, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0010425892833740157, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006726658345843486
weight_decay:  0.000275295357184808
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.350300919963047
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 99.17
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.7098344638943672
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.6422808167990297
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.10
run time now: 2.735647201538086
total time:  2.7890726500190794
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.33 ± 0.81
  Final Train: 99.72 ± 0.48
   Final Test: 71.13 ± 0.87
[I 2023-06-11 23:32:45,142] Trial 215 finished with value: 73.33332824707031 and parameters: {'Fwd': 0.000307856029405107, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 7.445852303299282, 'loop': 2, 'loss': 'CE', 'lr': 0.006726658345843486, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000275295357184808, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009291166089999057
weight_decay:  0.0004266783924652538
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1822899389080703
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.613856018986553
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.5270942389033735
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.357851505279541
total time:  2.4035116098821163
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 71.13 ± 0.90
[I 2023-06-11 23:32:48,079] Trial 216 finished with value: 72.86666107177734 and parameters: {'Fwd': 0.00140531745077067, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.738796214578263, 'loop': 2, 'loss': 'CE', 'lr': 0.009291166089999057, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004266783924652538, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.005640147279583425
weight_decay:  4.3124356618768305e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0057378390338272
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 71.90
Split: 01, Run: 02
None time:  0.594599325908348
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 03
None time:  0.5836804769933224
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.219351053237915
total time:  2.276489427080378
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 0.87
  Final Train: 99.72 ± 0.48
   Final Test: 71.70 ± 0.53
[I 2023-06-11 23:32:50,804] Trial 217 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.00043877362745664734, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.346836107160737, 'loop': 2, 'loss': 'CE', 'lr': 0.005640147279583425, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.3124356618768305e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.005897472640915811
weight_decay:  0.00012829820510063968
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9471256528049707
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 71.50
Split: 01, Run: 02
None time:  0.6203256631270051
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.6681382260285318
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.2681877613067627
total time:  2.3246246848721057
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 0.87
  Final Train: 99.72 ± 0.48
   Final Test: 70.40 ± 1.01
[I 2023-06-11 23:32:53,556] Trial 218 finished with value: 72.4000015258789 and parameters: {'Fwd': 0.00105110454569088, 'K': 2, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.324010937237366, 'loop': 2, 'loss': 'CE', 'lr': 0.005897472640915811, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012829820510063968, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.45
lr:  0.00281886236625193
weight_decay:  8.127137797638297e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7466851309873164
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 54.10
Split: 01, Run: 02
None time:  0.9756629390176386
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 99.17
   Final Test: 67.00
Split: 01, Run: 03
None time:  0.687311609974131
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.4424774646759033
total time:  2.4949666201137006
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.27 ± 5.74
  Final Train: 99.72 ± 0.48
   Final Test: 63.93 ± 8.71
[I 2023-06-11 23:32:56,515] Trial 219 finished with value: 66.26666259765625 and parameters: {'Fwd': 0.002655985788451076, 'K': 2, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 8.874902277241935, 'loop': 2, 'loss': 'CE', 'lr': 0.00281886236625193, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.127137797638297e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.005315043341211991
weight_decay:  4.6922786838646405e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2837902021128684
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.6412432710640132
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.6375906309112906
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.70
run time now: 2.596989393234253
total time:  2.644078708952293
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 70.93 ± 1.53
[I 2023-06-11 23:32:59,703] Trial 220 finished with value: 73.4000015258789 and parameters: {'Fwd': 0.0008482519605745575, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.091008997016429, 'loop': 2, 'loss': 'CE', 'lr': 0.005315043341211991, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.6922786838646405e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.002278585718056533
weight_decay:  4.176795619040041e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0560189930256456
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 96.67
   Final Test: 65.50
Split: 01, Run: 02
None time:  0.8833863171748817
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 99.17
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.6870045268442482
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.00
run time now: 2.6604745388031006
total time:  2.7134618188720196
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.33 ± 1.81
  Final Train: 98.61 ± 1.73
   Final Test: 66.97 ± 1.45
[I 2023-06-11 23:33:02,900] Trial 221 finished with value: 67.33333587646484 and parameters: {'Fwd': 0.0004251567990686558, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 7.9866701916911, 'loop': 2, 'loss': 'CE', 'lr': 0.002278585718056533, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.176795619040041e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007224180795651558
weight_decay:  3.307424138052065e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8713798969984055
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02
None time:  0.6316546539310366
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.5778906231280416
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.80
run time now: 2.1136677265167236
total time:  2.176235791062936
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 2.08
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 1.63
[I 2023-06-11 23:33:05,580] Trial 222 finished with value: 72.99999237060547 and parameters: {'Fwd': 0.00043040292252009924, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.41449133730889, 'loop': 2, 'loss': 'CE', 'lr': 0.007224180795651558, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.307424138052065e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.007887911647627718
weight_decay:  5.18106408090842e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0794487970415503
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.5617641641292721
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.5433110028970987
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.30
run time now: 2.2184369564056396
total time:  2.2738753180019557
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.93 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 71.30 ± 0.10
[I 2023-06-11 23:33:08,305] Trial 223 finished with value: 73.9333267211914 and parameters: {'Fwd': 0.0006031084138702946, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.627362728415017, 'loop': 2, 'loss': 'CE', 'lr': 0.007887911647627718, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.18106408090842e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.0031314148178776514
weight_decay:  6.242531699233306e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9118302329443395
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.60
Split: 01, Run: 02
None time:  0.6132850570138544
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.9387648259289563
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 98.33
   Final Test: 70.70
run time now: 2.5059216022491455
total time:  2.562527362955734
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 0.64
  Final Train: 99.44 ± 0.96
   Final Test: 71.03 ± 1.43
[I 2023-06-11 23:33:11,315] Trial 224 finished with value: 72.26667022705078 and parameters: {'Fwd': 0.000695180875080389, 'K': 8, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.59991700404722, 'loop': 2, 'loss': 'CE', 'lr': 0.0031314148178776514, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.242531699233306e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0020695006653529656
weight_decay:  6.164182528050796e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7721785949543118
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 02
None time:  0.9620599788613617
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.5941637279465795
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.3628010749816895
total time:  2.4142157181631774
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 1.33
  Final Train: 99.72 ± 0.48
   Final Test: 69.37 ± 1.56
[I 2023-06-11 23:33:14,269] Trial 225 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.0006110735845079655, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 8.532665547524946, 'loop': 2, 'loss': 'CE', 'lr': 0.0020695006653529656, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.164182528050796e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.006226735479631811
weight_decay:  9.727812985401117e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7497515871655196
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 02
None time:  0.577596354065463
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.5816567379515618
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.70
run time now: 1.9498672485351562
total time:  2.017329749884084
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 2.16
  Final Train: 100.00 ± 0.00
   Final Test: 68.23 ± 1.36
[I 2023-06-11 23:33:16,815] Trial 226 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.0019897772014670924, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.333536275573058, 'loop': 2, 'loss': 'CE', 'lr': 0.006226735479631811, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.727812985401117e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.30000000000000004
lr:  0.004831600143785622
weight_decay:  7.857807021132313e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6855434370227158
None Run 01:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 60.00
Split: 01, Run: 02
None time:  0.6927086550276726
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.6066498418804258
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.10
run time now: 2.026914358139038
total time:  2.077821027021855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.93 ± 4.46
  Final Train: 100.00 ± 0.00
   Final Test: 65.93 ± 5.14
[I 2023-06-11 23:33:19,308] Trial 227 finished with value: 65.93333435058594 and parameters: {'Fwd': 0.000889232391096671, 'K': 4, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.610527723667323, 'loop': 2, 'loss': 'MSE', 'lr': 0.004831600143785622, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.857807021132313e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008561102498033173
weight_decay:  5.191481471230121e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0283321689348668
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.5743502981495112
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.57337881391868
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 2.2113025188446045
total time:  2.2708454120438546
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 70.67 ± 0.64
[I 2023-06-11 23:33:22,034] Trial 228 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.0005922550750267088, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.15000000000000002, 'lambda2': 9.180896649318587, 'loop': 2, 'loss': 'CE', 'lr': 0.008561102498033173, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.191481471230121e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.006739442217147409
weight_decay:  0.00019900894627076886
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5954112680628896
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 02
None time:  0.5816082789096981
None Run 02:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 60.40
Split: 01, Run: 03
None time:  0.5845172391273081
None Run 03:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 99.17
   Final Test: 59.70
run time now: 1.7951226234436035
total time:  1.847954822005704
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.73 ± 3.25
  Final Train: 99.72 ± 0.48
   Final Test: 61.90 ± 3.22
[I 2023-06-11 23:33:24,389] Trial 229 finished with value: 60.733333587646484 and parameters: {'Fwd': 1.5732579900464444e-06, 'K': 3, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 5.3936102656958855, 'loop': 2, 'loss': 'CE', 'lr': 0.006739442217147409, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00019900894627076886, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.007512988772293939
weight_decay:  2.240323287357019e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9727063199970871
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.6203019309323281
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.6254492260050029
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.2529144287109375
total time:  2.3078447689767927
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.07 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 70.40 ± 0.61
[I 2023-06-11 23:33:27,157] Trial 230 finished with value: 73.06666564941406 and parameters: {'Fwd': 0.0011006240570911366, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.460866734165542, 'loop': 2, 'loss': 'CE', 'lr': 0.007512988772293939, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.240323287357019e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008045075426878604
weight_decay:  2.9010766021733636e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.925270871957764
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.6096274750307202
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.6176383278798312
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.185248374938965
total time:  2.237695674877614
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 1.39
[I 2023-06-11 23:33:29,850] Trial 231 finished with value: 72.86666870117188 and parameters: {'Fwd': 0.000253883767492817, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.814156812016801, 'loop': 2, 'loss': 'CE', 'lr': 0.008045075426878604, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.9010766021733636e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.007929349221529599
weight_decay:  0.00011163489575382698
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.844600569922477
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.7239104988984764
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.5984811121597886
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.20633602142334
total time:  2.2668432099744678
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.70
[I 2023-06-11 23:33:32,539] Trial 232 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.0003909899932715413, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.9790989367798, 'loop': 2, 'loss': 'CE', 'lr': 0.007929349221529599, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011163489575382698, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.45
lr:  0.009113617650790606
weight_decay:  0.002623834352420541
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0798770310357213
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.5552052401471883
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.5697739759925753
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.238245725631714
total time:  2.2951182541437447
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.72
  Final Train: 99.72 ± 0.48
   Final Test: 70.17 ± 0.23
[I 2023-06-11 23:33:35,296] Trial 233 finished with value: 72.0 and parameters: {'Fwd': 0.0005136125945216099, 'K': 2, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.733577847102898, 'loop': 2, 'loss': 'CE', 'lr': 0.009113617650790606, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002623834352420541, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007077903787861557
weight_decay:  4.155972789914658e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7914151391014457
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.6101323880720884
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.5957097781356424
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.031590461730957
total time:  2.0933426569681615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.13 ± 0.46
  Final Train: 99.72 ± 0.48
   Final Test: 69.90 ± 1.56
[I 2023-06-11 23:33:37,821] Trial 234 finished with value: 73.13333129882812 and parameters: {'Fwd': 0.0003156282776698477, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.55, 'lambda2': 9.64729105633519, 'loop': 2, 'loss': 'CE', 'lr': 0.007077903787861557, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.155972789914658e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008446721766091767
weight_decay:  0.002103724983771361
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9007962651085109
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 61.00
Split: 01, Run: 02
None time:  0.6116233298089355
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.5664732730947435
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.90
run time now: 2.1173977851867676
total time:  2.1737859260756522
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.53 ± 2.42
  Final Train: 100.00 ± 0.00
   Final Test: 65.63 ± 4.01
[I 2023-06-11 23:33:40,451] Trial 235 finished with value: 67.53333282470703 and parameters: {'Fwd': 0.0007020773756043461, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 9.373925296819309, 'loop': 2, 'loss': 'CE', 'lr': 0.008446721766091767, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002103724983771361, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.005749469268180762
weight_decay:  3.890592392800057e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0411442129407078
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 99.17
   Final Test: 66.70
Split: 01, Run: 02
None time:  0.6557712380308658
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.30
Split: 01, Run: 03
None time:  0.6470033680088818
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.379114866256714
total time:  2.434379216050729
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.00 ± 0.69
  Final Train: 99.72 ± 0.48
   Final Test: 67.43 ± 1.63
[I 2023-06-11 23:33:43,382] Trial 236 finished with value: 69.0 and parameters: {'Fwd': 0.0004578219792725463, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 9.987491830061627, 'loop': 2, 'loss': 'CE', 'lr': 0.005749469268180762, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.890592392800057e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0007902298504783742
weight_decay:  6.741058572456728e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1497646991629153
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.570356658892706
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.5770829489920288
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.3314356803894043
total time:  2.3866695140022784
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 1.25
[I 2023-06-11 23:33:46,240] Trial 237 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.0016342668869661172, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 9.836932405949455, 'loop': 2, 'loss': 'CE', 'lr': 0.0007902298504783742, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.741058572456728e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.009994970757679788
weight_decay:  2.346805305588229e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.216848996002227
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 71.60
Split: 01, Run: 02
None time:  0.5478111389093101
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  0.6137893700506538
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.4098310470581055
total time:  2.4628009339794517
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.20 ± 0.40
  Final Train: 99.72 ± 0.48
   Final Test: 70.10 ± 1.95
[I 2023-06-11 23:33:49,140] Trial 238 finished with value: 74.20000457763672 and parameters: {'Fwd': 0.0008480487953175536, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.012049246974536, 'loop': 2, 'loss': 'CE', 'lr': 0.009994970757679788, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.346805305588229e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.009309220987304398
weight_decay:  2.6528745322534465e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.281714387005195
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 98.33
   Final Test: 72.20
Split: 01, Run: 02
None time:  0.6434697408694774
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  0.6053881330881268
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.5641419887542725
total time:  2.626588071929291
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.20 ± 0.40
  Final Train: 99.44 ± 0.96
   Final Test: 71.10 ± 1.35
[I 2023-06-11 23:33:52,290] Trial 239 finished with value: 74.19999694824219 and parameters: {'Fwd': 1.9200658075120468e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 8.874633082926815, 'loop': 2, 'loss': 'CE', 'lr': 0.009309220987304398, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.6528745322534465e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.009744183487701308
weight_decay:  2.153997148157353e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2162801071535796
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.6205109900329262
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.5163822430185974
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 66.30
run time now: 2.3858673572540283
total time:  2.453793043969199
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 0.42
  Final Train: 99.72 ± 0.48
   Final Test: 68.10 ± 1.75
[I 2023-06-11 23:33:55,197] Trial 240 finished with value: 72.9333267211914 and parameters: {'Fwd': 7.843479822441625e-05, 'K': 1, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 8.951792832634228, 'loop': 2, 'loss': 'CE', 'lr': 0.009744183487701308, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.153997148157353e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.008624082541165859
weight_decay:  2.7203510769927398e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1198165048845112
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.508389632217586
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.5080736309755594
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.168333053588867
total time:  2.235677155898884
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 1.06
  Final Train: 99.72 ± 0.48
   Final Test: 69.43 ± 0.67
[I 2023-06-11 23:33:57,830] Trial 241 finished with value: 72.99999237060547 and parameters: {'Fwd': 1.591042619929271e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 8.80549750566638, 'loop': 2, 'loss': 'CE', 'lr': 0.008624082541165859, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.7203510769927398e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.009232388126542477
weight_decay:  2.2301894930889674e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2749938201159239
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.6131685948930681
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.5903489848133177
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 2.512699842453003
total time:  2.569766730070114
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.31
  Final Train: 99.72 ± 0.48
   Final Test: 69.33 ± 0.15
[I 2023-06-11 23:34:00,833] Trial 242 finished with value: 72.33333587646484 and parameters: {'Fwd': 0.005582525115610928, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 9.143919089517786, 'loop': 2, 'loss': 'CE', 'lr': 0.009232388126542477, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2301894930889674e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.009867877385548467
weight_decay:  1.7480625097740072e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2743192161433399
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.520311295054853
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  0.5523435899522156
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.3863677978515625
total time:  2.4370337820146233
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 0.90
  Final Train: 99.72 ± 0.48
   Final Test: 69.13 ± 0.96
[I 2023-06-11 23:34:03,731] Trial 243 finished with value: 73.53333282470703 and parameters: {'Fwd': 0.0008785725640517553, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 8.46730829469535, 'loop': 2, 'loss': 'CE', 'lr': 0.009867877385548467, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7480625097740072e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.007365990425980225
weight_decay:  1.2814989098297948e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5936, Train: 99.17%, Valid: 73.20% Test: 70.70%
Split: 01, Run: 01
None time:  1.1222634450532496
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 99.17
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.48409442394040525
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.42104160296730697
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.0600006580352783
total time:  2.11049298197031
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.07 ± 0.76
  Final Train: 99.72 ± 0.48
   Final Test: 70.83 ± 0.71
[I 2023-06-11 23:34:06,262] Trial 244 finished with value: 74.0666732788086 and parameters: {'Fwd': 0.0012460515828078176, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 8.974734312985438, 'loop': 1, 'loss': 'CE', 'lr': 0.007365990425980225, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2814989098297948e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.00745589511867014
weight_decay:  1.6484892062468744e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7014975091442466
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.604066075058654
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.49067985406145453
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.90
run time now: 1.8288111686706543
total time:  1.8796219599898905
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 1.40
  Final Train: 99.72 ± 0.48
   Final Test: 70.97 ± 0.81
[I 2023-06-11 23:34:08,599] Trial 245 finished with value: 73.4000015258789 and parameters: {'Fwd': 4.248519806695198e-06, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 8.976732537239482, 'loop': 1, 'loss': 'CE', 'lr': 0.00745589511867014, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6484892062468744e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.008460669325483445
weight_decay:  5.284711086458919e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0375376348383725
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.5127012499142438
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  0.5338658359833062
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 67.70
run time now: 2.116605520248413
total time:  2.1712148329243064
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 2.04
  Final Train: 99.72 ± 0.48
   Final Test: 69.50 ± 2.16
[I 2023-06-11 23:34:11,219] Trial 246 finished with value: 72.33332824707031 and parameters: {'Fwd': 0.0012464704222699436, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 8.625826707821647, 'loop': 1, 'loss': 'CE', 'lr': 0.008460669325483445, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.284711086458919e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00677504742234402
weight_decay:  2.6603158305870527e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5787, Train: 99.17%, Valid: 72.20% Test: 69.70%
Split: 01, Run: 01
None time:  1.2113608880899847
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.49232604703865945
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.505130599020049
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.10
run time now: 2.2407407760620117
total time:  2.29184254584834
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.58
  Final Train: 99.72 ± 0.48
   Final Test: 69.73 ± 0.85
[I 2023-06-11 23:34:13,941] Trial 247 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.001588650885972934, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.244343328868323, 'loop': 1, 'loss': 'CE', 'lr': 0.00677504742234402, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.6603158305870527e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.007686071480281946
weight_decay:  1.2569683388968898e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.006964032072574
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.6670255230274051
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.6427185118664056
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.80
run time now: 2.348618745803833
total time:  2.406606830190867
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 70.83 ± 0.95
[I 2023-06-11 23:34:16,778] Trial 248 finished with value: 72.9333267211914 and parameters: {'Fwd': 0.0010826913011920672, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 5.079957421165055, 'loop': 2, 'loss': 'CE', 'lr': 0.007686071480281946, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2569683388968898e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.5
lr:  0.009189269257416626
weight_decay:  1.2764268987773919e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.49539254885166883
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 02
None time:  0.47577704302966595
None Run 02:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.10
Split: 01, Run: 03
None time:  0.4589090929366648
None Run 03:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 99.17
   Final Test: 59.80
run time now: 1.4619736671447754
total time:  1.5168722621165216
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.33 ± 4.02
  Final Train: 99.72 ± 0.48
   Final Test: 62.17 ± 4.72
[I 2023-06-11 23:34:18,739] Trial 249 finished with value: 64.33333587646484 and parameters: {'Fwd': 0.000802696493039398, 'K': 1, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 9.021849063926068, 'loop': 0, 'loss': 'CE', 'lr': 0.009189269257416626, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2764268987773919e-05, 'weightedloss': True}. Best is trial 127 with value: 74.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.008250438162443764
weight_decay:  8.026483610020513e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0588189370464534
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 72.50
Split: 01, Run: 02
None time:  0.6087888930924237
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.621976608177647
None Run 03:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.323453903198242
total time:  2.379786480916664
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.93 ± 1.03
  Final Train: 99.72 ± 0.48
   Final Test: 70.63 ± 1.62
[I 2023-06-11 23:34:21,575] Trial 250 finished with value: 74.93333435058594 and parameters: {'Fwd': 5.404972860114749e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.826124275463265, 'loop': 2, 'loss': 'CE', 'lr': 0.008250438162443764, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.026483610020513e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00840029708375673
weight_decay:  9.249360789988047e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0442758749704808
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.6045377447735518
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 65.90
Split: 01, Run: 03
None time:  0.5973378052003682
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.282623291015625
total time:  2.334345320938155
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 68.70 ± 2.46
[I 2023-06-11 23:34:24,381] Trial 251 finished with value: 73.46666717529297 and parameters: {'Fwd': 2.5757642144320293e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 8.703486492347128, 'loop': 2, 'loss': 'CE', 'lr': 0.00840029708375673, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.249360789988047e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00989333573229119
weight_decay:  0.00014968974953250824
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.08391691185534
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.6106756939552724
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.7384110330604017
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.4658195972442627
total time:  2.5275258680339903
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 0.50
  Final Train: 99.72 ± 0.48
   Final Test: 70.13 ± 1.01
[I 2023-06-11 23:34:27,349] Trial 252 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.00012300665614177293, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.867336892633933, 'loop': 2, 'loss': 'CE', 'lr': 0.00989333573229119, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00014968974953250824, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.00733179073663718
weight_decay:  8.234925045605437e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9234304500278085
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 02
None time:  0.9072384049650282
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.5644089840352535
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.427255392074585
total time:  2.4813970089890063
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 1.31
  Final Train: 100.00 ± 0.00
   Final Test: 68.63 ± 2.00
[I 2023-06-11 23:34:30,297] Trial 253 finished with value: 71.20000457763672 and parameters: {'Fwd': 4.6887461974089625e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 8.276132416862351, 'loop': 2, 'loss': 'CE', 'lr': 0.00733179073663718, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.234925045605437e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00794307561007885
weight_decay:  0.00011727049250817722
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6466922489926219
None Run 01:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 47.70
Split: 01, Run: 02
None time:  1.045852130977437
None Run 02:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 80.83
   Final Test: 56.80
Split: 01, Run: 03
None time:  1.101209837011993
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 87.50
   Final Test: 64.70
run time now: 2.827749490737915
total time:  2.881704363040626
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.33 ± 8.80
  Final Train: 89.44 ± 9.73
   Final Test: 56.40 ± 8.51
[I 2023-06-11 23:34:33,694] Trial 254 finished with value: 57.33333206176758 and parameters: {'Fwd': 0.0013533175558718986, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.0, 'gnnepoch': 80, 'lambda1': 0.45, 'lambda2': 4.3277819740425185, 'loop': 2, 'loss': 'CE', 'lr': 0.00794307561007885, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011727049250817722, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.009044559995484872
weight_decay:  1.0026261155598332e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0548699591308832
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 02
None time:  0.5668437730055302
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  0.5614807019010186
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 62.50
run time now: 2.2157368659973145
total time:  2.2706745518371463
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 1.53
  Final Train: 100.00 ± 0.00
   Final Test: 65.03 ± 2.25
[I 2023-06-11 23:34:36,372] Trial 255 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.0009794069908945244, 'K': 1, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.99903062853461, 'loop': 1, 'loss': 'CE', 'lr': 0.009044559995484872, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0026261155598332e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.006567543843011452
weight_decay:  7.07390778874977e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3890382999088615
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.6310799620114267
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.6695744700264186
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 69.00
run time now: 2.722166061401367
total time:  2.7752268260810524
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.60
  Final Train: 99.72 ± 0.48
   Final Test: 70.00 ± 0.95
[I 2023-06-11 23:34:39,613] Trial 256 finished with value: 73.4000015258789 and parameters: {'Fwd': 0.0007303635992731191, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.184030135583301, 'loop': 2, 'loss': 'CE', 'lr': 0.006567543843011452, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.07390778874977e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.008437717470020123
weight_decay:  5.643768644386831e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0752003090456128
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 92.50
   Final Test: 72.30
Split: 01, Run: 02
None time:  0.5626056070905179
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.4763119649142027
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.10
run time now: 2.1517508029937744
total time:  2.205161828082055
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.47 ± 0.31
  Final Train: 97.50 ± 4.33
   Final Test: 70.67 ± 1.60
[I 2023-06-11 23:34:42,289] Trial 257 finished with value: 74.46666717529297 and parameters: {'Fwd': 0.0011959625139789291, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 0.6843553470272257, 'loop': 2, 'loss': 'CE', 'lr': 0.008437717470020123, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.643768644386831e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.008553752052762697
weight_decay:  5.643950231784706e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6097348830662668
None Run 01:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 49.90
Split: 01, Run: 02
None time:  0.9039024689700454
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.9727284288965166
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.40
run time now: 2.5292482376098633
total time:  2.5752386150415987
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.33 ± 8.51
  Final Train: 100.00 ± 0.00
   Final Test: 62.10 ± 10.57
[I 2023-06-11 23:34:45,410] Trial 258 finished with value: 61.33333206176758 and parameters: {'Fwd': 0.002144506738636976, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 7.934375567860387, 'loop': 2, 'loss': 'MSE', 'lr': 0.008553752052762697, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.643950231784706e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.007656684147398313
weight_decay:  7.164728827741332e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4455227709840983
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.5957964109256864
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.6228262321092188
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.6973414421081543
total time:  2.746400748146698
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.53 ± 0.51
[I 2023-06-11 23:34:48,600] Trial 259 finished with value: 73.9333267211914 and parameters: {'Fwd': 0.0012851600360035726, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.40612757537178, 'loop': 2, 'loss': 'CE', 'lr': 0.007656684147398313, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.164728827741332e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.009988613189723926
weight_decay:  6.89039413733526e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9966298788785934
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 71.50
Split: 01, Run: 02
None time:  0.6287726480513811
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  0.5282031779643148
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.186711311340332
total time:  2.246889118803665
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.67 ± 0.23
  Final Train: 99.72 ± 0.48
   Final Test: 70.87 ± 0.78
[I 2023-06-11 23:34:51,377] Trial 260 finished with value: 72.66665649414062 and parameters: {'Fwd': 0.001551019774538694, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 7.82675175140688, 'loop': 2, 'loss': 'CE', 'lr': 0.009988613189723926, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.89039413733526e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00729266379358692
weight_decay:  9.107753220993131e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.46787317586131394
None Run 01:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 49.90
Split: 01, Run: 02
None time:  1.5637626179959625
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 90.83
   Final Test: 72.10
Split: 01, Run: 03
None time:  0.676152277039364
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 2.740788459777832
total time:  2.7960620601661503
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.40 ± 12.68
  Final Train: 96.94 ± 5.29
   Final Test: 63.73 ± 12.07
[I 2023-06-11 23:34:54,620] Trial 261 finished with value: 64.4000015258789 and parameters: {'Fwd': 0.0012489422177532176, 'K': 1, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 4.880795251044881, 'loop': 2, 'loss': 'CE', 'lr': 0.00729266379358692, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.107753220993131e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.007837694107538483
weight_decay:  5.40583869405418e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.079562994884327
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 93.33
   Final Test: 72.10
Split: 01, Run: 02
None time:  0.5333822180982679
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.4700694440398365
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 67.90
run time now: 2.115710496902466
total time:  2.1776266819797456
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.20
  Final Train: 97.78 ± 3.85
   Final Test: 69.60 ± 2.21
[I 2023-06-11 23:34:57,263] Trial 262 finished with value: 73.4000015258789 and parameters: {'Fwd': 0.0018729936208780034, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 1.2193478072642914, 'loop': 2, 'loss': 'CE', 'lr': 0.007837694107538483, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.40583869405418e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.009053347377426642
weight_decay:  6.731044860186229e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4772194279357791
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.00
Split: 01, Run: 02
None time:  0.4188646129332483
None Run 02:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 56.60
Split: 01, Run: 03
None time:  0.44076944212429225
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 99.17
   Final Test: 64.50
run time now: 1.3776655197143555
total time:  1.431453201919794
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.93 ± 5.33
  Final Train: 99.72 ± 0.48
   Final Test: 62.37 ± 5.05
[I 2023-06-11 23:34:59,132] Trial 263 finished with value: 63.93333053588867 and parameters: {'Fwd': 0.0011661075699633692, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 4.642675177852289, 'loop': 0, 'loss': 'CE', 'lr': 0.009053347377426642, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.731044860186229e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.007147558915445924
weight_decay:  8.057753574468365e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4966832920908928
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  0.5585801880806684
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.5816669801715761
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 65.10
run time now: 2.6706318855285645
total time:  2.7225798568688333
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.13 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 68.17 ± 2.77
[I 2023-06-11 23:35:02,335] Trial 264 finished with value: 73.1333236694336 and parameters: {'Fwd': 0.0009884003477159007, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 9.418230354428184, 'loop': 2, 'loss': 'CE', 'lr': 0.007147558915445924, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.057753574468365e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00784925881465555
weight_decay:  4.785616196256368e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8369642770849168
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.7560351409483701
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.5724859181791544
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 67.20
run time now: 2.1994783878326416
total time:  2.2573372619226575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 99.72 ± 0.48
   Final Test: 68.63 ± 1.32
[I 2023-06-11 23:35:05,151] Trial 265 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0014736681578643987, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 1.5157740541373084, 'loop': 2, 'loss': 'CE', 'lr': 0.00784925881465555, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.785616196256368e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.008667327467040156
weight_decay:  6.164228373769524e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.433354217093438
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 95.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  0.6002551019191742
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.5247518089599907
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.589810609817505
total time:  2.6337848410476
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.73 ± 1.40
  Final Train: 98.33 ± 2.89
   Final Test: 70.97 ± 0.91
[I 2023-06-11 23:35:08,220] Trial 266 finished with value: 73.73332977294922 and parameters: {'Fwd': 0.0022719286064080677, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 3.3748857205018497, 'loop': 2, 'loss': 'CE', 'lr': 0.008667327467040156, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.164228373769524e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0005685996630877199
weight_decay:  3.467884308055418e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4000998809933662
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.6706276650074869
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  1.0294659619685262
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 71.70
run time now: 3.1334962844848633
total time:  3.181947355857119
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.31
  Final Train: 99.44 ± 0.48
   Final Test: 71.17 ± 0.68
[I 2023-06-11 23:35:11,907] Trial 267 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.002494752041409693, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 5.37741348331089, 'loop': 2, 'loss': 'CE', 'lr': 0.0005685996630877199, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.467884308055418e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0014789506656368758
weight_decay:  5.83347879069855e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9540510261431336
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 67.70
Split: 01, Run: 02
None time:  1.6675284900702536
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 90.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.6062176648993045
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 64.70
run time now: 3.2608468532562256
total time:  3.3148852600716054
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.20
  Final Train: 96.39 ± 5.55
   Final Test: 67.30 ± 2.42
[I 2023-06-11 23:35:15,659] Trial 268 finished with value: 70.60000610351562 and parameters: {'Fwd': 0.0018897158963296476, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 1.6627844021850153, 'loop': 2, 'loss': 'CE', 'lr': 0.0014789506656368758, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.83347879069855e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.001337578537036591
weight_decay:  0.00010564743252400515
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3417730268556625
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 97.50
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.1114513447973877
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.6924829690251499
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.50
run time now: 3.1795365810394287
total time:  3.222481087082997
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.31
  Final Train: 98.61 ± 1.27
   Final Test: 69.67 ± 1.07
[I 2023-06-11 23:35:19,330] Trial 269 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.002555615823904613, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 2.261358233265506, 'loop': 2, 'loss': 'CE', 'lr': 0.001337578537036591, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010564743252400515, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.006632001100962893
weight_decay:  7.15867090790934e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6662753280252218
None Run 01:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 02
None time:  0.6755630520638078
None Run 02:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 52.10
Split: 01, Run: 03
None time:  0.6463541490957141
None Run 03:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 49.90
run time now: 2.0214173793792725
total time:  2.0686775979120284
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.80 ± 4.54
  Final Train: 100.00 ± 0.00
   Final Test: 53.00 ± 3.63
[I 2023-06-11 23:35:21,869] Trial 270 finished with value: 50.80000305175781 and parameters: {'Fwd': 0.0030828673324813176, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 0.2772865537803756, 'loop': 2, 'loss': 'CE', 'lr': 0.006632001100962893, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.15867090790934e-06, 'weightedloss': False}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0018108475743995813
weight_decay:  5.113611306764963e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1654707989655435
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 93.33
   Final Test: 65.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.4959, Train: 85.83%, Valid: 68.80% Test: 69.00%
Split: 01, Run: 02
None time:  1.8314953020308167
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 85.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.6332163920160383
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.80
run time now: 3.6626060009002686
total time:  3.717988899210468
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.13 ± 1.33
  Final Train: 92.78 ± 7.52
   Final Test: 67.47 ± 1.97
[I 2023-06-11 23:35:26,026] Trial 271 finished with value: 68.13333129882812 and parameters: {'Fwd': 0.0038201512105841143, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 0.4104325306878946, 'loop': 2, 'loss': 'CE', 'lr': 0.0018108475743995813, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.113611306764963e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.008508153342094824
weight_decay:  4.100843508994749e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9083666610531509
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.5955685100052506
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.6131544460076839
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.15024995803833
total time:  2.1984529739711434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.58
  Final Train: 99.72 ± 0.48
   Final Test: 69.53 ± 0.15
[I 2023-06-11 23:35:28,685] Trial 272 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.00146041342622611, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 3.2448849456115574, 'loop': 2, 'loss': 'CE', 'lr': 0.008508153342094824, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.100843508994749e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.007431220883152992
weight_decay:  0.00026147953252360465
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0426768739707768
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.8132522399537265
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 96.67
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.6142329601570964
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 68.70
run time now: 2.5034666061401367
total time:  2.5573690708260983
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.64
  Final Train: 96.94 ± 2.10
   Final Test: 68.87 ± 1.16
[I 2023-06-11 23:35:31,654] Trial 273 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.00209801075633836, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 0.7943072040326724, 'loop': 2, 'loss': 'CE', 'lr': 0.007431220883152992, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00026147953252360465, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.007918213004749576
weight_decay:  0.00010185803045578542
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5298529961146414
None Run 01:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 53.10
Split: 01, Run: 02
None time:  1.5193331339396536
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 81.67
   Final Test: 64.90
Split: 01, Run: 03
None time:  0.8242922280915082
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 68.30
run time now: 2.9069364070892334
total time:  2.9595741459634155
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.80 ± 8.86
  Final Train: 91.67 ± 9.28
   Final Test: 62.10 ± 7.98
[I 2023-06-11 23:35:35,033] Trial 274 finished with value: 62.79999923706055 and parameters: {'Fwd': 0.0011185237216480108, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 1.7250970401946828, 'loop': 2, 'loss': 'CE', 'lr': 0.007918213004749576, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010185803045578542, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0002662902501643503
weight_decay:  0.0001764971526545776
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.602369697066024
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.0326606407761574
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.012849512975663
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.679377555847168
total time:  3.7363083108793944
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 1.29
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.58
[I 2023-06-11 23:35:39,230] Trial 275 finished with value: 70.9333267211914 and parameters: {'Fwd': 0.0009095662203603802, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 2.0722512995787845, 'loop': 2, 'loss': 'CE', 'lr': 0.0002662902501643503, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001764971526545776, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00017063742731135737
weight_decay:  6.603611189679179e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.687284555984661
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 67.30
Split: 01, Run: 02
None time:  0.9659434340428561
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.6268443039152771
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.80
run time now: 3.3142199516296387
total time:  3.370073693804443
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 1.25
  Final Train: 99.72 ± 0.48
   Final Test: 69.73 ± 2.27
[I 2023-06-11 23:35:43,063] Trial 276 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.0001007064160304424, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 2.17869142406707, 'loop': 2, 'loss': 'CE', 'lr': 0.00017063742731135737, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.603611189679179e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.006910164225938437
weight_decay:  0.06692926252291286
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0921947439201176
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.7886443948373199
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  0.8122043709736317
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.90
run time now: 2.7257633209228516
total time:  2.776094258064404
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 68.63 ± 1.22
[I 2023-06-11 23:35:46,302] Trial 277 finished with value: 72.06665802001953 and parameters: {'Fwd': 5.89000143822625e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 5.555308983346431, 'loop': 2, 'loss': 'CE', 'lr': 0.006910164225938437, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.06692926252291286, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.00881076091812791
weight_decay:  8.465729581203258e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6510771061293781
None Run 01:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.60
Split: 01, Run: 02
None time:  0.6294684270396829
None Run 02:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 50.20
Split: 01, Run: 03
None time:  0.6378815011121333
None Run 03:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.50
run time now: 1.9621634483337402
total time:  2.018275886075571
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.20 ± 5.70
  Final Train: 100.00 ± 0.00
   Final Test: 55.77 ± 5.65
[I 2023-06-11 23:35:48,753] Trial 278 finished with value: 57.20000076293945 and parameters: {'Fwd': 0.001743082912659661, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 3.0332479583745844, 'loop': 2, 'loss': 'MSE', 'lr': 0.00881076091812791, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.465729581203258e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.006183530915364824
weight_decay:  4.4889407757560935e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6043063220568001
None Run 01:
Highest Train: 100.00
Highest Valid: 36.40
  Final Train: 100.00
   Final Test: 39.80
Split: 01, Run: 02
None time:  1.729078436968848
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 85.83
   Final Test: 65.90
Split: 01, Run: 03
None time:  0.6576833040453494
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 63.10
run time now: 3.0248122215270996
total time:  3.078123542945832
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.27 ± 18.07
  Final Train: 95.28 ± 8.18
   Final Test: 56.27 ± 14.33
[I 2023-06-11 23:35:52,260] Trial 279 finished with value: 57.266666412353516 and parameters: {'Fwd': 4.682698933968623e-05, 'K': 1, 'alpha': 0.1, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 0.17902638482397304, 'loop': 2, 'loss': 'CE', 'lr': 0.006183530915364824, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.4889407757560935e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.007860034121528709
weight_decay:  0.012069629929922695
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2163073369301856
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.577424910152331
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.586194264004007
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 2.4225218296051025
total time:  2.4930580989457667
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.47 ± 0.76
  Final Train: 98.33 ± 2.89
   Final Test: 69.43 ± 0.45
[I 2023-06-11 23:35:55,230] Trial 280 finished with value: 72.46666717529297 and parameters: {'Fwd': 0.0012850554591232368, 'K': 3, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 3.9635337503691233, 'loop': 2, 'loss': 'CE', 'lr': 0.007860034121528709, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.012069629929922695, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008903311174775271
weight_decay:  3.1872228968875004e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.00080372299999
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 71.60
Split: 01, Run: 02
None time:  0.6734380591660738
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.642871516989544
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.355611801147461
total time:  2.398341780062765
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.20 ± 1.22
  Final Train: 99.72 ± 0.48
   Final Test: 70.50 ± 1.01
[I 2023-06-11 23:35:58,048] Trial 281 finished with value: 74.20000457763672 and parameters: {'Fwd': 1.4694711321688702e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 6.807025535484198, 'loop': 2, 'loss': 'CE', 'lr': 0.008903311174775271, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.1872228968875004e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0010198989041598576
weight_decay:  3.168695986204152e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7482731898780912
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.3506151249166578
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.7480921801179647
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.00
run time now: 2.879507541656494
total time:  2.9295298599172384
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 1.56
  Final Train: 99.44 ± 0.48
   Final Test: 68.60 ± 1.44
[I 2023-06-11 23:36:01,376] Trial 282 finished with value: 69.80000305175781 and parameters: {'Fwd': 1.2520515679242704e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 6.105545330792036, 'loop': 2, 'loss': 'CE', 'lr': 0.0010198989041598576, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.168695986204152e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.009031262367158836
weight_decay:  2.9949895524813166e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.032910091103986
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 93.33
   Final Test: 68.00
Split: 01, Run: 02
None time:  0.7599484859965742
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 03
None time:  0.7197238479275256
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 66.90
run time now: 2.5451812744140625
total time:  2.601244238903746
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 2.25
  Final Train: 97.78 ± 3.85
   Final Test: 67.00 ± 0.95
[I 2023-06-11 23:36:04,479] Trial 283 finished with value: 71.19999694824219 and parameters: {'Fwd': 0.0001937653635667144, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 2.7898291154662487, 'loop': 2, 'loss': 'CE', 'lr': 0.009031262367158836, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.9949895524813166e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.009034263822692025
weight_decay:  0.00023897165294273925
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.736941906856373
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.7647301510442048
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 03
None time:  0.769364204024896
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.90
run time now: 2.305388927459717
total time:  2.348011682042852
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 71.10 ± 1.11
[I 2023-06-11 23:36:07,278] Trial 284 finished with value: 73.5999984741211 and parameters: {'Fwd': 1.3833089796432078e-05, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 6.467598811097478, 'loop': 2, 'loss': 'CE', 'lr': 0.009034263822692025, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00023897165294273925, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.15000000000000002
lr:  0.007168314733324247
weight_decay:  2.0203744922405562e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5317780999466777
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 90.83
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.6411498880479485
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.7460575350560248
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.9555225372314453
total time:  3.012366109061986
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 0.20
  Final Train: 96.94 ± 5.29
   Final Test: 70.67 ± 0.42
[I 2023-06-11 23:36:10,752] Trial 285 finished with value: 73.0 and parameters: {'Fwd': 2.058565446800358e-05, 'K': 4, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 6.9732412377087165, 'loop': 2, 'loss': 'CE', 'lr': 0.007168314733324247, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.0203744922405562e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.1
lr:  0.0007084723070480606
weight_decay:  0.00013509561740684614
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.899103679927066
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 92.50
   Final Test: 65.10
Split: 01, Run: 02
None time:  0.7757167369127274
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.6487594249192625
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 67.90
run time now: 2.364588499069214
total time:  2.42401229403913
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.73 ± 3.00
  Final Train: 96.67 ± 3.63
   Final Test: 67.90 ± 2.80
[I 2023-06-11 23:36:13,613] Trial 286 finished with value: 68.73333740234375 and parameters: {'Fwd': 3.278990135095788e-05, 'K': 7, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 1.929503568569361, 'loop': 2, 'loss': 'CE', 'lr': 0.0007084723070480606, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00013509561740684614, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.008471353631231318
weight_decay:  3.312327173322486e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9973988451529294
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.6820370270870626
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 03
None time:  0.5642154719680548
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.281019926071167
total time:  2.3256939598359168
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 0.99
  Final Train: 99.72 ± 0.48
   Final Test: 71.30 ± 0.95
[I 2023-06-11 23:36:16,450] Trial 287 finished with value: 72.9333267211914 and parameters: {'Fwd': 1.3203354586953965e-05, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 7.549162946939524, 'loop': 2, 'loss': 'CE', 'lr': 0.008471353631231318, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.312327173322486e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.006248779550693851
weight_decay:  3.9505680436692934e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9066568911075592
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 02
None time:  0.650327195879072
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.5874446409288794
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.1788980960845947
total time:  2.2389613520354033
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.97 ± 0.57
[I 2023-06-11 23:36:19,205] Trial 288 finished with value: 72.4000015258789 and parameters: {'Fwd': 8.614633029979652e-05, 'K': 3, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 6.938196720544795, 'loop': 2, 'loss': 'CE', 'lr': 0.006248779550693851, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.9505680436692934e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.00929467097838179
weight_decay:  5.716374883927017e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.618352421792224
None Run 01:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 52.10
Split: 01, Run: 02
None time:  0.5615076690446585
None Run 02:
Highest Train: 100.00
Highest Valid: 42.00
  Final Train: 100.00
   Final Test: 40.90
Split: 01, Run: 03
None time:  0.6130178088787943
None Run 03:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 41.90
run time now: 1.8250908851623535
total time:  1.8792921910062432
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 47.47 ± 7.18
  Final Train: 100.00 ± 0.00
   Final Test: 44.97 ± 6.20
[I 2023-06-11 23:36:21,621] Trial 289 finished with value: 47.4666633605957 and parameters: {'Fwd': 0.00011096240619005221, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 3.629926255711984, 'loop': 2, 'loss': 'CE', 'lr': 0.00929467097838179, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.716374883927017e-05, 'weightedloss': False}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0025667578121164295
weight_decay:  0.006490415290160571
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6309660871047527
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02
None time:  0.9350471408106387
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.5577783000189811
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.156648635864258
total time:  2.201462888158858
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 2.62
  Final Train: 99.72 ± 0.48
   Final Test: 69.70 ± 1.35
[I 2023-06-11 23:36:24,303] Trial 290 finished with value: 70.5999984741211 and parameters: {'Fwd': 1.9287113983302916e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 8.0694815080428, 'loop': 1, 'loss': 'CE', 'lr': 0.0025667578121164295, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006490415290160571, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8
lr:  0.006929212314800163
weight_decay:  0.0001753802390652182
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5105061349458992
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 88.33
   Final Test: 68.50
Split: 01, Run: 02
None time:  0.5792227829806507
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.6899013109505177
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.81392502784729
total time:  2.861943081021309
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 0.61
  Final Train: 96.11 ± 6.74
   Final Test: 69.03 ± 0.50
[I 2023-06-11 23:36:27,598] Trial 291 finished with value: 69.73332977294922 and parameters: {'Fwd': 0.00013727847923261882, 'K': 2, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 4.523808849654001, 'loop': 2, 'loss': 'CE', 'lr': 0.006929212314800163, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001753802390652182, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008285959411719564
weight_decay:  0.00011952537177692114
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.39646868710406125
None Run 01:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 38.20
Split: 01, Run: 02
None time:  0.5083113920409232
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.35186920687556267
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.90
run time now: 1.2899644374847412
total time:  1.3435883531346917
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.40 ± 19.06
  Final Train: 100.00 ± 0.00
   Final Test: 59.67 ± 18.60
[I 2023-06-11 23:36:29,406] Trial 292 finished with value: 61.399993896484375 and parameters: {'Fwd': 0.0009980640380298385, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 30, 'lambda1': 0.1, 'lambda2': 2.5472907985901045, 'loop': 2, 'loss': 'CE', 'lr': 0.008285959411719564, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011952537177692114, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0076207502734870055
weight_decay:  4.372387417639594e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2572882450185716
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.6329447240568697
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.5665997848846018
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.4934802055358887
total time:  2.548831574851647
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.47 ± 0.31
  Final Train: 99.72 ± 0.48
   Final Test: 69.50 ± 1.21
[I 2023-06-11 23:36:32,433] Trial 293 finished with value: 74.46666717529297 and parameters: {'Fwd': 4.045238529959551e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 8.723208264453492, 'loop': 2, 'loss': 'CE', 'lr': 0.0076207502734870055, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.372387417639594e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.65
lr:  0.007452347301970377
weight_decay:  4.456565638089608e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9289928919170052
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 92.50
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.7462928020395339
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.83
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.6435347269289196
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.3595516681671143
total time:  2.4108201728668064
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.31
  Final Train: 96.11 ± 3.76
   Final Test: 69.50 ± 0.10
[I 2023-06-11 23:36:35,397] Trial 294 finished with value: 71.33333587646484 and parameters: {'Fwd': 3.0121045241101814e-05, 'K': 2, 'alpha': 0.65, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 0.8563893651389165, 'loop': 2, 'loss': 'CE', 'lr': 0.007452347301970377, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.456565638089608e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.006980605159174529
weight_decay:  0.00030364194308522374
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0379502528812736
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 68.20
Split: 01, Run: 02
None time:  0.6786235091276467
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 03
None time:  0.7046635278966278
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.452982187271118
total time:  2.5133690249640495
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.76
  Final Train: 99.72 ± 0.48
   Final Test: 67.97 ± 1.66
[I 2023-06-11 23:36:38,363] Trial 295 finished with value: 71.53333282470703 and parameters: {'Fwd': 7.215374553223176e-05, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 7.363046559473826, 'loop': 2, 'loss': 'CE', 'lr': 0.006980605159174529, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00030364194308522374, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.006326365799240265
weight_decay:  2.7788571011344286e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7137947010342032
None Run 01:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 55.00
Split: 01, Run: 02
None time:  0.7739275540225208
None Run 02:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 64.80
Split: 01, Run: 03
None time:  0.584896236890927
None Run 03:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.30
run time now: 2.1079821586608887
total time:  2.1624256239738315
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.33 ± 4.79
  Final Train: 100.00 ± 0.00
   Final Test: 60.70 ± 5.09
[I 2023-06-11 23:36:40,993] Trial 296 finished with value: 61.33333206176758 and parameters: {'Fwd': 4.51940341557522e-05, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 8.452210151212732, 'loop': 2, 'loss': 'MSE', 'lr': 0.006326365799240265, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.7788571011344286e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.2
lr:  0.0024574525627622827
weight_decay:  0.008887716751788196
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7235938678495586
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 61.20
Split: 01, Run: 02
None time:  0.7551932670176029
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 63.00
Split: 01, Run: 03
None time:  0.8330049840733409
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 61.60
run time now: 2.351029634475708
total time:  2.4090980030596256
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 61.93 ± 0.95
[I 2023-06-11 23:36:43,983] Trial 297 finished with value: 64.80000305175781 and parameters: {'Fwd': 0.00017011932478030886, 'K': 6, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.037433388332406, 'loop': 2, 'loss': 'CE', 'lr': 0.0024574525627622827, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.008887716751788196, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0020248452963746192
weight_decay:  0.019769969586833757
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.215676766820252
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 68.80
Split: 01, Run: 02
None time:  0.6475339280441403
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  0.8558035378810018
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 70.00
run time now: 2.7557296752929688
total time:  2.809662139043212
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.72
  Final Train: 99.44 ± 0.48
   Final Test: 68.63 ± 1.46
[I 2023-06-11 23:36:47,415] Trial 298 finished with value: 70.20000457763672 and parameters: {'Fwd': 7.85541367907874e-06, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 5.858088314423856, 'loop': 2, 'loss': 'CE', 'lr': 0.0020248452963746192, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.019769969586833757, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.007610994583663686
weight_decay:  7.4145585811233e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9012780708726496
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 72.00
Split: 01, Run: 02
None time:  0.6337905088439584
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.6181307921651751
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.185839891433716
total time:  2.230303132208064
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.00 ± 0.00
  Final Train: 99.72 ± 0.48
   Final Test: 70.63 ± 1.21
[I 2023-06-11 23:36:50,145] Trial 299 finished with value: 74.0 and parameters: {'Fwd': 6.077577034562305e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.2452519282652, 'loop': 2, 'loss': 'CE', 'lr': 0.007610994583663686, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.4145585811233e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.009943669839914357
weight_decay:  6.366177906667876e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.021406820975244
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.5845421219710261
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.6873279139399529
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.90
run time now: 2.326190233230591
total time:  2.3834782268386334
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.87 ± 0.23
  Final Train: 99.72 ± 0.48
   Final Test: 70.73 ± 1.46
[I 2023-06-11 23:36:52,977] Trial 300 finished with value: 73.86666870117188 and parameters: {'Fwd': 7.02764799296768e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.72221647098926, 'loop': 2, 'loss': 'CE', 'lr': 0.009943669839914357, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.366177906667876e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.00970872283085299
weight_decay:  7.692911967883072e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0219324799254537
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 72.50
Split: 01, Run: 02
None time:  0.5948946638964117
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.6241860659793019
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 71.60
run time now: 2.2803328037261963
total time:  2.343630379997194
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.73 ± 0.99
  Final Train: 99.72 ± 0.48
   Final Test: 71.10 ± 1.71
[I 2023-06-11 23:36:55,769] Trial 301 finished with value: 74.73332977294922 and parameters: {'Fwd': 4.582940897892115e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.587227672563985, 'loop': 2, 'loss': 'CE', 'lr': 0.00970872283085299, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.692911967883072e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.009924419081895322
weight_decay:  6.227173310598745e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1953898188658059
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 97.50
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.5274727907963097
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.6117391029838473
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 67.40
run time now: 2.3673763275146484
total time:  2.4210642410907894
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.87 ± 0.46
  Final Train: 99.17 ± 1.44
   Final Test: 69.10 ± 1.93
[I 2023-06-11 23:36:58,632] Trial 302 finished with value: 73.86666870117188 and parameters: {'Fwd': 6.472195220281744e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 8.637297705736737, 'loop': 2, 'loss': 'CE', 'lr': 0.009924419081895322, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.227173310598745e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.009888436119128746
weight_decay:  1.5307972124394615e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6523818289861083
None Run 01:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 33.90
Split: 01, Run: 02
None time:  1.1066253769677132
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.5224086940288544
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 61.00
run time now: 2.3144280910491943
total time:  2.3707208468113095
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.67 ± 20.33
  Final Train: 97.78 ± 3.85
   Final Test: 54.93 ± 18.75
[I 2023-06-11 23:37:01,570] Trial 303 finished with value: 57.66666793823242 and parameters: {'Fwd': 4.367756829710015e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 8.313912044853845, 'loop': 2, 'loss': 'CE', 'lr': 0.009888436119128746, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.5307972124394615e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.00039220732164244916
weight_decay:  2.2684351650261995e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5404301141388714
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.6240581120364368
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.9358235311228782
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.30
run time now: 3.139275074005127
total time:  3.196362583898008
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 1.40
  Final Train: 99.72 ± 0.48
   Final Test: 71.13 ± 0.21
[I 2023-06-11 23:37:05,213] Trial 304 finished with value: 73.0 and parameters: {'Fwd': 5.655041452419755e-05, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.769024304345216, 'loop': 2, 'loss': 'CE', 'lr': 0.00039220732164244916, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2684351650261995e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.00924390945711666
weight_decay:  6.457865675852978e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5226175738498569
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.9735746150836349
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.173933289013803
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 4.702862977981567
total time:  4.7538357300218195
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 70.27 ± 0.12
[I 2023-06-11 23:37:10,408] Trial 305 finished with value: 71.0 and parameters: {'Fwd': 3.797270444886207e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.532518412606917, 'loop': 2, 'loss': 'CE', 'lr': 0.00924390945711666, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.457865675852978e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.003604083926028991
weight_decay:  4.005259761731913e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7108221631497145
None Run 01:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 94.17
   Final Test: 63.60
Split: 01, Run: 02
None time:  0.7224139899481088
None Run 02:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 64.90
Split: 01, Run: 03
None time:  0.7362743890844285
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 60.30
run time now: 3.2021214962005615
total time:  3.2525867810472846
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.33 ± 0.64
  Final Train: 98.06 ± 3.37
   Final Test: 62.93 ± 2.37
[I 2023-06-11 23:37:14,118] Trial 306 finished with value: 64.33333587646484 and parameters: {'Fwd': 3.673797088978947e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 8.20134760503793, 'loop': 2, 'loss': 'CE', 'lr': 0.003604083926028991, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.005259761731913e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.009181330896459566
weight_decay:  6.001470696011881e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2343083899468184
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 96.67
   Final Test: 72.70
Split: 01, Run: 02
None time:  0.6452308378648013
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.6106602300424129
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 2.5296027660369873
total time:  2.5957921999506652
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.73 ± 0.12
  Final Train: 98.89 ± 1.92
   Final Test: 71.27 ± 1.45
[I 2023-06-11 23:37:17,203] Trial 307 finished with value: 73.73332977294922 and parameters: {'Fwd': 2.6443792295592788e-05, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.78572832516275, 'loop': 2, 'loss': 'CE', 'lr': 0.009181330896459566, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.001470696011881e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.0016536869852395795
weight_decay:  9.226897247475283e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3548725149594247
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 02
None time:  0.6465028249658644
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.7122935811057687
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.745044708251953
total time:  2.7907951509114355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.50
[I 2023-06-11 23:37:20,433] Trial 308 finished with value: 73.5999984741211 and parameters: {'Fwd': 4.283400358414655e-05, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 7.715587397737022, 'loop': 2, 'loss': 'CE', 'lr': 0.0016536869852395795, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.226897247475283e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.008173310303428563
weight_decay:  8.119495193136289e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5572678230237216
None Run 01:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 56.80
Split: 01, Run: 02
None time:  0.49534444021992385
None Run 02:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 40.30
Split: 01, Run: 03
None time:  0.5179653090890497
None Run 03:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 35.30
run time now: 1.602379322052002
total time:  1.6582265140023082
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 42.47 ± 11.91
  Final Train: 100.00 ± 0.00
   Final Test: 44.13 ± 11.25
[I 2023-06-11 23:37:22,553] Trial 309 finished with value: 42.46666717529297 and parameters: {'Fwd': 3.2515000022996175e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 6.528249502997972, 'loop': 2, 'loss': 'CE', 'lr': 0.008173310303428563, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.119495193136289e-06, 'weightedloss': False}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.6000000000000001
lr:  0.00044613871375888685
weight_decay:  5.939010012527163e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4613021691329777
None Run 01:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 54.60
Split: 01, Run: 02
None time:  0.5252015017904341
None Run 02:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 63.40
Split: 01, Run: 03
None time:  0.5144505640491843
None Run 03:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 65.30
run time now: 1.5331165790557861
total time:  1.5914731780067086
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.93 ± 3.60
  Final Train: 100.00 ± 0.00
   Final Test: 61.10 ± 5.71
[I 2023-06-11 23:37:24,678] Trial 310 finished with value: 60.93333435058594 and parameters: {'Fwd': 6.397508918216389e-05, 'K': 1, 'alpha': 0.6000000000000001, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 8.360443141179047, 'loop': 0, 'loss': 'CE', 'lr': 0.00044613871375888685, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.939010012527163e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.0029248107037965006
weight_decay:  8.898439375309294e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.404578055953607
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 99.17
   Final Test: 65.30
Split: 01, Run: 02
None time:  0.6248577751684934
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 03
None time:  0.8707960720639676
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 68.50
run time now: 2.933135509490967
total time:  2.9753574319183826
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 1.17
  Final Train: 99.44 ± 0.48
   Final Test: 66.73 ± 1.63
[I 2023-06-11 23:37:28,115] Trial 311 finished with value: 69.93333435058594 and parameters: {'Fwd': 5.143054102407597e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 8.64784293236051, 'loop': 2, 'loss': 'CE', 'lr': 0.0029248107037965006, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.898439375309294e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.003179926142441895
weight_decay:  1.1797628315241569e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9325239879544824
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 02
None time:  0.7318147248588502
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.5624990530777723
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.2695400714874268
total time:  2.3177928579971194
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 1.60
[I 2023-06-11 23:37:30,882] Trial 312 finished with value: 70.5999984741211 and parameters: {'Fwd': 8.843339882915533e-05, 'K': 9, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 8.868927660402084, 'loop': 2, 'loss': 'CE', 'lr': 0.003179926142441895, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1797628315241569e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.009964609990641077
weight_decay:  8.089965546602665e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8893403480760753
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.6579820779152215
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.6755132609978318
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.25594162940979
total time:  2.3199629560112953
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.73 ± 0.61
  Final Train: 99.72 ± 0.48
   Final Test: 69.10 ± 0.78
[I 2023-06-11 23:37:33,679] Trial 313 finished with value: 72.73332977294922 and parameters: {'Fwd': 5.845977891620324e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 5.04306889370835, 'loop': 2, 'loss': 'CE', 'lr': 0.009964609990641077, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.089965546602665e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.00783367334759148
weight_decay:  3.605244220179249e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.335236893966794
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 68.60
Split: 01, Run: 02
None time:  0.6083731660619378
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  0.6262144700158387
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.602802038192749
total time:  2.657290016999468
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 1.10
  Final Train: 99.72 ± 0.48
   Final Test: 68.73 ± 0.91
[I 2023-06-11 23:37:36,792] Trial 314 finished with value: 71.73332977294922 and parameters: {'Fwd': 5.451695524759663e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 7.258880538403046, 'loop': 2, 'loss': 'CE', 'lr': 0.00783367334759148, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.605244220179249e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.25
lr:  0.001154623113500099
weight_decay:  1.4224336398738907e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0112297818996012
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 85.83
   Final Test: 71.10
Split: 01, Run: 02
None time:  0.7061775110196322
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.5607113349251449
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.3152050971984863
total time:  2.3724948109593242
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 0.69
  Final Train: 95.28 ± 8.18
   Final Test: 70.50 ± 0.79
[I 2023-06-11 23:37:39,728] Trial 315 finished with value: 72.20000457763672 and parameters: {'Fwd': 7.057607564101028e-05, 'K': 5, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 1.1296519048446365, 'loop': 2, 'loss': 'CE', 'lr': 0.001154623113500099, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4224336398738907e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.008901661007026742
weight_decay:  5.0870844375659655e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5294894520193338
None Run 01:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 57.70
Split: 01, Run: 02
None time:  0.5991301229223609
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 03
None time:  1.093958554090932
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.90
run time now: 2.256561279296875
total time:  2.315537717193365
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.20 ± 3.61
  Final Train: 100.00 ± 0.00
   Final Test: 64.43 ± 5.93
[I 2023-06-11 23:37:42,555] Trial 316 finished with value: 65.19999694824219 and parameters: {'Fwd': 8.477566889683038e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 8.549418112055601, 'loop': 1, 'loss': 'MSE', 'lr': 0.008901661007026742, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.0870844375659655e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008243456280321415
weight_decay:  1.7090693433718724e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8220881479792297
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.6698717609979212
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.6676020810846239
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.1922309398651123
total time:  2.2373030818998814
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.33 ± 0.55
[I 2023-06-11 23:37:45,223] Trial 317 finished with value: 72.86666107177734 and parameters: {'Fwd': 0.00010060524007332537, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 6.71085594416658, 'loop': 2, 'loss': 'CE', 'lr': 0.008243456280321415, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7090693433718724e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.007502399325568294
weight_decay:  1.0244769226121526e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6306259150151163
None Run 01:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 60.10
Split: 01, Run: 02
None time:  0.6188916768878698
None Run 02:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 55.70
Split: 01, Run: 03
None time:  0.6117196078412235
None Run 03:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 52.60
run time now: 1.8931057453155518
total time:  1.936642182059586
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.27 ± 3.33
  Final Train: 100.00 ± 0.00
   Final Test: 56.13 ± 3.77
[I 2023-06-11 23:37:47,623] Trial 318 finished with value: 56.266666412353516 and parameters: {'Fwd': 2.0554934499050693e-05, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 8.844499128314276, 'loop': 2, 'loss': 'CE', 'lr': 0.007502399325568294, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.0244769226121526e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.004699775177161062
weight_decay:  1.869414038226656e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3714422341436148
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 02
None time:  1.2010324511211365
None Run 02:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 03
None time:  1.2884125791024417
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
run time now: 3.8953263759613037
total time:  3.9531290070153773
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.50 ± 0.00
[I 2023-06-11 23:37:52,042] Trial 319 finished with value: 51.40000534057617 and parameters: {'Fwd': 4.0433963428450324e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.0, 'lambda2': 9.109378608690884, 'loop': 2, 'loss': 'CE', 'lr': 0.004699775177161062, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.869414038226656e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.008917368009744082
weight_decay:  1.289558523650916e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0337662959937006
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 02
None time:  0.7248774140607566
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  0.5577235140372068
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.348853349685669
total time:  2.4034077890682966
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 71.30 ± 0.44
[I 2023-06-11 23:37:54,899] Trial 320 finished with value: 74.26667022705078 and parameters: {'Fwd': 2.7113341378712797e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.117427840306322, 'loop': 2, 'loss': 'CE', 'lr': 0.008917368009744082, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.289558523650916e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008398126681951959
weight_decay:  1.3655384252814064e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9924910999834538
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 87.50
   Final Test: 71.90
Split: 01, Run: 02
None time:  0.6389482908416539
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.636411870829761
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 99.17
   Final Test: 71.30
run time now: 2.3036386966705322
total time:  2.3506159149110317
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.93 ± 0.50
  Final Train: 95.56 ± 6.99
   Final Test: 71.23 ± 0.70
[I 2023-06-11 23:37:57,718] Trial 321 finished with value: 73.9333267211914 and parameters: {'Fwd': 3.487943165836749e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 0.016897803851002258, 'loop': 2, 'loss': 'CE', 'lr': 0.008398126681951959, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3655384252814064e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008584077910979919
weight_decay:  1.1535247511300664e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.818495153915137
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 91.67
   Final Test: 66.30
Split: 01, Run: 02
None time:  0.6058524530380964
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.527716277865693
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.40
run time now: 1.9870457649230957
total time:  2.055405341088772
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 1.93
  Final Train: 96.67 ± 4.41
   Final Test: 68.23 ± 1.86
[I 2023-06-11 23:38:00,270] Trial 322 finished with value: 70.4000015258789 and parameters: {'Fwd': 2.4083712691743403e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 0.7742881068035462, 'loop': 2, 'loss': 'CE', 'lr': 0.008584077910979919, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1535247511300664e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0009886699836086548
weight_decay:  1.2953031717631825e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2736548348329961
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 88.33
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.9731707749888301
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 93.33
   Final Test: 72.40
Split: 01, Run: 03
None time:  0.7378977700136602
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 67.20
run time now: 3.018017053604126
total time:  3.0725766809191555
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 0.83
  Final Train: 93.89 ± 5.85
   Final Test: 69.93 ± 2.61
[I 2023-06-11 23:38:03,895] Trial 323 finished with value: 73.53333282470703 and parameters: {'Fwd': 3.392109341657948e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 0.34047182080742694, 'loop': 2, 'loss': 'CE', 'lr': 0.0009886699836086548, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2953031717631825e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008004831974666957
weight_decay:  1.478687503530486e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5765060468111187
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  0.7195795448496938
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.5833825110457838
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 99.17
   Final Test: 69.00
run time now: 1.9219043254852295
total time:  1.975215101847425
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 2.32
  Final Train: 97.50 ± 2.20
   Final Test: 68.00 ± 1.00
[I 2023-06-11 23:38:06,426] Trial 324 finished with value: 70.73332977294922 and parameters: {'Fwd': 2.9597866185174914e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 0.09686649578765932, 'loop': 2, 'loss': 'CE', 'lr': 0.008004831974666957, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.478687503530486e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.004263843577274636
weight_decay:  2.196748348682131e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8720168818254024
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1951203469652683
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.1470198950264603
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.249168872833252
total time:  3.299296925077215
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.55
[I 2023-06-11 23:38:10,174] Trial 325 finished with value: 71.4666748046875 and parameters: {'Fwd': 2.642731689939029e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 7.638850146458801, 'loop': 2, 'loss': 'CE', 'lr': 0.004263843577274636, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.196748348682131e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.009033140954348522
weight_decay:  3.4796466739513416e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0454, Train: 80.00%, Valid: 67.40% Test: 69.40%
Split: 01, Run: 01
None time:  1.7681909480597824
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 80.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.72820557304658
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 03
None time:  0.6456311100628227
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 66.50
run time now: 3.1766316890716553
total time:  3.2254455969668925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.73 ± 0.64
  Final Train: 93.33 ± 11.55
   Final Test: 67.30 ± 1.65
[I 2023-06-11 23:38:13,886] Trial 326 finished with value: 68.73332977294922 and parameters: {'Fwd': 3.6084939704878895e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 0.5963055431630825, 'loop': 2, 'loss': 'CE', 'lr': 0.009033140954348522, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.4796466739513416e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.00657892503445293
weight_decay:  2.817434727157198e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5666272710077465
None Run 01:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 55.60
Split: 01, Run: 02
None time:  0.49291518586687744
None Run 02:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 42.40
Split: 01, Run: 03
None time:  0.5603011520579457
None Run 03:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 54.20
run time now: 1.6547377109527588
total time:  1.6986646719742566
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.93 ± 6.77
  Final Train: 100.00 ± 0.00
   Final Test: 50.73 ± 7.25
[I 2023-06-11 23:38:16,085] Trial 327 finished with value: 50.93333435058594 and parameters: {'Fwd': 2.374665988665572e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 1.385775780147931, 'loop': 2, 'loss': 'CE', 'lr': 0.00657892503445293, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.817434727157198e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.001927675866128696
weight_decay:  1.8188064553497902e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7368348899763077
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 64.70
Split: 01, Run: 02
None time:  1.093105865875259
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.7745674829930067
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 68.20
run time now: 2.6369147300720215
total time:  2.6860722221899778
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 2.12
  Final Train: 98.61 ± 1.73
   Final Test: 67.07 ± 2.05
[I 2023-06-11 23:38:19,207] Trial 328 finished with value: 69.60000610351562 and parameters: {'Fwd': 1.806325187289711e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 4.000539903253984, 'loop': 2, 'loss': 'CE', 'lr': 0.001927675866128696, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.8188064553497902e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0076160344400272
weight_decay:  1.104250262683665e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5856447019614279
None Run 01:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 56.70
Split: 01, Run: 02
None time:  0.6115249728318304
None Run 02:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 49.60
Split: 01, Run: 03
None time:  0.5735208110418171
None Run 03:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 43.30
run time now: 1.804319143295288
total time:  1.8520466960035264
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.20 ± 7.52
  Final Train: 100.00 ± 0.00
   Final Test: 49.87 ± 6.70
[I 2023-06-11 23:38:21,573] Trial 329 finished with value: 52.20000076293945 and parameters: {'Fwd': 2.9879716185761774e-05, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 0.22943537657606286, 'loop': 2, 'loss': 'CE', 'lr': 0.0076160344400272, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.104250262683665e-05, 'weightedloss': False}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  1.0
lr:  0.008501411860893244
weight_decay:  3.72822285941308e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7901966639328748
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 02
None time:  0.7124460709746927
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.7900746059603989
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.10
run time now: 2.327597141265869
total time:  2.390772202052176
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 68.27 ± 0.72
[I 2023-06-11 23:38:24,567] Trial 330 finished with value: 69.33333587646484 and parameters: {'Fwd': 5.073280464348959e-05, 'K': 4, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.15000000000000002, 'lambda2': 8.255744007142555, 'loop': 2, 'loss': 'CE', 'lr': 0.008501411860893244, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.72822285941308e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0050989386716185
weight_decay:  1.4632054450161277e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2939602239057422
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 89.17
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.6280584558844566
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 03
None time:  0.6394614200107753
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 66.50
run time now: 2.5930845737457275
total time:  2.6421131680253893
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 0.12
  Final Train: 96.39 ± 6.25
   Final Test: 68.10 ± 2.86
[I 2023-06-11 23:38:27,784] Trial 331 finished with value: 73.53333282470703 and parameters: {'Fwd': 1.711112933100255e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 0.42275056767373564, 'loop': 2, 'loss': 'CE', 'lr': 0.0050989386716185, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4632054450161277e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007932791193727806
weight_decay:  9.37236262538049e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0830221350770444
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 68.40
Split: 01, Run: 02
None time:  0.5707722520455718
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.5427331819664687
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.2295563220977783
total time:  2.2717123860493302
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 1.25
  Final Train: 99.44 ± 0.96
   Final Test: 69.70 ± 1.76
[I 2023-06-11 23:38:30,578] Trial 332 finished with value: 71.39999389648438 and parameters: {'Fwd': 2.108348306132289e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 8.222865587659857, 'loop': 1, 'loss': 'CE', 'lr': 0.007932791193727806, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.37236262538049e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.009051540269681765
weight_decay:  4.787112950215102e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5230318331159651
None Run 01:
Highest Train: 100.00
Highest Valid: 36.00
  Final Train: 100.00
   Final Test: 40.60
Split: 01, Run: 02
None time:  0.6711317780427635
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 92.50
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.5597837760578841
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.80
run time now: 1.7887024879455566
total time:  1.8466277120169252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.47 ± 19.46
  Final Train: 97.50 ± 4.33
   Final Test: 59.67 ± 16.52
[I 2023-06-11 23:38:32,953] Trial 333 finished with value: 58.4666633605957 and parameters: {'Fwd': 0.00022582911154543417, 'K': 2, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 0.6377151944904739, 'loop': 2, 'loss': 'CE', 'lr': 0.009051540269681765, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.787112950215102e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.007029393300369572
weight_decay:  0.005186347954588326
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1280, Train: 84.17%, Valid: 68.60% Test: 66.30%
Split: 01, Run: 01
None time:  1.7590045041870326
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 83.33
   Final Test: 66.90
Split: 01, Run: 02
None time:  0.6986102878581733
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 97.50
   Final Test: 66.60
Split: 01, Run: 03
None time:  0.5780223850160837
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 67.50
run time now: 3.069807529449463
total time:  3.120182252023369
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 1.85
  Final Train: 93.06 ± 8.43
   Final Test: 67.00 ± 0.46
[I 2023-06-11 23:38:36,555] Trial 334 finished with value: 70.73332977294922 and parameters: {'Fwd': 4.1397591356445505e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 0.05878388393313194, 'loop': 2, 'loss': 'CE', 'lr': 0.007029393300369572, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005186347954588326, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.00596283862104209
weight_decay:  2.677765184915315e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9907240699976683
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 92.50
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.6097973000723869
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.6550387879833579
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.2901318073272705
total time:  2.3453146959654987
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 1.31
  Final Train: 97.50 ± 4.33
   Final Test: 70.77 ± 0.40
[I 2023-06-11 23:38:39,378] Trial 335 finished with value: 72.99999237060547 and parameters: {'Fwd': 0.02735140367075331, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 1.0180281636153659, 'loop': 2, 'loss': 'CE', 'lr': 0.00596283862104209, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.677765184915315e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.009228806575751931
weight_decay:  0.0003827461990969726
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9121020617894828
None Run 01:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.20
Split: 01, Run: 02
None time:  0.7616980029270053
None Run 02:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 59.80
Split: 01, Run: 03
None time:  0.9051288911141455
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.30
run time now: 2.6112937927246094
total time:  2.6626581710297614
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.93 ± 5.75
  Final Train: 100.00 ± 0.00
   Final Test: 61.10 ± 5.66
[I 2023-06-11 23:38:42,533] Trial 336 finished with value: 61.9333381652832 and parameters: {'Fwd': 0.06501719675908067, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 6.007203955150063, 'loop': 2, 'loss': 'MSE', 'lr': 0.009228806575751931, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003827461990969726, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.008346823378500857
weight_decay:  2.047735842234726e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5262288299854845
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  0.5794739029370248
None Run 02:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 61.40
Split: 01, Run: 03
None time:  0.5559943160042167
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 1.6954901218414307
total time:  1.757279132027179
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.73 ± 4.11
  Final Train: 100.00 ± 0.00
   Final Test: 66.23 ± 4.24
[I 2023-06-11 23:38:44,752] Trial 337 finished with value: 68.73332977294922 and parameters: {'Fwd': 1.1235205965126664e-05, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 8.047934738685857, 'loop': 0, 'loss': 'CE', 'lr': 0.008346823378500857, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.047735842234726e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0006770118131980946
weight_decay:  4.0459481782264454e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7234862810000777
None Run 01:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.30
Split: 01, Run: 02
None time:  0.6311643249355257
None Run 02:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 61.40
Split: 01, Run: 03
None time:  0.6065954121295363
None Run 03:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 57.10
run time now: 1.9938359260559082
total time:  2.0487353468779474
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.73 ± 2.23
  Final Train: 100.00 ± 0.00
   Final Test: 59.27 ± 2.15
[I 2023-06-11 23:38:47,279] Trial 338 finished with value: 60.733333587646484 and parameters: {'Fwd': 0.04934454835405554, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.15000000000000002, 'lambda2': 6.72033632117564, 'loop': 2, 'loss': 'CE', 'lr': 0.0006770118131980946, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.0459481782264454e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007529799578147109
weight_decay:  7.889756464993029e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3889024890959263
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 97.50
   Final Test: 65.90
Split: 01, Run: 02
None time:  0.50584293785505
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.5189566249027848
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 68.60
run time now: 2.4477250576019287
total time:  2.501966601004824
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 1.89
  Final Train: 99.17 ± 1.44
   Final Test: 68.17 ± 2.08
[I 2023-06-11 23:38:50,232] Trial 339 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.009319721525153308, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 7.895620002645869, 'loop': 2, 'loss': 'CE', 'lr': 0.007529799578147109, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.889756464993029e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0009510705203543557
weight_decay:  0.00022193562916595586
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7585055851377547
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02
None time:  0.857131001772359
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 97.50
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.749708317918703
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 96.67
   Final Test: 70.60
run time now: 2.3984861373901367
total time:  2.4402840819675475
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.80
  Final Train: 98.06 ± 1.73
   Final Test: 69.07 ± 1.33
[I 2023-06-11 23:38:53,198] Trial 340 finished with value: 71.80000305175781 and parameters: {'Fwd': 2.7305383886559395e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 0.9617014052974906, 'loop': 2, 'loss': 'CE', 'lr': 0.0009510705203543557, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00022193562916595586, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.006615611688919969
weight_decay:  0.0018731723707248106
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4120311399456114
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.5414402869064361
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.6426939000375569
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.628460645675659
total time:  2.6764415230136365
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.69
  Final Train: 99.72 ± 0.48
   Final Test: 70.27 ± 0.46
[I 2023-06-11 23:38:56,340] Trial 341 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.00015412012740836784, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 4.721361340214382, 'loop': 2, 'loss': 'CE', 'lr': 0.006615611688919969, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0018731723707248106, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008420116181694913
weight_decay:  5.1790482378892504e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9357755270320922
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 99.17
   Final Test: 67.10
Split: 01, Run: 02
None time:  0.5979925598949194
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.5739559081848711
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 67.70
run time now: 2.1488564014434814
total time:  2.215015030000359
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.40 ± 1.39
  Final Train: 99.72 ± 0.48
   Final Test: 67.73 ± 0.65
[I 2023-06-11 23:38:59,018] Trial 342 finished with value: 69.4000015258789 and parameters: {'Fwd': 0.01409130486269746, 'K': 2, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 8.49227560673495, 'loop': 2, 'loss': 'CE', 'lr': 0.008420116181694913, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.1790482378892504e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.003488945860365275
weight_decay:  0.0005648764582427457
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6828264719806612
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02
None time:  1.7729222238995135
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.7628476119134575
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.70
run time now: 3.2515063285827637
total time:  3.3090969549957663
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.07 ± 2.23
  Final Train: 99.72 ± 0.48
   Final Test: 67.97 ± 2.16
[I 2023-06-11 23:39:02,917] Trial 343 finished with value: 69.06665802001953 and parameters: {'Fwd': 1.4948906653615992e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 7.4572704508942, 'loop': 2, 'loss': 'CE', 'lr': 0.003488945860365275, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0005648764582427457, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.00145142484900156
weight_decay:  3.3586705971978556e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3812376540154219
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 67.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.4908, Train: 89.17%, Valid: 71.40% Test: 70.40%
Split: 01, Run: 02
None time:  1.7895177961327136
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 89.17
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.5214424058794975
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.50
run time now: 3.7258763313293457
total time:  3.770791101967916
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 1.14
  Final Train: 94.17 ± 5.46
   Final Test: 69.63 ± 2.07
[I 2023-06-11 23:39:07,174] Trial 344 finished with value: 71.0666732788086 and parameters: {'Fwd': 2.3117053913114217e-05, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.15000000000000002, 'lambda2': 2.6452086214397186, 'loop': 2, 'loss': 'CE', 'lr': 0.00145142484900156, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.3586705971978556e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.009937723580455384
weight_decay:  2.42473328057097e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2259715429972857
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 92.50
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.5812893339898437
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.6086511870380491
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 68.00
run time now: 2.449101448059082
total time:  2.509879150893539
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.50
  Final Train: 97.50 ± 4.33
   Final Test: 69.33 ± 1.30
[I 2023-06-11 23:39:10,189] Trial 345 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.000615801658174007, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 0.5359714253766084, 'loop': 2, 'loss': 'CE', 'lr': 0.009937723580455384, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.42473328057097e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0027490729725945812
weight_decay:  1.20988836023751e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.781474205898121
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.40
Split: 01, Run: 02
None time:  0.9026810540817678
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.6661062519997358
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.60
run time now: 2.3834753036499023
total time:  2.433962991926819
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 3.44
  Final Train: 99.72 ± 0.48
   Final Test: 70.13 ± 3.16
[I 2023-06-11 23:39:13,077] Trial 346 finished with value: 70.33332824707031 and parameters: {'Fwd': 4.1276735379608325e-05, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 5.991756028695182, 'loop': 2, 'loss': 'CE', 'lr': 0.0027490729725945812, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.20988836023751e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.007361429142200883
weight_decay:  4.6514270874539144e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7533786848653108
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 90.83
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.8874362788628787
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 88.33
   Final Test: 65.90
Split: 01, Run: 03
None time:  0.5912586210761219
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 67.70
run time now: 2.264723539352417
total time:  2.318225825903937
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 3.41
  Final Train: 93.06 ± 6.14
   Final Test: 68.00 ± 2.26
[I 2023-06-11 23:39:15,895] Trial 347 finished with value: 70.9333267211914 and parameters: {'Fwd': 0.0014040059280707408, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 0.005414424820261245, 'loop': 2, 'loss': 'CE', 'lr': 0.007361429142200883, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.6514270874539144e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.009119630818353578
weight_decay:  5.723785126766031e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5669260530266911
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 59.30
Split: 01, Run: 02
None time:  0.6085999889764935
None Run 02:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 56.70
Split: 01, Run: 03
None time:  0.5319548009429127
None Run 03:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 55.80
run time now: 1.7485988140106201
total time:  1.7955388489644974
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.20 ± 1.64
  Final Train: 100.00 ± 0.00
   Final Test: 57.27 ± 1.82
[I 2023-06-11 23:39:18,194] Trial 348 finished with value: 60.20000076293945 and parameters: {'Fwd': 0.00011935766838979496, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 1.5802375035334704, 'loop': 2, 'loss': 'CE', 'lr': 0.009119630818353578, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.723785126766031e-05, 'weightedloss': False}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.00035014703502504784
weight_decay:  1.7432520608366565e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3703941141720861
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.6590645299293101
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 03
None time:  0.6514995989855379
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.7137115001678467
total time:  2.765317128971219
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 0.72
  Final Train: 99.72 ± 0.48
   Final Test: 71.47 ± 0.72
[I 2023-06-11 23:39:21,420] Trial 349 finished with value: 72.99999237060547 and parameters: {'Fwd': 5.295832647173673e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 4.424024954354035, 'loop': 2, 'loss': 'CE', 'lr': 0.00035014703502504784, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7432520608366565e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00214360452708741
weight_decay:  1.547140584696398e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8833589260466397
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.9368416790384799
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 03
None time:  0.9161117330659181
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.7716851234436035
total time:  2.828768193954602
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 1.59
[I 2023-06-11 23:39:24,769] Trial 350 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.0017042585784578699, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 5.632168061950248, 'loop': 2, 'loss': 'CE', 'lr': 0.00214360452708741, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.547140584696398e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.007973226450464542
weight_decay:  0.00033022598018660567
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5916623298544437
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 02
None time:  0.6329128299839795
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 03
None time:  0.7931510780472308
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.10
run time now: 2.051348924636841
total time:  2.105492757167667
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.00 ± 2.23
  Final Train: 100.00 ± 0.00
   Final Test: 66.23 ± 0.96
[I 2023-06-11 23:39:27,358] Trial 351 finished with value: 68.0 and parameters: {'Fwd': 3.359049282439845e-05, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 6.319464846663831, 'loop': 2, 'loss': 'CE', 'lr': 0.007973226450464542, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00033022598018660567, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.005448927328615819
weight_decay:  1.4105294092859931e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8968214790802449
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.6166386590339243
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.726237362017855
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.2723047733306885
total time:  2.334213538095355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 0.75
[I 2023-06-11 23:39:30,177] Trial 352 finished with value: 73.39999389648438 and parameters: {'Fwd': 1.7452754459378152e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 3.5754066313398205, 'loop': 2, 'loss': 'CE', 'lr': 0.005448927328615819, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4105294092859931e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.000637478798276841
weight_decay:  3.640885121549543e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5270169891882688
None Run 01:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 41.70
Split: 01, Run: 02
None time:  1.3027602229267359
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 90.83
   Final Test: 71.50
Split: 01, Run: 03
None time:  0.24553734087385237
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 71.20
run time now: 2.1099202632904053
total time:  2.1551626319997013
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.80 ± 14.73
  Final Train: 96.67 ± 5.07
   Final Test: 61.47 ± 17.12
[I 2023-06-11 23:39:32,863] Trial 353 finished with value: 62.79999923706055 and parameters: {'Fwd': 1.0072815551072638e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 10, 'lambda1': 0.4, 'lambda2': 2.443740563577901, 'loop': 2, 'loss': 'CE', 'lr': 0.000637478798276841, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.640885121549543e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.0068248801906667265
weight_decay:  0.00023404405353863708
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1430281300563365
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 97.50
   Final Test: 71.60
Split: 01, Run: 02
None time:  0.7084671310149133
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.6880020978860557
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 67.70
run time now: 2.574784755706787
total time:  2.624661338981241
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 1.06
  Final Train: 99.17 ± 1.44
   Final Test: 69.33 ± 2.03
[I 2023-06-11 23:39:35,952] Trial 354 finished with value: 72.20000457763672 and parameters: {'Fwd': 0.0006500875989729437, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 9.265927437968587, 'loop': 2, 'loss': 'CE', 'lr': 0.0068248801906667265, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00023404405353863708, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.006015218740487818
weight_decay:  0.027417509375800956
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6328558539971709
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.00
Split: 01, Run: 02
None time:  0.6577053968794644
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  0.4733646761160344
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 1.798668384552002
total time:  1.8481301381252706
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.00 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 68.73 ± 3.25
[I 2023-06-11 23:39:38,284] Trial 355 finished with value: 69.0 and parameters: {'Fwd': 0.000984442520424173, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 4.792792875030704, 'loop': 1, 'loss': 'MSE', 'lr': 0.006015218740487818, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.027417509375800956, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0005379163322908842
weight_decay:  0.032977569799260864
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.052588630001992
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.8796575288288295
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.5494295791722834
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 67.80
run time now: 2.5145301818847656
total time:  2.569686856120825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.81
  Final Train: 99.72 ± 0.48
   Final Test: 69.43 ± 1.42
[I 2023-06-11 23:39:41,362] Trial 356 finished with value: 72.33332824707031 and parameters: {'Fwd': 0.0012880804993201042, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.45, 'lambda2': 5.854279206449058, 'loop': 2, 'loss': 'CE', 'lr': 0.0005379163322908842, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.032977569799260864, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00858357334706682
weight_decay:  6.536628002654462e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1584930401295424
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 02
None time:  0.7320246549788862
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.6940765001345426
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.6156060695648193
total time:  2.672719034133479
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.80 ± 0.87
[I 2023-06-11 23:39:44,625] Trial 357 finished with value: 74.5999984741211 and parameters: {'Fwd': 0.0007002074672859424, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.563825916917478, 'loop': 2, 'loss': 'CE', 'lr': 0.00858357334706682, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.536628002654462e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00754595275100063
weight_decay:  7.943332678869364e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6638443320989609
None Run 01:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 49.10
Split: 01, Run: 02
None time:  0.980455321026966
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.8077277140691876
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 98.33
   Final Test: 71.20
run time now: 2.495903491973877
total time:  2.5550192641094327
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.47 ± 11.85
  Final Train: 99.17 ± 0.83
   Final Test: 63.77 ± 12.70
[I 2023-06-11 23:39:47,775] Trial 358 finished with value: 65.46666717529297 and parameters: {'Fwd': 0.000561089673865402, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 1.3515976688706521, 'loop': 2, 'loss': 'CE', 'lr': 0.00754595275100063, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.943332678869364e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008524296168539976
weight_decay:  5.7561262294134397e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7185059250332415
None Run 01:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 02
None time:  0.6370948820840567
None Run 02:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 52.20
Split: 01, Run: 03
None time:  0.6746647690888494
None Run 03:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 43.20
run time now: 2.0641558170318604
total time:  2.128991534933448
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.87 ± 6.52
  Final Train: 100.00 ± 0.00
   Final Test: 50.80 ± 7.01
[I 2023-06-11 23:39:50,372] Trial 359 finished with value: 53.866668701171875 and parameters: {'Fwd': 0.0008207084115508165, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 3.767414212768072, 'loop': 2, 'loss': 'CE', 'lr': 0.008524296168539976, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.7561262294134397e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0017200363460953033
weight_decay:  7.127491694306333e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8969298400916159
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.50
Split: 01, Run: 02
None time:  1.332720743957907
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.050581080839038
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.90
run time now: 3.3140265941619873
total time:  3.37235271721147
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 3.67
  Final Train: 100.00 ± 0.00
   Final Test: 68.77 ± 3.83
[I 2023-06-11 23:39:54,269] Trial 360 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.0005127270322574587, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.577293449236025, 'loop': 2, 'loss': 'CE', 'lr': 0.0017200363460953033, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.127491694306333e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.006941634830162807
weight_decay:  0.00045896474868775444
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.006045948015526
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.031226763036102
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.8840451291762292
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.960455894470215
total time:  3.0143406980205327
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.10 ± 0.69
[I 2023-06-11 23:39:57,849] Trial 361 finished with value: 72.19999694824219 and parameters: {'Fwd': 0.0007482243418100956, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 8.974719657979046, 'loop': 2, 'loss': 'CE', 'lr': 0.006941634830162807, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00045896474868775444, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007920507871989628
weight_decay:  9.791052296690475e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1213851310312748
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.6901417581830174
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.8386824589688331
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.6938211917877197
total time:  2.7550044448580593
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.47 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.53
[I 2023-06-11 23:40:01,072] Trial 362 finished with value: 72.46666717529297 and parameters: {'Fwd': 7.551477411901993e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 8.37014184995233, 'loop': 2, 'loss': 'CE', 'lr': 0.007920507871989628, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.791052296690475e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009177049425951638
weight_decay:  8.647460680637815e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3741244971752167
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.50
Split: 01, Run: 02
None time:  0.6551577220670879
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.6468428000807762
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.709866523742676
total time:  2.757850632071495
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.40
  Final Train: 99.72 ± 0.48
   Final Test: 70.90 ± 0.52
[I 2023-06-11 23:40:04,283] Trial 363 finished with value: 73.39999389648438 and parameters: {'Fwd': 0.00022115555613374724, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.242288612717884, 'loop': 2, 'loss': 'CE', 'lr': 0.009177049425951638, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.647460680637815e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.006425566336640802
weight_decay:  0.00020050193322346195
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0342642629984766
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 02
None time:  0.7059614071622491
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 72.60
Split: 01, Run: 03
None time:  0.7498663258738816
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 71.60
run time now: 2.521913528442383
total time:  2.576217751018703
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.33 ± 1.10
  Final Train: 99.72 ± 0.48
   Final Test: 72.00 ± 0.53
[I 2023-06-11 23:40:07,356] Trial 364 finished with value: 74.33333587646484 and parameters: {'Fwd': 2.133002167725731e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 2.8168818161275926, 'loop': 2, 'loss': 'CE', 'lr': 0.006425566336640802, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00020050193322346195, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0062768527811078246
weight_decay:  0.0001893882762036488
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3859341670759022
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  2.619106715079397
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 92.50
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.222937076119706
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 5.2655816078186035
total time:  5.319225351093337
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.11
  Final Train: 97.50 ± 4.33
   Final Test: 70.00 ± 0.66
[I 2023-06-11 23:40:13,188] Trial 365 finished with value: 70.20000457763672 and parameters: {'Fwd': 1.9578592158981566e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 1.6234898216028115, 'loop': 2, 'loss': 'CE', 'lr': 0.0062768527811078246, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001893882762036488, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0007572264442794542
weight_decay:  0.000300857883470575
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.291093837004155
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.2201109000016004
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.7786414779257029
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.80
run time now: 3.3217153549194336
total time:  3.380778422113508
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.76
  Final Train: 99.44 ± 0.48
   Final Test: 70.80 ± 1.91
[I 2023-06-11 23:40:17,114] Trial 366 finished with value: 71.73333740234375 and parameters: {'Fwd': 2.5057926018019383e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 4.046034830317045, 'loop': 2, 'loss': 'CE', 'lr': 0.0007572264442794542, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000300857883470575, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.005276368913649346
weight_decay:  0.00017372700442872636
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6850786409340799
None Run 01:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 58.40
Split: 01, Run: 02
None time:  0.5972556711640209
None Run 02:
Highest Train: 100.00
Highest Valid: 42.00
  Final Train: 100.00
   Final Test: 45.70
Split: 01, Run: 03
None time:  0.6231089099310338
None Run 03:
Highest Train: 100.00
Highest Valid: 40.80
  Final Train: 100.00
   Final Test: 44.20
run time now: 1.938687801361084
total time:  2.000688594998792
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 46.13 ± 8.22
  Final Train: 100.00 ± 0.00
   Final Test: 49.43 ± 7.80
[I 2023-06-11 23:40:19,629] Trial 367 finished with value: 46.133331298828125 and parameters: {'Fwd': 1.6220564420604466e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 1.1734755326378408, 'loop': 2, 'loss': 'CE', 'lr': 0.005276368913649346, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00017372700442872636, 'weightedloss': False}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.001311165295912447
weight_decay:  0.00026317427808074124
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8655645940452814
None Run 01:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 60.00
Split: 01, Run: 02
None time:  1.5297407151665539
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.8168627100531012
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.2442262172698975
total time:  3.288800640963018
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 6.84
  Final Train: 99.72 ± 0.48
   Final Test: 67.07 ± 6.16
[I 2023-06-11 23:40:23,391] Trial 368 finished with value: 68.46666717529297 and parameters: {'Fwd': 8.495506057448709e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 5.294089613253536, 'loop': 2, 'loss': 'CE', 'lr': 0.001311165295912447, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00026317427808074124, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0039188402685057045
weight_decay:  0.000212740447792997
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3186101710889488
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 99.17
   Final Test: 64.00
Split: 01, Run: 02
None time:  0.9039854952134192
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 99.17
   Final Test: 66.30
Split: 01, Run: 03
None time:  0.7445903159677982
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.000190496444702
total time:  3.0533678180072457
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 1.11
  Final Train: 99.44 ± 0.48
   Final Test: 66.83 ± 3.13
[I 2023-06-11 23:40:26,925] Trial 369 finished with value: 69.20000457763672 and parameters: {'Fwd': 1.375350615237863e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 2.836729228185838, 'loop': 2, 'loss': 'CE', 'lr': 0.0039188402685057045, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000212740447792997, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.004412091314564845
weight_decay:  6.243593926624239e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6164030951913446
None Run 01:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 55.90
Split: 01, Run: 02
None time:  1.5156662228982896
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.3437116730492562
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.5088682174682617
total time:  3.5620554951019585
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.27 ± 8.54
  Final Train: 100.00 ± 0.00
   Final Test: 65.53 ± 8.35
[I 2023-06-11 23:40:30,961] Trial 370 finished with value: 67.26667022705078 and parameters: {'Fwd': 0.00629083039073677, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 9.476672801509153, 'loop': 2, 'loss': 'CE', 'lr': 0.004412091314564845, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.243593926624239e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.006615105701862321
weight_decay:  4.435719345053459e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3842768070753664
None Run 01:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 46.00
Split: 01, Run: 02
None time:  1.2499233409762383
None Run 02:
Highest Train: 100.00
Highest Valid: 30.80
  Final Train: 86.67
   Final Test: 34.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.1606, Train: 90.83%, Valid: 61.40% Test: 64.40%
Split: 01, Run: 03
None time:  1.6023747501894832
None Run 03:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 92.50
   Final Test: 64.20
run time now: 3.269002676010132
total time:  3.3253017920069396
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 46.73 ± 15.34
  Final Train: 93.06 ± 6.68
   Final Test: 48.23 ± 14.98
[I 2023-06-11 23:40:34,787] Trial 371 finished with value: 46.73333740234375 and parameters: {'Fwd': 0.0006255051481555455, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 0.4, 'lambda2': 9.674726082396111, 'loop': 2, 'loss': 'CE', 'lr': 0.006615105701862321, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.435719345053459e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.0
lr:  0.0060926734815894825
weight_decay:  2.8352432205938545e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.520781763130799
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 91.67
   Final Test: 68.10
Split: 01, Run: 02
None time:  0.6730135539546609
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.6629150679800659
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.892035722732544
total time:  2.9454207189846784
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 0.42
  Final Train: 97.22 ± 4.81
   Final Test: 69.90 ± 1.56
[I 2023-06-11 23:40:38,201] Trial 372 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.0009356924075167816, 'K': 4, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 1.9733591644961401, 'loop': 2, 'loss': 'CE', 'lr': 0.0060926734815894825, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.8352432205938545e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0072960571355151485
weight_decay:  0.004003226244543624
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0731135678943247
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.727098261937499
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 03
None time:  0.7407345999963582
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.5724220275878906
total time:  2.6188931700307876
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 0.69
  Final Train: 99.72 ± 0.48
   Final Test: 70.77 ± 1.29
[I 2023-06-11 23:40:41,327] Trial 373 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.0004945155115926048, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 7.751324988966918, 'loop': 2, 'loss': 'CE', 'lr': 0.0072960571355151485, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004003226244543624, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.005694828534633324
weight_decay:  0.00015003364382148903
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.40956543199718
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 94.17
   Final Test: 68.70
Split: 01, Run: 02
None time:  0.8425443980377167
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 98.33
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.6040713379625231
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.70
run time now: 2.8895034790039062
total time:  2.9496380009222776
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.46
  Final Train: 97.50 ± 3.00
   Final Test: 69.30 ± 1.04
[I 2023-06-11 23:40:44,875] Trial 374 finished with value: 72.33333587646484 and parameters: {'Fwd': 0.00010381677248872645, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 2.0301397139729183, 'loop': 2, 'loss': 'CE', 'lr': 0.005694828534633324, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00015003364382148903, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.15000000000000002
lr:  0.007278432394849823
weight_decay:  0.00010068552816698503
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1817571930587292
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 59.10
Split: 01, Run: 02
None time:  1.2318457239307463
None Run 02:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 58.50
Split: 01, Run: 03
None time:  0.5753387280274183
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.80
run time now: 3.0277512073516846
total time:  3.080032645026222
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.73 ± 4.09
  Final Train: 100.00 ± 0.00
   Final Test: 61.13 ± 4.05
[I 2023-06-11 23:40:48,411] Trial 375 finished with value: 63.73333740234375 and parameters: {'Fwd': 0.0006845205698109424, 'K': 6, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 8.67834356933623, 'loop': 2, 'loss': 'MSE', 'lr': 0.007278432394849823, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010068552816698503, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.009989895260535508
weight_decay:  7.058115604121072e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7305802388582379
None Run 01:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 55.10
Split: 01, Run: 02
None time:  0.7356250940356404
None Run 02:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 96.67
   Final Test: 45.40
Split: 01, Run: 03
None time:  0.6929380712099373
None Run 03:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 99.17
   Final Test: 45.70
run time now: 2.1960692405700684
total time:  2.2395818009972572
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.73 ± 4.82
  Final Train: 98.61 ± 1.73
   Final Test: 48.73 ± 5.52
[I 2023-06-11 23:40:51,138] Trial 376 finished with value: 52.733333587646484 and parameters: {'Fwd': 0.0011165235038987948, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.222947731620643, 'loop': 2, 'loss': 'CE', 'lr': 0.009989895260535508, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.058115604121072e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00478217544329694
weight_decay:  5.4542357447528066e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6175277058500797
None Run 01:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 60.90
Split: 01, Run: 02
None time:  1.2559797330759466
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 65.50
Split: 01, Run: 03
None time:  0.8490139949135482
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 99.17
   Final Test: 67.30
run time now: 2.7545981407165527
total time:  2.7983602650929242
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.13 ± 6.93
  Final Train: 99.17 ± 0.83
   Final Test: 64.57 ± 3.30
[I 2023-06-11 23:40:54,372] Trial 377 finished with value: 64.13333129882812 and parameters: {'Fwd': 0.0001332217363621439, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 2.736516943785514, 'loop': 2, 'loss': 'CE', 'lr': 0.00478217544329694, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.4542357447528066e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.0012639749384620055
weight_decay:  0.0012257164506649738
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.945372560992837
None Run 01:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 98.33
   Final Test: 59.80
Split: 01, Run: 02
None time:  0.9830246609635651
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 94.17
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.6266609318554401
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 2.5905470848083496
total time:  2.6373933609575033
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.07 ± 5.46
  Final Train: 97.50 ± 3.00
   Final Test: 66.33 ± 5.67
[I 2023-06-11 23:40:57,500] Trial 378 finished with value: 66.06666564941406 and parameters: {'Fwd': 2.177239439550605e-05, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 1.857039264541327, 'loop': 2, 'loss': 'CE', 'lr': 0.0012639749384620055, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0012257164506649738, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.1
lr:  0.0008567769132651078
weight_decay:  0.000142048704134162
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1124524271581322
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.00
Split: 01, Run: 02
None time:  1.0942773080896586
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.00
Split: 01, Run: 03
None time:  1.1836641361005604
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.00
run time now: 3.4291112422943115
total time:  3.4859519579913467
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.00 ± 0.00
[I 2023-06-11 23:41:01,454] Trial 379 finished with value: 51.20000076293945 and parameters: {'Fwd': 0.018164154622751557, 'K': 5, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.0, 'lambda2': 8.064517649943873, 'loop': 2, 'loss': 'CE', 'lr': 0.0008567769132651078, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000142048704134162, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0001327114845197971
weight_decay:  7.86332393087012e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.45932324486784637
None Run 01:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 35.70
Split: 01, Run: 02
None time:  0.43154719402082264
None Run 02:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 56.40
Split: 01, Run: 03
None time:  0.5040573980659246
None Run 03:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 60.10
run time now: 1.42922043800354
total time:  1.4852927359752357
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.73 ± 11.91
  Final Train: 100.00 ± 0.00
   Final Test: 50.73 ± 13.15
[I 2023-06-11 23:41:03,429] Trial 380 finished with value: 53.733333587646484 and parameters: {'Fwd': 0.00033030374304957245, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 3.4455336938100336, 'loop': 0, 'loss': 'CE', 'lr': 0.0001327114845197971, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.86332393087012e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.006548095211559833
weight_decay:  3.272039671515144e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0954599601682276
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9203022359870374
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 03
None time:  0.6088823708705604
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 69.00
run time now: 2.6610023975372314
total time:  2.725222383160144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 2.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 1.49
[I 2023-06-11 23:41:06,800] Trial 381 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.004757460564108051, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 8.970415738998387, 'loop': 2, 'loss': 'CE', 'lr': 0.006548095211559833, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.272039671515144e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0034074728945980405
weight_decay:  8.45039797031326e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.164982906775549
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.0296916710212827
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.7115288160275668
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 4.9534406661987305
total time:  5.008722584927455
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.20 ± 0.52
[I 2023-06-11 23:41:12,348] Trial 382 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.0008568430155375305, 'K': 1, 'alpha': 0.2, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 9.5503135878775, 'loop': 2, 'loss': 'CE', 'lr': 0.0034074728945980405, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.45039797031326e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.7000000000000001
lr:  0.007870657979340834
weight_decay:  4.5654428205895737e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.2802282718475908
None Run 01:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 38.10
Split: 01, Run: 02
None time:  0.7388099159579724
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.5020865818951279
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 70.10
run time now: 1.5534124374389648
total time:  1.6081135689746588
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.40 ± 19.41
  Final Train: 99.17 ± 0.83
   Final Test: 59.67 ± 18.68
[I 2023-06-11 23:41:14,471] Trial 383 finished with value: 60.39999771118164 and parameters: {'Fwd': 0.001703366383265142, 'K': 1, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 20, 'lambda1': 0.25, 'lambda2': 5.116526481215725, 'loop': 2, 'loss': 'CE', 'lr': 0.007870657979340834, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.5654428205895737e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.009158679964601943
weight_decay:  0.00019607205868710795
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.94654256477952
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 97.50
   Final Test: 66.60
Split: 01, Run: 02
None time:  0.6918967859819531
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.6428480928298086
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.30
run time now: 2.3136274814605713
total time:  2.3672497398220003
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 1.36
  Final Train: 99.17 ± 1.44
   Final Test: 67.60 ± 1.18
[I 2023-06-11 23:41:17,299] Trial 384 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.0002727362355087044, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 2.471904653125774, 'loop': 2, 'loss': 'CE', 'lr': 0.009158679964601943, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019607205868710795, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.008191858970955897
weight_decay:  2.2600893445043308e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9668710860423744
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 95.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.7381847200449556
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.83
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.5882968888618052
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.3265910148620605
total time:  2.3755628000944853
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.92
  Final Train: 96.94 ± 2.68
   Final Test: 70.23 ± 0.55
[I 2023-06-11 23:41:20,188] Trial 385 finished with value: 71.5999984741211 and parameters: {'Fwd': 2.990257981094775e-05, 'K': 2, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 1.4092907551131377, 'loop': 2, 'loss': 'CE', 'lr': 0.008191858970955897, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2600893445043308e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0025065744611508147
weight_decay:  4.513920956288973e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7663747800979763
None Run 01:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.30
Split: 01, Run: 02
None time:  0.6232133039738983
None Run 02:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 62.50
Split: 01, Run: 03
None time:  0.6577285390812904
None Run 03:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 61.60
run time now: 2.0791378021240234
total time:  2.1338490140624344
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.27 ± 1.70
  Final Train: 100.00 ± 0.00
   Final Test: 61.80 ± 0.62
[I 2023-06-11 23:41:22,889] Trial 386 finished with value: 62.266666412353516 and parameters: {'Fwd': 0.00018990421599047902, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 3.0678552579116425, 'loop': 1, 'loss': 'CE', 'lr': 0.0025065744611508147, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.513920956288973e-06, 'weightedloss': False}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0003109851969116385
weight_decay:  0.0002775352848359816
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.533664541086182
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.211146895075217
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.0914607890881598
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.20
run time now: 3.8691675662994385
total time:  3.9183582640253007
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.56
[I 2023-06-11 23:41:27,311] Trial 387 finished with value: 71.4666748046875 and parameters: {'Fwd': 0.001136668125896706, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 1.806332811261849, 'loop': 2, 'loss': 'CE', 'lr': 0.0003109851969116385, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002775352848359816, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007094455940636015
weight_decay:  0.00011741059881308106
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4360256800428033
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 95.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  0.5723437799606472
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.6436501131393015
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.30
run time now: 2.6858062744140625
total time:  2.7394655160605907
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 1.40
  Final Train: 98.33 ± 2.89
   Final Test: 69.63 ± 1.50
[I 2023-06-11 23:41:30,619] Trial 388 finished with value: 70.9333267211914 and parameters: {'Fwd': 1.012030697328476e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 7.054090932680913, 'loop': 2, 'loss': 'CE', 'lr': 0.007094455940636015, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011741059881308106, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.008697160126129706
weight_decay:  0.0003566453711793014
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9366205830592662
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.7465045491699129
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.5843139430508018
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.3010058403015137
total time:  2.359421922825277
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 1.75
  Final Train: 100.00 ± 0.00
   Final Test: 70.47 ± 0.31
[I 2023-06-11 23:41:33,479] Trial 389 finished with value: 72.13333129882812 and parameters: {'Fwd': 6.20546094404943e-05, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 9.36723434911524, 'loop': 2, 'loss': 'CE', 'lr': 0.008697160126129706, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003566453711793014, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.001150149566676405
weight_decay:  6.306058579478687e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9768174008931965
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 67.90
Split: 01, Run: 02
None time:  0.5818822120781988
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.6007031190674752
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.90
run time now: 2.1954989433288574
total time:  2.2489983229897916
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.60 ± 1.64
  Final Train: 97.78 ± 3.85
   Final Test: 66.53 ± 2.28
[I 2023-06-11 23:41:36,184] Trial 390 finished with value: 67.5999984741211 and parameters: {'Fwd': 0.0007174526871594666, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 2.145738653899345, 'loop': 2, 'loss': 'CE', 'lr': 0.001150149566676405, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.306058579478687e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.55
lr:  0.0015785504539001126
weight_decay:  4.013796768449745e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7022689760196954
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 68.50
Split: 01, Run: 02
None time:  0.8180448221974075
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.752666121115908
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 68.70
run time now: 3.305670738220215
total time:  3.364805364049971
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.20
  Final Train: 99.44 ± 0.48
   Final Test: 68.73 ± 0.25
[I 2023-06-11 23:41:40,011] Trial 391 finished with value: 71.80000305175781 and parameters: {'Fwd': 6.520146727186138e-06, 'K': 1, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 8.832245921504622, 'loop': 2, 'loss': 'CE', 'lr': 0.0015785504539001126, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.013796768449745e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.0010820966035459654
weight_decay:  0.0033037058921147277
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8102781029883772
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 65.70
Split: 01, Run: 02
None time:  1.1934204131830484
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.9427013101521879
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 71.10
run time now: 2.980475902557373
total time:  3.045509546995163
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.31
  Final Train: 99.44 ± 0.48
   Final Test: 68.60 ± 2.72
[I 2023-06-11 23:41:43,531] Trial 392 finished with value: 70.13333129882812 and parameters: {'Fwd': 1.7281645023795748e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 8.454058014466899, 'loop': 2, 'loss': 'CE', 'lr': 0.0010820966035459654, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0033037058921147277, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0004522239088768306
weight_decay:  8.00887338667839e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4121560170315206
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.7660018499009311
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.7687395471148193
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.978595733642578
total time:  3.0334402238950133
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.64
  Final Train: 99.72 ± 0.48
   Final Test: 70.40 ± 0.61
[I 2023-06-11 23:41:47,044] Trial 393 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.0005345577062036316, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 3.406333658109643, 'loop': 2, 'loss': 'CE', 'lr': 0.0004522239088768306, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.00887338667839e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.007611414185780695
weight_decay:  5.22218195641148e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6364983380772173
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 63.00
Split: 01, Run: 02
None time:  0.6249664288479835
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.722435041796416
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 68.90
run time now: 2.022012948989868
total time:  2.0687277808319777
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 3.32
  Final Train: 100.00 ± 0.00
   Final Test: 67.20 ± 3.66
[I 2023-06-11 23:41:49,632] Trial 394 finished with value: 69.13333129882812 and parameters: {'Fwd': 4.866511439353221e-05, 'K': 2, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 9.142875504618829, 'loop': 2, 'loss': 'MSE', 'lr': 0.007611414185780695, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.22218195641148e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.1
lr:  0.0031675906165851775
weight_decay:  5.1294224383066935e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8541851681657135
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.50
Split: 01, Run: 02
None time:  0.9467369311023504
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 93.33
   Final Test: 66.40
Split: 01, Run: 03
None time:  0.685587891144678
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 68.50
run time now: 2.5257303714752197
total time:  2.574011341901496
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.87 ± 1.90
  Final Train: 97.50 ± 3.63
   Final Test: 66.80 ± 1.54
[I 2023-06-11 23:41:52,685] Trial 395 finished with value: 67.86666107177734 and parameters: {'Fwd': 1.2757988361455582e-05, 'K': 4, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 3.8056593887061165, 'loop': 2, 'loss': 'CE', 'lr': 0.0031675906165851775, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.1294224383066935e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.009249359347489158
weight_decay:  2.9072890299350934e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6101469839923084
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 60.00
Split: 01, Run: 02
None time:  0.5493810540065169
None Run 02:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.30
Split: 01, Run: 03
None time:  0.6952305810991675
None Run 03:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 47.50
run time now: 1.90153169631958
total time:  1.956599002936855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.20 ± 5.90
  Final Train: 100.00 ± 0.00
   Final Test: 54.27 ± 6.31
[I 2023-06-11 23:41:55,230] Trial 396 finished with value: 56.20000076293945 and parameters: {'Fwd': 0.0008882055961718482, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 6.419302769546616, 'loop': 2, 'loss': 'CE', 'lr': 0.009249359347489158, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.9072890299350934e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0063761961596910345
weight_decay:  0.00015453627739092442
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3610774921253324
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.6235181330703199
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  0.6086105857975781
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.6272356510162354
total time:  2.679386102827266
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 69.27 ± 1.65
[I 2023-06-11 23:41:58,398] Trial 397 finished with value: 72.9333267211914 and parameters: {'Fwd': 0.0014414587317459417, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 9.699849093472746, 'loop': 2, 'loss': 'CE', 'lr': 0.0063761961596910345, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00015453627739092442, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.009998232661268376
weight_decay:  1.8075693816269257e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4826499631162733
None Run 01:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 48.30
Split: 01, Run: 02
None time:  0.880261244950816
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  0.4342393158003688
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 67.10
run time now: 1.830476999282837
total time:  1.8795271711423993
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.67 ± 10.98
  Final Train: 100.00 ± 0.00
   Final Test: 61.10 ± 11.09
[I 2023-06-11 23:42:00,803] Trial 398 finished with value: 63.66666793823242 and parameters: {'Fwd': 0.000431696964524077, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.2, 'lambda2': 9.508610866007277, 'loop': 2, 'loss': 'CE', 'lr': 0.009998232661268376, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.8075693816269257e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0038195782272140845
weight_decay:  0.0007234168300529159
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8963080211542547
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.6964667129795998
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.59599035885185
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.228961944580078
total time:  2.282573736971244
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.07 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.47 ± 0.71
[I 2023-06-11 23:42:03,557] Trial 399 finished with value: 73.0666732788086 and parameters: {'Fwd': 3.937426346336592e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 8.736643931967595, 'loop': 2, 'loss': 'CE', 'lr': 0.0038195782272140845, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007234168300529159, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008384459763703946
weight_decay:  0.00010218858321917478
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2548271750565618
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 94.17
   Final Test: 71.80
Split: 01, Run: 02
None time:  0.6685460349544883
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.6352373319678009
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.592628240585327
total time:  2.650799463968724
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.73 ± 1.10
  Final Train: 98.06 ± 3.37
   Final Test: 71.13 ± 0.61
[I 2023-06-11 23:42:06,721] Trial 400 finished with value: 73.73332977294922 and parameters: {'Fwd': 2.3211305879958317e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 4.337316217322687, 'loop': 2, 'loss': 'CE', 'lr': 0.008384459763703946, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010218858321917478, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0022178109266758235
weight_decay:  7.151748715434968e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7288659238256514
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 02
None time:  0.9144417310599238
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 99.17
   Final Test: 65.70
Split: 01, Run: 03
None time:  0.6980227960739285
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.00
run time now: 2.376368522644043
total time:  2.4309373958967626
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.31
  Final Train: 99.72 ± 0.48
   Final Test: 66.73 ± 0.93
[I 2023-06-11 23:42:09,643] Trial 401 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.0010718482140801727, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 5.685613889376139, 'loop': 2, 'loss': 'CE', 'lr': 0.0022178109266758235, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.151748715434968e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.006909551856296406
weight_decay:  0.0002269528835465298
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.935146062169224
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.9369143221992999
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  0.8554875361733139
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.7621090412139893
total time:  2.8158661238849163
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.50 ± 0.72
[I 2023-06-11 23:42:12,978] Trial 402 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0007020265757076539, 'K': 3, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.121122731806716, 'loop': 2, 'loss': 'CE', 'lr': 0.006909551856296406, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002269528835465298, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.005788202685292046
weight_decay:  6.570932146707632e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5154327049385756
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 82.50
   Final Test: 64.90
Split: 01, Run: 02
None time:  0.9848971180617809
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 92.50
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.7127295651007444
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 65.20
run time now: 3.24452543258667
total time:  3.293543249834329
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 1.73
  Final Train: 91.67 ± 8.78
   Final Test: 66.43 ± 2.40
[I 2023-06-11 23:42:16,826] Trial 403 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.0031182977547415227, 'K': 1, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 1.032309130819168, 'loop': 2, 'loss': 'CE', 'lr': 0.005788202685292046, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.570932146707632e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.00021574093653498695
weight_decay:  3.8693794706336935e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6286403560079634
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 94.17
   Final Test: 68.80
Split: 01, Run: 02
None time:  0.8074589089956135
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.7593843000940979
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.2292568683624268
total time:  3.2834614149760455
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 1.63
  Final Train: 98.06 ± 3.37
   Final Test: 69.83 ± 0.91
[I 2023-06-11 23:42:20,577] Trial 404 finished with value: 72.26667022705078 and parameters: {'Fwd': 0.0019482164703615173, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 4.2094905170400025, 'loop': 2, 'loss': 'CE', 'lr': 0.00021574093653498695, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.8693794706336935e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.007802264869005026
weight_decay:  5.773722281935042e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6286665110383183
None Run 01:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 56.10
Split: 01, Run: 02
None time:  0.6358087589032948
None Run 02:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 46.70
Split: 01, Run: 03
None time:  0.6367632618639618
None Run 03:
Highest Train: 100.00
Highest Valid: 34.60
  Final Train: 100.00
   Final Test: 38.30
run time now: 1.933777093887329
total time:  1.9880592850968242
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 45.20 ± 11.25
  Final Train: 100.00 ± 0.00
   Final Test: 47.03 ± 8.90
[I 2023-06-11 23:42:23,052] Trial 405 finished with value: 45.20000076293945 and parameters: {'Fwd': 1.2076101284655225e-06, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 8.155455707490304, 'loop': 2, 'loss': 'CE', 'lr': 0.007802264869005026, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.773722281935042e-05, 'weightedloss': False}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.005069446636512114
weight_decay:  2.5965333506527217e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4381420481950045
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.8290027829352766
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.7297784241382033
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.20
run time now: 3.0346107482910156
total time:  3.085230011958629
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 2.12
  Final Train: 100.00 ± 0.00
   Final Test: 71.20 ± 1.05
[I 2023-06-11 23:42:26,636] Trial 406 finished with value: 72.0 and parameters: {'Fwd': 0.0005561950150037135, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.1, 'lambda2': 9.345929956146025, 'loop': 2, 'loss': 'CE', 'lr': 0.005069446636512114, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.5965333506527217e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.008655230047340095
weight_decay:  0.00046716153594810524
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4945095169823617
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 96.67
   Final Test: 67.90
Split: 01, Run: 02
None time:  0.6108906317967921
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  0.6534403129480779
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.7913506031036377
total time:  2.839403775986284
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 1.33
  Final Train: 98.89 ± 1.92
   Final Test: 68.30 ± 1.25
[I 2023-06-11 23:42:29,954] Trial 407 finished with value: 69.13333892822266 and parameters: {'Fwd': 0.0013776563859231536, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.762306901356984, 'loop': 2, 'loss': 'CE', 'lr': 0.008655230047340095, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00046716153594810524, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.007412466280497549
weight_decay:  3.214167312643633e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0888572600670159
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 97.50
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.5248647818807513
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.5519876799080521
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.2047319412231445
total time:  2.259992507053539
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 1.33
  Final Train: 99.17 ± 1.44
   Final Test: 69.47 ± 0.15
[I 2023-06-11 23:42:32,697] Trial 408 finished with value: 72.26666259765625 and parameters: {'Fwd': 3.149277539114337e-06, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.2, 'lambda2': 3.125929961335294, 'loop': 2, 'loss': 'CE', 'lr': 0.007412466280497549, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.214167312643633e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.006441543039250075
weight_decay:  0.00012060959955858954
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0248958070296794
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.8550021590199322
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.6175069420132786
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 2.529128074645996
total time:  2.586332487175241
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.50
  Final Train: 99.44 ± 0.48
   Final Test: 69.50 ± 0.36
[I 2023-06-11 23:42:35,776] Trial 409 finished with value: 71.53333282470703 and parameters: {'Fwd': 9.277621566819258e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.605894551322006, 'loop': 2, 'loss': 'CE', 'lr': 0.006441543039250075, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012060959955858954, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.009278940422008736
weight_decay:  4.7192629837769916e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.20627690409310162
None Run 01:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 41.00
Split: 01, Run: 02
None time:  0.17896719998680055
None Run 02:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 36.20
Split: 01, Run: 03
None time:  0.43362282402813435
None Run 03:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 39.10
run time now: 0.8534953594207764
total time:  0.904223594116047
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 39.67 ± 2.93
  Final Train: 100.00 ± 0.00
   Final Test: 38.77 ± 2.42
[I 2023-06-11 23:42:37,131] Trial 410 finished with value: 39.66666793823242 and parameters: {'Fwd': 0.0008950049518628609, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 0, 'lambda1': 0.30000000000000004, 'lambda2': 7.322168583687271, 'loop': 2, 'loss': 'CE', 'lr': 0.009278940422008736, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.7192629837769916e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.0004907020469361642
weight_decay:  7.796047169188057e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2708225860260427
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.6417927669826895
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 03
None time:  0.6476332719903439
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.20
run time now: 2.5985968112945557
total time:  2.65505903493613
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.67 ± 0.50
  Final Train: 99.72 ± 0.48
   Final Test: 71.23 ± 1.25
[I 2023-06-11 23:42:40,243] Trial 411 finished with value: 72.66666412353516 and parameters: {'Fwd': 1.4442236093711128e-05, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 8.874940595395595, 'loop': 2, 'loss': 'CE', 'lr': 0.0004907020469361642, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.796047169188057e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.00802202655821374
weight_decay:  1.0265207785483898e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7965192070696503
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  1.1647083489224315
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.775916701881215
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.50
run time now: 2.7688143253326416
total time:  2.812809205148369
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 71.13 ± 0.32
[I 2023-06-11 23:42:43,531] Trial 412 finished with value: 72.73332977294922 and parameters: {'Fwd': 0.000382275408334024, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 9.589055935489263, 'loop': 2, 'loss': 'CE', 'lr': 0.00802202655821374, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0265207785483898e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0071083755204669205
weight_decay:  0.0001767130821983649
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7277578378561884
None Run 01:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.50
Split: 01, Run: 02
None time:  0.9451355028431863
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.40
Split: 01, Run: 03
None time:  0.72690434101969
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.4342050552368164
total time:  2.481318778824061
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.40 ± 3.08
  Final Train: 100.00 ± 0.00
   Final Test: 67.10 ± 2.46
[I 2023-06-11 23:42:46,486] Trial 413 finished with value: 67.4000015258789 and parameters: {'Fwd': 0.00014610976077810174, 'K': 2, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.015263245787555, 'loop': 2, 'loss': 'MSE', 'lr': 0.0071083755204669205, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001767130821983649, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008482468480853989
weight_decay:  3.212252529481229e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5792285108473152
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 63.90
Split: 01, Run: 02
None time:  0.8099965050350875
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 03
None time:  0.6184240051079541
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.30
run time now: 2.039346218109131
total time:  2.0936902870889753
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 4.16
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 5.19
[I 2023-06-11 23:42:49,047] Trial 414 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.03192023011937262, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.362557175327629, 'loop': 1, 'loss': 'CE', 'lr': 0.008482468480853989, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.212252529481229e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.0018685272481561662
weight_decay:  2.0357558327293617e-05
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7455727159976959
None Run 01:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.40
Split: 01, Run: 02
None time:  0.7500064959749579
None Run 02:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 54.00
Split: 01, Run: 03
None time:  0.6882292090449482
None Run 03:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 51.50
run time now: 2.216860771179199
total time:  2.2619551778770983
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.27 ± 7.31
  Final Train: 100.00 ± 0.00
   Final Test: 55.97 ± 5.71
[I 2023-06-11 23:42:51,787] Trial 415 finished with value: 56.266666412353516 and parameters: {'Fwd': 0.0002609048281188489, 'K': 2, 'alpha': 0.2, 'dropout': 0.0, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 2.211783169825897, 'loop': 2, 'loss': 'CE', 'lr': 0.0018685272481561662, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.0357558327293617e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00908559950536606
weight_decay:  9.249169306815077e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5718753051478416
None Run 01:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 54.00
Split: 01, Run: 02
None time:  0.9414053740911186
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.49355410202406347
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.40
run time now: 2.0401611328125
total time:  2.088779893005267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.53 ± 9.73
  Final Train: 99.72 ± 0.48
   Final Test: 63.80 ± 8.49
[I 2023-06-11 23:42:54,326] Trial 416 finished with value: 65.53333282470703 and parameters: {'Fwd': 2.9689936261735177e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 8.415046918309907, 'loop': 2, 'loss': 'CE', 'lr': 0.00908559950536606, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.249169306815077e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.007765527603461549
weight_decay:  8.5509502773264e-06
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6664610779844224
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 53.60
Split: 01, Run: 02
None time:  0.7162202070467174
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.80
Split: 01, Run: 03
None time:  0.6195638971403241
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.80
run time now: 2.0458364486694336
total time:  2.0953121641650796
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.33 ± 9.64
  Final Train: 100.00 ± 0.00
   Final Test: 62.07 ± 7.48
[I 2023-06-11 23:42:56,916] Trial 417 finished with value: 62.33333206176758 and parameters: {'Fwd': 0.0011930883197326884, 'K': 8, 'alpha': 0.1, 'dropout': 0.1, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 1.2230300191190797, 'loop': 2, 'loss': 'CE', 'lr': 0.007765527603461549, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.5509502773264e-06, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.004462128911420691
weight_decay:  0.06936345528156344
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8776138790417463
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 67.00
Split: 01, Run: 02
None time:  0.721748269861564
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 66.00
Split: 01, Run: 03
None time:  0.5802406938746572
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.70
run time now: 2.2140119075775146
total time:  2.266331563005224
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 0.70
  Final Train: 99.44 ± 0.48
   Final Test: 66.90 ± 0.85
[I 2023-06-11 23:42:59,718] Trial 418 finished with value: 69.86666107177734 and parameters: {'Fwd': 1.8940788816417606e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 3.23241840108144, 'loop': 2, 'loss': 'CE', 'lr': 0.004462128911420691, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.06936345528156344, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0054806455099817636
weight_decay:  0.045001494437490755
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5512246440630406
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.5864063219632953
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 03
None time:  0.5778778567910194
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.750379800796509
total time:  2.8003086731769145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 68.27 ± 2.19
[I 2023-06-11 23:43:03,020] Trial 419 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.0007130912861009728, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.810529102554957, 'loop': 2, 'loss': 'CE', 'lr': 0.0054806455099817636, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.045001494437490755, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006775541378082769
weight_decay:  0.00024656233657163826
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0142805729992688
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 67.90
Split: 01, Run: 02
None time:  0.572741094045341
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.6905601599719375
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.3106818199157715
total time:  2.35823798016645
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.50
  Final Train: 99.72 ± 0.48
   Final Test: 68.57 ± 0.59
[I 2023-06-11 23:43:05,849] Trial 420 finished with value: 71.13333129882812 and parameters: {'Fwd': 5.931819766472013e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 6.75619668670617, 'loop': 2, 'loss': 'CE', 'lr': 0.006775541378082769, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00024656233657163826, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0008892332159643703
weight_decay:  4.9383219546577266e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3102216909173876
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 99.17
   Final Test: 67.20
Split: 01, Run: 02
None time:  0.9381805451121181
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9064500799868256
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 67.50
run time now: 3.1881444454193115
total time:  3.2432239789050072
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 2.34
  Final Train: 99.44 ± 0.48
   Final Test: 68.27 ± 1.59
[I 2023-06-11 23:43:09,614] Trial 421 finished with value: 70.26667022705078 and parameters: {'Fwd': 7.382112180016179e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 2.9452217088986656, 'loop': 2, 'loss': 'CE', 'lr': 0.0008892332159643703, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.9383219546577266e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.00924687854524491
weight_decay:  0.01946260216588759
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6064769299700856
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.8389837809372693
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.3664931550156325
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 4.845840930938721
total time:  4.897557959891856
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.20
  Final Train: 99.44 ± 0.48
   Final Test: 70.13 ± 0.49
[I 2023-06-11 23:43:15,031] Trial 422 finished with value: 71.0 and parameters: {'Fwd': 0.001647542376799522, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 7.574812099850011, 'loop': 2, 'loss': 'CE', 'lr': 0.00924687854524491, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01946260216588759, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0026877616468557334
weight_decay:  6.728656970759229e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5259, Train: 100.00%, Valid: 71.60% Test: 71.30%
Split: 01, Run: 01
None time:  1.7802155339159071
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.5694146470632404
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.5102793839760125
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.20
run time now: 2.8936431407928467
total time:  2.942352752899751
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 69.07 ± 2.07
[I 2023-06-11 23:43:18,450] Trial 423 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.0001762384419798918, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.1, 'lambda2': 9.211334524127663, 'loop': 2, 'loss': 'CE', 'lr': 0.0026877616468557334, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.728656970759229e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.009975120074019876
weight_decay:  0.0008311559054471638
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6149952309206128
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.50
Split: 01, Run: 02
None time:  0.6430180680472404
None Run 02:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 53.20
Split: 01, Run: 03
None time:  0.6264078549575061
None Run 03:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 51.50
run time now: 1.9176104068756104
total time:  1.9598773319739848
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.20 ± 5.97
  Final Train: 100.00 ± 0.00
   Final Test: 55.73 ± 5.92
[I 2023-06-11 23:43:20,876] Trial 424 finished with value: 55.20000076293945 and parameters: {'Fwd': 0.007311654882977481, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.992907993481207, 'loop': 2, 'loss': 'CE', 'lr': 0.009975120074019876, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008311559054471638, 'weightedloss': False}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.006204769081513624
weight_decay:  0.00036425939127623176
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.926361545920372
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 94.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  0.5879289139993489
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.6132217429112643
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 68.70
run time now: 2.1708288192749023
total time:  2.214988865889609
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 1.01
  Final Train: 97.50 ± 2.89
   Final Test: 69.93 ± 1.07
[I 2023-06-11 23:43:23,572] Trial 425 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.0005580263699328795, 'K': 10, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 2.361810946548509, 'loop': 2, 'loss': 'CE', 'lr': 0.006204769081513624, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00036425939127623176, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0013677195035583436
weight_decay:  3.676415214977728e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1034120039548725
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  0.9937547859735787
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.6998367561027408
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.831653118133545
total time:  2.885436886223033
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.40
  Final Train: 99.72 ± 0.48
   Final Test: 70.10 ± 0.82
[I 2023-06-11 23:43:26,950] Trial 426 finished with value: 72.0 and parameters: {'Fwd': 0.00093938326096808, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 9.585537490027468, 'loop': 2, 'loss': 'CE', 'lr': 0.0013677195035583436, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.676415214977728e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.007685639573935794
weight_decay:  0.012439772392837794
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8901189360767603
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 96.67
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.6749360908288509
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.7567028570920229
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.355999231338501
total time:  2.4085909510031343
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.87 ± 1.10
  Final Train: 98.61 ± 1.73
   Final Test: 71.30 ± 0.10
[I 2023-06-11 23:43:29,856] Trial 427 finished with value: 73.86666107177734 and parameters: {'Fwd': 4.5970159341896776e-05, 'K': 3, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 1.5309928512888327, 'loop': 2, 'loss': 'CE', 'lr': 0.007685639573935794, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.012439772392837794, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0012169421378206442
weight_decay:  0.0001282957400944071
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6836142020765692
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 99.17
   Final Test: 71.70
Split: 01, Run: 02
None time:  0.6762232941109687
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.6797159798443317
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.90
run time now: 2.0731189250946045
total time:  2.124517629155889
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 1.33
  Final Train: 99.44 ± 0.48
   Final Test: 70.57 ± 1.33
[I 2023-06-11 23:43:32,471] Trial 428 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.002178102280202611, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 3.6659418893516573, 'loop': 1, 'loss': 'CE', 'lr': 0.0012169421378206442, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001282957400944071, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.004167087521827071
weight_decay:  2.2824842981150193e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5785417729057372
None Run 01:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 52.90
Split: 01, Run: 02
None time:  0.9527852560859174
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.6032813549973071
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.172421455383301
total time:  2.23186320788227
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.53 ± 10.34
  Final Train: 99.72 ± 0.48
   Final Test: 63.73 ± 9.39
[I 2023-06-11 23:43:35,332] Trial 429 finished with value: 64.53333282470703 and parameters: {'Fwd': 3.5818209015992395e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 6.5818592262122655, 'loop': 2, 'loss': 'CE', 'lr': 0.004167087521827071, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2824842981150193e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0008156525769072895
weight_decay:  1.5552446015056427e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7052020500414073
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 02
None time:  1.4223264909815043
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 94.17
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.6198924689088017
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.70
run time now: 2.7798011302948
total time:  2.825752642005682
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.95
  Final Train: 98.06 ± 3.37
   Final Test: 68.17 ± 0.61
[I 2023-06-11 23:43:38,752] Trial 430 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.00047503334083214867, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 4.938144151654556, 'loop': 2, 'loss': 'CE', 'lr': 0.0008156525769072895, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.5552446015056427e-05, 'weightedloss': True}. Best is trial 250 with value: 74.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.008622389759965779
weight_decay:  8.774986994060111e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1637768691871315
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 02
None time:  0.5602520820684731
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.6383551878388971
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.3953609466552734
total time:  2.4448232951108366
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.93 ± 1.42
  Final Train: 100.00 ± 0.00
   Final Test: 71.27 ± 0.38
[I 2023-06-11 23:43:41,682] Trial 431 finished with value: 74.93334197998047 and parameters: {'Fwd': 0.0007746290645325757, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 8.880677113134627, 'loop': 2, 'loss': 'CE', 'lr': 0.008622389759965779, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.774986994060111e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.00867115776191752
weight_decay:  0.00016676486603024124
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3443993439432234
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.5916188359260559
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 66.00
Split: 01, Run: 03
None time:  0.6430872888304293
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.6185476779937744
total time:  2.6734160848427564
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.47 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.10 ± 2.79
[I 2023-06-11 23:43:44,825] Trial 432 finished with value: 72.46666717529297 and parameters: {'Fwd': 0.000608201734656416, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.663989294114906, 'loop': 2, 'loss': 'CE', 'lr': 0.00867115776191752, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00016676486603024124, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.008359163618082685
weight_decay:  9.760943079575346e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.00% Test: 49.10%
Split: 01, Run: 01
None time:  0.8548021919559687
None Run 01:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 49.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.00% Test: 49.10%
Split: 01, Run: 02
None time:  0.8308109289500862
None Run 02:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 49.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.00% Test: 49.10%
Split: 01, Run: 03
None time:  0.8038091398775578
None Run 03:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 49.00
run time now: 2.5244081020355225
total time:  2.571819531964138
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.00 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 49.00 ± 0.00
[I 2023-06-11 23:43:47,854] Trial 433 finished with value: 49.0 and parameters: {'Fwd': 0.08970595221330588, 'K': 3, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.0, 'lambda2': 8.895078659550498, 'loop': 0, 'loss': 'CE', 'lr': 0.008359163618082685, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.760943079575346e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.003046163105563339
weight_decay:  1.187144231835252e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7209949579555541
None Run 01:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 55.80
Split: 01, Run: 02
None time:  1.428787562996149
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  0.6644576578401029
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.20
run time now: 2.8482890129089355
total time:  2.901752832811326
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.47 ± 4.91
  Final Train: 100.00 ± 0.00
   Final Test: 63.37 ± 6.55
[I 2023-06-11 23:43:51,233] Trial 434 finished with value: 65.46666717529297 and parameters: {'Fwd': 0.0008595902118967817, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 5.512543121831289, 'loop': 2, 'loss': 'MSE', 'lr': 0.003046163105563339, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.187144231835252e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.006954999606580744
weight_decay:  0.09383376488700935
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0739789751823992
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.40
Split: 01, Run: 02
None time:  0.714991427026689
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  0.6437403031159192
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.20
run time now: 2.466249465942383
total time:  2.52621663804166
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 67.70 ± 0.44
[I 2023-06-11 23:43:54,214] Trial 435 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.0007403554426604333, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 8.400996977739034, 'loop': 2, 'loss': 'CE', 'lr': 0.006954999606580744, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.09383376488700935, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.009292718794600299
weight_decay:  5.308292165497313e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2017974979244173
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 87.50
   Final Test: 67.70
Split: 01, Run: 02
None time:  0.5711821170989424
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.5828317299019545
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.390205144882202
total time:  2.4493350270204246
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 1.70
  Final Train: 95.83 ± 7.22
   Final Test: 69.63 ± 1.68
[I 2023-06-11 23:43:57,153] Trial 436 finished with value: 70.53333282470703 and parameters: {'Fwd': 2.4729119738720603e-05, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 0.748159344366242, 'loop': 2, 'loss': 'CE', 'lr': 0.009292718794600299, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.308292165497313e-06, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.2
lr:  0.008205547789277989
weight_decay:  0.00019447917418181118
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7104550329968333
None Run 01:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 54.10
Split: 01, Run: 02
None time:  0.8250332209281623
None Run 02:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 93.33
   Final Test: 53.40
Split: 01, Run: 03
None time:  0.5973220078740269
None Run 03:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 64.50
run time now: 2.1714086532592773
total time:  2.2285553789697587
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.00 ± 3.98
  Final Train: 97.78 ± 3.85
   Final Test: 57.33 ± 6.22
[I 2023-06-11 23:43:59,941] Trial 437 finished with value: 54.0 and parameters: {'Fwd': 0.00035249353949771213, 'K': 5, 'alpha': 0.2, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.085581531179832, 'loop': 2, 'loss': 'CE', 'lr': 0.008205547789277989, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019447917418181118, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.009960290738268526
weight_decay:  5.7907351500132196e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0195852778851986
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.572158140828833
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.5944514949806035
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.2193596363067627
total time:  2.2673982169944793
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 70.97 ± 0.55
[I 2023-06-11 23:44:02,697] Trial 438 finished with value: 73.39999389648438 and parameters: {'Fwd': 1.0745529351622569e-05, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 8.775169267731961, 'loop': 1, 'loss': 'CE', 'lr': 0.009960290738268526, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.7907351500132196e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007333676141690865
weight_decay:  0.00012529307617106282
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6139447409659624
None Run 01:
Highest Train: 100.00
Highest Valid: 36.40
  Final Train: 100.00
   Final Test: 38.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0229, Train: 84.17%, Valid: 61.20% Test: 61.10%
Split: 01, Run: 02
None time:  1.7953787250444293
None Run 02:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 85.00
   Final Test: 60.50
Split: 01, Run: 03
None time:  0.9676802149042487
None Run 03:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 96.67
   Final Test: 63.50
run time now: 3.4087765216827393
total time:  3.4555963079910725
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.00 ± 15.33
  Final Train: 93.89 ± 7.88
   Final Test: 54.03 ± 13.88
[I 2023-06-11 23:44:06,624] Trial 439 finished with value: 54.0 and parameters: {'Fwd': 0.0006706206655830735, 'K': 1, 'alpha': 0.05, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 2.7712897045527636, 'loop': 2, 'loss': 'CE', 'lr': 0.007333676141690865, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012529307617106282, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.002327847414990563
weight_decay:  1.0845273465227073e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.691773071885109
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 02
None time:  1.0224873051047325
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 03
None time:  1.306004909100011
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.0525310039520264
total time:  3.112551460042596
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 1.91
  Final Train: 100.00 ± 0.00
   Final Test: 68.00 ± 2.04
[I 2023-06-11 23:44:10,257] Trial 440 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.004003751585670376, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 4.065873789446204, 'loop': 2, 'loss': 'CE', 'lr': 0.002327847414990563, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0845273465227073e-06, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.0058796939716378345
weight_decay:  0.007119950281483653
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8215351640246809
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 02
None time:  0.7179671998601407
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  0.6577814540360123
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.50
run time now: 2.230491876602173
total time:  2.2804269860498607
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 67.60 ± 0.90
[I 2023-06-11 23:44:13,084] Trial 441 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.000458563892198038, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 7.913778113330559, 'loop': 2, 'loss': 'CE', 'lr': 0.0058796939716378345, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007119950281483653, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0014719686347481485
weight_decay:  7.441735627046544e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9360316449310631
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.1790546239353716
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.6651867711916566
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.814119338989258
total time:  2.8676184888463467
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 1.22
  Final Train: 99.72 ± 0.48
   Final Test: 70.57 ± 1.31
[I 2023-06-11 23:44:16,540] Trial 442 finished with value: 72.0666732788086 and parameters: {'Fwd': 0.00011814221170637413, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.134709887199767, 'loop': 2, 'loss': 'CE', 'lr': 0.0014719686347481485, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.441735627046544e-06, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008750486997872795
weight_decay:  4.1015576900731314e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9583363709971309
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.5486486509907991
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.5477145039476454
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 2.0878384113311768
total time:  2.1376560549251735
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.13 ± 0.50
  Final Train: 99.72 ± 0.48
   Final Test: 69.67 ± 1.10
[I 2023-06-11 23:44:19,245] Trial 443 finished with value: 73.13333129882812 and parameters: {'Fwd': 0.0010403613236702528, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 4.623425744890589, 'loop': 2, 'loss': 'CE', 'lr': 0.008750486997872795, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.1015576900731314e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.65
lr:  0.001981638221264595
weight_decay:  8.516972669065794e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6237831921316683
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.30
Split: 01, Run: 02
None time:  1.0343765639699996
None Run 02:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 98.33
   Final Test: 61.40
Split: 01, Run: 03
None time:  0.6829682160168886
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 63.80
run time now: 2.3828160762786865
total time:  2.4318612329661846
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.87 ± 2.08
  Final Train: 99.44 ± 0.96
   Final Test: 62.83 ± 1.27
[I 2023-06-11 23:44:22,317] Trial 444 finished with value: 62.866668701171875 and parameters: {'Fwd': 1.661397056094338e-06, 'K': 4, 'alpha': 0.65, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 8.581746851085317, 'loop': 2, 'loss': 'CE', 'lr': 0.001981638221264595, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.516972669065794e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00496495071399043
weight_decay:  4.712670554549755e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6557650959584862
None Run 01:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 59.10
Split: 01, Run: 02
None time:  0.616002889117226
None Run 02:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 03
None time:  0.5840326210018247
None Run 03:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 52.70
run time now: 1.8896067142486572
total time:  1.941387448925525
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.87 ± 4.79
  Final Train: 100.00 ± 0.00
   Final Test: 54.43 ± 4.09
[I 2023-06-11 23:44:24,714] Trial 445 finished with value: 52.86666488647461 and parameters: {'Fwd': 1.6386160235959455e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 0.597141015436133, 'loop': 2, 'loss': 'CE', 'lr': 0.00496495071399043, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.712670554549755e-05, 'weightedloss': False}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0007413875519461388
weight_decay:  0.0002767033187995677
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9985116771422327
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 70.70
Split: 01, Run: 02
None time:  1.3358758129179478
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 96.67
   Final Test: 71.40
Split: 01, Run: 03
None time:  0.875670984853059
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 97.50
   Final Test: 72.60
run time now: 3.243016242980957
total time:  3.299784821923822
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 0.40
  Final Train: 97.78 ± 1.27
   Final Test: 71.57 ± 0.96
[I 2023-06-11 23:44:28,553] Trial 446 finished with value: 72.5999984741211 and parameters: {'Fwd': 8.095229783788553e-05, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.15000000000000002, 'lambda2': 2.4118012443677017, 'loop': 2, 'loss': 'CE', 'lr': 0.0007413875519461388, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002767033187995677, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.008053649198969332
weight_decay:  0.00014579523342982264
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.38697566487826407
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.00
Split: 01, Run: 02
None time:  0.9790185198653489
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.660833888920024
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.0590507984161377
total time:  2.113503908040002
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.87 ± 12.53
  Final Train: 99.72 ± 0.48
   Final Test: 64.33 ± 11.55
[I 2023-06-11 23:44:31,131] Trial 447 finished with value: 65.86666870117188 and parameters: {'Fwd': 0.0008095896485423925, 'K': 1, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.2, 'lambda2': 8.944752177899787, 'loop': 2, 'loss': 'CE', 'lr': 0.008053649198969332, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00014579523342982264, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.0003939630964590428
weight_decay:  0.0005585667591000864
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9459130328614265
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.8716115020215511
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  0.706782927038148
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.564546823501587
total time:  2.6081237429752946
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 71.23 ± 0.71
[I 2023-06-11 23:44:34,230] Trial 448 finished with value: 72.20000457763672 and parameters: {'Fwd': 0.00029206408438277407, 'K': 3, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 6.175627807336496, 'loop': 2, 'loss': 'CE', 'lr': 0.0003939630964590428, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005585667591000864, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.00646374237165396
weight_decay:  2.6098809910817462e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0672976979985833
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 71.90
Split: 01, Run: 02
None time:  0.6194566700141877
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.596228500129655
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.20
run time now: 2.3318729400634766
total time:  2.3950246369931847
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.27 ± 0.61
  Final Train: 99.72 ± 0.48
   Final Test: 71.90 ± 0.30
[I 2023-06-11 23:44:37,254] Trial 449 finished with value: 74.26667022705078 and parameters: {'Fwd': 0.0002069634443643844, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.25202100768138, 'loop': 2, 'loss': 'CE', 'lr': 0.00646374237165396, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.6098809910817462e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006447249993949491
weight_decay:  2.2825999383485743e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0629729288630188
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 71.10
Split: 01, Run: 02
None time:  0.5604637099895626
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.6605888758786023
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.90
run time now: 2.317288637161255
total time:  2.365091811865568
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.73 ± 0.64
  Final Train: 99.72 ± 0.48
   Final Test: 70.63 ± 0.64
[I 2023-06-11 23:44:40,066] Trial 450 finished with value: 73.73332977294922 and parameters: {'Fwd': 0.0001979691332935574, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.248185689243572, 'loop': 2, 'loss': 'CE', 'lr': 0.006447249993949491, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2825999383485743e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.005663058682628675
weight_decay:  2.9680423635027252e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6401137099601328
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.2121403240598738
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.7398392069153488
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 67.20
run time now: 3.634640693664551
total time:  3.689465817064047
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 68.53 ± 1.16
[I 2023-06-11 23:44:44,246] Trial 451 finished with value: 70.86666870117188 and parameters: {'Fwd': 5.077141155927441e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 7.3126911502483685, 'loop': 2, 'loss': 'CE', 'lr': 0.005663058682628675, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.9680423635027252e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.00709294202109547
weight_decay:  1.77824024081872e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7977383839897811
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02
None time:  0.7237693660426885
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.8720920789055526
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.30
run time now: 2.4276742935180664
total time:  2.476990981027484
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 1.80
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 1.35
[I 2023-06-11 23:44:47,222] Trial 452 finished with value: 70.73333740234375 and parameters: {'Fwd': 3.0594300139495314e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.2, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 6.949170582604346, 'loop': 2, 'loss': 'MSE', 'lr': 0.00709294202109547, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.77824024081872e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0018115152469909302
weight_decay:  1.3761498082473226e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9640925971325487
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.6371066828723997
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.686961866915226
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.3214616775512695
total time:  3.3695944061037153
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 1.59
  Final Train: 99.72 ± 0.48
   Final Test: 69.60 ± 1.40
[I 2023-06-11 23:44:51,067] Trial 453 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.00021068204243163398, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 7.191412272992173, 'loop': 2, 'loss': 'CE', 'lr': 0.0018115152469909302, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3761498082473226e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0010739081481962547
weight_decay:  3.4367189139239526e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.468076759018004
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.6856036270037293
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.6060165821108967
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 67.40
run time now: 2.793408155441284
total time:  2.835400440962985
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 99.72 ± 0.48
   Final Test: 69.00 ± 1.39
[I 2023-06-11 23:44:54,416] Trial 454 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.00026293652879488295, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.046785033392503, 'loop': 2, 'loss': 'CE', 'lr': 0.0010739081481962547, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.4367189139239526e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.006334525304159644
weight_decay:  2.568585130462871e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2685674040112644
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.6540142470039427
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.6899643938522786
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.6444666385650635
total time:  2.7043214151635766
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.80 ± 0.80
  Final Train: 99.72 ± 0.48
   Final Test: 70.73 ± 0.55
[I 2023-06-11 23:44:57,634] Trial 455 finished with value: 73.79999542236328 and parameters: {'Fwd': 3.913015657230141e-05, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 8.831839891970906, 'loop': 2, 'loss': 'CE', 'lr': 0.006334525304159644, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.568585130462871e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8
lr:  0.005348566655861049
weight_decay:  1.9386369529998903e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5018384028226137
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 64.90
Split: 01, Run: 02
None time:  0.524094854015857
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 03
None time:  0.5294771259650588
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.40
run time now: 1.5899145603179932
total time:  1.6566244009882212
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 65.30 ± 1.15
[I 2023-06-11 23:44:59,850] Trial 456 finished with value: 68.86666870117188 and parameters: {'Fwd': 0.008923244264303907, 'K': 2, 'alpha': 0.8, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 7.753339614551776, 'loop': 0, 'loss': 'CE', 'lr': 0.005348566655861049, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.9386369529998903e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.000937170628020881
weight_decay:  1.0297264430377127e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6111018641386181
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.111454081023112
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 99.17
   Final Test: 68.30
Split: 01, Run: 03
None time:  1.1773298850748688
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.9322924613952637
total time:  3.9915281659923494
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.61
  Final Train: 99.72 ± 0.48
   Final Test: 69.70 ± 1.22
[I 2023-06-11 23:45:04,303] Trial 457 finished with value: 69.93333435058594 and parameters: {'Fwd': 0.00016143810185106783, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.36667159955735, 'loop': 2, 'loss': 'CE', 'lr': 0.000937170628020881, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0297264430377127e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0024001313315939908
weight_decay:  0.00022548906831260253
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9814350190572441
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  0.6402715209405869
None Run 02:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 55.70
Split: 01, Run: 03
None time:  0.5856357151642442
None Run 03:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.10
run time now: 2.2391083240509033
total time:  2.2941237699706107
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.73 ± 7.94
  Final Train: 100.00 ± 0.00
   Final Test: 62.03 ± 7.49
[I 2023-06-11 23:45:07,133] Trial 458 finished with value: 62.733333587646484 and parameters: {'Fwd': 0.0011400013460150435, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 8.27336358836467, 'loop': 2, 'loss': 'CE', 'lr': 0.0024001313315939908, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00022548906831260253, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.008960903734944608
weight_decay:  2.7413538140593237e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.226493971887976
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.8261319040320814
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.3184106380213052
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.60
run time now: 3.4052820205688477
total time:  3.455974742071703
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.61
  Final Train: 99.44 ± 0.48
   Final Test: 70.43 ± 0.21
[I 2023-06-11 23:45:11,055] Trial 459 finished with value: 71.0666732788086 and parameters: {'Fwd': 1.9902321380725485e-05, 'K': 3, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 8.578067732175377, 'loop': 2, 'loss': 'CE', 'lr': 0.008960903734944608, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.7413538140593237e-06, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.009998899706054266
weight_decay:  0.00030159489859229457
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0290881441906095
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 99.17
   Final Test: 71.50
Split: 01, Run: 02
None time:  0.7610881621949375
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 99.17
   Final Test: 72.50
Split: 01, Run: 03
None time:  0.6882010360714048
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.40
run time now: 2.5129778385162354
total time:  2.565839588874951
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.93 ± 0.64
  Final Train: 99.44 ± 0.48
   Final Test: 72.47 ± 0.95
[I 2023-06-11 23:45:14,265] Trial 460 finished with value: 74.93333435058594 and parameters: {'Fwd': 0.040718055557874944, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 5.296262837061286, 'loop': 2, 'loss': 'CE', 'lr': 0.009998899706054266, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00030159489859229457, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.009547655565643555
weight_decay:  0.00042980096725820505
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8265800301451236
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.7147233569994569
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.6369511070661247
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.212275981903076
total time:  2.2701617788989097
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.47 ± 1.33
  Final Train: 99.72 ± 0.48
   Final Test: 70.63 ± 0.71
[I 2023-06-11 23:45:17,099] Trial 461 finished with value: 72.46666717529297 and parameters: {'Fwd': 0.0001044387547923953, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 6.301441069506822, 'loop': 1, 'loss': 'CE', 'lr': 0.009547655565643555, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00042980096725820505, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0015574670295812984
weight_decay:  0.0001597586133913692
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6349865959491581
None Run 01:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 62.30
Split: 01, Run: 02
None time:  1.0919961710460484
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 99.17
   Final Test: 65.60
Split: 01, Run: 03
None time:  0.6705663490574807
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 61.10
run time now: 2.429783582687378
total time:  2.4747787239030004
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.87 ± 4.15
  Final Train: 99.72 ± 0.48
   Final Test: 63.00 ± 2.33
[I 2023-06-11 23:45:20,069] Trial 462 finished with value: 64.86666870117188 and parameters: {'Fwd': 0.045565337869458156, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 4.234214875726513, 'loop': 1, 'loss': 'CE', 'lr': 0.0015574670295812984, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001597586133913692, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.003679683357874838
weight_decay:  0.0003677884925298908
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.2590003148652613
None Run 01:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 47.50
Split: 01, Run: 02
None time:  0.660609123064205
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.3015283471904695
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 1.2549471855163574
total time:  1.3070693670306355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.93 ± 12.95
  Final Train: 99.72 ± 0.48
   Final Test: 62.60 ± 13.08
[I 2023-06-11 23:45:21,940] Trial 463 finished with value: 64.93333435058594 and parameters: {'Fwd': 0.0207855128547526, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 30, 'lambda1': 0.35000000000000003, 'lambda2': 5.382103121842883, 'loop': 1, 'loss': 'CE', 'lr': 0.003679683357874838, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003677884925298908, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0006328465299220112
weight_decay:  4.751589400510716e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0018835349474102
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 02
None time:  0.6765517920721322
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  0.5473608749452978
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 66.30
run time now: 2.257530927658081
total time:  2.310085189063102
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 66.23 ± 0.60
[I 2023-06-11 23:45:24,748] Trial 464 finished with value: 70.60000610351562 and parameters: {'Fwd': 0.02364454162641558, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 7.103935378139865, 'loop': 1, 'loss': 'CE', 'lr': 0.0006328465299220112, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.751589400510716e-06, 'weightedloss': False}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009197286114111776
weight_decay:  0.00029292993169101783
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0289228849578649
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 95.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.6869623840320855
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.6196384551003575
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 2.3701250553131104
total time:  2.4187563320156187
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 1.10
  Final Train: 98.33 ± 2.89
   Final Test: 69.27 ± 0.46
[I 2023-06-11 23:45:27,663] Trial 465 finished with value: 71.06666564941406 and parameters: {'Fwd': 0.031851869781235775, 'K': 2, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 3.9753378157945782, 'loop': 1, 'loss': 'CE', 'lr': 0.009197286114111776, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00029292993169101783, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0032898191560527556
weight_decay:  0.008747011983628521
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.720793348038569
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 68.70
Split: 01, Run: 02
None time:  0.6362483210396022
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 03
None time:  0.7490478160325438
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.1384665966033936
total time:  3.1886101071722806
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.80
  Final Train: 98.89 ± 1.92
   Final Test: 68.30 ± 1.54
[I 2023-06-11 23:45:31,354] Trial 466 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.003393394513787702, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 7.55671048015857, 'loop': 2, 'loss': 'CE', 'lr': 0.0032898191560527556, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008747011983628521, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.000524287715645989
weight_decay:  6.4834138532723785e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8298909820150584
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 02
None time:  1.0183775720652193
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.5670008501037955
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.450124740600586
total time:  2.5035430849529803
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 1.22
  Final Train: 99.72 ± 0.48
   Final Test: 69.43 ± 2.01
[I 2023-06-11 23:45:34,309] Trial 467 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.010256766840223953, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 4.96902626240935, 'loop': 1, 'loss': 'CE', 'lr': 0.000524287715645989, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.4834138532723785e-06, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.007308827841803286
weight_decay:  0.0010315409861898787
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9735378678888083
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.7008846250828356
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.6516768021974713
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.358138084411621
total time:  2.403170645935461
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.67 ± 0.12
  Final Train: 99.72 ± 0.48
   Final Test: 70.53 ± 0.75
[I 2023-06-11 23:45:37,195] Trial 468 finished with value: 72.66666412353516 and parameters: {'Fwd': 0.0003673722502921055, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 5.859913578511848, 'loop': 2, 'loss': 'CE', 'lr': 0.007308827841803286, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0010315409861898787, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.009949767357851884
weight_decay:  0.0003179743240770049
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8557385501917452
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.7507306628394872
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.7225622499827296
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.3627002239227295
total time:  2.419652249896899
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 1.92
  Final Train: 100.00 ± 0.00
   Final Test: 70.23 ± 0.75
[I 2023-06-11 23:45:40,110] Trial 469 finished with value: 72.13333892822266 and parameters: {'Fwd': 0.07276797561562891, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 6.533886896955871, 'loop': 2, 'loss': 'CE', 'lr': 0.009949767357851884, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003179743240770049, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.1
lr:  0.008408244137376054
weight_decay:  0.00020739637652636932
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.885278764879331
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 98.33
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.7187722178641707
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  0.7257984958123416
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 71.20
run time now: 2.369257688522339
total time:  2.4149787698406726
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.81
  Final Train: 99.44 ± 0.96
   Final Test: 70.60 ± 1.22
[I 2023-06-11 23:45:43,008] Trial 470 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.00014557760597588504, 'K': 7, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 4.60385875187083, 'loop': 2, 'loss': 'CE', 'lr': 0.008408244137376054, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00020739637652636932, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0060652222013001435
weight_decay:  0.00026493755723279227
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2599486380349845
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 95.83
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.8522487580776215
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.6194855561479926
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.80
run time now: 2.7658843994140625
total time:  2.8213490799535066
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 0.72
  Final Train: 98.61 ± 2.41
   Final Test: 70.13 ± 0.31
[I 2023-06-11 23:45:46,365] Trial 471 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.013134851043730649, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 3.154821646657273, 'loop': 2, 'loss': 'CE', 'lr': 0.0060652222013001435, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00026493755723279227, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006671536663199215
weight_decay:  9.05690258512588e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7284284420311451
None Run 01:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 53.90
Split: 01, Run: 02
None time:  0.6794359069317579
None Run 02:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.60
Split: 01, Run: 03
None time:  0.65063964901492
None Run 03:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 61.70
run time now: 2.0911409854888916
total time:  2.154558596899733
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.27 ± 2.53
  Final Train: 100.00 ± 0.00
   Final Test: 59.40 ± 4.78
[I 2023-06-11 23:45:49,029] Trial 472 finished with value: 60.26666259765625 and parameters: {'Fwd': 0.023498140178324356, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 5.137619687400637, 'loop': 2, 'loss': 'MSE', 'lr': 0.006671536663199215, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.05690258512588e-06, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007771399581881901
weight_decay:  0.00011157641494296638
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6167394339572638
None Run 01:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 57.40
Split: 01, Run: 02
None time:  0.6259073109831661
None Run 02:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 50.50
Split: 01, Run: 03
None time:  0.6135816930327564
None Run 03:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 40.10
run time now: 1.8879354000091553
total time:  1.9358455929905176
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.60 ± 6.50
  Final Train: 100.00 ± 0.00
   Final Test: 49.33 ± 8.71
[I 2023-06-11 23:45:51,448] Trial 473 finished with value: 54.60000228881836 and parameters: {'Fwd': 0.010960483773033445, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 4.497468010508598, 'loop': 2, 'loss': 'CE', 'lr': 0.007771399581881901, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00011157641494296638, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.009991581315489407
weight_decay:  0.00020388560070380793
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4650237108580768
None Run 01:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 56.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.1149, Train: 85.00%, Valid: 66.80% Test: 67.20%
Split: 01, Run: 02
None time:  1.7468484910205007
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 85.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  0.6402982820291072
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 99.17
   Final Test: 68.70
run time now: 2.888209104537964
total time:  2.9549501449801028
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.87 ± 7.70
  Final Train: 94.72 ± 8.43
   Final Test: 64.10 ± 6.79
[I 2023-06-11 23:45:54,924] Trial 474 finished with value: 62.866668701171875 and parameters: {'Fwd': 0.0027116547276133324, 'K': 2, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 4.803075185087128, 'loop': 2, 'loss': 'CE', 'lr': 0.009991581315489407, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00020388560070380793, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00896453698992426
weight_decay:  0.015166278161864381
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8614294249564409
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  0.8020163469482213
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.7155635110102594
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.415055274963379
total time:  2.4745835319627076
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 69.40 ± 1.00
[I 2023-06-11 23:45:58,025] Trial 475 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.02005689574567726, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 3.692334559083687, 'loop': 2, 'loss': 'CE', 'lr': 0.00896453698992426, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.015166278161864381, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.006959321748068207
weight_decay:  1.6183134378251132e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1637147651053965
None Run 01:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 80.83
   Final Test: 59.50
Split: 01, Run: 02
None time:  1.0017712919507176
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 84.17
   Final Test: 66.40
Split: 01, Run: 03
None time:  0.8322954920586199
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 94.17
   Final Test: 67.80
run time now: 3.039651870727539
total time:  3.0884611140936613
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.67 ± 6.47
  Final Train: 86.39 ± 6.94
   Final Test: 64.57 ± 4.44
[I 2023-06-11 23:46:01,642] Trial 476 finished with value: 64.66666412353516 and parameters: {'Fwd': 0.008106897290967353, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 1.7645969795811973, 'loop': 2, 'loss': 'CE', 'lr': 0.006959321748068207, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6183134378251132e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.008540597147173472
weight_decay:  2.6354010950030618e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8774601579643786
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.6230040360242128
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.6353133372031152
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.50
run time now: 2.174069404602051
total time:  2.2403126491699368
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.83 ± 0.65
[I 2023-06-11 23:46:04,383] Trial 477 finished with value: 73.4000015258789 and parameters: {'Fwd': 0.05332151172302634, 'K': 3, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.45, 'lambda2': 5.291498043771426, 'loop': 2, 'loss': 'CE', 'lr': 0.008540597147173472, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.6354010950030618e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.004692454668423733
weight_decay:  1.1796649162140054e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9314210370648652
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 02
None time:  0.801168684149161
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 03
None time:  0.7240397960413247
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.491844415664673
total time:  2.5470028480049223
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 1.97
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 1.96
[I 2023-06-11 23:46:07,504] Trial 478 finished with value: 73.26667022705078 and parameters: {'Fwd': 0.0002841583977344389, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 5.795174721923287, 'loop': 2, 'loss': 'CE', 'lr': 0.004692454668423733, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1796649162140054e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.004090406677589408
weight_decay:  8.128854255222922e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.089802531991154
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.2655890230089426
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9033431960269809
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.291206121444702
total time:  3.3583358109463006
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.70
[I 2023-06-11 23:46:11,439] Trial 479 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.00021420654806055705, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 6.845372292451803, 'loop': 2, 'loss': 'CE', 'lr': 0.004090406677589408, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.128854255222922e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007654792970528404
weight_decay:  0.00010620028238171151
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8995980371255428
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 94.17
   Final Test: 70.30
Split: 01, Run: 02
None time:  0.6650983549188823
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 95.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  0.619536962825805
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.218125104904175
total time:  2.2733545200899243
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 0.50
  Final Train: 96.39 ± 3.15
   Final Test: 70.80 ± 1.04
[I 2023-06-11 23:46:14,267] Trial 480 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.0032359258271490773, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 0.8888171123084866, 'loop': 2, 'loss': 'CE', 'lr': 0.007654792970528404, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010620028238171151, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.005496104418607588
weight_decay:  0.0018603746915287628
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0990897330921143
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  0.6452768652234226
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 03
None time:  0.7331336250063032
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 68.60
run time now: 2.511202335357666
total time:  2.5668291109614074
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 1.36
  Final Train: 99.72 ± 0.48
   Final Test: 68.70 ± 1.75
[I 2023-06-11 23:46:17,353] Trial 481 finished with value: 72.53333282470703 and parameters: {'Fwd': 0.006521829858703444, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 6.047333537283179, 'loop': 2, 'loss': 'CE', 'lr': 0.005496104418607588, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0018603746915287628, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.002198892296296577
weight_decay:  0.0004059772296916178
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8239449919201434
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.2111805139575154
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 99.17
   Final Test: 66.00
Split: 01, Run: 03
None time:  0.5456931870430708
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.20
run time now: 2.6146457195281982
total time:  2.6692990870215
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 0.72
  Final Train: 99.72 ± 0.48
   Final Test: 68.07 ± 2.00
[I 2023-06-11 23:46:20,550] Trial 482 finished with value: 69.5999984741211 and parameters: {'Fwd': 0.005386111357601363, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.142122118106151, 'loop': 2, 'loss': 'CE', 'lr': 0.002198892296296577, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004059772296916178, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00927566221765217
weight_decay:  0.0001606737346830451
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5895115949679166
None Run 01:
Highest Train: 100.00
Highest Valid: 27.40
  Final Train: 100.00
   Final Test: 27.60
Split: 01, Run: 02
None time:  0.8071343230549246
None Run 02:
Highest Train: 100.00
Highest Valid: 18.80
  Final Train: 100.00
   Final Test: 18.20
Split: 01, Run: 03
None time:  0.6514532219152898
None Run 03:
Highest Train: 100.00
Highest Valid: 21.20
  Final Train: 100.00
   Final Test: 21.30
run time now: 2.080247402191162
total time:  2.1343833319842815
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 22.47 ± 4.44
  Final Train: 100.00 ± 0.00
   Final Test: 22.37 ± 4.79
[I 2023-06-11 23:46:23,175] Trial 483 finished with value: 22.466665267944336 and parameters: {'Fwd': 0.005276369229534767, 'K': 1, 'alpha': 0.1, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 8.793198299808274, 'loop': 2, 'loss': 'CE', 'lr': 0.00927566221765217, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001606737346830451, 'weightedloss': False}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0012326062907846735
weight_decay:  0.0006034059931184145
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7031178399920464
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 02
None time:  0.9890685121063143
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 98.33
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.263438262976706
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 96.67
   Final Test: 70.30
run time now: 3.0086779594421387
total time:  3.071528804022819
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 1.91
  Final Train: 98.33 ± 1.67
   Final Test: 68.50 ± 1.80
[I 2023-06-11 23:46:26,879] Trial 484 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.06496202367769759, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 2.1917576150815856, 'loop': 2, 'loss': 'CE', 'lr': 0.0012326062907846735, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006034059931184145, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.05
lr:  0.008286482524268052
weight_decay:  3.2992165852772405e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8729961838107556
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 93.33
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.5837293940130621
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 67.90
Split: 01, Run: 03
None time:  0.64372926694341
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 68.20
run time now: 2.138903856277466
total time:  2.19749746308662
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.61
  Final Train: 97.22 ± 3.37
   Final Test: 68.57 ± 0.91
[I 2023-06-11 23:46:29,619] Trial 485 finished with value: 71.13333129882812 and parameters: {'Fwd': 0.011908646299029896, 'K': 6, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 1.3272030142608673, 'loop': 2, 'loss': 'CE', 'lr': 0.008286482524268052, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.2992165852772405e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.002614117317686379
weight_decay:  2.1303858936978542e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2149073840118945
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.8625056869350374
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.6446339711546898
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 67.70
run time now: 2.755983352661133
total time:  2.803534678183496
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.42
  Final Train: 99.44 ± 0.48
   Final Test: 68.67 ± 0.84
[I 2023-06-11 23:46:32,939] Trial 486 finished with value: 71.33333587646484 and parameters: {'Fwd': 6.107376467231172e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.483673959622502, 'loop': 2, 'loss': 'CE', 'lr': 0.002614117317686379, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.1303858936978542e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0017016623645854777
weight_decay:  6.727115978937907e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8566516968421638
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 61.60
Split: 01, Run: 02
None time:  1.5278105230536312
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 93.33
   Final Test: 65.60
Split: 01, Run: 03
None time:  0.6279949091840535
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.90
run time now: 3.045231580734253
total time:  3.1028638419229537
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.00 ± 2.82
  Final Train: 97.78 ± 3.85
   Final Test: 64.70 ± 2.76
[I 2023-06-11 23:46:36,511] Trial 487 finished with value: 65.0 and parameters: {'Fwd': 0.0004429492111719529, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 1.9029511264966845, 'loop': 2, 'loss': 'CE', 'lr': 0.0017016623645854777, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.727115978937907e-06, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.006175336604115957
weight_decay:  0.005850451674742434
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.642626313958317
None Run 01:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 43.20
Split: 01, Run: 02
None time:  1.214873577002436
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 99.17
   Final Test: 66.60
Split: 01, Run: 03
None time:  0.7456267210654914
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 99.17
   Final Test: 66.90
run time now: 2.6358606815338135
total time:  2.6781285610049963
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.13 ± 15.01
  Final Train: 99.44 ± 0.48
   Final Test: 58.90 ± 13.60
[I 2023-06-11 23:46:39,692] Trial 488 finished with value: 60.13333511352539 and parameters: {'Fwd': 0.010773743689835136, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 5.4495495344605605, 'loop': 2, 'loss': 'CE', 'lr': 0.006175336604115957, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005850451674742434, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0004159679432410266
weight_decay:  1.4651753511024324e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1279574250802398
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 98.33
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.6199791240505874
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.8593610159587115
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 71.40
run time now: 2.64153790473938
total time:  2.6926372861489654
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 0.95
  Final Train: 99.17 ± 0.83
   Final Test: 70.83 ± 0.81
[I 2023-06-11 23:46:42,842] Trial 489 finished with value: 72.93333435058594 and parameters: {'Fwd': 0.004377341784730224, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 3.503129550924106, 'loop': 2, 'loss': 'CE', 'lr': 0.0004159679432410266, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4651753511024324e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0072710502496841824
weight_decay:  0.0002615436325679632
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2052803090773523
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 98.33
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.6759544829837978
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 65.90
Split: 01, Run: 03
None time:  0.7002166470047086
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 65.20
run time now: 2.613996744155884
total time:  2.6658842291217297
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 1.81
  Final Train: 99.44 ± 0.96
   Final Test: 66.87 ± 2.31
[I 2023-06-11 23:46:45,963] Trial 490 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.027909087693793317, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 2.525669192223065, 'loop': 2, 'loss': 'CE', 'lr': 0.0072710502496841824, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002615436325679632, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.002804057660034389
weight_decay:  0.000140760147637698
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9555147478822619
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.7888345229439437
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.6492497799918056
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.427142858505249
total time:  2.4881177209317684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 0.60
  Final Train: 99.44 ± 0.48
   Final Test: 70.60 ± 0.35
[I 2023-06-11 23:46:48,989] Trial 491 finished with value: 72.79999542236328 and parameters: {'Fwd': 0.0003500742779432171, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 6.40023987664685, 'loop': 2, 'loss': 'CE', 'lr': 0.002804057660034389, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000140760147637698, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.15000000000000002
lr:  0.007917301699306278
weight_decay:  7.483027594188687e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5048525528982282
None Run 01:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 58.10
Split: 01, Run: 02
None time:  0.6340655591338873
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.6995532300788909
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.60
run time now: 1.8763816356658936
total time:  1.9318429320119321
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.73 ± 6.39
  Final Train: 100.00 ± 0.00
   Final Test: 64.20 ± 5.53
[I 2023-06-11 23:46:51,418] Trial 492 finished with value: 64.73332977294922 and parameters: {'Fwd': 0.014254451019295511, 'K': 4, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 8.98610404693556, 'loop': 1, 'loss': 'MSE', 'lr': 0.007917301699306278, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.483027594188687e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0003484804495591526
weight_decay:  3.7426950411157025e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3551773300860077
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.6865904331207275
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  0.6687806530389935
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.7431836128234863
total time:  2.789961560163647
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 1.07
[I 2023-06-11 23:46:54,805] Trial 493 finished with value: 71.53333282470703 and parameters: {'Fwd': 7.854681674250676e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.205159411683217, 'loop': 2, 'loss': 'CE', 'lr': 0.0003484804495591526, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.7426950411157025e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.1
lr:  0.0005683363443477482
weight_decay:  9.660186838401868e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8601651950739324
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  1.2166286339052022
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 72.90
Split: 01, Run: 03
None time:  0.6230005640536547
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.50
run time now: 2.7457735538482666
total time:  2.8016764111816883
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 1.30
  Final Train: 99.72 ± 0.48
   Final Test: 71.77 ± 1.03
[I 2023-06-11 23:46:58,252] Trial 494 finished with value: 72.0666732788086 and parameters: {'Fwd': 0.016279395096647286, 'K': 3, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.127961102379343, 'loop': 2, 'loss': 'CE', 'lr': 0.0005683363443477482, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.660186838401868e-05, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.006649682953672617
weight_decay:  4.107380471923647e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.842426281189546
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.6223451448604465
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.6626062598079443
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 67.20
run time now: 2.160989761352539
total time:  2.207804908975959
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 1.30
  Final Train: 99.72 ± 0.48
   Final Test: 69.37 ± 1.93
[I 2023-06-11 23:47:00,941] Trial 495 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.036364583987144476, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 2.6490093475536276, 'loop': 2, 'loss': 'CE', 'lr': 0.006649682953672617, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.107380471923647e-06, 'weightedloss': True}. Best is trial 431 with value: 74.93334197998047.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00909697128576139
weight_decay:  8.846704394769097e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0677558919414878
None Run 01:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 98.33
   Final Test: 71.60
Split: 01, Run: 02
None time:  0.6871337560005486
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.7228835029527545
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 71.20
run time now: 2.5103540420532227
total time:  2.559842939954251
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.33 ± 0.64
  Final Train: 99.44 ± 0.96
   Final Test: 70.97 ± 0.78
[I 2023-06-11 23:47:04,053] Trial 496 finished with value: 75.33333587646484 and parameters: {'Fwd': 0.008034375689049146, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 3.875005046858585, 'loop': 2, 'loss': 'CE', 'lr': 0.00909697128576139, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.846704394769097e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009194978913875967
weight_decay:  9.64379126080611e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5567, Train: 88.33%, Valid: 72.40% Test: 71.20%
Split: 01, Run: 01
None time:  1.9054456949234009
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 92.50
   Final Test: 72.40
Split: 01, Run: 02
None time:  0.7618262979667634
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.7519747279584408
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.00
run time now: 3.463085889816284
total time:  3.5234726201742887
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 0.83
  Final Train: 97.50 ± 4.33
   Final Test: 71.27 ± 1.03
[I 2023-06-11 23:47:08,172] Trial 497 finished with value: 73.53333282470703 and parameters: {'Fwd': 0.006267475485559797, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.6000000000000001, 'lambda2': 5.62903582128173, 'loop': 2, 'loss': 'CE', 'lr': 0.009194978913875967, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.64379126080611e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009995163440506183
weight_decay:  7.358189980665194e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2015146589837968
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 97.50
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.8032480929978192
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 92.50
   Final Test: 71.20
Split: 01, Run: 03
None time:  1.4948314221110195
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.00
   Final Test: 70.70
run time now: 4.533070802688599
total time:  4.588323251111433
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.31
  Final Train: 95.00 ± 2.50
   Final Test: 70.67 ± 0.55
[I 2023-06-11 23:47:13,265] Trial 498 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.006641144041884987, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 0.37845838407632654, 'loop': 2, 'loss': 'CE', 'lr': 0.009995163440506183, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.358189980665194e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008712879570052118
weight_decay:  1.0850612696767161e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.009088376071304
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.6320350880268961
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.6828016380313784
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.355997323989868
total time:  2.402304673101753
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.80 ± 1.59
  Final Train: 98.33 ± 2.89
   Final Test: 70.27 ± 1.21
[I 2023-06-11 23:47:16,173] Trial 499 finished with value: 73.79999542236328 and parameters: {'Fwd': 0.004371468777663302, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.55, 'lambda2': 2.3025639218638427, 'loop': 2, 'loss': 'CE', 'lr': 0.008712879570052118, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0850612696767161e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0007069058390394079
weight_decay:  7.45363167302065e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.6357, Train: 91.67%, Valid: 69.80% Test: 70.30%
Split: 01, Run: 01
None time:  1.8483747139107436
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 91.67
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.6897390189114958
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.0900024799630046
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.70
run time now: 3.6610543727874756
total time:  3.707477082964033
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 1.04
  Final Train: 96.94 ± 4.59
   Final Test: 70.10 ± 0.60
[I 2023-06-11 23:47:20,358] Trial 500 finished with value: 71.20000457763672 and parameters: {'Fwd': 2.5532659981625214e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 3.413180951183876, 'loop': 2, 'loss': 'CE', 'lr': 0.0007069058390394079, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.45363167302065e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00010612819082463517
weight_decay:  1.2067595126230575e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.870911454083398
None Run 01:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 99.17
   Final Test: 56.10
Split: 01, Run: 02
None time:  0.8934497439768165
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.80
Split: 01, Run: 03
None time:  0.7482319460250437
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.20
run time now: 3.5465810298919678
total time:  3.6005242271348834
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.67 ± 4.61
  Final Train: 99.72 ± 0.48
   Final Test: 62.03 ± 5.28
[I 2023-06-11 23:47:24,448] Trial 501 finished with value: 64.66666412353516 and parameters: {'Fwd': 0.016494044313575935, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.55, 'lambda2': 4.3254467404642, 'loop': 2, 'loss': 'CE', 'lr': 0.00010612819082463517, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2067595126230575e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009167636713546484
weight_decay:  0.0016070994602719426
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6656844310928136
None Run 01:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 57.90
Split: 01, Run: 02
None time:  0.6403941879980266
None Run 02:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 50.50
Split: 01, Run: 03
None time:  0.6086268639191985
None Run 03:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 46.60
run time now: 1.9476370811462402
total time:  2.0086611779406667
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.93 ± 7.44
  Final Train: 100.00 ± 0.00
   Final Test: 51.67 ± 5.74
[I 2023-06-11 23:47:26,964] Trial 502 finished with value: 53.93333053588867 and parameters: {'Fwd': 0.01838622874420117, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 2.8817623165711974, 'loop': 2, 'loss': 'CE', 'lr': 0.009167636713546484, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0016070994602719426, 'weightedloss': False}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00026548292821178645
weight_decay:  0.00090420846793995
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.389233092078939
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 99.17
   Final Test: 67.90
Split: 01, Run: 02
None time:  0.695352358976379
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.8116304080467671
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.929840326309204
total time:  2.98458070284687
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 2.16
  Final Train: 99.72 ± 0.48
   Final Test: 68.60 ± 0.70
[I 2023-06-11 23:47:30,489] Trial 503 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.007890953716846566, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 4.013981250936447, 'loop': 2, 'loss': 'CE', 'lr': 0.00026548292821178645, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00090420846793995, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.005012501426011689
weight_decay:  6.067347596397172e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7513283810112625
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.20
Split: 01, Run: 02
None time:  0.6943790290970355
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.20
Split: 01, Run: 03
None time:  0.6852153278887272
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.20
run time now: 2.1629154682159424
total time:  2.2072415058501065
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.20 ± 0.00
[I 2023-06-11 23:47:33,321] Trial 504 finished with value: 51.20000076293945 and parameters: {'Fwd': 0.013000708271371354, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.0, 'lambda2': 4.58948334152484, 'loop': 0, 'loss': 'CE', 'lr': 0.005012501426011689, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.067347596397172e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008431475993442503
weight_decay:  1.8503177062950313e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.497423263033852
None Run 01:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 50.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.5914, Train: 93.33%, Valid: 70.20% Test: 69.90%
Split: 01, Run: 02
None time:  1.7629670859314501
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.5190231401938945
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.8126139640808105
total time:  2.865351205924526
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.20 ± 11.29
  Final Train: 97.78 ± 3.85
   Final Test: 63.30 ± 11.17
[I 2023-06-11 23:47:36,693] Trial 505 finished with value: 65.20000457763672 and parameters: {'Fwd': 0.025338078614482486, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 4.801665682965208, 'loop': 2, 'loss': 'CE', 'lr': 0.008431475993442503, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.8503177062950313e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007458029781452248
weight_decay:  0.002785879021596555
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.45366771914996207
None Run 01:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 43.00
Split: 01, Run: 02
None time:  0.96432945295237
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 93.33
   Final Test: 71.70
Split: 01, Run: 03
None time:  0.4759649378247559
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 1.9266717433929443
total time:  1.9692821779754013
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.67 ± 18.25
  Final Train: 97.78 ± 3.85
   Final Test: 61.30 ± 15.90
[I 2023-06-11 23:47:39,236] Trial 506 finished with value: 63.66666793823242 and parameters: {'Fwd': 0.02306013448617803, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 40, 'lambda1': 0.65, 'lambda2': 3.3530921557250717, 'loop': 2, 'loss': 'CE', 'lr': 0.007458029781452248, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002785879021596555, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00928278942616762
weight_decay:  8.700858347513137e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3968301909044385
None Run 01:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 88.33
   Final Test: 57.50
Split: 01, Run: 02
None time:  0.7365623938385397
None Run 02:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 66.00
Split: 01, Run: 03
None time:  0.8974252031184733
None Run 03:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 97.50
   Final Test: 66.10
run time now: 3.0650906562805176
total time:  3.1176941560115665
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.20 ± 3.42
  Final Train: 95.28 ± 6.14
   Final Test: 63.20 ± 4.94
[I 2023-06-11 23:47:42,827] Trial 507 finished with value: 59.20000076293945 and parameters: {'Fwd': 0.015882165724175643, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 3.5775278136597732, 'loop': 2, 'loss': 'CE', 'lr': 0.00928278942616762, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.700858347513137e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.002888695243583087
weight_decay:  0.0003105360482210111
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5030246342066675
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 93.33
   Final Test: 65.70
Split: 01, Run: 02
None time:  0.6559821870177984
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 62.70
Split: 01, Run: 03
None time:  0.7321959070395678
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 66.90
run time now: 2.9233953952789307
total time:  2.9696380731184036
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.07 ± 1.79
  Final Train: 97.78 ± 3.85
   Final Test: 65.10 ± 2.16
[I 2023-06-11 23:47:46,346] Trial 508 finished with value: 68.06666564941406 and parameters: {'Fwd': 0.002236673058042329, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.5, 'lambda2': 3.963886460227565, 'loop': 2, 'loss': 'CE', 'lr': 0.002888695243583087, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003105360482210111, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009968844568821422
weight_decay:  0.00018661932289642933
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0432983050122857
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 02
None time:  1.058646939927712
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.1731533820275217
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.306746244430542
total time:  3.359965795883909
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 70.83 ± 0.96
[I 2023-06-11 23:47:50,301] Trial 509 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.003936608398669503, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.05, 'lambda2': 4.4419291491920125, 'loop': 2, 'loss': 'CE', 'lr': 0.009968844568821422, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00018661932289642933, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.008110462704578915
weight_decay:  3.2002610498275566e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6858311360701919
None Run 01:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 51.40
Split: 01, Run: 02
None time:  0.7071851619984955
None Run 02:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 63.80
Split: 01, Run: 03
None time:  0.5660923491232097
None Run 03:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 56.10
run time now: 1.9932246208190918
total time:  2.0483041289262474
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.20 ± 3.94
  Final Train: 100.00 ± 0.00
   Final Test: 57.10 ± 6.26
[I 2023-06-11 23:47:52,976] Trial 510 finished with value: 59.20000076293945 and parameters: {'Fwd': 0.06627789555448668, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.35000000000000003, 'lambda2': 5.180967182527248, 'loop': 2, 'loss': 'MSE', 'lr': 0.008110462704578915, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.2002610498275566e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0067406125118972225
weight_decay:  2.4743697215900624e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4151230060961097
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 92.50
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0177103439345956
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 97.50
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.7642709030769765
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 67.00
run time now: 3.2361037731170654
total time:  3.2866457090713084
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 96.67 ± 3.82
   Final Test: 68.53 ± 1.60
[I 2023-06-11 23:47:56,768] Trial 511 finished with value: 71.5999984741211 and parameters: {'Fwd': 6.289476213808083e-06, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.5, 'lambda2': 3.0708170408489086, 'loop': 2, 'loss': 'CE', 'lr': 0.0067406125118972225, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.4743697215900624e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.0034931470660019494
weight_decay:  4.548830130729236e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7122201181482524
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 02
None time:  0.6363233199808747
None Run 02:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 96.67
   Final Test: 61.20
Split: 01, Run: 03
None time:  0.6613687539938837
None Run 03:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 99.17
   Final Test: 51.20
run time now: 2.050198793411255
total time:  2.0999847629573196
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.00 ± 5.50
  Final Train: 98.61 ± 1.73
   Final Test: 59.33 ± 7.38
[I 2023-06-11 23:47:59,362] Trial 512 finished with value: 62.0 and parameters: {'Fwd': 0.0008622077271611862, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 8.647987234248006, 'loop': 2, 'loss': 'CE', 'lr': 0.0034931470660019494, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.548830130729236e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.55
lr:  0.005834890729244244
weight_decay:  1.4582174761802432e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7883184889797121
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.8763777441345155
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.6953990410547704
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.392350196838379
total time:  2.4386607189662755
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.73 ± 0.64
  Final Train: 99.72 ± 0.48
   Final Test: 70.97 ± 0.15
[I 2023-06-11 23:48:02,343] Trial 513 finished with value: 72.73332977294922 and parameters: {'Fwd': 0.0013290745619025767, 'K': 1, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 6.6875897780310165, 'loop': 2, 'loss': 'CE', 'lr': 0.005834890729244244, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4582174761802432e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008568500885376725
weight_decay:  5.32494576297796e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9385137120261788
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 02
None time:  0.5410010889172554
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.4651153308805078
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 1.978022813796997
total time:  2.024173174984753
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 0.61
  Final Train: 99.72 ± 0.48
   Final Test: 69.80 ± 0.78
[I 2023-06-11 23:48:04,878] Trial 514 finished with value: 72.9333267211914 and parameters: {'Fwd': 0.008900021463159295, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 3.8343734453113556, 'loop': 2, 'loss': 'CE', 'lr': 0.008568500885376725, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.32494576297796e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.002119236846778223
weight_decay:  6.0116931723493685e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5412, Train: 99.17%, Valid: 69.80% Test: 69.70%
Split: 01, Run: 01
None time:  1.6864425020758063
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0190216139890254
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 03
None time:  1.0754394931718707
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 70.70
run time now: 3.8253071308135986
total time:  3.8926898180507123
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.61
  Final Train: 99.44 ± 0.48
   Final Test: 70.73 ± 1.05
[I 2023-06-11 23:48:09,361] Trial 515 finished with value: 70.53333282470703 and parameters: {'Fwd': 1.3159734866091944e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.1, 'lambda2': 3.266153248209763, 'loop': 2, 'loss': 'CE', 'lr': 0.002119236846778223, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.0116931723493685e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007523086290423096
weight_decay:  0.00023050105742108555
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2337845989968628
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 02
None time:  1.0805401580873877
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.7827072269283235
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.1315360069274902
total time:  3.185391533887014
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 1.00
  Final Train: 99.72 ± 0.48
   Final Test: 70.57 ± 0.76
[I 2023-06-11 23:48:13,056] Trial 516 finished with value: 73.0 and parameters: {'Fwd': 0.03742077671256635, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 6.257461711650016, 'loop': 2, 'loss': 'CE', 'lr': 0.007523086290423096, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00023050105742108555, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.009971806084492326
weight_decay:  4.217567693960683e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3750077949371189
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.8757579629309475
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.8099538451060653
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 71.30
run time now: 4.094620227813721
total time:  4.1457407139241695
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 1.39
  Final Train: 99.44 ± 0.48
   Final Test: 70.43 ± 0.85
[I 2023-06-11 23:48:17,660] Trial 517 finished with value: 71.00000762939453 and parameters: {'Fwd': 0.03459627397822361, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 5.114940406426283, 'loop': 2, 'loss': 'CE', 'lr': 0.009971806084492326, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.217567693960683e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.007059749298415528
weight_decay:  3.257453250533193e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3992092048283666
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 86.67
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.8989643750246614
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 63.50
Split: 01, Run: 03
None time:  0.6943738318514079
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 65.90
run time now: 3.0242459774017334
total time:  3.079474041936919
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.31
  Final Train: 95.56 ± 7.70
   Final Test: 66.53 ± 3.39
[I 2023-06-11 23:48:21,231] Trial 518 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.03819980192332844, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 1.1187948655579139, 'loop': 2, 'loss': 'CE', 'lr': 0.007059749298415528, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.257453250533193e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.0001983212704969726
weight_decay:  0.00035127912119422184
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3041322650387883
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02
None time:  0.7402288930024952
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.8011951379012316
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.881157636642456
total time:  2.929674042155966
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 69.33 ± 1.03
[I 2023-06-11 23:48:24,650] Trial 519 finished with value: 71.0 and parameters: {'Fwd': 0.08363640918096138, 'K': 3, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 7.81422937890692, 'loop': 2, 'loss': 'CE', 'lr': 0.0001983212704969726, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00035127912119422184, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.0
lr:  0.004370152355312616
weight_decay:  0.0001315511398841545
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9294648950453848
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 92.50
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.624340777983889
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.5707015320658684
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.1619956493377686
total time:  2.2075996489729732
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.81
  Final Train: 97.50 ± 4.33
   Final Test: 69.30 ± 0.53
[I 2023-06-11 23:48:27,358] Trial 520 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.00023774078132223693, 'K': 4, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 1.5893915323086412, 'loop': 2, 'loss': 'CE', 'lr': 0.004370152355312616, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001315511398841545, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.008762017761758337
weight_decay:  8.555815803567883e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9240257141645998
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 95.83
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.4995393021963537
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.5870336589869112
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.056187391281128
total time:  2.1058347108773887
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.00 ± 0.00
  Final Train: 98.61 ± 2.41
   Final Test: 70.37 ± 1.36
[I 2023-06-11 23:48:29,940] Trial 521 finished with value: 74.0 and parameters: {'Fwd': 0.0005442659012008158, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 8.88597235253614, 'loop': 2, 'loss': 'CE', 'lr': 0.008762017761758337, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.555815803567883e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.15000000000000002
lr:  0.000617686694259071
weight_decay:  2.7592818035805147e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8086297039408237
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 95.83
   Final Test: 61.60
Split: 01, Run: 02
None time:  0.7025685580447316
None Run 02:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 98.33
   Final Test: 65.40
Split: 01, Run: 03
None time:  0.6556476498953998
None Run 03:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 99.17
   Final Test: 66.30
run time now: 2.2129244804382324
total time:  2.2715126138646156
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.60 ± 1.39
  Final Train: 97.78 ± 1.73
   Final Test: 64.43 ± 2.49
[I 2023-06-11 23:48:32,782] Trial 522 finished with value: 63.60000228881836 and parameters: {'Fwd': 0.048210380926006366, 'K': 5, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 0.9108388461956836, 'loop': 2, 'loss': 'CE', 'lr': 0.000617686694259071, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.7592818035805147e-05, 'weightedloss': False}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00798322311566232
weight_decay:  0.00046888801073084204
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.559146183077246
None Run 01:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 43.10
Split: 01, Run: 02
None time:  0.6626766230911016
None Run 02:
Highest Train: 100.00
Highest Valid: 31.80
  Final Train: 100.00
   Final Test: 34.30
Split: 01, Run: 03
None time:  0.5968392018694431
None Run 03:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 47.80
run time now: 1.857926607131958
total time:  1.9135883708950132
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 40.53 ± 8.25
  Final Train: 100.00 ± 0.00
   Final Test: 41.73 ± 6.85
[I 2023-06-11 23:48:35,204] Trial 523 finished with value: 40.5333366394043 and parameters: {'Fwd': 0.04247463546349436, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.40974338898596, 'loop': 2, 'loss': 'CE', 'lr': 0.00798322311566232, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00046888801073084204, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.003763597103395402
weight_decay:  6.169971030829357e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1669755578041077
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 87.50
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.6667731520719826
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.7024546910542995
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 64.70
run time now: 2.5700371265411377
total time:  2.620645164977759
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.42
  Final Train: 95.83 ± 7.22
   Final Test: 68.10 ± 3.11
[I 2023-06-11 23:48:38,326] Trial 524 finished with value: 72.33333587646484 and parameters: {'Fwd': 0.0010766762479067498, 'K': 2, 'alpha': 0.2, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 4.143955481448462, 'loop': 2, 'loss': 'CE', 'lr': 0.003763597103395402, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.169971030829357e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0010046810747909956
weight_decay:  1.7942352943560325e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2802798990160227
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.0804155808873475
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 96.67
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.6645428100600839
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.057803153991699
total time:  3.1175635049585253
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 98.33 ± 1.67
   Final Test: 70.40 ± 0.36
[I 2023-06-11 23:48:41,964] Trial 525 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.002571497965688616, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 2.0474562717738256, 'loop': 2, 'loss': 'CE', 'lr': 0.0010046810747909956, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7942352943560325e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.005244253550223612
weight_decay:  0.0012093405206843393
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6315082290675491
None Run 01:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 51.80
Split: 01, Run: 02
None time:  1.8598898861091584
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.753101390087977
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.278341293334961
total time:  3.326069968054071
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.40 ± 11.09
  Final Train: 99.72 ± 0.48
   Final Test: 64.07 ± 10.63
[I 2023-06-11 23:48:45,821] Trial 526 finished with value: 64.4000015258789 and parameters: {'Fwd': 0.06985099491865222, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.073768448950647, 'loop': 2, 'loss': 'CE', 'lr': 0.005244253550223612, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0012093405206843393, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0062771320736438015
weight_decay:  0.0002257717468922784
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1925614620558918
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.6256539989262819
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.5344105651602149
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.30
run time now: 2.3869831562042236
total time:  2.443354566814378
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 70.60 ± 0.62
[I 2023-06-11 23:48:48,767] Trial 527 finished with value: 73.53333282470703 and parameters: {'Fwd': 0.005604552916682644, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.43931964262515, 'loop': 2, 'loss': 'CE', 'lr': 0.0062771320736438015, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002257717468922784, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0013730318175247582
weight_decay:  0.0001701002684240648
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.78284553415142
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 64.20
Split: 01, Run: 02
None time:  1.1465440590400249
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 99.17
   Final Test: 65.70
Split: 01, Run: 03
None time:  0.9018747569061816
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 99.17
   Final Test: 65.00
run time now: 2.863520860671997
total time:  2.915632003219798
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.47 ± 2.20
  Final Train: 99.44 ± 0.48
   Final Test: 64.97 ± 0.75
[I 2023-06-11 23:48:52,211] Trial 528 finished with value: 66.46666717529297 and parameters: {'Fwd': 3.5600973776646765e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 5.494892267681843, 'loop': 2, 'loss': 'CE', 'lr': 0.0013730318175247582, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001701002684240648, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008496063684779087
weight_decay:  3.6599237730434865e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.691934617003426
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 48.80
Split: 01, Run: 02
None time:  0.6787769729271531
None Run 02:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 59.20
Split: 01, Run: 03
None time:  0.6481391480192542
None Run 03:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 62.60
run time now: 2.0528500080108643
total time:  2.1097159921191633
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.67 ± 6.58
  Final Train: 100.00 ± 0.00
   Final Test: 56.87 ± 7.19
[I 2023-06-11 23:48:54,929] Trial 529 finished with value: 58.66666793823242 and parameters: {'Fwd': 4.7445707385491096e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 7.931180712491105, 'loop': 2, 'loss': 'MSE', 'lr': 0.008496063684779087, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.6599237730434865e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.009194116206869095
weight_decay:  1.917463100713052e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6939438069239259
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.5859385977964848
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.5742351328954101
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.80
run time now: 1.887986183166504
total time:  1.9424551441334188
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 70.57 ± 0.67
[I 2023-06-11 23:48:57,400] Trial 530 finished with value: 73.53333282470703 and parameters: {'Fwd': 0.000125819155856407, 'K': 3, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 8.722338248262389, 'loop': 2, 'loss': 'CE', 'lr': 0.009194116206869095, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.917463100713052e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.00741612594561699
weight_decay:  5.096584172252684e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6810100479051471
None Run 01:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 59.10
Split: 01, Run: 02
None time:  0.6050607820507139
None Run 02:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 61.50
Split: 01, Run: 03
None time:  0.6855392300058156
None Run 03:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 96.67
   Final Test: 53.10
run time now: 2.004615545272827
total time:  2.0470995539799333
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.07 ± 3.97
  Final Train: 98.89 ± 1.92
   Final Test: 57.90 ± 4.33
[I 2023-06-11 23:48:59,963] Trial 531 finished with value: 58.06666946411133 and parameters: {'Fwd': 0.05444047133950172, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 3.818198020442974, 'loop': 2, 'loss': 'CE', 'lr': 0.00741612594561699, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.096584172252684e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.0019120991546056037
weight_decay:  5.6437771416856105e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7684917841106653
None Run 01:
Highest Train: 100.00
Highest Valid: 41.80
  Final Train: 100.00
   Final Test: 41.70
Split: 01, Run: 02
None time:  1.6590728461742401
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  1.7109639970585704
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 68.00
run time now: 4.170999526977539
total time:  4.22809426416643
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.53 ± 14.49
  Final Train: 100.00 ± 0.00
   Final Test: 59.10 ± 15.07
[I 2023-06-11 23:49:04,699] Trial 532 finished with value: 58.5333366394043 and parameters: {'Fwd': 0.02720317879616267, 'K': 1, 'alpha': 0.25, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 9.248010614357037, 'loop': 2, 'loss': 'CE', 'lr': 0.0019120991546056037, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.6437771416856105e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0008300155510415886
weight_decay:  0.03411415117535159
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8566367090679705
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02
None time:  1.428080391138792
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.8662056990433484
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.1877949237823486
total time:  3.2425084651913494
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 1.17
  Final Train: 99.72 ± 0.48
   Final Test: 69.10 ± 0.79
[I 2023-06-11 23:49:08,481] Trial 533 finished with value: 70.86666107177734 and parameters: {'Fwd': 0.0016427669444213568, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 4.860981854457314, 'loop': 2, 'loss': 'CE', 'lr': 0.0008300155510415886, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03411415117535159, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0005103773453322357
weight_decay:  4.360351226536091e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5786538971588016
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.945972743909806
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 03
None time:  1.5635120689403266
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 98.33
   Final Test: 71.00
run time now: 4.122117280960083
total time:  4.181821536971256
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 0.69
  Final Train: 99.44 ± 0.96
   Final Test: 71.87 ± 1.33
[I 2023-06-11 23:49:13,176] Trial 534 finished with value: 72.79999542236328 and parameters: {'Fwd': 0.00071840348637813, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 5.85282171423085, 'loop': 2, 'loss': 'CE', 'lr': 0.0005103773453322357, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.360351226536091e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.006855868736835615
weight_decay:  1.1894601563975133e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9979327239561826
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 68.40
Split: 01, Run: 02
None time:  0.6856416689697653
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.6533238980919123
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.3718273639678955
total time:  2.4322137171402574
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 1.39
  Final Train: 99.72 ± 0.48
   Final Test: 69.70 ± 1.35
[I 2023-06-11 23:49:16,064] Trial 535 finished with value: 72.4000015258789 and parameters: {'Fwd': 0.0009680626161229696, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 4.167263258558094, 'loop': 2, 'loss': 'CE', 'lr': 0.006855868736835615, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1894601563975133e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.007892118964008226
weight_decay:  0.00030413363305245003
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2386463060975075
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 98.33
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.5974235360044986
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.6954360478557646
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.564629316329956
total time:  2.6211811718530953
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.67 ± 0.12
  Final Train: 99.44 ± 0.96
   Final Test: 70.00 ± 0.44
[I 2023-06-11 23:49:19,168] Trial 536 finished with value: 72.66666412353516 and parameters: {'Fwd': 1.6657113804594763e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 8.253709018823812, 'loop': 2, 'loss': 'CE', 'lr': 0.007892118964008226, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00030413363305245003, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00036748804894107734
weight_decay:  0.01198219754683586
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.627152943983674
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 02
None time:  0.6055534440092742
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.90
Split: 01, Run: 03
None time:  0.6404421071056277
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.10
run time now: 1.9062235355377197
total time:  1.9626777009107172
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 64.73 ± 0.72
[I 2023-06-11 23:49:21,580] Trial 537 finished with value: 67.66666412353516 and parameters: {'Fwd': 0.08959842812364247, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 2.80378506811653, 'loop': 0, 'loss': 'CE', 'lr': 0.00036748804894107734, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01198219754683586, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.00610447422339824
weight_decay:  7.701435996767816e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0469085599761456
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 93.33
   Final Test: 65.70
Split: 01, Run: 02
None time:  0.5868066460825503
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 62.40
Split: 01, Run: 03
None time:  0.6490709620993584
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.3180785179138184
total time:  2.3655995898880064
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 1.10
  Final Train: 97.78 ± 3.85
   Final Test: 65.90 ± 3.60
[I 2023-06-11 23:49:24,401] Trial 538 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.0005424070137422046, 'K': 2, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.55, 'lambda2': 7.455862607770728, 'loop': 2, 'loss': 'CE', 'lr': 0.00610447422339824, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.701435996767816e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009164290428396659
weight_decay:  0.00010787216068858933
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1037732718978077
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.7394878421910107
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.8002235270105302
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.50
run time now: 2.67689847946167
total time:  2.723270972026512
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 2.39
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 1.34
[I 2023-06-11 23:49:27,602] Trial 539 finished with value: 72.33333587646484 and parameters: {'Fwd': 2.2583127502719737e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 8.87467868958092, 'loop': 2, 'loss': 'CE', 'lr': 0.009164290428396659, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010787216068858933, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.008122365197325029
weight_decay:  0.0948254313575755
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6057504878845066
None Run 01:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 56.00
Split: 01, Run: 02
None time:  0.6079959720373154
None Run 02:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 47.10
Split: 01, Run: 03
None time:  0.5452000999357551
None Run 03:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 39.40
run time now: 1.7944719791412354
total time:  1.843009889125824
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 46.53 ± 8.81
  Final Train: 100.00 ± 0.00
   Final Test: 47.50 ± 8.31
[I 2023-06-11 23:49:29,951] Trial 540 finished with value: 46.5333366394043 and parameters: {'Fwd': 0.007308659094578075, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 1.3816571563672277, 'loop': 2, 'loss': 'CE', 'lr': 0.008122365197325029, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0948254313575755, 'weightedloss': False}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00024731780835119977
weight_decay:  2.407485586167863e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.7887, Train: 93.33%, Valid: 69.80% Test: 68.80%
Split: 01, Run: 01
None time:  1.7200256348587573
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 94.17
   Final Test: 68.10
Split: 01, Run: 02
None time:  0.7360223571304232
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 03
None time:  0.688904328038916
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 71.20
run time now: 3.1772797107696533
total time:  3.232019793940708
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 1.59
  Final Train: 97.78 ± 3.15
   Final Test: 70.37 ± 1.99
[I 2023-06-11 23:49:33,709] Trial 541 finished with value: 72.20000457763672 and parameters: {'Fwd': 6.539649926623839e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 1.7398305324409238, 'loop': 2, 'loss': 'CE', 'lr': 0.00024731780835119977, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.407485586167863e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.001082565109528634
weight_decay:  9.593935062849132e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1783604910597205
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.1702914459165186
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 98.33
   Final Test: 72.40
Split: 01, Run: 03
None time:  0.64205217291601
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.024226665496826
total time:  3.080138775985688
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 1.56
  Final Train: 99.44 ± 0.96
   Final Test: 70.33 ± 2.21
[I 2023-06-11 23:49:37,314] Trial 542 finished with value: 72.20000457763672 and parameters: {'Fwd': 0.0030745261124973874, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 6.574381364275475, 'loop': 2, 'loss': 'CE', 'lr': 0.001082565109528634, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.593935062849132e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.004737100300725526
weight_decay:  1.3783218666015262e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9902628369163722
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.6845648020971566
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.5878311840351671
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.50
run time now: 2.2968335151672363
total time:  2.347811898915097
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 1.08
[I 2023-06-11 23:49:40,180] Trial 543 finished with value: 71.93334197998047 and parameters: {'Fwd': 3.0070827091692713e-05, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 5.616258902124292, 'loop': 2, 'loss': 'CE', 'lr': 0.004737100300725526, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3783218666015262e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.0001721185170838902
weight_decay:  6.371906129875887e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8824, Train: 99.17%, Valid: 69.20% Test: 69.10%
Split: 01, Run: 01
None time:  1.8933097440749407
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.6049803590867668
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.7985717738047242
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.3304898738861084
total time:  3.3809935299213976
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 1.89
  Final Train: 99.72 ± 0.48
   Final Test: 69.83 ± 0.67
[I 2023-06-11 23:49:44,050] Trial 544 finished with value: 71.33333587646484 and parameters: {'Fwd': 9.650232473656486e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 6.147701422048983, 'loop': 2, 'loss': 'CE', 'lr': 0.0001721185170838902, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.371906129875887e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.007046644378114007
weight_decay:  2.992084227510729e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2846488361246884
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 84.17
   Final Test: 68.20
Split: 01, Run: 02
None time:  0.5114896860904992
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  0.526034572860226
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 68.80
run time now: 2.354731321334839
total time:  2.409435505978763
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 1.22
  Final Train: 94.44 ± 8.91
   Final Test: 68.37 ± 0.38
[I 2023-06-11 23:49:47,047] Trial 545 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0013460696432577898, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 0.17724495413629482, 'loop': 2, 'loss': 'CE', 'lr': 0.007046644378114007, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.992084227510729e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.009994985250874678
weight_decay:  4.1908450038487954e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5174, Train: 100.00%, Valid: 72.20% Test: 70.80%
Split: 01, Run: 01
None time:  1.7204775100108236
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  1.0627947959583253
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 03
None time:  0.5785652850754559
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.00
run time now: 3.395292043685913
total time:  3.451607181923464
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 72.00 ± 1.05
[I 2023-06-11 23:49:51,029] Trial 546 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.012314856257665327, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.1, 'lambda2': 8.582335429684413, 'loop': 2, 'loss': 'CE', 'lr': 0.009994985250874678, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.1908450038487954e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.008655142981536603
weight_decay:  2.0357143735634414e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3277059569954872
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 89.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.607190498849377
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 03
None time:  0.6305411260109395
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 67.60
run time now: 2.5996005535125732
total time:  2.6555483280681074
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 1.36
  Final Train: 96.39 ± 6.25
   Final Test: 67.87 ± 1.32
[I 2023-06-11 23:49:54,249] Trial 547 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.00019191012999792372, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 0.42923989173331145, 'loop': 2, 'loss': 'CE', 'lr': 0.008655142981536603, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.0357143735634414e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.005463184159841137
weight_decay:  0.0053520968119919335
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6714560680557042
None Run 01:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 56.80
Split: 01, Run: 02
None time:  0.6697099909652025
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 65.70
Split: 01, Run: 03
None time:  0.6822105399332941
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 67.20
run time now: 2.0568835735321045
total time:  2.1124989159870893
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.60 ± 6.16
  Final Train: 100.00 ± 0.00
   Final Test: 63.23 ± 5.62
[I 2023-06-11 23:49:56,882] Trial 548 finished with value: 63.59999465942383 and parameters: {'Fwd': 0.0007842949086378671, 'K': 3, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 2.694945251861089, 'loop': 2, 'loss': 'MSE', 'lr': 0.005463184159841137, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0053520968119919335, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.15000000000000002
lr:  0.002385030772616274
weight_decay:  0.0005768498833192047
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9106162891257554
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.1237892000935972
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.6905436650849879
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.40
run time now: 2.761776924133301
total time:  2.815571356797591
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 1.03
  Final Train: 99.72 ± 0.48
   Final Test: 69.27 ± 0.76
[I 2023-06-11 23:50:00,187] Trial 549 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.0003150992136404891, 'K': 4, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 7.205789051954161, 'loop': 2, 'loss': 'CE', 'lr': 0.002385030772616274, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005768498833192047, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.004084772709640458
weight_decay:  7.380786231949825e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7920487560331821
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.5859027979895473
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 03
None time:  0.5649155750870705
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 1.9758491516113281
total time:  2.035792487906292
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.00 ± 0.60
  Final Train: 99.72 ± 0.48
   Final Test: 68.57 ± 2.63
[I 2023-06-11 23:50:02,735] Trial 550 finished with value: 74.0 and parameters: {'Fwd': 0.00041139032604539915, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 9.81589215645537, 'loop': 2, 'loss': 'CE', 'lr': 0.004084772709640458, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.380786231949825e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.8500000000000001
lr:  0.0076271960573767415
weight_decay:  0.00019342819867031476
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.633587348042056
None Run 01:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.30
Split: 01, Run: 02
None time:  0.7653697540517896
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 03
None time:  0.8643171521835029
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 67.90
run time now: 2.311448097229004
total time:  2.3643850469961762
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.67 ± 3.56
  Final Train: 99.72 ± 0.48
   Final Test: 65.30 ± 3.52
[I 2023-06-11 23:50:05,686] Trial 551 finished with value: 67.66666412353516 and parameters: {'Fwd': 4.389895391489031e-05, 'K': 1, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 3.103250800058209, 'loop': 2, 'loss': 'CE', 'lr': 0.0076271960573767415, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019342819867031476, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.5
lr:  0.006752890020019712
weight_decay:  2.0623343320665153e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6975305660162121
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 02
None time:  0.7004498529713601
None Run 02:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 58.90
Split: 01, Run: 03
None time:  0.6811925629153848
None Run 03:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 99.17
   Final Test: 54.30
run time now: 2.113032341003418
total time:  2.1613719610031694
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.00 ± 8.99
  Final Train: 99.72 ± 0.48
   Final Test: 60.17 ± 6.59
[I 2023-06-11 23:50:08,359] Trial 552 finished with value: 61.0 and parameters: {'Fwd': 0.0010061789643052103, 'K': 2, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 9.534192853897075, 'loop': 2, 'loss': 'CE', 'lr': 0.006752890020019712, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.0623343320665153e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.009101610519762588
weight_decay:  0.00024366045385744244
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5209702989086509
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.5527221220545471
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.5765888039022684
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 2.6838035583496094
total time:  2.7292211179155856
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 0.72
  Final Train: 99.72 ± 0.48
   Final Test: 70.27 ± 0.61
[I 2023-06-11 23:50:11,623] Trial 553 finished with value: 72.5999984741211 and parameters: {'Fwd': 0.0019055617084983271, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.097162072745153, 'loop': 2, 'loss': 'CE', 'lr': 0.009101610519762588, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00024366045385744244, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.30000000000000004
lr:  0.006087919685993827
weight_decay:  0.0006894025501429606
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6353919061366469
None Run 01:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 45.70
Split: 01, Run: 02
None time:  0.6564196099061519
None Run 02:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 57.80
Split: 01, Run: 03
None time:  0.5973342698998749
None Run 03:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 62.90
run time now: 1.9275224208831787
total time:  1.9784309659153223
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.47 ± 8.00
  Final Train: 100.00 ± 0.00
   Final Test: 55.47 ± 8.83
[I 2023-06-11 23:50:14,079] Trial 554 finished with value: 54.4666633605957 and parameters: {'Fwd': 1.1231965040426863e-05, 'K': 6, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 4.676364875904571, 'loop': 2, 'loss': 'CE', 'lr': 0.006087919685993827, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006894025501429606, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008225059119163255
weight_decay:  1.230122869241324e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0011034000199288
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.9346260179299861
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.206054511014372
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.90
run time now: 3.18013334274292
total time:  3.228332428028807
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.40 ± 0.50
[I 2023-06-11 23:50:17,817] Trial 555 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.01800521281558227, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.34789285714849, 'loop': 2, 'loss': 'CE', 'lr': 0.008225059119163255, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.230122869241324e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.0008920766916588023
weight_decay:  5.393650812574314e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9122441220097244
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.70
Split: 01, Run: 02
None time:  1.455828782171011
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 98.33
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.7360433749854565
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 67.90
run time now: 3.1395702362060547
total time:  3.2105219510849565
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 3.75
  Final Train: 99.44 ± 0.96
   Final Test: 67.93 ± 3.25
[I 2023-06-11 23:50:21,533] Trial 556 finished with value: 69.73332977294922 and parameters: {'Fwd': 0.009886710335086266, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 6.958825685538013, 'loop': 2, 'loss': 'CE', 'lr': 0.0008920766916588023, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.393650812574314e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0017453263794723049
weight_decay:  0.00012157569360399797
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2025821218267083
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 90.83
   Final Test: 65.40
Split: 01, Run: 02
None time:  1.3028303508181125
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 87.50
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.6421926009934396
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.1809566020965576
total time:  3.2362982099875808
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 3.12
  Final Train: 92.78 ± 6.47
   Final Test: 68.37 ± 2.74
[I 2023-06-11 23:50:25,226] Trial 557 finished with value: 68.80000305175781 and parameters: {'Fwd': 0.004757164350171702, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 0.5734842431312837, 'loop': 2, 'loss': 'CE', 'lr': 0.0017453263794723049, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012157569360399797, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.6000000000000001
lr:  0.00741630203589865
weight_decay:  0.002001637758484203
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1287580339703709
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 02
None time:  0.8747557350434363
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.6168393900152296
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.20
run time now: 2.652920722961426
total time:  2.6982195370364934
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 1.56
  Final Train: 99.72 ± 0.48
   Final Test: 68.67 ± 1.57
[I 2023-06-11 23:50:28,436] Trial 558 finished with value: 70.0 and parameters: {'Fwd': 0.0006316904332221774, 'K': 1, 'alpha': 0.6000000000000001, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 5.997693151099326, 'loop': 2, 'loss': 'CE', 'lr': 0.00741630203589865, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002001637758484203, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.009048672925281182
weight_decay:  0.007710419258907269
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5402085010427982
None Run 01:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 56.40
Split: 01, Run: 02
None time:  0.5309886129107326
None Run 02:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 53.40
Split: 01, Run: 03
None time:  0.5686494279652834
None Run 03:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 49.50
run time now: 1.6743290424346924
total time:  1.724221213022247
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.73 ± 5.66
  Final Train: 100.00 ± 0.00
   Final Test: 53.10 ± 3.46
[I 2023-06-11 23:50:30,657] Trial 559 finished with value: 53.733333587646484 and parameters: {'Fwd': 0.046978454177392784, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 8.95787049981535, 'loop': 2, 'loss': 'CE', 'lr': 0.009048672925281182, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007710419258907269, 'weightedloss': False}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.003174776302073559
weight_decay:  7.093720326620492e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.4887, Train: 100.00%, Valid: 71.60% Test: 69.70%
Split: 01, Run: 01
None time:  1.891657039988786
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.7250558559317142
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.80
Split: 01, Run: 03
None time:  1.5928343639243394
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.30
run time now: 4.2420501708984375
total time:  4.2956895811948925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 3.67
  Final Train: 100.00 ± 0.00
   Final Test: 68.93 ± 3.81
[I 2023-06-11 23:50:35,466] Trial 560 finished with value: 70.33332824707031 and parameters: {'Fwd': 2.0110647090521224e-05, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 3.772086374464382, 'loop': 2, 'loss': 'CE', 'lr': 0.003174776302073559, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.093720326620492e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.005778274935663472
weight_decay:  0.00015611970976211022
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2526089230086654
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 95.00
   Final Test: 67.20
Split: 01, Run: 02
None time:  0.60327915311791
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  0.5947389649227262
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 66.40
run time now: 2.4842071533203125
total time:  2.5453574978746474
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 1.51
  Final Train: 98.33 ± 2.89
   Final Test: 66.90 ± 0.44
[I 2023-06-11 23:50:38,483] Trial 561 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.000150070064176979, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 3.486054152914575, 'loop': 2, 'loss': 'CE', 'lr': 0.005778274935663472, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00015611970976211022, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.006619214934195206
weight_decay:  2.689495458183741e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6905101859010756
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  0.767525483854115
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.7072924799285829
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.90
run time now: 3.197244167327881
total time:  3.2459075360093266
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.81
  Final Train: 99.72 ± 0.48
   Final Test: 71.23 ± 0.70
[I 2023-06-11 23:50:42,254] Trial 562 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.003699752641699602, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 8.388123386290033, 'loop': 2, 'loss': 'CE', 'lr': 0.006619214934195206, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.689495458183741e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.008055078229317352
weight_decay:  9.150408017674889e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4818299959879369
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.6948443409055471
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.6068196499254555
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.817331552505493
total time:  2.864369688089937
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 71.20 ± 0.56
[I 2023-06-11 23:50:45,694] Trial 563 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.02951693343206476, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.8531413994393, 'loop': 2, 'loss': 'CE', 'lr': 0.008055078229317352, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.150408017674889e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.009933054324112161
weight_decay:  3.289077654910802e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8022122860420495
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 99.17
   Final Test: 66.30
Split: 01, Run: 02
None time:  0.5650629259180278
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 99.17
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.47570835216902196
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.50
run time now: 1.877655029296875
total time:  1.9323924989439547
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 3.16
  Final Train: 99.44 ± 0.48
   Final Test: 68.53 ± 2.25
[I 2023-06-11 23:50:48,216] Trial 564 finished with value: 71.66666412353516 and parameters: {'Fwd': 5.4055523778630145e-05, 'K': 3, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.15000000000000002, 'lambda2': 2.9445479688171052, 'loop': 2, 'loss': 'CE', 'lr': 0.009933054324112161, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.289077654910802e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.008549556985434924
weight_decay:  0.00038724808302804996
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9646741701290011
None Run 01:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 94.17
   Final Test: 55.80
Split: 01, Run: 02
None time:  0.6379715939983726
None Run 02:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 60.60
Split: 01, Run: 03
None time:  0.695323402993381
None Run 03:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 99.17
   Final Test: 61.60
run time now: 2.332155466079712
total time:  2.40337614598684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.07 ± 2.72
  Final Train: 97.78 ± 3.15
   Final Test: 59.33 ± 3.10
[I 2023-06-11 23:50:51,137] Trial 565 finished with value: 59.06666564941406 and parameters: {'Fwd': 0.0008303153454042955, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 5.26254471738071, 'loop': 2, 'loss': 'CE', 'lr': 0.008549556985434924, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00038724808302804996, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.007364708835354704
weight_decay:  5.234097994790814e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5092600609641522
None Run 01:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 45.20
Split: 01, Run: 02
None time:  0.6704808499198407
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.4862907330971211
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 67.90
run time now: 1.6990606784820557
total time:  1.7428709818050265
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.67 ± 16.03
  Final Train: 99.44 ± 0.96
   Final Test: 60.37 ± 13.13
[I 2023-06-11 23:50:53,407] Trial 566 finished with value: 62.66666793823242 and parameters: {'Fwd': 0.0012126386292351159, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 1.0, 'lambda2': 4.3377054794735335, 'loop': 2, 'loss': 'CE', 'lr': 0.007364708835354704, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.234097994790814e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.001232596058306459
weight_decay:  4.051175956421296e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7193157260771841
None Run 01:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 02
None time:  0.6540516070090234
None Run 02:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 47.50
Split: 01, Run: 03
None time:  0.7888494650833309
None Run 03:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 99.17
   Final Test: 56.80
run time now: 2.2073185443878174
total time:  2.273766261059791
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.67 ± 4.92
  Final Train: 99.72 ± 0.48
   Final Test: 53.77 ± 5.43
[I 2023-06-11 23:50:56,339] Trial 567 finished with value: 53.66666793823242 and parameters: {'Fwd': 0.00045248118121348597, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 8.718006756652242, 'loop': 0, 'loss': 'CE', 'lr': 0.001232596058306459, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.051175956421296e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.004978716430151472
weight_decay:  1.9171224141910243e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7206694560591131
None Run 01:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 55.90
Split: 01, Run: 02
None time:  0.9029597919434309
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  0.7049529489595443
None Run 03:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 63.10
run time now: 2.3626227378845215
total time:  2.4173418688587844
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.20 ± 4.26
  Final Train: 100.00 ± 0.00
   Final Test: 62.03 ± 5.68
[I 2023-06-11 23:50:59,248] Trial 568 finished with value: 60.20000076293945 and parameters: {'Fwd': 0.08740618487966041, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.092146357773823, 'loop': 2, 'loss': 'MSE', 'lr': 0.004978716430151472, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.9171224141910243e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.00043406539376609213
weight_decay:  0.055877499502413226
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7510385680943727
None Run 01:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 63.80
Split: 01, Run: 02
None time:  0.642133949091658
None Run 02:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 61.30
Split: 01, Run: 03
None time:  0.6697926491033286
None Run 03:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 61.50
run time now: 2.0964667797088623
total time:  2.144675002899021
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.07 ± 3.30
  Final Train: 100.00 ± 0.00
   Final Test: 62.20 ± 1.39
[I 2023-06-11 23:51:01,933] Trial 569 finished with value: 61.06666946411133 and parameters: {'Fwd': 0.0002384462934794219, 'K': 2, 'alpha': 0.1, 'dropout': 0.1, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.242433553855463, 'loop': 2, 'loss': 'CE', 'lr': 0.00043406539376609213, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.055877499502413226, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009230332257770315
weight_decay:  4.9500554098146154e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7727491869591177
None Run 01:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 41.40
Split: 01, Run: 02
None time:  1.270891065010801
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 95.00
   Final Test: 61.70
Split: 01, Run: 03
None time:  0.5687376649584621
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.60
run time now: 2.644536018371582
total time:  2.695468955906108
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.13 ± 11.06
  Final Train: 98.33 ± 2.89
   Final Test: 55.90 ± 12.64
[I 2023-06-11 23:51:05,211] Trial 570 finished with value: 60.133331298828125 and parameters: {'Fwd': 2.7776448070592476e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.54824468244152, 'loop': 2, 'loss': 'CE', 'lr': 0.009230332257770315, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.9500554098146154e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.007816224090545755
weight_decay:  1.2677999091958706e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8275571039412171
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.6687863310799003
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.6903944839723408
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 2.2197773456573486
total time:  2.2744502548594028
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.20 ± 1.40
  Final Train: 99.72 ± 0.48
   Final Test: 70.13 ± 1.17
[I 2023-06-11 23:51:08,015] Trial 571 finished with value: 73.19999694824219 and parameters: {'Fwd': 0.0006727746388969511, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.6000000000000001, 'lambda2': 5.035206149917564, 'loop': 2, 'loss': 'CE', 'lr': 0.007816224090545755, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2677999091958706e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.002016232680051046
weight_decay:  0.0002975598681836977
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4826967041008174
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.00
   Final Test: 66.60
Split: 01, Run: 02
None time:  0.6511126889381558
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 66.00
Split: 01, Run: 03
None time:  0.936596472049132
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 94.17
   Final Test: 66.70
run time now: 3.103147029876709
total time:  3.1494202041067183
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.67 ± 1.50
  Final Train: 94.72 ± 5.02
   Final Test: 66.43 ± 0.38
[I 2023-06-11 23:51:11,606] Trial 572 finished with value: 69.66666412353516 and parameters: {'Fwd': 3.6632057714095063e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 1.0158396941659158, 'loop': 2, 'loss': 'CE', 'lr': 0.002016232680051046, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002975598681836977, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0033036735669063127
weight_decay:  1.0534380302452137e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5998056060634553
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 72.70
Split: 01, Run: 02
None time:  0.7140570180490613
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.6852114780340344
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.0317471027374268
total time:  3.091673064045608
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.73 ± 0.58
  Final Train: 99.72 ± 0.48
   Final Test: 71.07 ± 1.52
[I 2023-06-11 23:51:15,227] Trial 573 finished with value: 73.73333740234375 and parameters: {'Fwd': 0.0014565692840175922, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 6.79390126127085, 'loop': 2, 'loss': 'CE', 'lr': 0.0033036735669063127, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0534380302452137e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.006666452655845416
weight_decay:  1.630517208402859e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1984563278965652
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.3599237632006407
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.0121789341792464
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.6038084030151367
total time:  3.6641127329785377
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 70.43 ± 0.42
[I 2023-06-11 23:51:19,366] Trial 574 finished with value: 70.93334197998047 and parameters: {'Fwd': 8.343441888218595e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 2.0652617775367466, 'loop': 2, 'loss': 'CE', 'lr': 0.006666452655845416, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.630517208402859e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0030017115764854156
weight_decay:  0.01004697942549683
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0145868610125035
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.60
Split: 01, Run: 02
None time:  0.9429599489085376
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 95.83
   Final Test: 72.90
Split: 01, Run: 03
None time:  0.8447427561040968
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.00
run time now: 2.8363358974456787
total time:  2.8947541650850326
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 3.29
  Final Train: 98.61 ± 2.41
   Final Test: 69.83 ± 4.55
[I 2023-06-11 23:51:22,767] Trial 575 finished with value: 71.20000457763672 and parameters: {'Fwd': 1.4158244874776518e-05, 'K': 2, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 9.023691662017898, 'loop': 2, 'loss': 'CE', 'lr': 0.0030017115764854156, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.01004697942549683, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0001389673549271866
weight_decay:  7.283473459394774e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.083971343934536
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 02
None time:  1.121307459892705
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 03
None time:  0.6696722549386322
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.70
run time now: 2.919405221939087
total time:  2.9738286200445145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 67.43 ± 1.12
[I 2023-06-11 23:51:26,353] Trial 576 finished with value: 69.86666870117188 and parameters: {'Fwd': 0.002460874383617997, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 7.536591661060267, 'loop': 2, 'loss': 'CE', 'lr': 0.0001389673549271866, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.283473459394774e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9
lr:  0.008605861052175522
weight_decay:  0.0001396268361736071
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.101867686957121
None Run 01:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 50.10
Split: 01, Run: 02
None time:  1.221779259154573
None Run 02:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 50.10
Split: 01, Run: 03
None time:  1.1530535500496626
None Run 03:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 50.10
run time now: 3.509742498397827
total time:  3.5588986328803003
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 50.10 ± 0.00
[I 2023-06-11 23:51:30,389] Trial 577 finished with value: 50.59999465942383 and parameters: {'Fwd': 0.02102982897758262, 'K': 1, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.0, 'lambda2': 9.995602134401471, 'loop': 2, 'loss': 'CE', 'lr': 0.008605861052175522, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001396268361736071, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.004474484848414473
weight_decay:  2.4556058690285586e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.70677678193897
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.5719149820506573
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.49740121606737375
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.8096156120300293
total time:  2.85336737614125
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 1.56
  Final Train: 98.33 ± 2.89
   Final Test: 69.23 ± 0.15
[I 2023-06-11 23:51:33,775] Trial 578 finished with value: 72.79999542236328 and parameters: {'Fwd': 0.0010387474008303555, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.2, 'lambda2': 2.519211551962374, 'loop': 2, 'loss': 'CE', 'lr': 0.004474484848414473, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.4556058690285586e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.001385920023151844
weight_decay:  0.020883544316609347
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8149069491773844
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 02
None time:  1.0821780289988965
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.725566036067903
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.657442808151245
total time:  2.705425319960341
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 2.23
  Final Train: 99.72 ± 0.48
   Final Test: 69.33 ± 2.12
[I 2023-06-11 23:51:36,998] Trial 579 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.001964394438547349, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.408895668330828, 'loop': 2, 'loss': 'CE', 'lr': 0.001385920023151844, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.020883544316609347, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0007853848735346541
weight_decay:  0.00019415780214105392
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.534014489967376
None Run 01:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 55.10
Split: 01, Run: 02
None time:  0.7353763070423156
None Run 02:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 99.17
   Final Test: 57.40
Split: 01, Run: 03
None time:  0.6310155498795211
None Run 03:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 58.50
run time now: 1.9468464851379395
total time:  2.0176935018971562
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.40 ± 0.35
  Final Train: 99.72 ± 0.48
   Final Test: 57.00 ± 1.73
[I 2023-06-11 23:51:39,517] Trial 580 finished with value: 59.39999771118164 and parameters: {'Fwd': 0.0005628365586489462, 'K': 7, 'alpha': 0.5, 'dropout': 0.0, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 6.330328776035884, 'loop': 2, 'loss': 'CE', 'lr': 0.0007853848735346541, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019415780214105392, 'weightedloss': False}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.009972409644540749
weight_decay:  7.902870919616254e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9723160590510815
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.7419907101429999
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.6687853380572051
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.425788402557373
total time:  2.487596770050004
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 0.60
  Final Train: 99.72 ± 0.48
   Final Test: 69.40 ± 0.62
[I 2023-06-11 23:51:42,487] Trial 581 finished with value: 69.80000305175781 and parameters: {'Fwd': 0.0008570840922843432, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 8.529271589651316, 'loop': 2, 'loss': 'CE', 'lr': 0.009972409644540749, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.902870919616254e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0025934858103235695
weight_decay:  0.00011400118477718647
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3586297989822924
None Run 01:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 37.60
Split: 01, Run: 02
None time:  1.1539957078639418
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 92.50
   Final Test: 67.20
Split: 01, Run: 03
None time:  0.24217001418583095
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 65.80
run time now: 1.7885282039642334
total time:  1.8417619939427823
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.13 ± 16.61
  Final Train: 97.50 ± 4.33
   Final Test: 56.87 ± 16.70
[I 2023-06-11 23:51:44,792] Trial 582 finished with value: 60.133331298828125 and parameters: {'Fwd': 7.81478065374653e-05, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 10, 'lambda1': 0.25, 'lambda2': 1.8673355395935456, 'loop': 2, 'loss': 'CE', 'lr': 0.0025934858103235695, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011400118477718647, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.75
lr:  0.007467260083285076
weight_decay:  5.7332909474595866e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.029286207165569
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.865954136941582
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.7704688699450344
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.00
run time now: 2.7002370357513428
total time:  2.765957497060299
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.53
  Final Train: 99.72 ± 0.48
   Final Test: 68.40 ± 0.46
[I 2023-06-11 23:51:48,055] Trial 583 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.00032828317343157223, 'K': 3, 'alpha': 0.75, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 8.705724440648044, 'loop': 2, 'loss': 'CE', 'lr': 0.007467260083285076, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.7332909474595866e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.0015589106714190917
weight_decay:  0.0002458568734283892
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7058539821300656
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.70
Split: 01, Run: 02
None time:  1.3307621369604021
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 99.17
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.7011640139389783
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.7717063426971436
total time:  2.8183144519571215
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 1.60
  Final Train: 99.72 ± 0.48
   Final Test: 67.50 ± 3.41
[I 2023-06-11 23:51:51,472] Trial 584 finished with value: 68.79999542236328 and parameters: {'Fwd': 2.271119280531271e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 9.739017474852579, 'loop': 2, 'loss': 'CE', 'lr': 0.0015589106714190917, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002458568734283892, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.45
lr:  0.0037257163931543624
weight_decay:  3.563772485020751e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.33715471602045
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 02
None time:  1.1907750419341028
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.5619250820018351
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.1230626106262207
total time:  3.165906721027568
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 0.87
  Final Train: 99.72 ± 0.48
   Final Test: 69.37 ± 1.01
[I 2023-06-11 23:51:55,089] Trial 585 finished with value: 72.5999984741211 and parameters: {'Fwd': 0.00010748267789580702, 'K': 1, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 7.755306636936519, 'loop': 2, 'loss': 'CE', 'lr': 0.0037257163931543624, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.563772485020751e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.005725380204508787
weight_decay:  8.609437443360536e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7431370979174972
None Run 01:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 56.00
Split: 01, Run: 02
None time:  0.9050645148381591
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.83
   Final Test: 71.10
Split: 01, Run: 03
None time:  0.7345745018683374
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.80
run time now: 2.417520523071289
total time:  2.462367988890037
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.73 ± 9.68
  Final Train: 98.61 ± 2.41
   Final Test: 66.30 ± 8.93
[I 2023-06-11 23:51:58,070] Trial 586 finished with value: 66.73332977294922 and parameters: {'Fwd': 0.013690442067661577, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 2.4086613298197657, 'loop': 2, 'loss': 'CE', 'lr': 0.005725380204508787, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.609437443360536e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008342724879535465
weight_decay:  4.6006249143473064e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1308706090785563
None Run 01:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 63.50
Split: 01, Run: 02
None time:  0.8495830970350653
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  1.4441596269607544
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.10
run time now: 3.456667423248291
total time:  3.50865720002912
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.07 ± 3.97
  Final Train: 100.00 ± 0.00
   Final Test: 66.67 ± 2.75
[I 2023-06-11 23:52:02,136] Trial 587 finished with value: 65.06666564941406 and parameters: {'Fwd': 0.041246432698444434, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.222504336558249, 'loop': 2, 'loss': 'MSE', 'lr': 0.008342724879535465, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.6006249143473064e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0005715254776213043
weight_decay:  3.10569246887558e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1090276690665632
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  0.7734771640971303
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.3255274360999465
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 70.50
run time now: 3.2440578937530518
total time:  3.2994939759373665
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 1.25
  Final Train: 99.72 ± 0.48
   Final Test: 68.90 ± 1.77
[I 2023-06-11 23:52:05,893] Trial 588 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.00047354971381655966, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 4.35574757042983, 'loop': 2, 'loss': 'CE', 'lr': 0.0005715254776213043, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.10569246887558e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.00648571071407611
weight_decay:  3.7018272553568018e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6132195161189884
None Run 01:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 58.00
Split: 01, Run: 02
None time:  0.5597588869277388
None Run 02:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 55.20
Split: 01, Run: 03
None time:  0.5791707010939717
None Run 03:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 57.50
run time now: 1.7856481075286865
total time:  1.841806858079508
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.13 ± 3.14
  Final Train: 100.00 ± 0.00
   Final Test: 56.90 ± 1.49
[I 2023-06-11 23:52:08,255] Trial 589 finished with value: 58.133331298828125 and parameters: {'Fwd': 5.99394491366392e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.05, 'lambda2': 0.8192875175054412, 'loop': 2, 'loss': 'CE', 'lr': 0.00648571071407611, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.7018272553568018e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.009113010037389773
weight_decay:  6.690236001802133e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5521235840860754
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 02
None time:  0.6375699860509485
None Run 02:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 52.40
Split: 01, Run: 03
None time:  0.7236017640680075
None Run 03:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 95.00
   Final Test: 55.20
run time now: 1.948376178741455
total time:  2.00344413286075
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.20 ± 5.56
  Final Train: 98.33 ± 2.89
   Final Test: 57.90 ± 7.24
[I 2023-06-11 23:52:10,742] Trial 590 finished with value: 60.20000076293945 and parameters: {'Fwd': 0.0014730146594478155, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 8.889891982753438, 'loop': 2, 'loss': 'CE', 'lr': 0.009113010037389773, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.690236001802133e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.007140609194446724
weight_decay:  0.02183044282125903
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.28266005287878215
None Run 01:
Highest Train: 100.00
Highest Valid: 26.40
  Final Train: 100.00
   Final Test: 28.70
Split: 01, Run: 02
None time:  1.081972116138786
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 85.83
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.282923063961789
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 68.00
run time now: 1.6814448833465576
total time:  1.7319415530655533
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.40 ± 25.99
  Final Train: 95.00 ± 7.95
   Final Test: 54.97 ± 22.75
[I 2023-06-11 23:52:12,979] Trial 591 finished with value: 56.39999771118164 and parameters: {'Fwd': 0.009653572844275425, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 20, 'lambda1': 0.7000000000000001, 'lambda2': 3.2487546059483288, 'loop': 2, 'loss': 'CE', 'lr': 0.007140609194446724, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.02183044282125903, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00023420697105830027
weight_decay:  6.549047569031733e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3202350670471787
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 02
None time:  0.7623495638836175
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.9092804910615087
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.0232231616973877
total time:  3.0760590189602226
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 1.20
  Final Train: 100.00 ± 0.00
   Final Test: 68.63 ± 0.99
[I 2023-06-11 23:52:16,587] Trial 592 finished with value: 71.0 and parameters: {'Fwd': 0.00538591040855057, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 7.94563175455746, 'loop': 2, 'loss': 'CE', 'lr': 0.00023420697105830027, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.549047569031733e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.00045996333632460535
weight_decay:  0.00016933651870065423
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9309344249777496
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 02
None time:  0.9897465480025858
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.9123265489470214
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.90
run time now: 2.8659510612487793
total time:  2.907997053815052
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 1.78
  Final Train: 100.00 ± 0.00
   Final Test: 67.00 ± 1.21
[I 2023-06-11 23:52:20,004] Trial 593 finished with value: 68.79999542236328 and parameters: {'Fwd': 0.0006786305809487133, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 2.9955478524592904, 'loop': 2, 'loss': 'CE', 'lr': 0.00045996333632460535, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016933651870065423, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.0003171599170844523
weight_decay:  9.686322522972572e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4973579889629036
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  0.6790207559242845
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 03
None time:  0.7999370459001511
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.80
run time now: 3.0241777896881104
total time:  3.0790926271583885
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 1.25
  Final Train: 99.72 ± 0.48
   Final Test: 71.53 ± 0.93
[I 2023-06-11 23:52:23,558] Trial 594 finished with value: 72.4000015258789 and parameters: {'Fwd': 1.6195031719636463e-05, 'K': 3, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 5.720783941655443, 'loop': 2, 'loss': 'CE', 'lr': 0.0003171599170844523, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.686322522972572e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.007989434982110934
weight_decay:  9.80204646019528e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9180233040824533
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.6435849240515381
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.5864595391321927
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.30
run time now: 2.1880080699920654
total time:  2.2373227239586413
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 1.17
  Final Train: 99.72 ± 0.48
   Final Test: 70.97 ± 1.35
[I 2023-06-11 23:52:26,256] Trial 595 finished with value: 72.33333587646484 and parameters: {'Fwd': 0.0011408362944254663, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 8.280503528159388, 'loop': 2, 'loss': 'CE', 'lr': 0.007989434982110934, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.80204646019528e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.009280489513196518
weight_decay:  2.2179094858634706e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2056589650455862
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.5278297178447247
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.6042974430602044
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.374272584915161
total time:  2.4326440871227533
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.53 ± 0.64
  Final Train: 99.72 ± 0.48
   Final Test: 69.63 ± 1.44
[I 2023-06-11 23:52:29,150] Trial 596 finished with value: 74.53333282470703 and parameters: {'Fwd': 4.829631367699518e-06, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 9.678791305707165, 'loop': 2, 'loss': 'CE', 'lr': 0.009280489513196518, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2179094858634706e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00926987726941392
weight_decay:  2.276514478825859e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.206481629051268
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.564975876128301
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  0.7463424359448254
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.5506691932678223
total time:  2.6061280579306185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 2.02
[I 2023-06-11 23:52:32,275] Trial 597 finished with value: 72.93333435058594 and parameters: {'Fwd': 4.1856671109953e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 9.587574730160737, 'loop': 2, 'loss': 'CE', 'lr': 0.00926987726941392, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.276514478825859e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0007359983360167787
weight_decay:  2.5314904120172692e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9678022109437734
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 61.00
Split: 01, Run: 02
None time:  0.5034876891877502
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.10
Split: 01, Run: 03
None time:  0.7128564231097698
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 61.20
run time now: 2.2184488773345947
total time:  2.2618474059272557
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 61.77 ± 1.16
[I 2023-06-11 23:52:35,024] Trial 598 finished with value: 64.80001068115234 and parameters: {'Fwd': 7.316109120236894e-06, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.781232546308445, 'loop': 2, 'loss': 'CE', 'lr': 0.0007359983360167787, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.5314904120172692e-05, 'weightedloss': False}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.009107916749635707
weight_decay:  1.8629438423758195e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5852210109587759
None Run 01:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 49.60
Split: 01, Run: 02
None time:  1.204769531963393
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 98.33
   Final Test: 63.80
Split: 01, Run: 03
None time:  0.5235123168677092
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 66.60
run time now: 2.346858501434326
total time:  2.3987275040708482
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.53 ± 11.65
  Final Train: 99.44 ± 0.96
   Final Test: 60.00 ± 9.11
[I 2023-06-11 23:52:37,905] Trial 599 finished with value: 63.5333366394043 and parameters: {'Fwd': 1.945312603165097e-06, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.44493435648576, 'loop': 2, 'loss': 'CE', 'lr': 0.009107916749635707, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.8629438423758195e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00855328409783158
weight_decay:  2.921356024530288e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.411353665869683
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.544770868960768
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.5388887689914554
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.528550863265991
total time:  2.571268734987825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.33 ± 0.85
[I 2023-06-11 23:52:41,016] Trial 600 finished with value: 72.73332977294922 and parameters: {'Fwd': 5.8494627549543815e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.1, 'lambda2': 9.6505337846304, 'loop': 2, 'loss': 'CE', 'lr': 0.00855328409783158, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.921356024530288e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009370309015386534
weight_decay:  1.4976340307745212e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3885114239528775
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.7532576799858361
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.5995098669081926
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.7742443084716797
total time:  2.8171012240927666
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 0.60
  Final Train: 99.72 ± 0.48
   Final Test: 70.40 ± 0.53
[I 2023-06-11 23:52:44,478] Trial 601 finished with value: 72.79999542236328 and parameters: {'Fwd': 1.2642516878463594e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 9.11297688297827, 'loop': 2, 'loss': 'CE', 'lr': 0.009370309015386534, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4976340307745212e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.15000000000000002
lr:  0.0022154158943321896
weight_decay:  4.8502079044033496e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8664371750783175
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9507121460046619
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.5795781568158418
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.4384400844573975
total time:  2.4969620020128787
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.61
  Final Train: 99.72 ± 0.48
   Final Test: 69.40 ± 0.52
[I 2023-06-11 23:52:47,590] Trial 602 finished with value: 70.9333267211914 and parameters: {'Fwd': 5.197998302897776e-06, 'K': 4, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 9.98543028460499, 'loop': 2, 'loss': 'CE', 'lr': 0.0022154158943321896, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.8502079044033496e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.009945172201511462
weight_decay:  3.791030414210028e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4676777990534902
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 90.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.44589639082551
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 03
None time:  0.49371790303848684
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 67.10
run time now: 2.4552817344665527
total time:  2.505067152902484
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 0.31
  Final Train: 96.67 ± 5.77
   Final Test: 67.67 ± 2.79
[I 2023-06-11 23:52:50,668] Trial 603 finished with value: 72.5333251953125 and parameters: {'Fwd': 2.7170372889589997e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.4, 'lambda2': 1.5025348976642217, 'loop': 2, 'loss': 'CE', 'lr': 0.009945172201511462, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.791030414210028e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.007975549488375863
weight_decay:  2.053305078355776e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5256885699927807
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 64.70
Split: 01, Run: 02
None time:  0.5529806779231876
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.4966963450424373
None Run 03:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.90
run time now: 1.6102535724639893
total time:  1.669082570122555
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.67 ± 4.42
  Final Train: 100.00 ± 0.00
   Final Test: 64.97 ± 4.21
[I 2023-06-11 23:52:52,814] Trial 604 finished with value: 67.66666412353516 and parameters: {'Fwd': 4.404671166095296e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.340021195758137, 'loop': 0, 'loss': 'CE', 'lr': 0.007975549488375863, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.053305078355776e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.008600868060127869
weight_decay:  2.8101728428259105e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1444565351121128
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.6638590830843896
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  0.6031707481015474
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.20
run time now: 2.4427664279937744
total time:  2.4916204980108887
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 3.18
  Final Train: 100.00 ± 0.00
   Final Test: 71.00 ± 1.82
[I 2023-06-11 23:52:55,764] Trial 605 finished with value: 72.86666107177734 and parameters: {'Fwd': 8.871846298042542e-06, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.501268428039046, 'loop': 2, 'loss': 'CE', 'lr': 0.008600868060127869, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.8101728428259105e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00998033831224173
weight_decay:  0.000443706889860822
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.147522201994434
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  0.7589901469182223
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.8026709130499512
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.90
run time now: 2.742525339126587
total time:  2.7889849960338324
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.13 ± 0.46
  Final Train: 99.72 ± 0.48
   Final Test: 69.90 ± 1.40
[I 2023-06-11 23:52:59,118] Trial 606 finished with value: 73.13333129882812 and parameters: {'Fwd': 3.7309851019966816e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 5.341901690313511, 'loop': 2, 'loss': 'CE', 'lr': 0.00998033831224173, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000443706889860822, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0070058602988622015
weight_decay:  0.0002052025864519607
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8622755371034145
None Run 01:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 53.30
Split: 01, Run: 02
None time:  0.7852228519041091
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 61.00
Split: 01, Run: 03
None time:  0.6541773870121688
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 66.10
run time now: 2.332866907119751
total time:  2.382218087092042
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.53 ± 3.21
  Final Train: 100.00 ± 0.00
   Final Test: 60.13 ± 6.44
[I 2023-06-11 23:53:02,013] Trial 607 finished with value: 61.5333366394043 and parameters: {'Fwd': 3.369914642749409e-06, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 4.781130641297658, 'loop': 2, 'loss': 'MSE', 'lr': 0.0070058602988622015, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0002052025864519607, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.005100186382765144
weight_decay:  0.003499519868509372
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.711968275019899
None Run 01:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 94.17
   Final Test: 57.50
Split: 01, Run: 02
None time:  1.1084187170490623
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 98.33
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.9522416167892516
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 98.33
   Final Test: 68.50
run time now: 3.804676055908203
total time:  3.864612310193479
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.67 ± 8.72
  Final Train: 96.94 ± 2.41
   Final Test: 64.87 ± 6.38
[I 2023-06-11 23:53:06,349] Trial 608 finished with value: 64.66666412353516 and parameters: {'Fwd': 5.542439550715496e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.15000000000000002, 'lambda2': 3.618988390017075, 'loop': 2, 'loss': 'CE', 'lr': 0.005100186382765144, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003499519868509372, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.006279879631603271
weight_decay:  1.5345470702584898e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6339517950545996
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 65.20
Split: 01, Run: 02
None time:  0.613136483123526
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 94.17
   Final Test: 60.10
Split: 01, Run: 03
None time:  0.692165593849495
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 95.83
   Final Test: 68.90
run time now: 1.9849824905395508
total time:  2.0430124199483544
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.73 ± 3.65
  Final Train: 95.56 ± 1.27
   Final Test: 64.73 ± 4.42
[I 2023-06-11 23:53:08,917] Trial 609 finished with value: 65.73332977294922 and parameters: {'Fwd': 1.6671885403669205e-06, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 0.2303517001974163, 'loop': 2, 'loss': 'CE', 'lr': 0.006279879631603271, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.5345470702584898e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.003948770986662072
weight_decay:  0.0003302040953196231
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5633714681025594
None Run 01:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 42.00
Split: 01, Run: 02
None time:  1.0520200778264552
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 98.33
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.7044116838369519
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.00
run time now: 2.3537325859069824
total time:  2.4039382259361446
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.60 ± 15.97
  Final Train: 99.44 ± 0.96
   Final Test: 59.27 ± 14.95
[I 2023-06-11 23:53:11,834] Trial 610 finished with value: 60.60000228881836 and parameters: {'Fwd': 2.06162092448365e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 3.839305238728059, 'loop': 2, 'loss': 'CE', 'lr': 0.003948770986662072, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003302040953196231, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.15000000000000002
lr:  0.008524725921990856
weight_decay:  0.00014052515333546007
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9313742779195309
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.661046925932169
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.6932736299932003
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.20
run time now: 2.3349990844726562
total time:  2.380095456028357
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 71.30 ± 0.79
[I 2023-06-11 23:53:14,644] Trial 611 finished with value: 72.80000305175781 and parameters: {'Fwd': 8.559557263949323e-06, 'K': 5, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.055701854237212, 'loop': 2, 'loss': 'CE', 'lr': 0.008524725921990856, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00014052515333546007, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007562870287706527
weight_decay:  1.5490508419741816e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.00410451204516
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.625691673019901
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.1821462800726295
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.844156503677368
total time:  3.896066706860438
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 69.67 ± 0.46
[I 2023-06-11 23:53:19,055] Trial 612 finished with value: 70.93334197998047 and parameters: {'Fwd': 4.66018944349787e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 7.148690110629801, 'loop': 1, 'loss': 'CE', 'lr': 0.007562870287706527, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.5490508419741816e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0002143082152626731
weight_decay:  7.639084942592765e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3920225829351693
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 94.17
   Final Test: 66.50
Split: 01, Run: 02
None time:  0.7508806099649519
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.6774160990025848
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.90
run time now: 2.8530259132385254
total time:  2.8968812979292125
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 2.09
  Final Train: 97.50 ± 2.89
   Final Test: 68.50 ± 1.78
[I 2023-06-11 23:53:22,462] Trial 613 finished with value: 70.5999984741211 and parameters: {'Fwd': 1.764090545668151e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 0.6656564931790943, 'loop': 2, 'loss': 'CE', 'lr': 0.0002143082152626731, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.639084942592765e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0017031304762809875
weight_decay:  0.0686059711558027
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5675, Train: 99.17%, Valid: 72.60% Test: 71.10%
Split: 01, Run: 01
None time:  1.7397890440188348
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 71.50
Split: 01, Run: 02
None time:  0.48349408409558237
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 62.70
Split: 01, Run: 03
None time:  0.5303505270276219
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 66.20
run time now: 2.785653591156006
total time:  2.8315030781086534
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 1.62
  Final Train: 99.72 ± 0.48
   Final Test: 66.80 ± 4.43
[I 2023-06-11 23:53:25,797] Trial 614 finished with value: 71.66666412353516 and parameters: {'Fwd': 2.308269674483146e-06, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 9.283130156006193, 'loop': 2, 'loss': 'CE', 'lr': 0.0017031304762809875, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0686059711558027, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00923170201528821
weight_decay:  6.016275688379888e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2401616228744388
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 98.33
   Final Test: 70.40
Split: 01, Run: 02
None time:  0.6956108100712299
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.6424051949288696
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 65.90
run time now: 2.610494375228882
total time:  2.6636904808692634
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 1.21
  Final Train: 99.44 ± 0.96
   Final Test: 68.37 ± 2.28
[I 2023-06-11 23:53:28,976] Trial 615 finished with value: 72.86666870117188 and parameters: {'Fwd': 2.697409706832754e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 6.057000468354904, 'loop': 2, 'loss': 'CE', 'lr': 0.00923170201528821, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.016275688379888e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.002915604091398958
weight_decay:  0.000253830224477678
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9193933110218495
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.9920738700311631
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 95.83
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.6106091081164777
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 63.40
run time now: 2.5543150901794434
total time:  2.5955377428326756
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 1.03
  Final Train: 98.33 ± 2.20
   Final Test: 67.93 ± 3.93
[I 2023-06-11 23:53:32,182] Trial 616 finished with value: 71.46666717529297 and parameters: {'Fwd': 3.7212150849625294e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 4.118063008131433, 'loop': 2, 'loss': 'CE', 'lr': 0.002915604091398958, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000253830224477678, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.005552408150102207
weight_decay:  0.003971019279592652
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5546277661342174
None Run 01:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 58.40
Split: 01, Run: 02
None time:  0.5008962380234152
None Run 02:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 50.10
Split: 01, Run: 03
None time:  0.5562055599875748
None Run 03:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 47.60
run time now: 1.6467323303222656
total time:  1.706705188145861
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.00 ± 6.47
  Final Train: 100.00 ± 0.00
   Final Test: 52.03 ± 5.65
[I 2023-06-11 23:53:34,367] Trial 617 finished with value: 51.0 and parameters: {'Fwd': 1.1865038354900738e-06, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.01138635308315, 'loop': 2, 'loss': 'CE', 'lr': 0.005552408150102207, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003971019279592652, 'weightedloss': False}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00834595214581575
weight_decay:  4.0007710200880945e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6898202919401228
None Run 01:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 61.60
Split: 01, Run: 02
None time:  1.8752217721194029
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.8753565850201994
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.60
run time now: 3.475161552429199
total time:  3.5280237069819123
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.73 ± 6.74
  Final Train: 100.00 ± 0.00
   Final Test: 67.80 ± 5.41
[I 2023-06-11 23:53:38,378] Trial 618 finished with value: 68.73333740234375 and parameters: {'Fwd': 0.09985287064770142, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 9.732265541201622, 'loop': 2, 'loss': 'CE', 'lr': 0.00834595214581575, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.0007710200880945e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0071999396826182335
weight_decay:  9.110036807717188e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.345227699028328
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.7214865509886295
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.6157223570626229
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 68.60
run time now: 2.7145936489105225
total time:  2.759312368929386
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 0.12
  Final Train: 99.72 ± 0.48
   Final Test: 69.97 ± 1.18
[I 2023-06-11 23:53:41,641] Trial 619 finished with value: 73.46666717529297 and parameters: {'Fwd': 1.197629054152056e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 8.82606313407534, 'loop': 2, 'loss': 'CE', 'lr': 0.0071999396826182335, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.110036807717188e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.001179976562151259
weight_decay:  0.00572152358474989
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9163780501112342
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.60
Split: 01, Run: 02
None time:  1.3217249880544841
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 98.33
   Final Test: 71.10
Split: 01, Run: 03
None time:  0.7210104211699218
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 66.00
run time now: 2.9929933547973633
total time:  3.0627954190131277
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 4.01
  Final Train: 99.44 ± 0.96
   Final Test: 66.57 ± 4.28
[I 2023-06-11 23:53:45,228] Trial 620 finished with value: 69.13333129882812 and parameters: {'Fwd': 7.377797305410884e-06, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 4.54024253345386, 'loop': 2, 'loss': 'CE', 'lr': 0.001179976562151259, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00572152358474989, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.004453406876500121
weight_decay:  0.00011817010513187285
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5152046009898186
None Run 01:
Highest Train: 100.00
Highest Valid: 38.20
  Final Train: 100.00
   Final Test: 40.20
Split: 01, Run: 02
None time:  1.160348068922758
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 99.17
   Final Test: 65.50
Split: 01, Run: 03
None time:  0.614529682090506
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.50
run time now: 2.324051856994629
total time:  2.3758539429400116
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.93 ± 16.29
  Final Train: 99.72 ± 0.48
   Final Test: 56.07 ± 13.82
[I 2023-06-11 23:53:48,128] Trial 621 finished with value: 56.93333435058594 and parameters: {'Fwd': 5.269011582877077e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 9.169543501908434, 'loop': 2, 'loss': 'CE', 'lr': 0.004453406876500121, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011817010513187285, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0008854275123870373
weight_decay:  2.1516003093369336e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0354955701623112
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  1.4211570909246802
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  0.6597853158600628
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.20
run time now: 3.1502068042755127
total time:  3.2024543860461563
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 1.70
[I 2023-06-11 23:53:51,903] Trial 622 finished with value: 72.26667022705078 and parameters: {'Fwd': 2.3693496602719567e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 9.617226299414146, 'loop': 2, 'loss': 'CE', 'lr': 0.0008854275123870373, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.1516003093369336e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.003400761832766343
weight_decay:  5.067483832490069e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9715585641097277
None Run 01:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 93.33
   Final Test: 56.90
Split: 01, Run: 02
None time:  0.6350198690779507
None Run 02:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 56.30
Split: 01, Run: 03
None time:  0.9600382409989834
None Run 03:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 93.33
   Final Test: 61.40
run time now: 2.599640369415283
total time:  2.64472210011445
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.67 ± 1.40
  Final Train: 95.56 ± 3.85
   Final Test: 58.20 ± 2.79
[I 2023-06-11 23:53:55,051] Trial 623 finished with value: 59.66666793823242 and parameters: {'Fwd': 0.0001917191458153127, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 2.2719962492444123, 'loop': 2, 'loss': 'CE', 'lr': 0.003400761832766343, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.067483832490069e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0006074471696358451
weight_decay:  0.04724627530043868
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6895264401100576
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.65647232090123
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  1.0219688229262829
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 72.30
run time now: 3.401310682296753
total time:  3.4443795480765402
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.90
  Final Train: 99.44 ± 0.48
   Final Test: 71.43 ± 0.81
[I 2023-06-11 23:53:59,105] Trial 624 finished with value: 71.73332977294922 and parameters: {'Fwd': 9.267525362240646e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 6.430429699749651, 'loop': 2, 'loss': 'CE', 'lr': 0.0006074471696358451, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.04724627530043868, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.007869295882802984
weight_decay:  0.0027619724502467567
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6407543129753321
None Run 01:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 51.70
Split: 01, Run: 02
None time:  0.7240644032135606
None Run 02:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.00
Split: 01, Run: 03
None time:  0.857329203048721
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.20
run time now: 2.2538139820098877
total time:  2.3065989401657134
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.73 ± 6.84
  Final Train: 100.00 ± 0.00
   Final Test: 59.30 ± 6.67
[I 2023-06-11 23:54:01,966] Trial 625 finished with value: 59.733333587646484 and parameters: {'Fwd': 3.7029594689233408e-06, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 2.72387026958818, 'loop': 2, 'loss': 'MSE', 'lr': 0.007869295882802984, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0027619724502467567, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0004978684661686399
weight_decay:  3.140808274012265e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7856038180179894
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 02
None time:  0.6217217978555709
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 61.40
Split: 01, Run: 03
None time:  0.6079801570158452
None Run 03:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 59.00
run time now: 2.0473318099975586
total time:  2.0998537249397486
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.40 ± 4.23
  Final Train: 100.00 ± 0.00
   Final Test: 62.27 ± 3.78
[I 2023-06-11 23:54:04,584] Trial 626 finished with value: 63.40000534057617 and parameters: {'Fwd': 1.0390934900992824e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 8.937435165824049, 'loop': 2, 'loss': 'CE', 'lr': 0.0004978684661686399, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.140808274012265e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.006195632247648884
weight_decay:  0.0167610029067292
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8606468739453703
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.8230044518131763
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 95.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.5257916180416942
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.2472898960113525
total time:  2.31222578487359
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.72
  Final Train: 98.06 ± 2.68
   Final Test: 70.20 ± 1.31
[I 2023-06-11 23:54:07,386] Trial 627 finished with value: 71.79999542236328 and parameters: {'Fwd': 6.976012912077712e-06, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 7.3608758251504, 'loop': 1, 'loss': 'CE', 'lr': 0.006195632247648884, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0167610029067292, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.009051596179310811
weight_decay:  0.0008343405814593623
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9903949918225408
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 95.00
   Final Test: 67.50
Split: 01, Run: 02
None time:  0.6741592821199447
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 99.17
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.769774692831561
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 99.17
   Final Test: 67.80
run time now: 2.4752557277679443
total time:  2.521304661873728
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 0.61
  Final Train: 97.78 ± 2.41
   Final Test: 67.97 ± 0.57
[I 2023-06-11 23:54:10,440] Trial 628 finished with value: 68.46666717529297 and parameters: {'Fwd': 0.0002615477349039195, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 6.925614275839989, 'loop': 2, 'loss': 'CE', 'lr': 0.009051596179310811, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008343405814593623, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0014876111466340493
weight_decay:  0.004654615740024496
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5792007888667285
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 68.80
Split: 01, Run: 02
None time:  0.5886525029782206
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 60.10
Split: 01, Run: 03
None time:  0.6350013071205467
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.30
run time now: 2.8408708572387695
total time:  2.898319994099438
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.00 ± 2.46
  Final Train: 97.78 ± 3.85
   Final Test: 65.73 ± 4.89
[I 2023-06-11 23:54:13,932] Trial 629 finished with value: 69.0 and parameters: {'Fwd': 0.0009502500666668685, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 1.2786088024705458, 'loop': 2, 'loss': 'CE', 'lr': 0.0014876111466340493, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004654615740024496, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.006678641318622297
weight_decay:  1.2685484833494974e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3846508690621704
None Run 01:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 38.60
Split: 01, Run: 02
None time:  0.6702162839937955
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 97.50
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.37456176499836147
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 1.4617457389831543
total time:  1.504775813082233
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.00 ± 21.13
  Final Train: 99.17 ± 1.44
   Final Test: 59.30 ± 17.93
[I 2023-06-11 23:54:15,944] Trial 630 finished with value: 61.0 and parameters: {'Fwd': 0.00040193931110550467, 'K': 2, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 40, 'lambda1': 0.5, 'lambda2': 5.569547441616914, 'loop': 2, 'loss': 'CE', 'lr': 0.006678641318622297, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2685484833494974e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.0010129821219820286
weight_decay:  0.00016798688564370262
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7855311259627342
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 02
None time:  1.4117964641191065
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.5865823670756072
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.8142282962799072
total time:  2.8602150708902627
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 2.00
  Final Train: 99.72 ± 0.48
   Final Test: 68.63 ± 1.06
[I 2023-06-11 23:54:19,339] Trial 631 finished with value: 70.79999542236328 and parameters: {'Fwd': 3.1148916447473425e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 9.8610941033753, 'loop': 2, 'loss': 'CE', 'lr': 0.0010129821219820286, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00016798688564370262, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.007992192353687826
weight_decay:  0.0026285831415844563
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6054755679797381
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.7294856470543891
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.9782857440877706
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 4.34539270401001
total time:  4.391317942878231
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.65
[I 2023-06-11 23:54:24,275] Trial 632 finished with value: 71.0 and parameters: {'Fwd': 1.9167353527735547e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.450419540790165, 'loop': 2, 'loss': 'CE', 'lr': 0.007992192353687826, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0026285831415844563, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.00995169346947963
weight_decay:  6.670249132311933e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8878767041023821
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 02
None time:  0.6772162199486047
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  0.6244426548946649
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 2.2237021923065186
total time:  2.267828896874562
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 68.50 ± 1.22
[I 2023-06-11 23:54:27,074] Trial 633 finished with value: 71.4000015258789 and parameters: {'Fwd': 3.436165146881864e-06, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 8.701233036541506, 'loop': 2, 'loss': 'CE', 'lr': 0.00995169346947963, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.670249132311933e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.1
lr:  0.008747194294464748
weight_decay:  0.008886594597184744
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5307730960194021
None Run 01:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 46.10
Split: 01, Run: 02
None time:  0.6087145209312439
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.4440796950366348
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.50
run time now: 1.6188089847564697
total time:  1.6769640729762614
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.00 ± 15.49
  Final Train: 100.00 ± 0.00
   Final Test: 62.97 ± 14.61
[I 2023-06-11 23:54:29,297] Trial 634 finished with value: 64.0 and parameters: {'Fwd': 0.0007622417117534109, 'K': 4, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.2, 'lambda2': 6.681487192911526, 'loop': 2, 'loss': 'CE', 'lr': 0.008747194294464748, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008886594597184744, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.002663685564324941
weight_decay:  2.5225059794215484e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5745462931226939
None Run 01:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 50.70
Split: 01, Run: 02
None time:  1.5265603188890964
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.0299530860502273
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 95.83
   Final Test: 70.00
run time now: 3.162078619003296
total time:  3.2051041608210653
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.20 ± 11.82
  Final Train: 98.33 ± 2.20
   Final Test: 63.87 ± 11.41
[I 2023-06-11 23:54:33,052] Trial 635 finished with value: 63.20000076293945 and parameters: {'Fwd': 0.0636649962819188, 'K': 1, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 3.594633291834081, 'loop': 2, 'loss': 'CE', 'lr': 0.002663685564324941, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.5225059794215484e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.15000000000000002
lr:  0.007356705224901232
weight_decay:  1.7079648044937727e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.063102605054155
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 68.80
Split: 01, Run: 02
None time:  0.5900503108277917
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.5967903358396143
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.2863452434539795
total time:  2.338665226008743
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 69.43 ± 0.65
[I 2023-06-11 23:54:35,876] Trial 636 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.0017584096305583924, 'K': 3, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 7.631014535930698, 'loop': 2, 'loss': 'CE', 'lr': 0.007356705224901232, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7079648044937727e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.0002651627049953133
weight_decay:  3.918416819533785e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0067357730586082
None Run 01:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.00
Split: 01, Run: 02
None time:  0.6481908010318875
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.70
Split: 01, Run: 03
None time:  0.5850547559093684
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.80
run time now: 2.2728357315063477
total time:  2.3257556578610092
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.80 ± 1.31
  Final Train: 100.00 ± 0.00
   Final Test: 61.50 ± 1.41
[I 2023-06-11 23:54:38,700] Trial 637 finished with value: 63.79999923706055 and parameters: {'Fwd': 0.00012471559742272583, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 9.338400138683207, 'loop': 2, 'loss': 'CE', 'lr': 0.0002651627049953133, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.918416819533785e-05, 'weightedloss': False}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00015481763607168983
weight_decay:  0.00038900554933522867
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.9333, Train: 98.33%, Valid: 68.00% Test: 67.80%
Split: 01, Run: 01
None time:  1.7499403411056846
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 67.70
Split: 01, Run: 02
None time:  0.7356419409625232
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.689674278954044
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 68.50
run time now: 3.208477735519409
total time:  3.2630619229748845
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 2.16
  Final Train: 99.44 ± 0.96
   Final Test: 68.20 ± 0.44
[I 2023-06-11 23:54:42,483] Trial 638 finished with value: 70.46666717529297 and parameters: {'Fwd': 2.3163832336265143e-06, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 3.2313243312672713, 'loop': 2, 'loss': 'CE', 'lr': 0.00015481763607168983, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00038900554933522867, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009037197818386586
weight_decay:  0.00025405503929525454
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0196463440079242
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.83
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.5819584559649229
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  0.7146937940269709
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 97.50
   Final Test: 71.00
run time now: 2.349339723587036
total time:  2.3962447030935436
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 1.36
  Final Train: 97.78 ± 2.10
   Final Test: 71.20 ± 0.62
[I 2023-06-11 23:54:45,341] Trial 639 finished with value: 73.53333282470703 and parameters: {'Fwd': 0.007087503082616422, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 1.1913104935194998, 'loop': 2, 'loss': 'CE', 'lr': 0.009037197818386586, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00025405503929525454, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.007960154938273505
weight_decay:  9.703816995191805e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1904286090284586
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.6265317590441555
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  0.6939175301231444
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.90
run time now: 2.5439529418945312
total time:  2.5955843199044466
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 71.43 ± 0.50
[I 2023-06-11 23:54:48,475] Trial 640 finished with value: 73.06665802001953 and parameters: {'Fwd': 0.03169212703336828, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.05990534726619, 'loop': 2, 'loss': 'CE', 'lr': 0.007960154938273505, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.703816995191805e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0004065228042443349
weight_decay:  0.006600078380455302
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7850113019812852
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 68.50
Split: 01, Run: 02
None time:  0.7159180010203272
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.60
Split: 01, Run: 03
None time:  0.7254867320880294
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.266040563583374
total time:  3.3305730470456183
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 1.81
  Final Train: 99.72 ± 0.48
   Final Test: 70.30 ± 2.10
[I 2023-06-11 23:54:52,338] Trial 641 finished with value: 72.5333251953125 and parameters: {'Fwd': 0.0012577772826592997, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 5.770062669914385, 'loop': 2, 'loss': 'CE', 'lr': 0.0004065228042443349, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006600078380455302, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0018765412872760719
weight_decay:  0.0020549438204705128
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5687862641643733
None Run 01:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 47.90
Split: 01, Run: 02
None time:  0.4626025981269777
None Run 02:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 41.50
Split: 01, Run: 03
None time:  0.47065587993711233
None Run 03:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 42.30
run time now: 1.5348153114318848
total time:  1.5939314309507608
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 45.53 ± 6.17
  Final Train: 100.00 ± 0.00
   Final Test: 43.90 ± 3.49
[I 2023-06-11 23:54:54,407] Trial 642 finished with value: 45.5333366394043 and parameters: {'Fwd': 0.0005616527903975282, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 1.8614346244599562, 'loop': 0, 'loss': 'CE', 'lr': 0.0018765412872760719, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0020549438204705128, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.00688500173301383
weight_decay:  5.415214967091803e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8469713300000876
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.9355190221685916
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.7724267230369151
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.5869929790496826
total time:  2.6373369058128446
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 1.41
[I 2023-06-11 23:54:57,599] Trial 643 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.002987738435761591, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 6.156729152030367, 'loop': 2, 'loss': 'CE', 'lr': 0.00688500173301383, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.415214967091803e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0058941475801153435
weight_decay:  0.015039649460563157
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9797145600896329
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  0.5960580641403794
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.6076008200179785
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.2178876399993896
total time:  2.265114356065169
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.29
  Final Train: 100.00 ± 0.00
   Final Test: 69.33 ± 1.53
[I 2023-06-11 23:55:00,330] Trial 644 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.00016649211291249838, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 8.526897580125187, 'loop': 2, 'loss': 'MSE', 'lr': 0.0058941475801153435, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.015039649460563157, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  1.0
lr:  0.0006811177641056754
weight_decay:  8.01511201606568e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6836969719734043
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 60.00
Split: 01, Run: 02
None time:  0.6845804860349745
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 58.50
Split: 01, Run: 03
None time:  0.6488550810609013
None Run 03:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 58.90
run time now: 2.050447702407837
total time:  2.1053802520036697
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.07 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 59.13 ± 0.78
[I 2023-06-11 23:55:02,932] Trial 645 finished with value: 61.06666564941406 and parameters: {'Fwd': 0.0008785417404514284, 'K': 1, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.661624111454847, 'loop': 2, 'loss': 'CE', 'lr': 0.0006811177641056754, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.01511201606568e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.005321269807890413
weight_decay:  0.0001447475066593807
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6450114790350199
None Run 01:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 48.90
Split: 01, Run: 02
None time:  1.1079033149871975
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 94.17
   Final Test: 67.70
Split: 01, Run: 03
None time:  0.5813098091166466
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.3677234649658203
total time:  2.4179824891034514
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.60 ± 14.24
  Final Train: 98.06 ± 3.37
   Final Test: 62.30 ± 11.68
[I 2023-06-11 23:55:05,814] Trial 646 finished with value: 62.60000228881836 and parameters: {'Fwd': 1.6390866774171402e-06, 'K': 2, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 4.15852400357075, 'loop': 1, 'loss': 'CE', 'lr': 0.005321269807890413, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001447475066593807, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.009304928784204502
weight_decay:  0.0005668999091357347
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.234116183128208
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.83
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.6166474509518594
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.5954789861571044
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.00
run time now: 2.4817705154418945
total time:  2.5366178180556744
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.99
  Final Train: 98.61 ± 2.41
   Final Test: 71.23 ± 1.00
[I 2023-06-11 23:55:08,943] Trial 647 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.0003216212347171603, 'K': 3, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 4.545890915827109, 'loop': 2, 'loss': 'CE', 'lr': 0.009304928784204502, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005668999091357347, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00849264691009205
weight_decay:  0.08020274683471555
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4869126540143043
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  1.414697205182165
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 03
None time:  1.4608088040258735
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
run time now: 4.410683631896973
total time:  4.4686757531017065
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.30 ± 0.00
[I 2023-06-11 23:55:14,032] Trial 648 finished with value: 51.20000076293945 and parameters: {'Fwd': 3.0640660521745397e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.0, 'lambda2': 8.859856847173068, 'loop': 2, 'loss': 'CE', 'lr': 0.00849264691009205, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.08020274683471555, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00479055650299745
weight_decay:  0.00031488627125294963
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.247979565989226
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 94.17
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.6139164010528475
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 60.60
Split: 01, Run: 03
None time:  0.5588930600788444
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 66.70
run time now: 2.462228536605835
total time:  2.5210850189905614
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.69
  Final Train: 98.06 ± 3.37
   Final Test: 65.67 ± 4.64
[I 2023-06-11 23:55:17,114] Trial 649 finished with value: 70.5999984741211 and parameters: {'Fwd': 4.0130531523383484e-05, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 2.9851350899549685, 'loop': 2, 'loss': 'CE', 'lr': 0.00479055650299745, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00031488627125294963, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007504392615279218
weight_decay:  0.00011397717052338285
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9547456000000238
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.1229642610996962
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  2.1984006168786436
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.30
run time now: 4.333715915679932
total time:  4.385497905081138
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 70.63 ± 0.70
[I 2023-06-11 23:55:22,010] Trial 650 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0006625796763017143, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 4.930164133690537, 'loop': 2, 'loss': 'CE', 'lr': 0.007504392615279218, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011397717052338285, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.009925345254765384
weight_decay:  0.00019834768555333454
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5983957021962851
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 86.67
   Final Test: 67.20
Split: 01, Run: 02
None time:  0.48139215516857803
None Run 02:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 59.30
Split: 01, Run: 03
None time:  0.4656179181765765
None Run 03:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.40
run time now: 2.578754186630249
total time:  2.6327258609235287
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.53 ± 2.10
  Final Train: 95.56 ± 7.70
   Final Test: 62.30 ± 4.28
[I 2023-06-11 23:55:25,146] Trial 651 finished with value: 63.5333366394043 and parameters: {'Fwd': 0.0015426237731625452, 'K': 1, 'alpha': 0.4, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 9.24749905641654, 'loop': 2, 'loss': 'CE', 'lr': 0.009925345254765384, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019834768555333454, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.006352177280688134
weight_decay:  0.0017386719858445648
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9377119168639183
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.00
   Final Test: 68.70
Split: 01, Run: 02
None time:  0.6782974069938064
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 63.30
Split: 01, Run: 03
None time:  0.674784914124757
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 68.40
run time now: 2.323075771331787
total time:  2.378241875907406
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.69
  Final Train: 98.33 ± 2.89
   Final Test: 66.80 ± 3.03
[I 2023-06-11 23:55:28,029] Trial 652 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.008189548312976311, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 0.7478507681628921, 'loop': 2, 'loss': 'CE', 'lr': 0.006352177280688134, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0017386719858445648, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.008420981767700427
weight_decay:  3.216826431649862e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.307662065839395
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 92.50
   Final Test: 67.50
Split: 01, Run: 02
None time:  0.6006168799940497
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.6284086359664798
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.5782289505004883
total time:  2.643468301044777
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.03
  Final Train: 97.50 ± 4.33
   Final Test: 68.43 ± 1.01
[I 2023-06-11 23:55:31,138] Trial 653 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.003953701078715043, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 2.648388288080709, 'loop': 2, 'loss': 'CE', 'lr': 0.008420981767700427, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.216826431649862e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.002146915862310986
weight_decay:  2.2686699434667506e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5673677769955248
None Run 01:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.30
Split: 01, Run: 02
None time:  1.3916203069966286
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.1569964960217476
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 70.50
run time now: 3.1497414112091064
total time:  3.196634043008089
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.80 ± 6.59
  Final Train: 98.33 ± 1.67
   Final Test: 66.47 ± 7.07
[I 2023-06-11 23:55:34,883] Trial 654 finished with value: 66.79999542236328 and parameters: {'Fwd': 0.05389166615152438, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 1.6566793883251896, 'loop': 2, 'loss': 'CE', 'lr': 0.002146915862310986, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2686699434667506e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.007345364564825209
weight_decay:  6.437933992221252e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5866234840359539
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 02
None time:  0.6865054341033101
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 96.67
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.5548376569058746
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 1.8664743900299072
total time:  1.92189741297625
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 0.64
  Final Train: 98.89 ± 1.92
   Final Test: 69.00 ± 1.61
[I 2023-06-11 23:55:37,303] Trial 655 finished with value: 69.13333129882812 and parameters: {'Fwd': 2.6786060147059233e-06, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 0.270534875311626, 'loop': 2, 'loss': 'CE', 'lr': 0.007345364564825209, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.437933992221252e-05, 'weightedloss': False}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0009334783640413153
weight_decay:  4.425944744408531e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.30110969603993
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.5734935039654374
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.70
Split: 01, Run: 03
None time:  0.6657308179419488
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.70
run time now: 3.5711734294891357
total time:  3.6279680689331144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 1.55
  Final Train: 100.00 ± 0.00
   Final Test: 71.13 ± 2.71
[I 2023-06-11 23:55:41,396] Trial 656 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.021736652125533603, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 9.855832575904142, 'loop': 2, 'loss': 'CE', 'lr': 0.0009334783640413153, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.425944744408531e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.15000000000000002
lr:  0.0007867888984049405
weight_decay:  2.0641160047752796e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9803088179323822
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 98.33
   Final Test: 71.80
Split: 01, Run: 02
None time:  0.7060162739362568
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 98.33
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.6254723989404738
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.00
run time now: 2.347482204437256
total time:  2.403881540056318
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 0.20
  Final Train: 98.89 ± 0.96
   Final Test: 70.80 ± 1.56
[I 2023-06-11 23:55:44,306] Trial 657 finished with value: 72.79999542236328 and parameters: {'Fwd': 1.463835166430567e-05, 'K': 5, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 3.4827985272585407, 'loop': 2, 'loss': 'CE', 'lr': 0.0007867888984049405, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.0641160047752796e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.008977111961608091
weight_decay:  1.445764389178469e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9888885240070522
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 02
None time:  0.5557510058861226
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 03
None time:  0.5535154901444912
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.1372931003570557
total time:  2.1906726888846606
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.07 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 71.33 ± 1.10
[I 2023-06-11 23:55:47,064] Trial 658 finished with value: 75.0666732788086 and parameters: {'Fwd': 0.0010673753603421669, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.490014282287223, 'loop': 2, 'loss': 'CE', 'lr': 0.008977111961608091, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.445764389178469e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009989033957998933
weight_decay:  1.3707984014365832e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1714117040392011
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.5394635449629277
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.6260890599805862
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.368056535720825
total time:  2.416353384964168
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.57 ± 0.25
[I 2023-06-11 23:55:50,027] Trial 659 finished with value: 74.46666717529297 and parameters: {'Fwd': 0.0011223051469192728, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.114871245680291, 'loop': 2, 'loss': 'CE', 'lr': 0.009989033957998933, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3707984014365832e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009969940630654999
weight_decay:  1.84558258609808e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1758412441704422
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 96.67
   Final Test: 72.30
Split: 01, Run: 02
None time:  0.5321257950272411
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  0.5117143029347062
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.264772891998291
total time:  2.326498624868691
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.73 ± 0.12
  Final Train: 98.89 ± 1.92
   Final Test: 71.47 ± 0.80
[I 2023-06-11 23:55:52,959] Trial 660 finished with value: 73.73332977294922 and parameters: {'Fwd': 0.0008582572742225947, 'K': 2, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.470026401878613, 'loop': 2, 'loss': 'CE', 'lr': 0.009969940630654999, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.84558258609808e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009013506291927315
weight_decay:  1.1129244182157609e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5564761059358716
None Run 01:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 57.90
Split: 01, Run: 02
None time:  0.9901254160795361
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.7458302439190447
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.326664686203003
total time:  2.3836363528389484
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 9.22
  Final Train: 100.00 ± 0.00
   Final Test: 66.37 ± 7.38
[I 2023-06-11 23:55:55,906] Trial 661 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.0010615023087155054, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 9.199056785320124, 'loop': 2, 'loss': 'CE', 'lr': 0.009013506291927315, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1129244182157609e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.009946990346962637
weight_decay:  1.4607520813891054e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6589074691291898
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 85.83
   Final Test: 63.60
Split: 01, Run: 02
None time:  0.613206614041701
None Run 02:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 58.30
Split: 01, Run: 03
None time:  1.056704925140366
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 85.00
   Final Test: 67.40
run time now: 3.3644752502441406
total time:  3.4159142922144383
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.67 ± 2.16
  Final Train: 90.28 ± 8.43
   Final Test: 63.10 ± 4.57
[I 2023-06-11 23:55:59,807] Trial 662 finished with value: 64.66666412353516 and parameters: {'Fwd': 1.3646914305044647e-06, 'K': 3, 'alpha': 0.0, 'dropout': 0.2, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 2.1493911174892695, 'loop': 2, 'loss': 'CE', 'lr': 0.009946990346962637, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4607520813891054e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009235981263001194
weight_decay:  1.5193333581824459e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8145593020599335
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  0.5857261018827558
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.6237309142015874
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.10
run time now: 2.0591135025024414
total time:  2.1156686840113252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.93 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 71.03 ± 0.93
[I 2023-06-11 23:56:02,408] Trial 663 finished with value: 73.93333435058594 and parameters: {'Fwd': 0.0011507187742913988, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 5.2387621452562225, 'loop': 2, 'loss': 'CE', 'lr': 0.009235981263001194, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.5193333581824459e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00867569141795192
weight_decay:  2.2978318641452578e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.4776, Train: 100.00%, Valid: 56.60% Test: 58.30%
Split: 01, Run: 01
None time:  1.7033132209908217
None Run 01:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 57.10
Split: 01, Run: 02
None time:  0.7105488399975002
None Run 02:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 58.40
Split: 01, Run: 03
None time:  0.8500057370401919
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.40
run time now: 3.2965047359466553
total time:  3.3485554908402264
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.33 ± 4.54
  Final Train: 100.00 ± 0.00
   Final Test: 59.30 ± 2.76
[I 2023-06-11 23:56:06,320] Trial 664 finished with value: 57.33333206176758 and parameters: {'Fwd': 0.0007896762890312543, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 3.9537845682136927, 'loop': 2, 'loss': 'MSE', 'lr': 0.00867569141795192, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2978318641452578e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.00010235508974005221
weight_decay:  0.0004849474424211363
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5746769930701703
None Run 01:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 35.90
Split: 01, Run: 02
None time:  1.1805915599688888
None Run 02:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 56.60
Split: 01, Run: 03
None time:  0.5798449220601469
None Run 03:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 58.30
run time now: 2.3679866790771484
total time:  2.419969720998779
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.20 ± 12.57
  Final Train: 100.00 ± 0.00
   Final Test: 50.27 ± 12.47
[I 2023-06-11 23:56:09,379] Trial 665 finished with value: 54.20000076293945 and parameters: {'Fwd': 0.0005481179066828587, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 9.097502934793965, 'loop': 2, 'loss': 'CE', 'lr': 0.00010235508974005221, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0004849474424211363, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0015925523286959965
weight_decay:  1.2976257873283378e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1946257599629462
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 97.50
   Final Test: 68.30
Split: 01, Run: 02
None time:  1.1259727359283715
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 96.67
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.915500019909814
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 98.33
   Final Test: 72.10
run time now: 3.266187906265259
total time:  3.314753640908748
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 97.50 ± 0.83
   Final Test: 70.03 ± 1.92
[I 2023-06-11 23:56:13,217] Trial 666 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.0025539530834148344, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 2.4041520628322286, 'loop': 2, 'loss': 'CE', 'lr': 0.0015925523286959965, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2976257873283378e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009169352122665432
weight_decay:  0.011665149231131582
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5401097591966391
None Run 01:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 55.10
Split: 01, Run: 02
None time:  1.0314282590989023
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.5370971390511841
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 67.00
run time now: 2.1426706314086914
total time:  2.189263705862686
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.40 ± 13.53
  Final Train: 99.72 ± 0.48
   Final Test: 63.83 ± 7.66
[I 2023-06-11 23:56:15,955] Trial 667 finished with value: 64.4000015258789 and parameters: {'Fwd': 5.6721518683596095e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 6.541678202263973, 'loop': 2, 'loss': 'CE', 'lr': 0.009169352122665432, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.011665149231131582, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.00996211285244882
weight_decay:  0.00019667292020428238
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.4988, Train: 100.00%, Valid: 70.40% Test: 70.40%
Split: 01, Run: 01
None time:  2.003691959893331
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.6688486440107226
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 03
None time:  0.627957807155326
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 72.30
run time now: 3.3346619606018066
total time:  3.3795823170803487
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 71.53 ± 1.16
[I 2023-06-11 23:56:19,897] Trial 668 finished with value: 71.33333587646484 and parameters: {'Fwd': 2.7982897121237125e-05, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 9.462567360570086, 'loop': 2, 'loss': 'CE', 'lr': 0.00996211285244882, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019667292020428238, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008161172928380974
weight_decay:  9.794177953035955e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9397121800575405
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 96.67
   Final Test: 63.90
Split: 01, Run: 02
None time:  1.0475003540050238
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 86.67
   Final Test: 66.30
Split: 01, Run: 03
None time:  0.6896794990170747
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.80
run time now: 2.708944320678711
total time:  2.7560742569621652
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.73 ± 2.30
  Final Train: 94.44 ± 6.94
   Final Test: 66.00 ± 1.97
[I 2023-06-11 23:56:23,168] Trial 669 finished with value: 68.73332977294922 and parameters: {'Fwd': 0.0013606649860266552, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 0.4738092665124921, 'loop': 2, 'loss': 'CE', 'lr': 0.008161172928380974, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.794177953035955e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0086801533846816
weight_decay:  2.6469575010586733e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0342017030343413
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.8725856961682439
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.9208333590067923
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.861284017562866
total time:  3.905824795830995
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 1.11
  Final Train: 99.72 ± 0.48
   Final Test: 70.07 ± 0.55
[I 2023-06-11 23:56:27,590] Trial 670 finished with value: 71.00000762939453 and parameters: {'Fwd': 4.810984749720654e-05, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.799024859621984, 'loop': 2, 'loss': 'CE', 'lr': 0.0086801533846816, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.6469575010586733e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009125222398994602
weight_decay:  1.9542405512315953e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4695374800357968
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 89.17
   Final Test: 72.30
Split: 01, Run: 02
None time:  0.48965085088275373
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.6090589738450944
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 97.50
   Final Test: 71.00
run time now: 2.600149154663086
total time:  2.6626112398225814
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.13 ± 1.03
  Final Train: 95.56 ± 5.67
   Final Test: 70.87 ± 1.50
[I 2023-06-11 23:56:30,761] Trial 671 finished with value: 73.13333129882812 and parameters: {'Fwd': 0.0018599429554935249, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 0.9929337396989821, 'loop': 2, 'loss': 'CE', 'lr': 0.009125222398994602, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.9542405512315953e-05, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00999397388764728
weight_decay:  0.00023767465192931262
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4369177520275116
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 72.10
Split: 01, Run: 02
None time:  0.589913432020694
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.6048695428762585
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.10
run time now: 2.669416904449463
total time:  2.7138729710131884
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.60 ± 0.87
  Final Train: 99.72 ± 0.48
   Final Test: 71.73 ± 0.64
[I 2023-06-11 23:56:33,972] Trial 672 finished with value: 74.5999984741211 and parameters: {'Fwd': 9.91561700523034e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.296367051247001, 'loop': 2, 'loss': 'CE', 'lr': 0.00999397388764728, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00023767465192931262, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0012748051629957974
weight_decay:  0.00034566251832181065
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0542898990679532
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 61.00
Split: 01, Run: 02
None time:  1.1363355468492955
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.8173032188788056
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.40
run time now: 3.041123867034912
total time:  3.096644147997722
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 4.16
  Final Train: 100.00 ± 0.00
   Final Test: 67.53 ± 5.69
[I 2023-06-11 23:56:37,617] Trial 673 finished with value: 69.79999542236328 and parameters: {'Fwd': 1.2392626152563607e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 9.262870847928713, 'loop': 2, 'loss': 'CE', 'lr': 0.0012748051629957974, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00034566251832181065, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009396764559614376
weight_decay:  0.0013576439953764308
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4418162950314581
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 99.17
   Final Test: 65.10
Split: 01, Run: 02
None time:  0.678495452972129
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.10
Split: 01, Run: 03
None time:  0.7350054928101599
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.00
run time now: 2.898690700531006
total time:  2.955534994835034
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 0.50
  Final Train: 99.72 ± 0.48
   Final Test: 65.07 ± 0.95
[I 2023-06-11 23:56:41,084] Trial 674 finished with value: 68.46666717529297 and parameters: {'Fwd': 2.0524374235698422e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.04462048478786, 'loop': 2, 'loss': 'CE', 'lr': 0.009396764559614376, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0013576439953764308, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0003233811137220198
weight_decay:  0.0002281908414856145
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.900885249953717
None Run 01:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 50.70
Split: 01, Run: 02
None time:  0.6978735961019993
None Run 02:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 53.80
Split: 01, Run: 03
None time:  0.7330055078491569
None Run 03:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 55.20
run time now: 2.3641510009765625
total time:  2.4198208909947425
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.20 ± 1.91
  Final Train: 100.00 ± 0.00
   Final Test: 53.23 ± 2.30
[I 2023-06-11 23:56:43,998] Trial 675 finished with value: 56.20000076293945 and parameters: {'Fwd': 0.0010334559265615419, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 4.316036590589741, 'loop': 2, 'loss': 'CE', 'lr': 0.0003233811137220198, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002281908414856145, 'weightedloss': False}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009936555615480984
weight_decay:  0.00018396566210997846
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.277597937034443
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.699919949984178
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.6910381389316171
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.701094150543213
total time:  2.756192373810336
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 70.30 ± 0.46
[I 2023-06-11 23:56:47,311] Trial 676 finished with value: 72.79999542236328 and parameters: {'Fwd': 7.479864321169423e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 9.305009340730162, 'loop': 2, 'loss': 'CE', 'lr': 0.009936555615480984, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00018396566210997846, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009987598075111804
weight_decay:  0.0002849035325167089
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4595985801424831
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 98.33
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.8073592570144683
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.7075251140631735
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 68.50
run time now: 3.008542776107788
total time:  3.054642572067678
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.13 ± 0.83
  Final Train: 99.44 ± 0.96
   Final Test: 70.20 ± 1.49
[I 2023-06-11 23:56:50,905] Trial 677 finished with value: 74.13333892822266 and parameters: {'Fwd': 1.178487548255615e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.178832771416651, 'loop': 2, 'loss': 'CE', 'lr': 0.009987598075111804, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002849035325167089, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00994209284476026
weight_decay:  0.0009291494773303556
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2665125550702214
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  0.6709220048505813
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.8519275148864836
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.30
run time now: 2.8199262619018555
total time:  2.8651785631664097
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.67 ± 1.29
  Final Train: 100.00 ± 0.00
   Final Test: 71.67 ± 0.85
[I 2023-06-11 23:56:54,352] Trial 678 finished with value: 74.66666412353516 and parameters: {'Fwd': 1.2175795779512882e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.621920805475277, 'loop': 2, 'loss': 'CE', 'lr': 0.00994209284476026, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009291494773303556, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009326609149565993
weight_decay:  0.000999396915394788
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3235225970856845
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 99.17
   Final Test: 67.10
Split: 01, Run: 02
None time:  0.7994534040335566
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 65.30
Split: 01, Run: 03
None time:  0.7539154819678515
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 64.40
run time now: 2.910465955734253
total time:  2.9539326610974967
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.87 ± 0.76
  Final Train: 99.72 ± 0.48
   Final Test: 65.60 ± 1.37
[I 2023-06-11 23:56:57,940] Trial 679 finished with value: 68.86666870117188 and parameters: {'Fwd': 9.528220165582532e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 7.300114616469697, 'loop': 2, 'loss': 'CE', 'lr': 0.009326609149565993, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000999396915394788, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009860028710981837
weight_decay:  0.0005348135008022101
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2790559788700193
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 99.17
   Final Test: 65.80
Split: 01, Run: 02
None time:  0.8473957339301705
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  0.7783771120011806
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 67.90
run time now: 2.954322099685669
total time:  3.017585150897503
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 2.12
  Final Train: 99.72 ± 0.48
   Final Test: 66.87 ± 1.05
[I 2023-06-11 23:57:01,606] Trial 680 finished with value: 69.60000610351562 and parameters: {'Fwd': 1.5328821898040918e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.4746733624473976, 'loop': 2, 'loss': 'CE', 'lr': 0.009860028710981837, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005348135008022101, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009147494833621404
weight_decay:  0.00041842554395048697
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4300796419847757
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.8942773689050227
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.8240229189395905
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.00
run time now: 3.181788682937622
total time:  3.2424703370779753
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.33 ± 0.50
  Final Train: 99.72 ± 0.48
   Final Test: 71.17 ± 0.85
[I 2023-06-11 23:57:05,435] Trial 681 finished with value: 74.33333587646484 and parameters: {'Fwd': 1.0576472512231048e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 7.6772790764119625, 'loop': 2, 'loss': 'CE', 'lr': 0.009147494833621404, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00041842554395048697, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00035420782638758986
weight_decay:  0.001692792713180854
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6530503800604492
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  0.9782882579602301
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.9419935969635844
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.607468605041504
total time:  3.662374606821686
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.75
[I 2023-06-11 23:57:09,690] Trial 682 finished with value: 71.26667022705078 and parameters: {'Fwd': 9.552848857335764e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 8.320114548381817, 'loop': 2, 'loss': 'CE', 'lr': 0.00035420782638758986, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001692792713180854, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00012079195060825806
weight_decay:  0.0007103936181868307
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.9535, Train: 100.00%, Valid: 60.20% Test: 58.40%
Split: 01, Run: 01
None time:  2.088616660097614
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.30
Split: 01, Run: 02
None time:  0.8071993379853666
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 65.50
Split: 01, Run: 03
None time:  1.0320631149224937
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.40
run time now: 3.962548017501831
total time:  4.014439991908148
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.20 ± 5.23
  Final Train: 100.00 ± 0.00
   Final Test: 63.40 ± 4.44
[I 2023-06-11 23:57:14,176] Trial 683 finished with value: 66.20000457763672 and parameters: {'Fwd': 1.4505371676192442e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 6.9598901863902665, 'loop': 2, 'loss': 'CE', 'lr': 0.00012079195060825806, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007103936181868307, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00012229543216282855
weight_decay:  0.0007920250839796252
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.9592, Train: 100.00%, Valid: 62.00% Test: 60.30%
Split: 01, Run: 01
None time:  1.9599450470414013
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 60.30
Split: 01, Run: 02
None time:  0.7609688609372824
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 03
None time:  0.7509934948757291
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 66.50
run time now: 3.5043063163757324
total time:  3.560670383973047
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.07 ± 5.25
  Final Train: 100.00 ± 0.00
   Final Test: 64.47 ± 3.61
[I 2023-06-11 23:57:18,249] Trial 684 finished with value: 68.0666732788086 and parameters: {'Fwd': 1.16704547360075e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.605959926187292, 'loop': 2, 'loss': 'CE', 'lr': 0.00012229543216282855, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007920250839796252, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008854658788334439
weight_decay:  0.0006468315452218488
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8058022549375892
None Run 01:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 52.40
Split: 01, Run: 02
None time:  1.126338189933449
None Run 02:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 62.40
Split: 01, Run: 03
None time:  0.8172774480190128
None Run 03:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 59.50
run time now: 2.7928857803344727
total time:  2.8643910749815404
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.80 ± 4.18
  Final Train: 100.00 ± 0.00
   Final Test: 58.10 ± 5.14
[I 2023-06-11 23:57:21,653] Trial 685 finished with value: 57.79999923706055 and parameters: {'Fwd': 9.253882117194754e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 7.822133074486612, 'loop': 2, 'loss': 'MSE', 'lr': 0.008854658788334439, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006468315452218488, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00869619290702438
weight_decay:  0.00045271594944345275
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4989573231432587
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 67.40
Split: 01, Run: 02
None time:  0.9194450578652322
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.817681343993172
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.272202253341675
total time:  3.3168731089681387
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 2.34
  Final Train: 99.72 ± 0.48
   Final Test: 69.57 ± 1.88
[I 2023-06-11 23:57:25,592] Trial 686 finished with value: 73.26666259765625 and parameters: {'Fwd': 1.540437282805018e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.25, 'lambda2': 8.027965641098609, 'loop': 2, 'loss': 'CE', 'lr': 0.00869619290702438, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00045271594944345275, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009274561842730122
weight_decay:  0.00036372680901112305
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8067866410128772
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 57.40
Split: 01, Run: 02
None time:  0.7248136990237981
None Run 02:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 48.20
Split: 01, Run: 03
None time:  0.837271261960268
None Run 03:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 41.90
run time now: 2.406135320663452
total time:  2.455090597970411
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.67 ± 8.75
  Final Train: 100.00 ± 0.00
   Final Test: 49.17 ± 7.80
[I 2023-06-11 23:57:28,571] Trial 687 finished with value: 52.66666793823242 and parameters: {'Fwd': 1.9576513822576043e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 7.703348697694691, 'loop': 2, 'loss': 'CE', 'lr': 0.009274561842730122, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00036372680901112305, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0006127664792216989
weight_decay:  1.0557724912763752e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5340191209688783
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.8607122770044953
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 03
None time:  1.104538032086566
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 69.00
run time now: 3.5368077754974365
total time:  3.585610721958801
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 2.19
  Final Train: 99.72 ± 0.48
   Final Test: 70.27 ± 1.36
[I 2023-06-11 23:57:32,681] Trial 688 finished with value: 71.73332977294922 and parameters: {'Fwd': 7.094506791202499e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 7.897587902613926, 'loop': 2, 'loss': 'CE', 'lr': 0.0006127664792216989, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0557724912763752e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00999340374890399
weight_decay:  0.0011525025400103074
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6985134580172598
None Run 01:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 31.80
Split: 01, Run: 02
None time:  1.5049086569342762
None Run 02:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 93.33
   Final Test: 58.00
Split: 01, Run: 03
None time:  0.7052295200992376
None Run 03:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 55.50
run time now: 2.9519717693328857
total time:  3.0153269281145185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.93 ± 15.57
  Final Train: 97.78 ± 3.85
   Final Test: 48.43 ± 14.46
[I 2023-06-11 23:57:36,175] Trial 689 finished with value: 52.93333435058594 and parameters: {'Fwd': 6.942391318803116e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 8.164246910811507, 'loop': 2, 'loss': 'CE', 'lr': 0.00999340374890399, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0011525025400103074, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008427526779849504
weight_decay:  1.4430716681848e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6565237541217357
None Run 01:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 36.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0543, Train: 81.67%, Valid: 67.20% Test: 65.50%
Split: 01, Run: 02
None time:  1.9555722929071635
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 82.50
   Final Test: 65.50
Split: 01, Run: 03
None time:  0.7495736610144377
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 66.00
run time now: 3.392695188522339
total time:  3.43637417210266
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.47 ± 18.98
  Final Train: 93.89 ± 9.87
   Final Test: 55.93 ± 17.00
[I 2023-06-11 23:57:40,166] Trial 690 finished with value: 57.4666633605957 and parameters: {'Fwd': 9.589911637481632e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 0.056328917489261165, 'loop': 2, 'loss': 'CE', 'lr': 0.008427526779849504, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4430716681848e-06, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00859421559278084
weight_decay:  0.0007758942613205517
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.249527590116486
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.2298673680052161
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.2671477210242301
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.40
run time now: 4.777789831161499
total time:  4.8356552720069885
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 1.67
  Final Train: 99.72 ± 0.48
   Final Test: 69.40 ± 0.92
[I 2023-06-11 23:57:45,557] Trial 691 finished with value: 69.33333587646484 and parameters: {'Fwd': 1.2200362512600152e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 8.01443515336037, 'loop': 2, 'loss': 'CE', 'lr': 0.00859421559278084, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0007758942613205517, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0024903688111475473
weight_decay:  0.0004507042051100839
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7892854020465165
None Run 01:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 47.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.5783, Train: 94.17%, Valid: 69.00% Test: 67.30%
Split: 01, Run: 02
None time:  2.07257830305025
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 94.17
   Final Test: 67.10
Split: 01, Run: 03
None time:  0.9310359039809555
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.10
run time now: 3.825094223022461
total time:  3.871657881885767
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.20 ± 13.53
  Final Train: 98.06 ± 3.37
   Final Test: 60.87 ± 11.67
[I 2023-06-11 23:57:49,953] Trial 692 finished with value: 62.20000076293945 and parameters: {'Fwd': 4.8301222208005235e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 7.338731938902995, 'loop': 2, 'loss': 'CE', 'lr': 0.0024903688111475473, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004507042051100839, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0007157567214616515
weight_decay:  0.038029851766535804
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.49137930595316
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 99.17
   Final Test: 64.10
Split: 01, Run: 02
None time:  1.0895012670662254
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 99.17
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.1097161718644202
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 70.50
run time now: 3.721484661102295
total time:  3.7658635850530118
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.60 ± 2.60
  Final Train: 99.17 ± 0.00
   Final Test: 68.03 ± 3.44
[I 2023-06-11 23:57:54,285] Trial 693 finished with value: 67.60000610351562 and parameters: {'Fwd': 1.519812835420456e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 3.3294652562274694, 'loop': 2, 'loss': 'CE', 'lr': 0.0007157567214616515, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.038029851766535804, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.001390906444907221
weight_decay:  0.00028441740526100994
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1910608250182122
None Run 01:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 62.70
Split: 01, Run: 02
None time:  1.7466602909844369
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 97.50
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.7880890849046409
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 65.30
run time now: 3.7615764141082764
total time:  3.8116120079066604
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.33 ± 3.95
  Final Train: 99.17 ± 1.44
   Final Test: 65.63 ± 3.11
[I 2023-06-11 23:57:58,578] Trial 694 finished with value: 66.33332824707031 and parameters: {'Fwd': 2.6149330507011285e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 8.488366712716914, 'loop': 2, 'loss': 'CE', 'lr': 0.001390906444907221, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00028441740526100994, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009198257138562744
weight_decay:  0.0006691147398626727
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.139167563058436
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.9515253698918968
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  0.8052344319876283
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.926842212677002
total time:  2.9786776350811124
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.73 ± 1.01
[I 2023-06-11 23:58:02,101] Trial 695 finished with value: 72.79999542236328 and parameters: {'Fwd': 0.05578335202573673, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 7.779144346806066, 'loop': 2, 'loss': 'CE', 'lr': 0.009198257138562744, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006691147398626727, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008346573922720577
weight_decay:  0.0009839416376601884
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1753791908267885
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 68.60
Split: 01, Run: 02
None time:  0.7277201779652387
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.0344166320282966
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.90
run time now: 2.9702227115631104
total time:  3.024927934166044
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 1.96
  Final Train: 99.72 ± 0.48
   Final Test: 70.13 ± 2.40
[I 2023-06-11 23:58:05,652] Trial 696 finished with value: 72.13333129882812 and parameters: {'Fwd': 1.767896172909104e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 7.509971602147939, 'loop': 2, 'loss': 'CE', 'lr': 0.008346573922720577, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009839416376601884, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00998233103206064
weight_decay:  0.0016795154259643254
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7190600938629359
None Run 01:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 55.70
Split: 01, Run: 02
None time:  0.6797141809947789
None Run 02:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 42.10
Split: 01, Run: 03
None time:  0.7082554071675986
None Run 03:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 44.10
run time now: 2.13775897026062
total time:  2.1862506980542094
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 45.93 ± 5.95
  Final Train: 100.00 ± 0.00
   Final Test: 47.30 ± 7.34
[I 2023-06-11 23:58:08,400] Trial 697 finished with value: 45.93333053588867 and parameters: {'Fwd': 0.012428153924723271, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 8.655032165948088, 'loop': 2, 'loss': 'CE', 'lr': 0.00998233103206064, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0016795154259643254, 'weightedloss': False}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.000961904987666809
weight_decay:  0.0008299590694380305
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7098036950919777
None Run 01:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 99.17
   Final Test: 55.80
Split: 01, Run: 02
None time:  1.091918173013255
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 63.90
Split: 01, Run: 03
None time:  1.515858406899497
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 68.50
run time now: 4.35006856918335
total time:  4.395642725983635
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.80 ± 6.84
  Final Train: 99.44 ± 0.48
   Final Test: 62.73 ± 6.43
[I 2023-06-11 23:58:13,283] Trial 698 finished with value: 64.79999542236328 and parameters: {'Fwd': 0.02756318248447932, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 6.00350771696578, 'loop': 2, 'loss': 'CE', 'lr': 0.000961904987666809, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008299590694380305, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00918274948080596
weight_decay:  0.0013042171528745373
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.234146208036691
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 66.50
Split: 01, Run: 02
None time:  0.7498385480139405
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.764625133946538
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 66.50
run time now: 2.7802352905273438
total time:  2.828087723115459
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 1.70
  Final Train: 98.61 ± 1.73
   Final Test: 67.37 ± 1.50
[I 2023-06-11 23:58:16,681] Trial 699 finished with value: 71.06666564941406 and parameters: {'Fwd': 1.0664349657536693e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 2.0793325470898454, 'loop': 2, 'loss': 'CE', 'lr': 0.00918274948080596, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0013042171528745373, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0002791213440991093
weight_decay:  0.0005121909509951996
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9193683909252286
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 99.17
   Final Test: 67.60
Split: 01, Run: 02
None time:  0.9022273940499872
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.9098359970375896
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.7791574001312256
total time:  3.8366581150330603
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 2.21
  Final Train: 99.72 ± 0.48
   Final Test: 68.83 ± 1.10
[I 2023-06-11 23:58:21,053] Trial 700 finished with value: 69.73333740234375 and parameters: {'Fwd': 0.01618207036713084, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 3.679019108690842, 'loop': 2, 'loss': 'CE', 'lr': 0.0002791213440991093, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005121909509951996, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.000827407677733274
weight_decay:  0.000256493460377987
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.324224472977221
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 68.10
Split: 01, Run: 02
None time:  1.2909793730359524
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.0125057820696384
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 96.67
   Final Test: 70.40
run time now: 3.660506010055542
total time:  3.7065566161181778
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.83
  Final Train: 96.11 ± 0.96
   Final Test: 69.83 ± 1.53
[I 2023-06-11 23:58:25,339] Trial 701 finished with value: 69.93333435058594 and parameters: {'Fwd': 8.895306226991405e-05, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 1.594677732349056, 'loop': 2, 'loss': 'CE', 'lr': 0.000827407677733274, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000256493460377987, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00019541050188961757
weight_decay:  0.00040030672122204586
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5138668830040842
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 66.30
Split: 01, Run: 02
None time:  0.800684591056779
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.7093043089844286
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 67.40
run time now: 3.0606930255889893
total time:  3.1078892659861594
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 1.00
  Final Train: 99.72 ± 0.48
   Final Test: 67.90 ± 1.90
[I 2023-06-11 23:58:29,084] Trial 702 finished with value: 70.80000305175781 and parameters: {'Fwd': 1.0072542817549689e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 2.583397536087502, 'loop': 2, 'loss': 'CE', 'lr': 0.00019541050188961757, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00040030672122204586, 'weightedloss': True}. Best is trial 496 with value: 75.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008047484134726515
weight_decay:  0.00013596750489849193
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3870483320206404
None Run 01:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 99.17
   Final Test: 72.50
Split: 01, Run: 02
None time:  0.7620287649333477
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  0.7747010320890695
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.9563586711883545
total time:  3.0142988809384406
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.40 ± 0.60
  Final Train: 99.72 ± 0.48
   Final Test: 70.90 ± 1.90
[I 2023-06-11 23:58:32,626] Trial 703 finished with value: 75.4000015258789 and parameters: {'Fwd': 2.2492000396580878e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 6.815443955298467, 'loop': 2, 'loss': 'CE', 'lr': 0.008047484134726515, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00013596750489849193, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.001110496467249154
weight_decay:  0.00015218229521802876
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0039926709141582
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 02
None time:  1.4436692849267274
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 67.40
Split: 01, Run: 03
None time:  1.1720847790129483
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.30
run time now: 3.650897264480591
total time:  3.6970005789771676
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 1.62
  Final Train: 99.44 ± 0.48
   Final Test: 67.43 ± 1.85
[I 2023-06-11 23:58:36,882] Trial 704 finished with value: 69.33333587646484 and parameters: {'Fwd': 3.340243258996215e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 6.908842607889551, 'loop': 2, 'loss': 'CE', 'lr': 0.001110496467249154, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00015218229521802876, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0018515940317667236
weight_decay:  0.00012853119260148514
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5628, Train: 99.17%, Valid: 69.00% Test: 69.10%
Split: 01, Run: 01
None time:  2.017131468048319
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.650064623914659
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.8303418208379298
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 66.90
run time now: 4.530191898345947
total time:  4.577105815988034
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 1.10
  Final Train: 99.44 ± 0.48
   Final Test: 68.63 ± 1.55
[I 2023-06-11 23:58:42,109] Trial 705 finished with value: 69.73332977294922 and parameters: {'Fwd': 0.038919659174468796, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 6.346055326134204, 'loop': 2, 'loss': 'CE', 'lr': 0.0018515940317667236, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012853119260148514, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008154186787894634
weight_decay:  0.00015930490537495906
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7718498569447547
None Run 01:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 60.70
Split: 01, Run: 02
None time:  0.8473464162088931
None Run 02:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 57.70
Split: 01, Run: 03
None time:  0.8476235349662602
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 95.00
   Final Test: 48.60
run time now: 2.5002176761627197
total time:  2.5456313309259713
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.00 ± 4.89
  Final Train: 98.33 ± 2.89
   Final Test: 55.67 ± 6.30
[I 2023-06-11 23:58:45,372] Trial 706 finished with value: 57.0 and parameters: {'Fwd': 0.010236324986393208, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 6.1756549492862565, 'loop': 2, 'loss': 'CE', 'lr': 0.008154186787894634, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00015930490537495906, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007845152712229278
weight_decay:  0.002090909588852012
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0764712148811668
None Run 01:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 58.30
Split: 01, Run: 02
None time:  1.9686266158241779
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.90
Split: 01, Run: 03
None time:  0.8845817148685455
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 65.50
run time now: 3.961716413497925
total time:  4.009278627811
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.40 ± 3.49
  Final Train: 100.00 ± 0.00
   Final Test: 62.90 ± 3.99
[I 2023-06-11 23:58:50,002] Trial 707 finished with value: 62.39999771118164 and parameters: {'Fwd': 0.00490296544976015, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 7.381583319979432, 'loop': 2, 'loss': 'MSE', 'lr': 0.007845152712229278, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002090909588852012, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008102765930597788
weight_decay:  0.00021832861001868685
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2006305009126663
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 70.90
Split: 01, Run: 02
None time:  0.8207315269391984
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.7567883909214288
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.810582399368286
total time:  2.8735288658645004
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.13 ± 0.58
  Final Train: 99.72 ± 0.48
   Final Test: 70.40 ± 0.56
[I 2023-06-11 23:58:53,443] Trial 708 finished with value: 73.13333129882812 and parameters: {'Fwd': 2.2886533785607736e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 6.369956531934065, 'loop': 2, 'loss': 'CE', 'lr': 0.008102765930597788, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00021832861001868685, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009997203663362042
weight_decay:  0.0011852582569435112
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6129906810820103
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 90.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.812897298950702
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 03
None time:  0.8356540729291737
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 64.90
run time now: 3.29524564743042
total time:  3.3450503260828555
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 0.35
  Final Train: 96.67 ± 5.77
   Final Test: 66.90 ± 2.72
[I 2023-06-11 23:58:57,278] Trial 709 finished with value: 72.79999542236328 and parameters: {'Fwd': 6.417190449673671e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 7.128798020750636, 'loop': 2, 'loss': 'CE', 'lr': 0.009997203663362042, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0011852582569435112, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008820347998811158
weight_decay:  0.0010280424313269157
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2942820528987795
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.5389527638908476
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  2.438114569056779
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 5.3024985790252686
total time:  5.357295333873481
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.67 ± 2.08
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 1.15
[I 2023-06-11 23:59:03,178] Trial 710 finished with value: 69.66666412353516 and parameters: {'Fwd': 0.06738934975990692, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.25, 'lambda2': 6.833559684092977, 'loop': 2, 'loss': 'CE', 'lr': 0.008820347998811158, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0010280424313269157, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0004093180352752011
weight_decay:  0.00012046886495396725
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3500, Train: 99.17%, Valid: 70.20% Test: 70.00%
Split: 01, Run: 01
None time:  1.9628401740919799
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0775291931349784
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.0005881921388209
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.0746307373046875
total time:  4.131143800914288
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.61
  Final Train: 99.72 ± 0.48
   Final Test: 70.37 ± 0.57
[I 2023-06-11 23:59:07,838] Trial 711 finished with value: 70.86666870117188 and parameters: {'Fwd': 1.199898332719213e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 6.78932089265002, 'loop': 2, 'loss': 'CE', 'lr': 0.0004093180352752011, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012046886495396725, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00786846194629319
weight_decay:  0.0001441782953149151
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3987072489690036
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 66.90
Split: 01, Run: 02
None time:  0.7513670600019395
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.8093345290981233
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.30
run time now: 3.000365972518921
total time:  3.058999683940783
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 1.56
  Final Train: 99.72 ± 0.48
   Final Test: 67.73 ± 0.74
[I 2023-06-11 23:59:11,386] Trial 712 finished with value: 71.0 and parameters: {'Fwd': 0.0029643791679017694, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 5.547180722296465, 'loop': 2, 'loss': 'CE', 'lr': 0.00786846194629319, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001441782953149151, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008899884780724888
weight_decay:  0.0013785132266667403
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9286641071084887
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.7397020189091563
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.8786570599768311
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.5770578384399414
total time:  2.63138091401197
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.07 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.23 ± 1.27
[I 2023-06-11 23:59:14,527] Trial 713 finished with value: 74.06666564941406 and parameters: {'Fwd': 4.192242342011179e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 7.571124070790173, 'loop': 2, 'loss': 'CE', 'lr': 0.008899884780724888, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0013785132266667403, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0035822702767740566
weight_decay:  0.003553548674828369
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8321866120677441
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 57.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.5305, Train: 87.50%, Valid: 71.80% Test: 69.10%
Split: 01, Run: 02
None time:  1.8832835878711194
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 87.50
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.7753387121483684
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 67.30
run time now: 3.5224146842956543
total time:  3.579512794036418
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.80 ± 6.58
  Final Train: 95.83 ± 7.22
   Final Test: 64.73 ± 6.16
[I 2023-06-11 23:59:18,621] Trial 714 finished with value: 67.79999542236328 and parameters: {'Fwd': 0.015086719531748874, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 1.443170623354624, 'loop': 2, 'loss': 'CE', 'lr': 0.0035822702767740566, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003553548674828369, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008414551693137724
weight_decay:  0.0028324697853108873
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1696631859522313
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 67.60
Split: 01, Run: 02
None time:  0.695346849039197
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 03
None time:  0.7334315672051162
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 66.70
run time now: 2.629765033721924
total time:  2.6773936070967466
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 1.20
  Final Train: 98.33 ± 2.89
   Final Test: 67.10 ± 0.46
[I 2023-06-11 23:59:21,821] Trial 715 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.0004594667355275342, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 5.879447428142238, 'loop': 2, 'loss': 'CE', 'lr': 0.008414551693137724, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0028324697853108873, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0011943983379902516
weight_decay:  0.00018503697340685067
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6919215379748493
None Run 01:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 58.60
Split: 01, Run: 02
None time:  0.6621869690716267
None Run 02:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 49.20
Split: 01, Run: 03
None time:  0.5845854158978909
None Run 03:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 44.20
run time now: 1.9695281982421875
total time:  2.0164379868656397
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.80 ± 8.66
  Final Train: 100.00 ± 0.00
   Final Test: 50.67 ± 7.31
[I 2023-06-11 23:59:24,342] Trial 716 finished with value: 49.79999923706055 and parameters: {'Fwd': 0.0006755539632721366, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 6.605084474414728, 'loop': 2, 'loss': 'CE', 'lr': 0.0011943983379902516, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00018503697340685067, 'weightedloss': False}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009189120455668012
weight_decay:  0.00010262756364462534
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5041478259954602
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 95.00
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.7874175868928432
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  0.8019072990864515
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 66.30
run time now: 3.124018907546997
total time:  3.1713682760018855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 0.42
  Final Train: 98.33 ± 2.89
   Final Test: 68.40 ± 2.67
[I 2023-06-11 23:59:27,984] Trial 717 finished with value: 73.53333282470703 and parameters: {'Fwd': 0.004762258273976949, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 2.7785899164422405, 'loop': 2, 'loss': 'CE', 'lr': 0.009189120455668012, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010262756364462534, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00018767267337112291
weight_decay:  0.002284072406816953
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8797, Train: 99.17%, Valid: 66.60% Test: 66.00%
Split: 01, Run: 01
None time:  2.0482387240044773
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 99.17
   Final Test: 66.00
Split: 01, Run: 02
None time:  0.8959305379539728
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.8067624110262841
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 67.80
run time now: 3.782714605331421
total time:  3.839062027866021
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 3.44
  Final Train: 99.72 ± 0.48
   Final Test: 67.33 ± 1.17
[I 2023-06-11 23:59:32,343] Trial 718 finished with value: 70.53333282470703 and parameters: {'Fwd': 2.2421592611343706e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 5.295406585796497, 'loop': 2, 'loss': 'CE', 'lr': 0.00018767267337112291, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002284072406816953, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.001584073869206892
weight_decay:  3.2338087280109e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2488475039135665
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02
None time:  1.412869580090046
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 03
None time:  0.716574823949486
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 63.10
run time now: 3.410111427307129
total time:  3.4545731130056083
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.42
  Final Train: 99.72 ± 0.48
   Final Test: 67.57 ± 4.19
[I 2023-06-11 23:59:36,325] Trial 719 finished with value: 71.46666717529297 and parameters: {'Fwd': 6.93989527540693e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 8.154439150126487, 'loop': 2, 'loss': 'CE', 'lr': 0.001584073869206892, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.2338087280109e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009999430993756126
weight_decay:  0.00024254109525189283
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0599901219829917
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 02
None time:  0.8242222249973565
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.9206781121902168
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.20
run time now: 2.8358404636383057
total time:  2.8953847461380064
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 71.50 ± 0.26
[I 2023-06-11 23:59:39,835] Trial 720 finished with value: 74.20000457763672 and parameters: {'Fwd': 0.0021207251219441383, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 7.998578008078694, 'loop': 2, 'loss': 'CE', 'lr': 0.009999430993756126, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00024254109525189283, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.003122987053052581
weight_decay:  0.00033221719701580416
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2058, Train: 98.33%, Valid: 58.60% Test: 58.10%
Split: 01, Run: 01
None time:  1.8361022039316595
None Run 01:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 98.33
   Final Test: 57.80
Split: 01, Run: 02
None time:  1.3389979989733547
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.9261982119642198
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 67.00
run time now: 4.1352455615997314
total time:  4.18736169510521
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.40 ± 7.62
  Final Train: 98.61 ± 0.48
   Final Test: 64.60 ± 5.97
[I 2023-06-11 23:59:44,651] Trial 721 finished with value: 67.4000015258789 and parameters: {'Fwd': 0.00827245435374904, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 7.114254060462644, 'loop': 2, 'loss': 'CE', 'lr': 0.003122987053052581, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00033221719701580416, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.00014657914552071875
weight_decay:  0.00017606485508580061
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9270672521088272
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 99.17
   Final Test: 66.00
Split: 01, Run: 02
None time:  0.8736088080331683
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.9286467309575528
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.50
run time now: 3.7630481719970703
total time:  3.8167916119564325
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 2.11
  Final Train: 99.72 ± 0.48
   Final Test: 68.30 ± 2.21
[I 2023-06-11 23:59:48,982] Trial 722 finished with value: 70.39999389648438 and parameters: {'Fwd': 4.477291105921609e-06, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 6.634626468012864, 'loop': 2, 'loss': 'CE', 'lr': 0.00014657914552071875, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00017606485508580061, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007785571307845321
weight_decay:  8.681658593911493e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.731775555992499
None Run 01:
Highest Train: 100.00
Highest Valid: 34.40
  Final Train: 100.00
   Final Test: 37.10
Split: 01, Run: 02
None time:  0.9487476269714534
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 99.17
   Final Test: 63.80
Split: 01, Run: 03
None time:  0.6881888799834996
None Run 03:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 57.70
run time now: 2.4022510051727295
total time:  2.4500886909663677
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.93 ± 17.81
  Final Train: 99.72 ± 0.48
   Final Test: 52.87 ± 13.99
[I 2023-06-11 23:59:51,956] Trial 723 finished with value: 54.93333435058594 and parameters: {'Fwd': 8.604343503994718e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 4.701167077385941, 'loop': 2, 'loss': 'CE', 'lr': 0.007785571307845321, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.681658593911493e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.000291418159067686
weight_decay:  0.0006321966015333486
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6527588011231273
None Run 01:
Highest Train: 100.00
Highest Valid: 32.80
  Final Train: 100.00
   Final Test: 29.80
Split: 01, Run: 02
None time:  0.8989574490115047
None Run 02:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 34.00
Split: 01, Run: 03
None time:  1.0529731211718172
None Run 03:
Highest Train: 100.00
Highest Valid: 38.40
  Final Train: 100.00
   Final Test: 38.40
run time now: 2.6374895572662354
total time:  2.68903442309238
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 35.00 ± 2.99
  Final Train: 100.00 ± 0.00
   Final Test: 34.07 ± 4.30
[I 2023-06-11 23:59:55,218] Trial 724 finished with value: 35.0 and parameters: {'Fwd': 0.02264036242727468, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 4.957133300248479, 'loop': 2, 'loss': 'MSE', 'lr': 0.000291418159067686, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006321966015333486, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008644425314433943
weight_decay:  1.2166463695501563e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7209976299200207
None Run 01:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 59.30
Split: 01, Run: 02
None time:  0.6919272548984736
None Run 02:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 47.00
Split: 01, Run: 03
None time:  0.7020216290839016
None Run 03:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 99.17
   Final Test: 50.70
run time now: 2.147108316421509
total time:  2.196803516941145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.73 ± 6.31
  Final Train: 99.72 ± 0.48
   Final Test: 52.33 ± 6.31
[I 2023-06-11 23:59:58,014] Trial 725 finished with value: 50.733333587646484 and parameters: {'Fwd': 3.087819330242699e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 4.471230141847098, 'loop': 2, 'loss': 'CE', 'lr': 0.008644425314433943, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.2166463695501563e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0005362146385571045
weight_decay:  0.0001128053910595165
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2998902720864862
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.6868689300026745
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.10
Split: 01, Run: 03
None time:  0.6751112400088459
None Run 03:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 59.00
run time now: 2.693150281906128
total time:  2.739242676878348
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.87 ± 5.75
  Final Train: 100.00 ± 0.00
   Final Test: 63.87 ± 5.29
[I 2023-06-12 00:00:01,324] Trial 726 finished with value: 64.86666870117188 and parameters: {'Fwd': 0.0009201951743042481, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.05, 'lambda2': 2.917979503162359, 'loop': 2, 'loss': 'CE', 'lr': 0.0005362146385571045, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001128053910595165, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.0005763038850259731
weight_decay:  0.00231434676005787
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.253200053004548
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.6212959110271186
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.83
   Final Test: 71.80
Split: 01, Run: 03
None time:  0.7163663750980049
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.62786865234375
total time:  3.6760451251175255
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.35
  Final Train: 98.61 ± 2.41
   Final Test: 70.00 ± 1.59
[I 2023-06-12 00:00:05,479] Trial 727 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.006964341103972979, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 7.7583236963743305, 'loop': 2, 'loss': 'CE', 'lr': 0.0005763038850259731, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00231434676005787, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0004477807338724913
weight_decay:  0.024759618410039114
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1741070600692183
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0112458688672632
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.9802891709841788
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.2092502117156982
total time:  3.257566737011075
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 70.53 ± 0.70
[I 2023-06-12 00:00:09,285] Trial 728 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.08043931583389394, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 4.7928856200305106, 'loop': 2, 'loss': 'CE', 'lr': 0.0004477807338724913, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.024759618410039114, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0003133962826082895
weight_decay:  0.05684976943493324
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5487178592011333
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02
None time:  0.7631194740533829
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.2285730820149183
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 70.70
run time now: 3.5715694427490234
total time:  3.614022657973692
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.81
  Final Train: 99.72 ± 0.48
   Final Test: 69.87 ± 1.12
[I 2023-06-12 00:00:13,403] Trial 729 finished with value: 70.53333282470703 and parameters: {'Fwd': 4.883874916982897e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 5.9101404001803814, 'loop': 2, 'loss': 'CE', 'lr': 0.0003133962826082895, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.05684976943493324, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00277244639093816
weight_decay:  2.439308299181306e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3651953940279782
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.5686109091620892
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  1.4753016920294613
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 4.446035623550415
total time:  4.500733432127163
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.37 ± 0.35
[I 2023-06-12 00:00:18,546] Trial 730 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.00013624328583471815, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 1.871752281475573, 'loop': 2, 'loss': 'CE', 'lr': 0.00277244639093816, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.439308299181306e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.45
lr:  0.0004954997859879087
weight_decay:  0.039238139473746436
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2051, Train: 100.00%, Valid: 72.00% Test: 70.20%
Split: 01, Run: 01
None time:  1.8634255479555577
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.1193128700833768
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.0033747020643204
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.20
run time now: 4.020277738571167
total time:  4.070394632872194
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 2.55
  Final Train: 100.00 ± 0.00
   Final Test: 68.80 ± 1.22
[I 2023-06-12 00:00:23,181] Trial 731 finished with value: 69.86666107177734 and parameters: {'Fwd': 0.03144056964444885, 'K': 1, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 5.463628852907818, 'loop': 2, 'loss': 'CE', 'lr': 0.0004954997859879087, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.039238139473746436, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.0042741004835657945
weight_decay:  0.0001324071878277771
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5671648990828544
None Run 01:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 61.20
Split: 01, Run: 02
None time:  0.6575990510173142
None Run 02:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 53.50
Split: 01, Run: 03
None time:  0.6287213088944554
None Run 03:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 55.00
run time now: 1.8848097324371338
total time:  1.939739977940917
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.07 ± 2.53
  Final Train: 100.00 ± 0.00
   Final Test: 56.57 ± 4.08
[I 2023-06-12 00:00:25,694] Trial 732 finished with value: 58.06666946411133 and parameters: {'Fwd': 0.019625013436788973, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 7.189865447387279, 'loop': 2, 'loss': 'CE', 'lr': 0.0042741004835657945, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001324071878277771, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0014587521030314985
weight_decay:  0.0013583305801603952
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.892774524865672
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 02
None time:  1.0373530799988657
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.0531256010290235
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 71.40
run time now: 3.013608694076538
total time:  3.0555215899366885
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.76
  Final Train: 99.44 ± 0.48
   Final Test: 70.03 ± 1.95
[I 2023-06-12 00:00:29,267] Trial 733 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.0038746353158849722, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 5.734553195854026, 'loop': 2, 'loss': 'CE', 'lr': 0.0014587521030314985, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0013583305801603952, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.002150395023064579
weight_decay:  1.6148383782907511e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9334301659837365
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 02
None time:  1.7583021379541606
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 97.50
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.5162695557810366
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.30
run time now: 3.2398836612701416
total time:  3.2953407738823444
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.67 ± 1.75
  Final Train: 99.17 ± 1.44
   Final Test: 66.97 ± 1.04
[I 2023-06-12 00:00:33,096] Trial 734 finished with value: 69.66666412353516 and parameters: {'Fwd': 5.635424574212831e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 8.371184032307161, 'loop': 2, 'loss': 'CE', 'lr': 0.002150395023064579, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6148383782907511e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.007238985448453747
weight_decay:  4.120871333118941e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6192556000314653
None Run 01:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 58.10
Split: 01, Run: 02
None time:  0.5865818131715059
None Run 02:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 48.10
Split: 01, Run: 03
None time:  0.6163308168761432
None Run 03:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 44.40
run time now: 1.8546640872955322
total time:  1.9049676258582622
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 48.33 ± 7.96
  Final Train: 100.00 ± 0.00
   Final Test: 50.20 ± 7.09
[I 2023-06-12 00:00:35,539] Trial 735 finished with value: 48.33333206176758 and parameters: {'Fwd': 0.0001044367317231309, 'K': 1, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 3.8353994263198627, 'loop': 2, 'loss': 'CE', 'lr': 0.007238985448453747, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.120871333118941e-06, 'weightedloss': False}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009228654003130997
weight_decay:  0.00028667639562041303
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3907057989854366
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.10
Split: 01, Run: 02
None time:  1.4308889480307698
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.10
Split: 01, Run: 03
None time:  1.566614898853004
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.10
run time now: 4.421981334686279
total time:  4.4684054099489
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.10 ± 0.00
[I 2023-06-12 00:00:40,651] Trial 736 finished with value: 51.20000076293945 and parameters: {'Fwd': 1.865664411704421e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.0, 'lambda2': 0.6079192438248717, 'loop': 2, 'loss': 'CE', 'lr': 0.009228654003130997, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00028667639562041303, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.007946506537843886
weight_decay:  0.0002128779809330997
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0693715368397534
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 95.83
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.6704831349197775
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.6313012300524861
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.4116833209991455
total time:  2.4548748079687357
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.20 ± 0.80
  Final Train: 98.61 ± 2.41
   Final Test: 70.13 ± 0.76
[I 2023-06-12 00:00:43,685] Trial 737 finished with value: 74.20000457763672 and parameters: {'Fwd': 0.0003733280338221568, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 3.1559966351984534, 'loop': 2, 'loss': 'CE', 'lr': 0.007946506537843886, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002128779809330997, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.001708844585798917
weight_decay:  1.6023810908543282e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7021049468312413
None Run 01:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 44.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.6015, Train: 87.50%, Valid: 69.40% Test: 69.40%
Split: 01, Run: 02
None time:  2.0572679431643337
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 87.50
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.7272262829355896
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 63.70
run time now: 3.5179953575134277
total time:  3.5852268799208105
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.93 ± 13.98
  Final Train: 95.83 ± 7.22
   Final Test: 59.13 ± 13.25
[I 2023-06-12 00:00:47,857] Trial 738 finished with value: 61.93333053588867 and parameters: {'Fwd': 0.04619408494723321, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.55, 'lambda2': 0.3369429557895521, 'loop': 2, 'loss': 'CE', 'lr': 0.001708844585798917, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6023810908543282e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008472880126398092
weight_decay:  0.0003744272331124666
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.564377031987533
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 95.00
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.7825732419732958
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.7967546209692955
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.1758861541748047
total time:  3.224800875876099
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.80 ± 1.04
  Final Train: 98.33 ± 2.89
   Final Test: 70.00 ± 1.51
[I 2023-06-12 00:00:51,586] Trial 739 finished with value: 73.79999542236328 and parameters: {'Fwd': 0.000556331045152424, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 3.4767329794835686, 'loop': 2, 'loss': 'CE', 'lr': 0.008472880126398092, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003744272331124666, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.009097169088610255
weight_decay:  9.65709576409807e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0015489070210606
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 88.33
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.6855478750076145
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.6057699311058968
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 97.50
   Final Test: 70.70
run time now: 2.33332896232605
total time:  2.382904570084065
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.81
  Final Train: 94.72 ± 5.55
   Final Test: 70.10 ± 0.52
[I 2023-06-12 00:00:54,485] Trial 740 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.0007976869732247121, 'K': 8, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 1.0104504788979003, 'loop': 2, 'loss': 'CE', 'lr': 0.009097169088610255, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.65709576409807e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007644073413199484
weight_decay:  0.0008658072137522823
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5550445900298655
None Run 01:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 54.00
Split: 01, Run: 02
None time:  1.2646693899296224
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 94.17
   Final Test: 62.80
Split: 01, Run: 03
None time:  0.5449068830348551
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 61.70
run time now: 2.3988473415374756
total time:  2.4445030000060797
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.27 ± 10.99
  Final Train: 98.06 ± 3.37
   Final Test: 59.50 ± 4.79
[I 2023-06-12 00:00:57,481] Trial 741 finished with value: 59.26666259765625 and parameters: {'Fwd': 0.0013257136378467932, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 5.175552727891251, 'loop': 2, 'loss': 'CE', 'lr': 0.007644073413199484, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008658072137522823, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.00011102276710608947
weight_decay:  0.09524886783981701
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6951125049963593
None Run 01:
Highest Train: 100.00
Highest Valid: 29.60
  Final Train: 100.00
   Final Test: 27.30
Split: 01, Run: 02
None time:  0.6666481979191303
None Run 02:
Highest Train: 100.00
Highest Valid: 30.60
  Final Train: 100.00
   Final Test: 28.20
Split: 01, Run: 03
None time:  0.6951563700567931
None Run 03:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 34.70
run time now: 2.0905139446258545
total time:  2.1372690780553967
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 31.47 ± 2.42
  Final Train: 100.00 ± 0.00
   Final Test: 30.07 ± 4.04
[I 2023-06-12 00:01:00,143] Trial 742 finished with value: 31.466665267944336 and parameters: {'Fwd': 0.005989364563248392, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 1.7084022850618408, 'loop': 2, 'loss': 'MSE', 'lr': 0.00011102276710608947, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.09524886783981701, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.006933507178440102
weight_decay:  0.034836923715791925
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1841418400872499
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.6448360800277442
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.5924673259723932
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.20
run time now: 2.4580419063568115
total time:  2.50418763817288
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 0.90
  Final Train: 98.33 ± 2.89
   Final Test: 69.03 ± 0.76
[I 2023-06-12 00:01:03,285] Trial 743 finished with value: 72.9333267211914 and parameters: {'Fwd': 1.2721647327782115e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.6000000000000001, 'lambda2': 3.9612635136335457, 'loop': 2, 'loss': 'CE', 'lr': 0.006933507178440102, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.034836923715791925, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0004881520464201085
weight_decay:  0.0001447013805708371
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8684571699704975
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.30
Split: 01, Run: 02
None time:  0.5561967310495675
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 03
None time:  0.5992947469931096
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.60
run time now: 2.0572402477264404
total time:  2.1114564719609916
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.13 ± 2.32
  Final Train: 100.00 ± 0.00
   Final Test: 65.03 ± 1.02
[I 2023-06-12 00:01:05,902] Trial 744 finished with value: 67.13333129882812 and parameters: {'Fwd': 2.5332928587708897e-05, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 7.027874027000041, 'loop': 2, 'loss': 'CE', 'lr': 0.0004881520464201085, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0001447013805708371, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009969687362218906
weight_decay:  0.0006024756442278977
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2963895071297884
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 99.17
   Final Test: 72.80
Split: 01, Run: 02
None time:  0.8602751169819385
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 03
None time:  0.6611629850231111
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.8492789268493652
total time:  2.889547483995557
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.07 ± 0.76
  Final Train: 99.72 ± 0.48
   Final Test: 71.80 ± 1.40
[I 2023-06-12 00:01:09,301] Trial 745 finished with value: 75.0666732788086 and parameters: {'Fwd': 0.0010185961664353818, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 7.382679686913936, 'loop': 2, 'loss': 'CE', 'lr': 0.009969687362218906, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006024756442278977, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009954357746301355
weight_decay:  0.0006658842369446005
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5240539950318635
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 95.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.8355081821791828
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 03
None time:  0.8206100391689688
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.80
run time now: 3.212641954421997
total time:  3.264269264880568
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.07 ± 1.03
  Final Train: 98.06 ± 2.68
   Final Test: 71.30 ± 0.56
[I 2023-06-12 00:01:13,085] Trial 746 finished with value: 73.06665802001953 and parameters: {'Fwd': 0.0011338052552762679, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 4.1241844098299865, 'loop': 2, 'loss': 'CE', 'lr': 0.009954357746301355, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006658842369446005, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0002448336156173859
weight_decay:  0.028101451977919186
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8421590079087764
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.817034451989457
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.8315401941072196
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.5298376083374023
total time:  3.5766399179119617
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.27 ± 0.25
[I 2023-06-12 00:01:17,182] Trial 747 finished with value: 71.39999389648438 and parameters: {'Fwd': 0.0007154189534489515, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 7.656315524517007, 'loop': 2, 'loss': 'CE', 'lr': 0.0002448336156173859, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.028101451977919186, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00022680721517481808
weight_decay:  9.878679420957289e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8000, Train: 100.00%, Valid: 66.40% Test: 66.40%
Split: 01, Run: 01
None time:  1.9698947030119598
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 02
None time:  0.7940063271671534
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.9531175061129034
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.747227191925049
total time:  3.8010797328315675
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 2.55
  Final Train: 100.00 ± 0.00
   Final Test: 68.80 ± 2.33
[I 2023-06-12 00:01:21,467] Trial 748 finished with value: 69.33333587646484 and parameters: {'Fwd': 0.0016441652894971087, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 7.576158184602151, 'loop': 2, 'loss': 'CE', 'lr': 0.00022680721517481808, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.878679420957289e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009957744928224972
weight_decay:  0.0004948718909804429
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3659034308511764
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 95.83
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.2940840551164001
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.358537114225328
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.90
run time now: 5.052523612976074
total time:  5.098075338173658
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 1.86
  Final Train: 98.61 ± 2.41
   Final Test: 69.57 ± 0.70
[I 2023-06-12 00:01:27,121] Trial 749 finished with value: 69.13333129882812 and parameters: {'Fwd': 0.0009796055450415851, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 2.2601895981778877, 'loop': 2, 'loss': 'CE', 'lr': 0.009957744928224972, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0004948718909804429, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008993834645530713
weight_decay:  0.0005813488737624025
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6342163430526853
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 99.17
   Final Test: 72.40
Split: 01, Run: 02
None time:  0.8365839251782745
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.8076784971635789
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.3148577213287354
total time:  3.3586945249699056
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.80 ± 0.60
  Final Train: 99.72 ± 0.48
   Final Test: 71.10 ± 1.15
[I 2023-06-12 00:01:31,014] Trial 750 finished with value: 74.79999542236328 and parameters: {'Fwd': 3.5711841106360035e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 7.346705363070125, 'loop': 2, 'loss': 'CE', 'lr': 0.008993834645530713, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005813488737624025, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0025032976626139358
weight_decay:  0.0007136774319272361
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5560047230683267
None Run 01:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 99.17
   Final Test: 58.50
Split: 01, Run: 02
None time:  0.8217334561049938
None Run 02:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.70
Split: 01, Run: 03
None time:  0.9208583298604935
None Run 03:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.50
run time now: 3.3363966941833496
total time:  3.381936874007806
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.80 ± 3.54
  Final Train: 99.72 ± 0.48
   Final Test: 60.57 ± 2.00
[I 2023-06-12 00:01:34,900] Trial 751 finished with value: 58.79999923706055 and parameters: {'Fwd': 5.3307581628551247e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 7.3723108044906365, 'loop': 2, 'loss': 'CE', 'lr': 0.0025032976626139358, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007136774319272361, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00021590773756233824
weight_decay:  0.0005367181128141976
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8301, Train: 100.00%, Valid: 70.40% Test: 68.80%
Split: 01, Run: 01
None time:  1.933772434014827
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 02
None time:  0.9407625140156597
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.1255586808547378
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
run time now: 4.031698226928711
total time:  4.075251427013427
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 1.15
[I 2023-06-12 00:01:39,545] Trial 752 finished with value: 71.26666259765625 and parameters: {'Fwd': 3.801380680518308e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.2, 'lambda2': 7.339272079657716, 'loop': 2, 'loss': 'CE', 'lr': 0.00021590773756233824, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005367181128141976, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00012345325707912224
weight_decay:  6.069901815351414e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8438, Train: 100.00%, Valid: 60.60% Test: 59.50%
Split: 01, Run: 01
None time:  1.9071260809432715
None Run 01:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 59.20
Split: 01, Run: 02
None time:  0.8523231172002852
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 65.30
Split: 01, Run: 03
None time:  0.898343644104898
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.20
run time now: 3.688471794128418
total time:  3.740135644096881
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.40 ± 5.03
  Final Train: 100.00 ± 0.00
   Final Test: 63.57 ± 3.81
[I 2023-06-12 00:01:43,816] Trial 753 finished with value: 66.4000015258789 and parameters: {'Fwd': 3.344334967155701e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 7.826600558945476, 'loop': 2, 'loss': 'CE', 'lr': 0.00012345325707912224, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.069901815351414e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9500000000000001
lr:  0.00815642449050442
weight_decay:  0.0008601373698978431
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6904694121330976
None Run 01:
Highest Train: 100.00
Highest Valid: 27.40
  Final Train: 100.00
   Final Test: 30.90
Split: 01, Run: 02
None time:  0.794245578115806
None Run 02:
Highest Train: 100.00
Highest Valid: 43.40
  Final Train: 100.00
   Final Test: 42.60
Split: 01, Run: 03
None time:  0.7967051339801401
None Run 03:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 51.80
run time now: 2.312185764312744
total time:  2.3544182751793414
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 40.93 ± 12.48
  Final Train: 100.00 ± 0.00
   Final Test: 41.77 ± 10.47
[I 2023-06-12 00:01:46,722] Trial 754 finished with value: 40.93333053588867 and parameters: {'Fwd': 4.647174903928388e-05, 'K': 1, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 7.522501943194544, 'loop': 2, 'loss': 'CE', 'lr': 0.00815642449050442, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008601373698978431, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008948334784209894
weight_decay:  0.000923122336769933
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7187171070836484
None Run 01:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 55.40
Split: 01, Run: 02
None time:  0.6841956509742886
None Run 02:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 49.10
Split: 01, Run: 03
None time:  0.7998120880220085
None Run 03:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 48.80
run time now: 2.23817777633667
total time:  2.2893119379878044
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 48.07 ± 1.85
  Final Train: 100.00 ± 0.00
   Final Test: 51.10 ± 3.73
[I 2023-06-12 00:01:49,575] Trial 755 finished with value: 48.06666564941406 and parameters: {'Fwd': 2.8945423604997493e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 3.25464059353483, 'loop': 2, 'loss': 'CE', 'lr': 0.008948334784209894, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000923122336769933, 'weightedloss': False}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0008620133970168425
weight_decay:  0.0005602781242639641
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0206775658298284
None Run 01:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 61.20
Split: 01, Run: 02
None time:  1.178532003192231
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.4116799721959978
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.6436564922332764
total time:  3.6912952288985252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.67 ± 4.74
  Final Train: 100.00 ± 0.00
   Final Test: 67.30 ± 5.29
[I 2023-06-12 00:01:53,904] Trial 756 finished with value: 68.66666412353516 and parameters: {'Fwd': 7.697362032775361e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 7.945550120062154, 'loop': 2, 'loss': 'CE', 'lr': 0.0008620133970168425, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005602781242639641, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.001324679574856337
weight_decay:  0.00045660362294743006
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.846411406993866
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.8922672071494162
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.7995975769590586
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 65.30
run time now: 4.5706446170806885
total time:  4.62759615899995
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.35
  Final Train: 99.44 ± 0.48
   Final Test: 68.43 ± 2.76
[I 2023-06-12 00:01:59,056] Trial 757 finished with value: 70.79999542236328 and parameters: {'Fwd': 3.6077200807900426e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 7.619352489761183, 'loop': 2, 'loss': 'CE', 'lr': 0.001324679574856337, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00045660362294743006, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0006777282631417532
weight_decay:  0.0005714786069737283
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.099392230156809
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 02
None time:  1.2607401930727065
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.46391480602324
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 97.50
   Final Test: 71.40
run time now: 3.8550806045532227
total time:  3.9047763128764927
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.07 ± 2.97
  Final Train: 98.89 ± 1.27
   Final Test: 68.80 ± 2.65
[I 2023-06-12 00:02:03,484] Trial 758 finished with value: 69.0666732788086 and parameters: {'Fwd': 6.16500569151195e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 2.3575757903937054, 'loop': 2, 'loss': 'CE', 'lr': 0.0006777282631417532, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005714786069737283, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007899257757502711
weight_decay:  0.0004461412824129787
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.783875921042636
None Run 01:
Highest Train: 100.00
Highest Valid: 43.40
  Final Train: 100.00
   Final Test: 44.80
Split: 01, Run: 02
None time:  0.7677391620818526
None Run 02:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 45.60
Split: 01, Run: 03
None time:  1.2910550569649786
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 99.17
   Final Test: 61.60
run time now: 2.8920958042144775
total time:  2.9337032709736377
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.87 ± 10.69
  Final Train: 99.72 ± 0.48
   Final Test: 50.67 ± 9.48
[I 2023-06-12 00:02:06,995] Trial 759 finished with value: 49.86666488647461 and parameters: {'Fwd': 4.138719445855471e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 4.381377705134838, 'loop': 2, 'loss': 'CE', 'lr': 0.007899257757502711, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004461412824129787, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007240874538133749
weight_decay:  0.0003917437464209555
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3538926430046558
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.9072364429011941
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  0.9128334070555866
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.207355260848999
total time:  3.258440317120403
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.00 ± 1.25
  Final Train: 99.72 ± 0.48
   Final Test: 71.13 ± 0.47
[I 2023-06-12 00:02:10,789] Trial 760 finished with value: 74.0 and parameters: {'Fwd': 0.01308162169136389, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.2, 'lambda2': 2.9898036300028807, 'loop': 2, 'loss': 'CE', 'lr': 0.007240874538133749, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003917437464209555, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008563405772632022
weight_decay:  0.000312577418463164
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.469848487060517
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.1632794681936502
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.9748889280017465
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 70.80
run time now: 3.6447131633758545
total time:  3.6925681058783084
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.33 ± 1.51
  Final Train: 99.44 ± 0.48
   Final Test: 70.30 ± 0.78
[I 2023-06-12 00:02:15,117] Trial 761 finished with value: 73.33333587646484 and parameters: {'Fwd': 6.701269919266073e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 9.625487506132613, 'loop': 2, 'loss': 'CE', 'lr': 0.008563405772632022, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000312577418463164, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0009648240346448903
weight_decay:  7.966572541287253e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6410924650263041
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 67.30
Split: 01, Run: 02
None time:  1.7782561220228672
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 92.50
   Final Test: 70.70
Split: 01, Run: 03
None time:  1.3066461600828916
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 92.50
   Final Test: 71.80
run time now: 4.757563829421997
total time:  4.80210364703089
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 1.51
  Final Train: 92.78 ± 0.48
   Final Test: 69.93 ± 2.35
[I 2023-06-12 00:02:20,542] Trial 762 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.010742404688069494, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 0.736127925358935, 'loop': 2, 'loss': 'CE', 'lr': 0.0009648240346448903, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.966572541287253e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0001430002619336598
weight_decay:  8.497596604679161e-05
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1808, Train: 99.17%, Valid: 69.60% Test: 68.60%
Split: 01, Run: 01
None time:  1.9869708840269595
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 68.30
Split: 01, Run: 02
None time:  0.9448164310306311
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.6455583779606968
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 98.33
   Final Test: 68.80
run time now: 4.60881495475769
total time:  4.651806999929249
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.67 ± 1.10
  Final Train: 99.17 ± 0.83
   Final Test: 68.37 ± 0.40
[I 2023-06-12 00:02:25,940] Trial 763 finished with value: 69.66666412353516 and parameters: {'Fwd': 4.107568573990413e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.0, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 2.560672059826113, 'loop': 2, 'loss': 'CE', 'lr': 0.0001430002619336598, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.497596604679161e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009254820267046786
weight_decay:  0.0006476248644968297
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7179104299284518
None Run 01:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 53.90
Split: 01, Run: 02
None time:  0.710275799036026
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 97.50
   Final Test: 63.20
Split: 01, Run: 03
None time:  0.7644724689889699
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 97.50
   Final Test: 67.50
run time now: 2.227550506591797
total time:  2.2749569858424366
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.33 ± 6.92
  Final Train: 98.33 ± 1.44
   Final Test: 61.53 ± 6.95
[I 2023-06-12 00:02:28,724] Trial 764 finished with value: 65.33333587646484 and parameters: {'Fwd': 0.0021052174280532954, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 0.0792798284342826, 'loop': 2, 'loss': 'CE', 'lr': 0.009254820267046786, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006476248644968297, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0035046641076164013
weight_decay:  0.00011920174915492914
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7955187719780952
None Run 01:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 54.50
Split: 01, Run: 02
None time:  0.8336925879120827
None Run 02:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 53.20
Split: 01, Run: 03
None time:  0.8424162198789418
None Run 03:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 52.70
run time now: 2.5036704540252686
total time:  2.5577081230003387
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.60 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 53.47 ± 0.93
[I 2023-06-12 00:02:31,792] Trial 765 finished with value: 54.59999465942383 and parameters: {'Fwd': 2.811335296250444e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.2, 'lambda2': 7.411146732165969, 'loop': 2, 'loss': 'CE', 'lr': 0.0035046641076164013, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00011920174915492914, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0075440006322288755
weight_decay:  1.1657854076872983e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.958217108855024
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.1115, Train: 100.00%, Valid: 66.40% Test: 67.00%
Split: 01, Run: 02
None time:  2.070869887014851
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  0.9313225680962205
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.10
run time now: 4.9939868450164795
total time:  5.040987298823893
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.13 ± 1.55
  Final Train: 100.00 ± 0.00
   Final Test: 67.50 ± 0.87
[I 2023-06-12 00:02:37,397] Trial 766 finished with value: 68.13333129882812 and parameters: {'Fwd': 0.00016070175097352096, 'K': 1, 'alpha': 0.0, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 1.4249716506989687, 'loop': 2, 'loss': 'MSE', 'lr': 0.0075440006322288755, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1657854076872983e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.0
lr:  0.008374331677593761
weight_decay:  0.00016699554919480129
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0771844510454684
None Run 01:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 02
None time:  0.9601213980931789
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.699660049052909
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.775703191757202
total time:  2.8373065430205315
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.47 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 71.23 ± 1.10
[I 2023-06-12 00:02:40,862] Trial 767 finished with value: 74.46666717529297 and parameters: {'Fwd': 0.09915204634270822, 'K': 7, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 7.301002437391982, 'loop': 2, 'loss': 'CE', 'lr': 0.008374331677593761, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00016699554919480129, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.0
lr:  0.008545571206785054
weight_decay:  0.000963740599028913
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9657243238762021
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  1.2031738001387566
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  0.7374169249087572
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.9443490505218506
total time:  2.986581370001659
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.93 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 70.77 ± 0.67
[I 2023-06-12 00:02:44,370] Trial 768 finished with value: 73.93333435058594 and parameters: {'Fwd': 0.0861443778686443, 'K': 5, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 7.158561342937241, 'loop': 2, 'loss': 'CE', 'lr': 0.008545571206785054, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000963740599028913, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.0011173047222701423
weight_decay:  0.00010118383805706455
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3627749730367213
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.3054576450958848
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  1.2819176011253148
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.990464210510254
total time:  4.035765026928857
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.23 ± 0.21
[I 2023-06-12 00:02:48,972] Trial 769 finished with value: 69.13333892822266 and parameters: {'Fwd': 0.08950794379657834, 'K': 9, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.1, 'lambda2': 7.264828667190789, 'loop': 2, 'loss': 'CE', 'lr': 0.0011173047222701423, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010118383805706455, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0007540922815042464
weight_decay:  0.0001656222358271609
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5895677029620856
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.7401969961356372
None Run 02:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 50.80
Split: 01, Run: 03
None time:  1.7107533861417323
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.10
run time now: 4.072385549545288
total time:  4.120893478160724
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.20 ± 11.11
  Final Train: 100.00 ± 0.00
   Final Test: 62.97 ± 10.54
[I 2023-06-12 00:02:53,642] Trial 770 finished with value: 62.20000076293945 and parameters: {'Fwd': 0.09201741372888986, 'K': 1, 'alpha': 0.0, 'dropout': 0.1, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 7.389370985875292, 'loop': 2, 'loss': 'CE', 'lr': 0.0007540922815042464, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001656222358271609, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.009088521286936714
weight_decay:  0.0001369004516212307
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2512343591079116
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 02
None time:  1.057475714944303
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.7205096250399947
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.072909355163574
total time:  3.128901917953044
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 71.37 ± 0.70
[I 2023-06-12 00:02:57,321] Trial 771 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.05938606750205137, 'K': 9, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 7.654660802038216, 'loop': 2, 'loss': 'CE', 'lr': 0.009088521286936714, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001369004516212307, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.0
lr:  0.008431603151930303
weight_decay:  0.0011053422732414614
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1015491771977395
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 02
None time:  0.9889600458554924
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.60
Split: 01, Run: 03
None time:  0.7357143699191511
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 71.70
run time now: 2.8656952381134033
total time:  2.913209494901821
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.13 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 71.97 ± 0.55
[I 2023-06-12 00:03:00,768] Trial 772 finished with value: 74.13333129882812 and parameters: {'Fwd': 0.03486458131249578, 'K': 6, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 7.757945136722893, 'loop': 2, 'loss': 'CE', 'lr': 0.008431603151930303, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0011053422732414614, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.05
lr:  0.009399100993074757
weight_decay:  0.0007535529022794345
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4610201460309327
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.7663308510091156
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  0.7244031759910285
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.30
run time now: 3.0020458698272705
total time:  3.044859291985631
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 1.29
  Final Train: 99.72 ± 0.48
   Final Test: 71.03 ± 1.55
[I 2023-06-12 00:03:04,295] Trial 773 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0035850352623594916, 'K': 7, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.05, 'lambda2': 3.7652798799659055, 'loop': 2, 'loss': 'CE', 'lr': 0.009399100993074757, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007535529022794345, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.002850016510766948
weight_decay:  0.017870794125410993
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7920933780260384
None Run 01:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 39.90
Split: 01, Run: 02
None time:  0.7595045980997384
None Run 02:
Highest Train: 100.00
Highest Valid: 30.80
  Final Train: 100.00
   Final Test: 32.10
Split: 01, Run: 03
None time:  0.7713430731091648
None Run 03:
Highest Train: 100.00
Highest Valid: 31.00
  Final Train: 100.00
   Final Test: 32.60
run time now: 2.372307777404785
total time:  2.432263019029051
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 33.47 ± 4.45
  Final Train: 100.00 ± 0.00
   Final Test: 34.87 ± 4.37
[I 2023-06-12 00:03:07,338] Trial 774 finished with value: 33.46666717529297 and parameters: {'Fwd': 0.05663995653934447, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 4.183237019976498, 'loop': 2, 'loss': 'CE', 'lr': 0.002850016510766948, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.017870794125410993, 'weightedloss': False}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.0
lr:  0.007964757033545426
weight_decay:  0.02389195425299434
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7859437349252403
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.50
Split: 01, Run: 02
None time:  0.9826943089719862
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 95.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.7678056880831718
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 96.67
   Final Test: 71.50
run time now: 2.5736751556396484
total time:  2.618641061009839
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 3.65
  Final Train: 97.22 ± 2.55
   Final Test: 69.20 ± 4.07
[I 2023-06-12 00:03:10,551] Trial 775 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.07004793309928697, 'K': 7, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 0.4496882253953297, 'loop': 2, 'loss': 'CE', 'lr': 0.007964757033545426, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.02389195425299434, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.0
lr:  0.00025033292750094126
weight_decay:  8.039949116014448e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4660697740036994
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 02
None time:  0.8533311479259282
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.7052753670141101
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.30
run time now: 3.0628232955932617
total time:  3.114977336023003
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 1.71
  Final Train: 100.00 ± 0.00
   Final Test: 68.40 ± 1.35
[I 2023-06-12 00:03:14,269] Trial 776 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.02040307020961635, 'K': 7, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 3.5861128941782994, 'loop': 2, 'loss': 'CE', 'lr': 0.00025033292750094126, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.039949116014448e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.0
lr:  0.0006493749871302565
weight_decay:  0.0005242554920271358
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8977451620157808
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 02
None time:  1.621771675068885
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.1058148071169853
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.20
run time now: 3.663212537765503
total time:  3.7178617569152266
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 1.17
  Final Train: 100.00 ± 0.00
   Final Test: 68.40 ± 1.91
[I 2023-06-12 00:03:18,601] Trial 777 finished with value: 69.86666870117188 and parameters: {'Fwd': 0.03814060181200123, 'K': 6, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.05, 'lambda2': 4.560739772610393, 'loop': 2, 'loss': 'CE', 'lr': 0.0006493749871302565, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005242554920271358, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009985606765252506
weight_decay:  0.0001032726778180175
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0755160069093108
None Run 01:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 73.10
Split: 01, Run: 02
None time:  0.8797009941190481
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.7722342349588871
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.7589011192321777
total time:  2.81203324906528
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.07 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 71.47 ± 1.42
[I 2023-06-12 00:03:21,972] Trial 778 finished with value: 75.06666564941406 and parameters: {'Fwd': 0.08877416735558016, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 7.287694489890272, 'loop': 2, 'loss': 'CE', 'lr': 0.009985606765252506, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001032726778180175, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.05
lr:  0.009894871751298917
weight_decay:  4.936721649873495e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0187022387981415
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 93.33
   Final Test: 72.00
Split: 01, Run: 02
None time:  0.7274372780229896
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 98.33
   Final Test: 72.10
Split: 01, Run: 03
None time:  0.7672099280171096
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 72.30
run time now: 2.5502281188964844
total time:  2.612431155052036
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 1.10
  Final Train: 96.94 ± 3.15
   Final Test: 72.13 ± 0.15
[I 2023-06-12 00:03:25,270] Trial 779 finished with value: 73.26666259765625 and parameters: {'Fwd': 0.04723759555842135, 'K': 6, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 1.3112979441113461, 'loop': 2, 'loss': 'CE', 'lr': 0.009894871751298917, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.936721649873495e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009266207295957292
weight_decay:  0.054557015294830154
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3108837890904397
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.7795592369511724
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.9162615679670125
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.90
run time now: 3.044039726257324
total time:  3.0974627260584384
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 1.55
[I 2023-06-12 00:03:28,929] Trial 780 finished with value: 73.4000015258789 and parameters: {'Fwd': 0.07982166820632391, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 6.999108886728579, 'loop': 2, 'loss': 'CE', 'lr': 0.009266207295957292, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.054557015294830154, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009957546984956408
weight_decay:  8.045351187871507e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1199091169983149
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 02
None time:  1.043520990991965
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.7535639968700707
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.950928211212158
total time:  2.9977476419880986
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 70.50 ± 0.90
[I 2023-06-12 00:03:32,434] Trial 781 finished with value: 72.86666870117188 and parameters: {'Fwd': 0.07259765011163613, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 7.1613643788620776, 'loop': 2, 'loss': 'CE', 'lr': 0.009957546984956408, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.045351187871507e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.009021706030248093
weight_decay:  0.00010107174739375182
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6039518769830465
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.10
Split: 01, Run: 02
None time:  0.7028717158827931
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 03
None time:  0.7730370028875768
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.10
run time now: 3.1182355880737305
total time:  3.1609394231345505
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 72.23 ± 1.03
[I 2023-06-12 00:03:36,072] Trial 782 finished with value: 73.26667022705078 and parameters: {'Fwd': 0.0942892697313527, 'K': 8, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 7.421375621411683, 'loop': 2, 'loss': 'CE', 'lr': 0.009021706030248093, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010107174739375182, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008499139922488113
weight_decay:  9.960774378782458e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0846352810040116
None Run 01:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 50.60
Split: 01, Run: 02
None time:  0.8164937009569257
None Run 02:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.80
Split: 01, Run: 03
None time:  0.8178150528110564
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 61.30
run time now: 2.751744270324707
total time:  2.8055114259477705
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.27 ± 7.26
  Final Train: 100.00 ± 0.00
   Final Test: 58.23 ± 6.65
[I 2023-06-12 00:03:39,397] Trial 783 finished with value: 59.266666412353516 and parameters: {'Fwd': 0.02658091448017315, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 7.268086307368175, 'loop': 2, 'loss': 'MSE', 'lr': 0.008499139922488113, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.960774378782458e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.0003852793959937424
weight_decay:  7.250169905166434e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0517561589367688
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.3382448400370777
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  1.2190314498730004
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.6534512042999268
total time:  3.699098494835198
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 70.40 ± 0.85
[I 2023-06-12 00:03:43,584] Trial 784 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.09481835597567533, 'K': 8, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 6.941162320137834, 'loop': 2, 'loss': 'CE', 'lr': 0.0003852793959937424, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.250169905166434e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00925428255030616
weight_decay:  1.501756387428e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6236217019613832
None Run 01:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 43.80
Split: 01, Run: 02
None time:  0.7534648438449949
None Run 02:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 47.10
Split: 01, Run: 03
None time:  0.6790348449721932
None Run 03:
Highest Train: 100.00
Highest Valid: 43.40
  Final Train: 100.00
   Final Test: 42.40
run time now: 2.088919162750244
total time:  2.143922296119854
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 44.93 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 44.43 ± 2.41
[I 2023-06-12 00:03:46,312] Trial 785 finished with value: 44.93333435058594 and parameters: {'Fwd': 0.08358823367444347, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 7.818283650420022, 'loop': 2, 'loss': 'CE', 'lr': 0.00925428255030616, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.501756387428e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.002463119471642895
weight_decay:  1.1238322522109044e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.335788067895919
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.8869030540809035
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  0.8985988867934793
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 72.30
run time now: 3.164095640182495
total time:  3.209394318982959
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.13 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 71.73 ± 0.49
[I 2023-06-12 00:03:50,190] Trial 786 finished with value: 73.13333129882812 and parameters: {'Fwd': 2.694319767130979e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 8.132258093743259, 'loop': 2, 'loss': 'CE', 'lr': 0.002463119471642895, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1238322522109044e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.0
lr:  0.0031614567948720176
weight_decay:  0.00012053273372142164
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9776768258307129
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 71.50
Split: 01, Run: 02
None time:  1.2069002920761704
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 95.00
   Final Test: 72.60
Split: 01, Run: 03
None time:  0.6918342988938093
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 97.50
   Final Test: 71.20
run time now: 2.914336919784546
total time:  2.971575604053214
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 0.72
  Final Train: 97.22 ± 2.10
   Final Test: 71.77 ± 0.74
[I 2023-06-12 00:03:53,711] Trial 787 finished with value: 72.99999237060547 and parameters: {'Fwd': 0.0701759142785817, 'K': 7, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 1.1361734009319182, 'loop': 2, 'loss': 'CE', 'lr': 0.0031614567948720176, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012053273372142164, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00028794860782089274
weight_decay:  8.646304600116352e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0569682631175965
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.1868371220771223
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.70
Split: 01, Run: 03
None time:  0.9969319941010326
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.60
run time now: 3.2747747898101807
total time:  3.323470424162224
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 65.77 ± 1.20
[I 2023-06-12 00:03:57,629] Trial 788 finished with value: 67.26666259765625 and parameters: {'Fwd': 0.035172464740405356, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 7.21269843226246, 'loop': 2, 'loss': 'CE', 'lr': 0.00028794860782089274, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.646304600116352e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0010234270463399771
weight_decay:  7.83728505140201e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8601775669958442
None Run 01:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 65.00
Split: 01, Run: 02
None time:  1.691541109001264
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.4961, Train: 95.00%, Valid: 71.80% Test: 70.60%
Split: 01, Run: 03
None time:  2.056462962878868
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 70.70
run time now: 4.64294958114624
total time:  4.701088940026239
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 4.85
  Final Train: 98.06 ± 2.68
   Final Test: 68.33 ± 2.97
[I 2023-06-12 00:04:02,963] Trial 789 finished with value: 69.19999694824219 and parameters: {'Fwd': 0.06261339892220026, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 2.0341977786442156, 'loop': 2, 'loss': 'CE', 'lr': 0.0010234270463399771, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.83728505140201e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008434014468215824
weight_decay:  0.000638796150018278
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3765742909163237
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.728077185107395
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.8109004991129041
None Run 03:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 71.80
run time now: 2.9480581283569336
total time:  3.002825123956427
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 2.41
  Final Train: 99.72 ± 0.48
   Final Test: 70.70 ± 1.42
[I 2023-06-12 00:04:06,602] Trial 790 finished with value: 73.53333282470703 and parameters: {'Fwd': 0.05858466228474341, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.544191391740715, 'loop': 2, 'loss': 'CE', 'lr': 0.008434014468215824, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000638796150018278, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00995261080031622
weight_decay:  6.73246063982556e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2965728999115527
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 67.60
Split: 01, Run: 02
None time:  0.9313755379989743
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.8402052209712565
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.100393056869507
total time:  3.151591500034556
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.20 ± 0.53
  Final Train: 99.72 ± 0.48
   Final Test: 69.07 ± 1.31
[I 2023-06-12 00:04:10,355] Trial 791 finished with value: 73.19999694824219 and parameters: {'Fwd': 0.00022729516695783717, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 5.400864322602737, 'loop': 2, 'loss': 'CE', 'lr': 0.00995261080031622, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.73246063982556e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0018789043018867674
weight_decay:  0.0003985682040398205
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5948041980154812
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 02
None time:  1.2591016669757664
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 03
None time:  1.138964117038995
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 99.17
   Final Test: 71.60
run time now: 4.035818815231323
total time:  4.079568871064112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 0.58
  Final Train: 99.44 ± 0.48
   Final Test: 71.17 ± 0.59
[I 2023-06-12 00:04:14,926] Trial 792 finished with value: 72.86666107177734 and parameters: {'Fwd': 0.04751662069112779, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 4.9874629087131215, 'loop': 2, 'loss': 'CE', 'lr': 0.0018789043018867674, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003985682040398205, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00018155794967771662
weight_decay:  7.029965955594417e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 1.0064, Train: 100.00%, Valid: 61.60% Test: 58.40%
Split: 01, Run: 01
None time:  1.7052228900138289
None Run 01:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 58.50
Split: 01, Run: 02
None time:  0.7205960280261934
None Run 02:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 60.60
Split: 01, Run: 03
None time:  0.7477383180521429
None Run 03:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 59.70
run time now: 3.212653875350952
total time:  3.2656603399664164
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.27 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 59.60 ± 1.05
[I 2023-06-12 00:04:18,716] Trial 793 finished with value: 62.26666259765625 and parameters: {'Fwd': 9.526609372666177e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 6.784485986242137, 'loop': 2, 'loss': 'CE', 'lr': 0.00018155794967771662, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.029965955594417e-05, 'weightedloss': False}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.05
lr:  0.009987687097394969
weight_decay:  0.0001205373943803684
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8857443740125746
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.7345039141364396
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  0.7473631938919425
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.4054114818573
total time:  2.4516406080219895
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 1.91
  Final Train: 99.72 ± 0.48
   Final Test: 70.67 ± 1.59
[I 2023-06-12 00:04:21,748] Trial 794 finished with value: 72.5999984741211 and parameters: {'Fwd': 0.0023479862893460296, 'K': 5, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 3.3643144649482277, 'loop': 2, 'loss': 'CE', 'lr': 0.009987687097394969, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001205373943803684, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007876588613391647
weight_decay:  0.02789275603967711
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.359228135086596
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9029158039484173
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 98.33
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.693883314030245
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 65.70
run time now: 2.993844747543335
total time:  3.0420945051591843
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.47 ± 0.70
  Final Train: 97.78 ± 2.55
   Final Test: 68.90 ± 2.86
[I 2023-06-12 00:04:25,369] Trial 795 finished with value: 72.46666717529297 and parameters: {'Fwd': 0.01619756498022413, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 4.708683880868515, 'loop': 2, 'loss': 'CE', 'lr': 0.007876588613391647, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.02789275603967711, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.009110575533287571
weight_decay:  1.0324716260606142e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2779561001807451
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 98.33
   Final Test: 70.50
Split: 01, Run: 02
None time:  0.7770649010781199
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.8417058710474521
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.941145420074463
total time:  2.9988610628060997
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 0.31
  Final Train: 99.44 ± 0.96
   Final Test: 70.50 ± 0.30
[I 2023-06-12 00:04:28,879] Trial 796 finished with value: 73.26666259765625 and parameters: {'Fwd': 7.576891767643354e-06, 'K': 10, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 7.399094423394209, 'loop': 2, 'loss': 'CE', 'lr': 0.009110575533287571, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0324716260606142e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.008411635629251697
weight_decay:  2.3817019826048194e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1565702799707651
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.8354058368131518
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  0.8104939879849553
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.8438124656677246
total time:  2.8971569419372827
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.03 ± 1.56
[I 2023-06-12 00:04:32,326] Trial 797 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.09399178844744017, 'K': 8, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 8.004716409962908, 'loop': 2, 'loss': 'CE', 'lr': 0.008411635629251697, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.3817019826048194e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007429841253766171
weight_decay:  1.2973510907848288e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4844405169133097
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.8219547960907221
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.792382069863379
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.60
run time now: 3.1298720836639404
total time:  3.1807654581498355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 70.90 ± 0.96
[I 2023-06-12 00:04:36,039] Trial 798 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.005660212942784953, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 7.11215912568997, 'loop': 2, 'loss': 'CE', 'lr': 0.007429841253766171, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2973510907848288e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.6000000000000001
lr:  0.009060767888342328
weight_decay:  0.019240540054091326
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8228710109833628
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02
None time:  0.7819719999097288
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.8429914959706366
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 69.00
run time now: 2.4854092597961426
total time:  2.5361662099603564
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 0.31
  Final Train: 99.72 ± 0.48
   Final Test: 68.97 ± 0.35
[I 2023-06-12 00:04:39,159] Trial 799 finished with value: 69.53333282470703 and parameters: {'Fwd': 2.067625920848411e-05, 'K': 6, 'alpha': 0.6000000000000001, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 5.131317811634187, 'loop': 2, 'loss': 'CE', 'lr': 0.009060767888342328, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.019240540054091326, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00672136997375889
weight_decay:  0.0015953267600801208
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0119648380205035
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 94.17
   Final Test: 67.90
Split: 01, Run: 02
None time:  0.7746607940644026
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.7662878360133618
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.583714723587036
total time:  2.637408781098202
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 2.34
  Final Train: 98.06 ± 3.37
   Final Test: 69.00 ± 1.21
[I 2023-06-12 00:04:42,416] Trial 800 finished with value: 71.86666107177734 and parameters: {'Fwd': 0.008708216102541345, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 0.7911938640125094, 'loop': 2, 'loss': 'CE', 'lr': 0.00672136997375889, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0015953267600801208, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007949293435954283
weight_decay:  0.00016685666852710447
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3080190001055598
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 94.17
   Final Test: 72.20
Split: 01, Run: 02
None time:  0.7877524511422962
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 98.33
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.7382347399834543
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 72.00
run time now: 2.86445951461792
total time:  2.9119469081051648
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.80 ± 0.40
  Final Train: 97.22 ± 2.68
   Final Test: 71.93 ± 0.31
[I 2023-06-12 00:04:45,873] Trial 801 finished with value: 73.79999542236328 and parameters: {'Fwd': 0.0437977862344668, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 1.1593279326007497, 'loop': 2, 'loss': 'CE', 'lr': 0.007949293435954283, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00016685666852710447, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.0
lr:  0.0001361911821041727
weight_decay:  1.3680270431894215e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6783857168629766
None Run 01:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 46.30
Split: 01, Run: 02
None time:  0.7719176281243563
None Run 02:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.70
Split: 01, Run: 03
None time:  0.7630781601183116
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.10
run time now: 2.2515318393707275
total time:  2.2965654691215605
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.67 ± 9.98
  Final Train: 100.00 ± 0.00
   Final Test: 56.37 ± 9.13
[I 2023-06-12 00:04:48,684] Trial 802 finished with value: 57.66666793823242 and parameters: {'Fwd': 5.405524405833369e-05, 'K': 7, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 1.8000093258284258, 'loop': 2, 'loss': 'CE', 'lr': 0.0001361911821041727, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3680270431894215e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00908621927501473
weight_decay:  3.793530085828941e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.802389106946066
None Run 01:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 52.80
Split: 01, Run: 02
None time:  0.80207280209288
None Run 02:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 75.83
   Final Test: 52.80
Split: 01, Run: 03
None time:  0.7493158599827439
None Run 03:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 98.33
   Final Test: 47.20
run time now: 2.3884875774383545
total time:  2.435955971945077
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.33 ± 4.69
  Final Train: 91.39 ± 13.50
   Final Test: 50.93 ± 3.23
[I 2023-06-12 00:04:51,794] Trial 803 finished with value: 54.33333206176758 and parameters: {'Fwd': 3.435073777509671e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 7.735800193419472, 'loop': 2, 'loss': 'CE', 'lr': 0.00908621927501473, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.793530085828941e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0003238936203375891
weight_decay:  0.0035628281939041424
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9158812910318375
None Run 01:
Highest Train: 100.00
Highest Valid: 33.00
  Final Train: 100.00
   Final Test: 32.10
Split: 01, Run: 02
None time:  1.095046630129218
None Run 02:
Highest Train: 100.00
Highest Valid: 35.60
  Final Train: 100.00
   Final Test: 36.40
Split: 01, Run: 03
None time:  0.9051167091820389
None Run 03:
Highest Train: 100.00
Highest Valid: 36.20
  Final Train: 100.00
   Final Test: 38.20
run time now: 2.9521379470825195
total time:  3.0057410448789597
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 34.93 ± 1.70
  Final Train: 100.00 ± 0.00
   Final Test: 35.57 ± 3.13
[I 2023-06-12 00:04:55,349] Trial 804 finished with value: 34.93333435058594 and parameters: {'Fwd': 0.001545433618053344, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 2.885211329777437, 'loop': 2, 'loss': 'MSE', 'lr': 0.0003238936203375891, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0035628281939041424, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008364827665535386
weight_decay:  9.001543774965105e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5592136131599545
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 02
None time:  1.036701827077195
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.7716508849989623
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 67.00
run time now: 3.4023635387420654
total time:  3.4572694830130786
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 1.83
  Final Train: 99.72 ± 0.48
   Final Test: 68.60 ± 1.65
[I 2023-06-12 00:04:59,316] Trial 805 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.0725164737119401, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 7.55370346680768, 'loop': 2, 'loss': 'CE', 'lr': 0.008364827665535386, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.001543774965105e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.004669093857643711
weight_decay:  5.038575563619687e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1355533921159804
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 63.20
Split: 01, Run: 02
None time:  0.7891758969053626
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.9870238550938666
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 71.10
run time now: 2.9431464672088623
total time:  2.9921149949077517
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 2.25
  Final Train: 99.44 ± 0.48
   Final Test: 68.00 ± 4.22
[I 2023-06-12 00:05:02,826] Trial 806 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.0002951524044987733, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 5.65935803957359, 'loop': 2, 'loss': 'CE', 'lr': 0.004669093857643711, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.038575563619687e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009983332507701536
weight_decay:  0.00013287122843453033
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9611275719944388
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 02
None time:  2.065983338980004
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 71.70
Split: 01, Run: 03
None time:  2.2596914311870933
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 71.00
run time now: 6.3198981285095215
total time:  6.375744700897485
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.12
  Final Train: 98.89 ± 0.48
   Final Test: 71.10 ± 0.56
[I 2023-06-12 00:05:09,860] Trial 807 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.026935034520699886, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 2.5793782541017705, 'loop': 2, 'loss': 'CE', 'lr': 0.009983332507701536, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013287122843453033, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0019948015154809904
weight_decay:  6.685745171855881e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.098618048010394
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.0568012208677828
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.126927562057972
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.30
run time now: 3.3163325786590576
total time:  3.3712881058454514
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.81
  Final Train: 99.72 ± 0.48
   Final Test: 68.87 ± 1.43
[I 2023-06-12 00:05:13,826] Trial 808 finished with value: 71.73332977294922 and parameters: {'Fwd': 3.397681940488341e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 7.024469420160015, 'loop': 2, 'loss': 'CE', 'lr': 0.0019948015154809904, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.685745171855881e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007521456044777658
weight_decay:  0.0007492712175323592
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0867652150336653
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 95.00
   Final Test: 72.30
Split: 01, Run: 02
None time:  0.9598459040280432
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 95.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.8337715519592166
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 65.40
run time now: 2.9134085178375244
total time:  2.9655388279352337
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.00 ± 0.20
  Final Train: 96.67 ± 2.89
   Final Test: 69.67 ± 3.73
[I 2023-06-12 00:05:17,342] Trial 809 finished with value: 74.0 and parameters: {'Fwd': 1.0449411205425956e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.5, 'lambda2': 3.181876934137253, 'loop': 2, 'loss': 'CE', 'lr': 0.007521456044777658, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007492712175323592, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008995859139040673
weight_decay:  0.00033726313704366
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1624079179018736
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.7559184180572629
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 03
None time:  0.692107138922438
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 71.80
run time now: 2.64312481880188
total time:  2.6933677960187197
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.07 ± 1.97
  Final Train: 99.72 ± 0.48
   Final Test: 71.57 ± 0.32
[I 2023-06-12 00:05:20,596] Trial 810 finished with value: 74.0666732788086 and parameters: {'Fwd': 0.002880962976889917, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 6.461829572508791, 'loop': 2, 'loss': 'CE', 'lr': 0.008995859139040673, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00033726313704366, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0013784963901046204
weight_decay:  1.6980674208436777e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.333017178112641
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  1.4920291749294847
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 03
None time:  1.4278782380279154
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
run time now: 4.284298419952393
total time:  4.334318089066073
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.30 ± 0.00
[I 2023-06-12 00:05:25,437] Trial 811 finished with value: 51.20000076293945 and parameters: {'Fwd': 1.6974650230334572e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.0, 'lambda2': 3.973926475212206, 'loop': 2, 'loss': 'CE', 'lr': 0.0013784963901046204, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6980674208436777e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008429672241074151
weight_decay:  0.00010690910148916884
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7957575998734683
None Run 01:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 58.60
Split: 01, Run: 02
None time:  1.217637448105961
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  1.0337308740708977
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.077937602996826
total time:  3.13098428491503
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.40 ± 8.50
  Final Train: 100.00 ± 0.00
   Final Test: 65.57 ± 6.08
[I 2023-06-12 00:05:29,167] Trial 812 finished with value: 68.39999389648438 and parameters: {'Fwd': 0.09987824398826908, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 9.438648115514075, 'loop': 2, 'loss': 'CE', 'lr': 0.008429672241074151, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010690910148916884, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.002013902222380483
weight_decay:  9.331266319715856e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7414445988833904
None Run 01:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 43.30
Split: 01, Run: 02
None time:  0.6263855691067874
None Run 02:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 39.80
Split: 01, Run: 03
None time:  0.6718279519118369
None Run 03:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 35.40
run time now: 2.0719869136810303
total time:  2.1216138610616326
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 41.27 ± 4.64
  Final Train: 100.00 ± 0.00
   Final Test: 39.50 ± 3.96
[I 2023-06-12 00:05:31,805] Trial 813 finished with value: 41.266666412353516 and parameters: {'Fwd': 5.666957987744292e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 8.271062807096984, 'loop': 2, 'loss': 'CE', 'lr': 0.002013902222380483, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.331266319715856e-06, 'weightedloss': False}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00016727979860415516
weight_decay:  0.0004455123677045488
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.645717595005408
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 99.17
   Final Test: 60.40
Split: 01, Run: 02
None time:  0.8648018271196634
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 03
None time:  0.7248775588814169
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 66.90
run time now: 3.2778282165527344
total time:  3.323738920968026
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.60 ± 4.68
  Final Train: 99.72 ± 0.48
   Final Test: 64.50 ± 3.57
[I 2023-06-12 00:05:35,618] Trial 814 finished with value: 67.5999984741211 and parameters: {'Fwd': 7.004566569343089e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 2.147871730421469, 'loop': 2, 'loss': 'CE', 'lr': 0.00016727979860415516, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004455123677045488, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0010491684775236732
weight_decay:  0.012545032968099184
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6444625940639526
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 90.00
   Final Test: 66.10
Split: 01, Run: 02
None time:  0.7917453330010176
None Run 02:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 54.90
Split: 01, Run: 03
None time:  0.7928544238675386
None Run 03:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 55.30
run time now: 3.268198251724243
total time:  3.3224061890505254
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.07 ± 8.47
  Final Train: 96.67 ± 5.77
   Final Test: 58.77 ± 6.35
[I 2023-06-12 00:05:39,460] Trial 815 finished with value: 60.06666946411133 and parameters: {'Fwd': 4.782155648457472e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.1, 'lambda2': 0.21628803101199123, 'loop': 2, 'loss': 'CE', 'lr': 0.0010491684775236732, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.012545032968099184, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.004381457073586102
weight_decay:  0.00025663880402437654
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8904566129203886
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.60
Split: 01, Run: 02
None time:  1.1309236460365355
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.857581740943715
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.10
run time now: 2.911267042160034
total time:  2.9576285590883344
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 3.74
  Final Train: 99.72 ± 0.48
   Final Test: 68.73 ± 3.59
[I 2023-06-12 00:05:42,928] Trial 816 finished with value: 71.26666259765625 and parameters: {'Fwd': 0.00012844004641044004, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 6.12496288002914, 'loop': 2, 'loss': 'CE', 'lr': 0.004381457073586102, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00025663880402437654, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0023122384298653823
weight_decay:  0.00021489237307968247
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7672900140751153
None Run 01:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 50.50
Split: 01, Run: 02
None time:  1.395786298904568
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 85.00
   Final Test: 62.80
Split: 01, Run: 03
None time:  0.7259407960809767
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 85.00
   Final Test: 66.30
run time now: 2.919692277908325
total time:  2.9632696688640863
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.13 ± 10.19
  Final Train: 90.00 ± 8.66
   Final Test: 59.87 ± 8.30
[I 2023-06-12 00:05:46,493] Trial 817 finished with value: 60.133331298828125 and parameters: {'Fwd': 2.36606741561046e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 0.01200416400006965, 'loop': 2, 'loss': 'CE', 'lr': 0.0023122384298653823, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00021489237307968247, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.000591236760647131
weight_decay:  0.08098555867094724
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0204739931505173
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 02
None time:  1.4123169400263578
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.1556185679510236
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 71.70
run time now: 3.6219091415405273
total time:  3.6665870000142604
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.10
  Final Train: 99.44 ± 0.48
   Final Test: 69.20 ± 2.33
[I 2023-06-12 00:05:50,686] Trial 818 finished with value: 70.33333587646484 and parameters: {'Fwd': 3.036671791319658e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 4.3637316529953445, 'loop': 2, 'loss': 'CE', 'lr': 0.000591236760647131, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.08098555867094724, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.006943297975749507
weight_decay:  0.00015872465530313658
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5394034599885345
None Run 01:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 57.10
Split: 01, Run: 02
None time:  0.9667591399047524
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 95.83
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.5622198320925236
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.30
run time now: 2.100013494491577
total time:  2.156863389071077
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.27 ± 7.55
  Final Train: 98.33 ± 2.20
   Final Test: 65.30 ± 7.16
[I 2023-06-12 00:05:53,371] Trial 819 finished with value: 66.26667022705078 and parameters: {'Fwd': 0.0507318501434837, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 1.9206855091671946, 'loop': 2, 'loss': 'CE', 'lr': 0.006943297975749507, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00015872465530313658, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00606246139703919
weight_decay:  0.0011001776818496457
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.191390180028975
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 99.17
   Final Test: 71.70
Split: 01, Run: 02
None time:  0.634554942836985
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.792981875827536
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 70.70
run time now: 2.649061679840088
total time:  2.6938752129208297
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 0.64
  Final Train: 99.44 ± 0.48
   Final Test: 70.70 ± 1.00
[I 2023-06-12 00:05:56,586] Trial 820 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.0013236984487685962, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 4.794374144893851, 'loop': 2, 'loss': 'CE', 'lr': 0.00606246139703919, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0011001776818496457, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.00017517599941561777
weight_decay:  0.0005750535542109747
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7843165658414364
None Run 01:
Highest Train: 100.00
Highest Valid: 32.40
  Final Train: 100.00
   Final Test: 31.80
Split: 01, Run: 02
None time:  0.952661955030635
None Run 02:
Highest Train: 100.00
Highest Valid: 32.80
  Final Train: 100.00
   Final Test: 33.70
Split: 01, Run: 03
None time:  0.9184325321111828
None Run 03:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 37.40
run time now: 2.6909804344177246
total time:  2.7528220880776644
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 34.07 ± 2.55
  Final Train: 100.00 ± 0.00
   Final Test: 34.30 ± 2.85
[I 2023-06-12 00:05:59,987] Trial 821 finished with value: 34.06666564941406 and parameters: {'Fwd': 0.013035944354690658, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 8.569897992744636, 'loop': 2, 'loss': 'MSE', 'lr': 0.00017517599941561777, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005750535542109747, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.000828851792300414
weight_decay:  1.3042190624319867e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9121189969591796
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.8328242709394544
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 97.50
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.7381015180144459
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.5160584449768066
total time:  3.569650678196922
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.70
  Final Train: 99.17 ± 1.44
   Final Test: 69.47 ± 0.98
[I 2023-06-12 00:06:04,131] Trial 822 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.004164584330455258, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 3.7002594833050204, 'loop': 2, 'loss': 'CE', 'lr': 0.000828851792300414, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3042190624319867e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00033548496272003085
weight_decay:  5.908723302976245e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2190, Train: 90.83%, Valid: 68.80% Test: 69.90%
Split: 01, Run: 01
None time:  1.5120248820167035
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 90.83
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.49559758603572845
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.3765503028407693
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 2.4154915809631348
total time:  2.4701947008725256
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 0.64
  Final Train: 96.67 ± 5.07
   Final Test: 70.03 ± 0.40
[I 2023-06-12 00:06:07,166] Trial 823 finished with value: 69.73333740234375 and parameters: {'Fwd': 0.00018657631724305204, 'K': 1, 'alpha': 0.0, 'dropout': 0.5, 'gnnepoch': 30, 'lambda1': 0.35000000000000003, 'lambda2': 1.4774884115285014, 'loop': 2, 'loss': 'CE', 'lr': 0.00033548496272003085, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.908723302976245e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009173836771992154
weight_decay:  0.01030026166120425
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8241357228253037
None Run 01:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 50.20
Split: 01, Run: 02
None time:  0.8222610780503601
None Run 02:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 55.40
Split: 01, Run: 03
None time:  0.7725314209237695
None Run 03:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 51.60
run time now: 2.4491379261016846
total time:  2.501961822854355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.07 ± 2.08
  Final Train: 100.00 ± 0.00
   Final Test: 52.40 ± 2.69
[I 2023-06-12 00:06:10,174] Trial 824 finished with value: 50.06666564941406 and parameters: {'Fwd': 0.09980378211328594, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 4.198905837585825, 'loop': 2, 'loss': 'CE', 'lr': 0.009173836771992154, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.01030026166120425, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.003881057872261114
weight_decay:  8.840345793649358e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.708606531843543
None Run 01:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 60.50
Split: 01, Run: 02
None time:  0.694546485086903
None Run 02:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 58.30
Split: 01, Run: 03
None time:  0.7255489740055054
None Run 03:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 56.40
run time now: 2.160418748855591
total time:  2.2076937791425735
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.47 ± 1.62
  Final Train: 100.00 ± 0.00
   Final Test: 58.40 ± 2.05
[I 2023-06-12 00:06:12,978] Trial 825 finished with value: 57.466670989990234 and parameters: {'Fwd': 8.273374872885897e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 7.4118629014556365, 'loop': 2, 'loss': 'CE', 'lr': 0.003881057872261114, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.840345793649358e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0011715445164893984
weight_decay:  6.717124473677014e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.079669628990814
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.1131384698674083
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  1.1322648369241506
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.3571581840515137
total time:  3.4059919680003077
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 68.50 ± 0.87
[I 2023-06-12 00:06:16,944] Trial 826 finished with value: 70.13333129882812 and parameters: {'Fwd': 4.171169108192995e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 2.418906896112236, 'loop': 2, 'loss': 'CE', 'lr': 0.0011715445164893984, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.717124473677014e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007839654939656347
weight_decay:  7.623359423977695e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.2571726308669895
None Run 01:
Highest Train: 100.00
Highest Valid: 36.60
  Final Train: 100.00
   Final Test: 37.90
Split: 01, Run: 02
None time:  1.1249451669864357
None Run 02:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 90.00
   Final Test: 32.70
Split: 01, Run: 03
None time:  0.6818096789065748
None Run 03:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 48.80
run time now: 2.096822500228882
total time:  2.146527302917093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 40.07 ± 6.71
  Final Train: 96.67 ± 5.77
   Final Test: 39.80 ± 8.22
[I 2023-06-12 00:06:19,668] Trial 827 finished with value: 40.06666564941406 and parameters: {'Fwd': 8.37488316389976e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.6000000000000001, 'gnnepoch': 20, 'lambda1': 0.2, 'lambda2': 7.926484079969502, 'loop': 2, 'loss': 'CE', 'lr': 0.007839654939656347, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.623359423977695e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9
lr:  0.001283802531463007
weight_decay:  0.00011448589187256811
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5750370279420167
None Run 01:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 51.90
Split: 01, Run: 02
None time:  1.3256649861577898
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.83
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.7249018009752035
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.50
run time now: 2.658647060394287
total time:  2.703874808968976
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.33 ± 6.53
  Final Train: 96.94 ± 5.29
   Final Test: 63.20 ± 9.79
[I 2023-06-12 00:06:22,890] Trial 828 finished with value: 64.33333587646484 and parameters: {'Fwd': 1.8574081105618973e-06, 'K': 1, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 0.8739974531271563, 'loop': 2, 'loss': 'CE', 'lr': 0.001283802531463007, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011448589187256811, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.005254748022392386
weight_decay:  0.00798487100847085
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.71291817096062
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 98.33
   Final Test: 71.60
Split: 01, Run: 02
None time:  0.7417210082057863
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.6389698588754982
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.125782012939453
total time:  3.1745544981677085
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 0.12
  Final Train: 99.44 ± 0.96
   Final Test: 70.13 ± 1.29
[I 2023-06-12 00:06:26,618] Trial 829 finished with value: 73.26666259765625 and parameters: {'Fwd': 0.0018547917794324417, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.392381848543204, 'loop': 2, 'loss': 'CE', 'lr': 0.005254748022392386, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00798487100847085, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00930568828069744
weight_decay:  0.00031073951978048854
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2352504897862673
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 02
None time:  0.6969805709086359
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.7111524199135602
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 99.17
   Final Test: 72.70
run time now: 2.6747987270355225
total time:  2.72032874613069
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.27 ± 0.58
  Final Train: 99.72 ± 0.48
   Final Test: 71.23 ± 1.75
[I 2023-06-12 00:06:29,847] Trial 830 finished with value: 74.26666259765625 and parameters: {'Fwd': 0.019494401469100277, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 2.7340734030621743, 'loop': 2, 'loss': 'CE', 'lr': 0.00930568828069744, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00031073951978048854, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00011145336705234222
weight_decay:  0.00018305412206399068
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7670459460932761
None Run 01:
Highest Train: 100.00
Highest Valid: 36.40
  Final Train: 100.00
   Final Test: 35.90
Split: 01, Run: 02
None time:  0.838770077098161
None Run 02:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 99.17
   Final Test: 53.70
Split: 01, Run: 03
None time:  0.6885328812059015
None Run 03:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 57.40
run time now: 2.3267152309417725
total time:  2.372871577972546
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.13 ± 13.00
  Final Train: 99.72 ± 0.48
   Final Test: 49.00 ± 11.49
[I 2023-06-12 00:06:32,744] Trial 831 finished with value: 51.133331298828125 and parameters: {'Fwd': 2.687583090435237e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 0.6010405043007145, 'loop': 2, 'loss': 'CE', 'lr': 0.00011145336705234222, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00018305412206399068, 'weightedloss': False}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00041187183262672946
weight_decay:  0.01463888536089222
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2670310440007597
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 02
None time:  0.7908338049892336
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.4824, Train: 100.00%, Valid: 70.60% Test: 69.60%
Split: 01, Run: 03
None time:  1.9074897291138768
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.997985363006592
total time:  4.047510467004031
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 68.40 ± 1.55
[I 2023-06-12 00:06:37,417] Trial 832 finished with value: 69.5999984741211 and parameters: {'Fwd': 0.058620595670938594, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 7.246636675622172, 'loop': 2, 'loss': 'CE', 'lr': 0.00041187183262672946, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.01463888536089222, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00838731186877468
weight_decay:  0.0007789805338031685
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9115435229614377
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.6470371941104531
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.671829572878778
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.263080358505249
total time:  2.312387442914769
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 1.71
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.71
[I 2023-06-12 00:06:40,274] Trial 833 finished with value: 72.79999542236328 and parameters: {'Fwd': 1.387971079526717e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 6.62512623468394, 'loop': 2, 'loss': 'CE', 'lr': 0.00838731186877468, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007789805338031685, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0023356274769999723
weight_decay:  0.001429059830452521
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7020165019202977
None Run 01:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 50.30
Split: 01, Run: 02
None time:  0.8784055651631206
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 99.17
   Final Test: 66.30
Split: 01, Run: 03
None time:  1.142947860993445
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 95.00
   Final Test: 68.80
run time now: 2.75797176361084
total time:  2.8231293831486255
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.53 ± 9.67
  Final Train: 98.06 ± 2.68
   Final Test: 61.80 ± 10.04
[I 2023-06-12 00:06:43,601] Trial 834 finished with value: 63.5333366394043 and parameters: {'Fwd': 2.0913202921105515e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 3.0603493143114924, 'loop': 2, 'loss': 'CE', 'lr': 0.0023356274769999723, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001429059830452521, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00763278177288217
weight_decay:  1.771587006337397e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1111447219736874
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 94.17
   Final Test: 71.50
Split: 01, Run: 02
None time:  0.5473128650337458
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.5061257008928806
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.90
run time now: 2.197281837463379
total time:  2.263862101128325
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 0.64
  Final Train: 98.06 ± 3.37
   Final Test: 70.23 ± 1.70
[I 2023-06-12 00:06:46,429] Trial 835 finished with value: 73.26666259765625 and parameters: {'Fwd': 0.005777855575792299, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.4, 'lambda2': 1.6159858660167383, 'loop': 2, 'loss': 'CE', 'lr': 0.00763278177288217, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.771587006337397e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.006572096578632529
weight_decay:  0.0001445656581056535
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4503868462052196
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.7577934409491718
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 03
None time:  0.6990990429185331
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.90
run time now: 2.9389383792877197
total time:  2.9855649420060217
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.13 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 71.47 ± 0.67
[I 2023-06-12 00:06:49,942] Trial 836 finished with value: 74.13333129882812 and parameters: {'Fwd': 0.0011512119133453209, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.15000000000000002, 'lambda2': 7.665555310643562, 'loop': 2, 'loss': 'CE', 'lr': 0.006572096578632529, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001445656581056535, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.0
lr:  0.009907092207753522
weight_decay:  8.983094558952572e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8130219059530646
None Run 01:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 55.30
Split: 01, Run: 02
None time:  1.5088981038425118
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 90.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  0.8032003960106522
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.163750410079956
total time:  3.2070793460588902
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.60 ± 6.13
  Final Train: 96.67 ± 5.77
   Final Test: 63.87 ± 7.47
[I 2023-06-12 00:06:53,674] Trial 837 finished with value: 62.60000228881836 and parameters: {'Fwd': 0.003321702982233908, 'K': 6, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 6.85122659605015, 'loop': 2, 'loss': 'CE', 'lr': 0.009907092207753522, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.983094558952572e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.7000000000000001
lr:  0.0006861347621518302
weight_decay:  0.0004411931895778976
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8233629348687828
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 02
None time:  1.6649589268490672
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.940231746993959
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.4639229774475098
total time:  3.530860842904076
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 2.91
  Final Train: 99.72 ± 0.48
   Final Test: 69.80 ± 2.38
[I 2023-06-12 00:06:57,722] Trial 838 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.029138517318820112, 'K': 1, 'alpha': 0.7000000000000001, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 5.834093470375708, 'loop': 2, 'loss': 'CE', 'lr': 0.0006861347621518302, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004411931895778976, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00020814130902977243
weight_decay:  0.05894351848989441
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8409, Train: 99.17%, Valid: 68.80% Test: 68.10%
Split: 01, Run: 01
None time:  1.75115230306983
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 99.17
   Final Test: 67.60
Split: 01, Run: 02
None time:  0.635903534013778
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  0.6977614010684192
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.30
run time now: 3.1172354221343994
total time:  3.1677087950520217
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 2.42
  Final Train: 99.72 ± 0.48
   Final Test: 70.30 ± 2.36
[I 2023-06-12 00:07:01,398] Trial 839 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.0002502415184255774, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 3.405629621660393, 'loop': 2, 'loss': 'CE', 'lr': 0.00020814130902977243, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.05894351848989441, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009992365786465365
weight_decay:  5.6847078976019964e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2326537889894098
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.0487480780575424
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.6502804190386087
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.9638912677764893
total time:  3.0266190010588616
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.20 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 1.01
[I 2023-06-12 00:07:05,034] Trial 840 finished with value: 73.20000457763672 and parameters: {'Fwd': 2.899875333531936e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 9.148852465320532, 'loop': 2, 'loss': 'CE', 'lr': 0.009992365786465365, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.6847078976019964e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.008549670568299004
weight_decay:  0.0009378340227049623
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.754015640122816
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 02
None time:  0.6513046820182353
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.7700719519052655
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 66.40
run time now: 2.2178304195404053
total time:  2.267524614930153
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 67.27 ± 0.76
[I 2023-06-12 00:07:07,942] Trial 841 finished with value: 69.33333587646484 and parameters: {'Fwd': 5.065094759459512e-06, 'K': 8, 'alpha': 0.75, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 3.9321098474377028, 'loop': 2, 'loss': 'CE', 'lr': 0.008549670568299004, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009378340227049623, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.005736646836580408
weight_decay:  1.8527595430128035e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9856583550572395
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.40
Split: 01, Run: 02
None time:  2.0711417449638247
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  1.347786959959194
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.80
run time now: 4.4379355907440186
total time:  4.484552398091182
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.93 ± 2.08
  Final Train: 100.00 ± 0.00
   Final Test: 67.10 ± 1.48
[I 2023-06-12 00:07:12,959] Trial 842 finished with value: 67.9333267211914 and parameters: {'Fwd': 5.639947567005012e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.30000000000000004, 'gnnepoch': 120, 'lambda1': 0.25, 'lambda2': 4.556557171593877, 'loop': 2, 'loss': 'MSE', 'lr': 0.005736646836580408, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.8527595430128035e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007202477414314416
weight_decay:  1.2254853199825526e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.4859, Train: 100.00%, Valid: 73.60% Test: 71.80%
Split: 01, Run: 01
None time:  2.0615106439217925
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 02
None time:  0.8131447620689869
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 03
None time:  1.1553449069615453
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.70
run time now: 4.063835144042969
total time:  4.116467495914549
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 3.49
  Final Train: 100.00 ± 0.00
   Final Test: 70.23 ± 2.63
[I 2023-06-12 00:07:17,866] Trial 843 finished with value: 71.19998931884766 and parameters: {'Fwd': 0.007286939253777937, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.05, 'lambda2': 8.33594642476245, 'loop': 2, 'loss': 'CE', 'lr': 0.007202477414314416, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2254853199825526e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0015198542832607369
weight_decay:  0.0005506872469630652
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1843, Train: 99.17%, Valid: 68.40% Test: 67.20%
Split: 01, Run: 01
None time:  1.9140162121038884
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 99.17
   Final Test: 67.50
Split: 01, Run: 02
None time:  1.2808897509239614
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.442442201077938
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 70.10
run time now: 4.6700239181518555
total time:  4.72053312510252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 0.50
  Final Train: 99.17 ± 0.00
   Final Test: 69.10 ± 1.40
[I 2023-06-12 00:07:23,082] Trial 844 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.03845382786641821, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 9.554054295723153, 'loop': 2, 'loss': 'CE', 'lr': 0.0015198542832607369, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005506872469630652, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00022253072539739666
weight_decay:  9.840257634087064e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9769976900424808
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.60
Split: 01, Run: 02
None time:  0.8204385789576918
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 66.30
Split: 01, Run: 03
None time:  0.8561331848613918
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 63.50
run time now: 2.6874074935913086
total time:  2.7371569939423352
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.40 ± 1.31
  Final Train: 100.00 ± 0.00
   Final Test: 64.47 ± 1.59
[I 2023-06-12 00:07:26,377] Trial 845 finished with value: 66.4000015258789 and parameters: {'Fwd': 1.640579876047378e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 5.319606773615689, 'loop': 2, 'loss': 'CE', 'lr': 0.00022253072539739666, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.840257634087064e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00915188924913469
weight_decay:  0.00025823090839372084
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2484819879755378
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 71.10
Split: 01, Run: 02
None time:  0.5510181440040469
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.547512125922367
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.00
run time now: 2.3782541751861572
total time:  2.4374029240570962
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.33 ± 1.01
  Final Train: 99.72 ± 0.48
   Final Test: 70.17 ± 1.07
[I 2023-06-12 00:07:29,316] Trial 846 finished with value: 73.33332824707031 and parameters: {'Fwd': 0.00012213504893519983, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 5.076549139836532, 'loop': 2, 'loss': 'CE', 'lr': 0.00915188924913469, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00025823090839372084, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00019425359706790586
weight_decay:  8.074341950964823e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5433711758814752
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 02
None time:  0.7967893150635064
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.7670068040024489
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.00
run time now: 3.1379587650299072
total time:  3.184351883130148
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 68.20 ± 0.62
[I 2023-06-12 00:07:33,049] Trial 847 finished with value: 69.20000457763672 and parameters: {'Fwd': 1.0897481255239318e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 8.73419491451717, 'loop': 2, 'loss': 'CE', 'lr': 0.00019425359706790586, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.074341950964823e-05, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.05
lr:  0.004116678962168994
weight_decay:  4.028647379410312e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3258897699415684
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.4325156540144235
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0341888279654086
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.8274803161621094
total time:  3.878571879118681
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.46
[I 2023-06-12 00:07:37,555] Trial 848 finished with value: 72.20000457763672 and parameters: {'Fwd': 0.07129455867754975, 'K': 4, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 5.459379811325581, 'loop': 2, 'loss': 'CE', 'lr': 0.004116678962168994, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.028647379410312e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00046755398431223746
weight_decay:  0.00021658334243466248
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.106129019986838
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 02
None time:  1.0792804970405996
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.8232517149299383
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.60
run time now: 3.050222873687744
total time:  3.1008765280712396
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 71.37 ± 0.49
[I 2023-06-12 00:07:41,261] Trial 849 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.00044328263621757686, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 9.268390772065715, 'loop': 2, 'loss': 'CE', 'lr': 0.00046755398431223746, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00021658334243466248, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008020020137776064
weight_decay:  6.294625496243048e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6602030170615762
None Run 01:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 50.80
Split: 01, Run: 02
None time:  0.6490586290601641
None Run 02:
Highest Train: 100.00
Highest Valid: 40.40
  Final Train: 100.00
   Final Test: 40.60
Split: 01, Run: 03
None time:  0.6155491860117763
None Run 03:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 40.60
run time now: 1.9571545124053955
total time:  2.00199826201424
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 45.20 ± 6.35
  Final Train: 100.00 ± 0.00
   Final Test: 44.00 ± 5.89
[I 2023-06-12 00:07:43,839] Trial 850 finished with value: 45.20000076293945 and parameters: {'Fwd': 0.0014526947976456464, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 8.92119659927381, 'loop': 2, 'loss': 'CE', 'lr': 0.008020020137776064, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.294625496243048e-05, 'weightedloss': False}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009982997334343777
weight_decay:  1.2167547856647855e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0794231998734176
None Run 01:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 02
None time:  0.8338600259739906
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  0.740277495002374
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.691962718963623
total time:  2.7412983330432326
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 71.10 ± 0.44
[I 2023-06-12 00:07:47,172] Trial 851 finished with value: 74.80000305175781 and parameters: {'Fwd': 3.421523231249054e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 7.929986456697277, 'loop': 2, 'loss': 'CE', 'lr': 0.009982997334343777, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2167547856647855e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009299167447100049
weight_decay:  3.594562448538839e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0878675198182464
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  0.8514601348433644
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 03
None time:  0.7225663270801306
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 66.40
run time now: 2.695420980453491
total time:  2.7499278739560395
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 1.06
  Final Train: 99.72 ± 0.48
   Final Test: 68.47 ± 2.10
[I 2023-06-12 00:07:50,546] Trial 852 finished with value: 72.5999984741211 and parameters: {'Fwd': 2.2126671540624103e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 7.814264690934454, 'loop': 2, 'loss': 'CE', 'lr': 0.009299167447100049, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.594562448538839e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008989425340345414
weight_decay:  2.8305117148556525e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0785843629855663
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 68.80
Split: 01, Run: 02
None time:  0.8468803751748055
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.7199815439525992
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 67.30
run time now: 2.676297187805176
total time:  2.7261744730640203
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.73 ± 0.99
  Final Train: 99.72 ± 0.48
   Final Test: 68.67 ± 1.31
[I 2023-06-12 00:07:53,847] Trial 853 finished with value: 72.73332977294922 and parameters: {'Fwd': 1.378187401741977e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.685603533131744, 'loop': 2, 'loss': 'CE', 'lr': 0.008989425340345414, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.8305117148556525e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0034541969053512754
weight_decay:  4.643657452355498e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6728297828231007
None Run 01:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 47.50
Split: 01, Run: 02
None time:  1.3043079490307719
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 67.40
Split: 01, Run: 03
None time:  0.7391673510428518
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.30
run time now: 2.753268003463745
total time:  2.7954188680741936
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.87 ± 12.36
  Final Train: 99.72 ± 0.48
   Final Test: 60.73 ± 11.46
[I 2023-06-12 00:07:57,148] Trial 854 finished with value: 62.866668701171875 and parameters: {'Fwd': 3.8187637401696405e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 8.111749659247858, 'loop': 2, 'loss': 'CE', 'lr': 0.0034541969053512754, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.643657452355498e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009989135891205016
weight_decay:  1.1526798646619042e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.438388377893716
None Run 01:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 98.33
   Final Test: 71.90
Split: 01, Run: 02
None time:  0.8115571879316121
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 03
None time:  0.7694333039689809
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.10
run time now: 3.0551559925079346
total time:  3.106741561088711
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.87 ± 0.42
  Final Train: 99.44 ± 0.96
   Final Test: 72.03 ± 0.12
[I 2023-06-12 00:08:00,788] Trial 855 finished with value: 74.86666107177734 and parameters: {'Fwd': 6.356993653555718e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 8.007051660373849, 'loop': 2, 'loss': 'CE', 'lr': 0.009989135891205016, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1526798646619042e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0029859513477335678
weight_decay:  1.126945022103883e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5632, Train: 93.33%, Valid: 68.20% Test: 67.30%
Split: 01, Run: 01
None time:  1.8810790141578764
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 94.17
   Final Test: 67.10
Split: 01, Run: 02
None time:  0.9012625229079276
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.8725270491559058
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 63.60
run time now: 3.691488742828369
total time:  3.737605089088902
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 1.10
  Final Train: 98.06 ± 3.37
   Final Test: 66.43 ± 2.57
[I 2023-06-12 00:08:05,059] Trial 856 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.002183704927473616, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 7.930262371296635, 'loop': 2, 'loss': 'CE', 'lr': 0.0029859513477335678, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.126945022103883e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009972950857232342
weight_decay:  2.3440107170568217e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1891523760277778
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 68.20
Split: 01, Run: 02
None time:  0.79257628810592
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  0.7415287340991199
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.755361795425415
total time:  2.80166466999799
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 1.81
  Final Train: 99.72 ± 0.48
   Final Test: 68.47 ± 1.03
[I 2023-06-12 00:08:08,407] Trial 857 finished with value: 71.86666107177734 and parameters: {'Fwd': 7.414024389244678e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 7.376186502256058, 'loop': 2, 'loss': 'CE', 'lr': 0.009972950857232342, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.3440107170568217e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00016516339451405263
weight_decay:  1.127187904223015e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5595065250527114
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 65.70
Split: 01, Run: 02
None time:  1.0241857678629458
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.8064524529036134
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.80
run time now: 3.4319565296173096
total time:  3.4877662260551006
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 1.63
  Final Train: 100.00 ± 0.00
   Final Test: 67.97 ± 1.99
[I 2023-06-12 00:08:12,411] Trial 858 finished with value: 70.86666870117188 and parameters: {'Fwd': 6.197032538719495e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.50145159922092, 'loop': 2, 'loss': 'CE', 'lr': 0.00016516339451405263, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.127187904223015e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009963637901386498
weight_decay:  1.7645296972699043e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2241571540944278
None Run 01:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 98.33
   Final Test: 72.40
Split: 01, Run: 02
None time:  0.7590913521125913
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.6928924720268697
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.40
run time now: 2.7079341411590576
total time:  2.7569739168975502
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.53 ± 0.12
  Final Train: 99.44 ± 0.96
   Final Test: 71.13 ± 1.42
[I 2023-06-12 00:08:15,750] Trial 859 finished with value: 74.53333282470703 and parameters: {'Fwd': 8.154485536006044e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.912833544034574, 'loop': 2, 'loss': 'CE', 'lr': 0.009963637901386498, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7645296972699043e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009949287584163972
weight_decay:  1.0811457726775562e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.356064529856667
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.7494698797818273
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.807636131066829
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.90
run time now: 2.9453582763671875
total time:  2.99715632898733
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.13 ± 0.64
  Final Train: 99.72 ± 0.48
   Final Test: 70.93 ± 1.19
[I 2023-06-12 00:08:19,295] Trial 860 finished with value: 74.13333129882812 and parameters: {'Fwd': 5.914520777698466e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 8.143112587001712, 'loop': 2, 'loss': 'CE', 'lr': 0.009949287584163972, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0811457726775562e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009212780687704498
weight_decay:  1.8599778094249078e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8663706891238689
None Run 01:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 47.40
Split: 01, Run: 02
None time:  0.8521618200466037
None Run 02:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 56.20
Split: 01, Run: 03
None time:  0.8090343039948493
None Run 03:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 59.50
run time now: 2.573779344558716
total time:  2.6456335389520973
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.93 ± 6.35
  Final Train: 100.00 ± 0.00
   Final Test: 54.37 ± 6.25
[I 2023-06-12 00:08:22,488] Trial 861 finished with value: 54.93333435058594 and parameters: {'Fwd': 6.937898280799908e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 8.338918279126355, 'loop': 2, 'loss': 'MSE', 'lr': 0.009212780687704498, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.8599778094249078e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009893392993574796
weight_decay:  1.4758239790813998e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1737951799295843
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 95.83
   Final Test: 67.80
Split: 01, Run: 02
None time:  0.7554052469786257
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 03
None time:  0.7455241829156876
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 66.40
run time now: 2.7090556621551514
total time:  2.76861836691387
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 1.25
  Final Train: 98.61 ± 2.41
   Final Test: 66.87 ± 0.81
[I 2023-06-12 00:08:25,760] Trial 862 finished with value: 71.19999694824219 and parameters: {'Fwd': 5.181361210089854e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 7.938224793861818, 'loop': 2, 'loss': 'CE', 'lr': 0.009893392993574796, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4758239790813998e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008538459030697014
weight_decay:  1.038262369673344e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4473402651492506
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 97.50
   Final Test: 67.00
Split: 01, Run: 02
None time:  0.739986791042611
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 65.90
Split: 01, Run: 03
None time:  0.7077067329082638
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 65.50
run time now: 2.9269258975982666
total time:  2.98304193187505
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 0.72
  Final Train: 99.17 ± 1.44
   Final Test: 66.13 ± 0.78
[I 2023-06-12 00:08:29,291] Trial 863 finished with value: 69.79999542236328 and parameters: {'Fwd': 0.0016892473897333637, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 8.520978061319354, 'loop': 2, 'loss': 'CE', 'lr': 0.008538459030697014, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.038262369673344e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0001582305633803186
weight_decay:  1.7400666463635582e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.9027, Train: 99.17%, Valid: 64.20% Test: 64.20%
Split: 01, Run: 01
None time:  1.886340961093083
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 99.17
   Final Test: 64.30
Split: 01, Run: 02
None time:  0.7630120548419654
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  0.6601842059753835
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 66.10
run time now: 3.3416662216186523
total time:  3.401869833935052
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 3.37
  Final Train: 99.72 ± 0.48
   Final Test: 65.77 ± 1.33
[I 2023-06-12 00:08:33,250] Trial 864 finished with value: 68.46666717529297 and parameters: {'Fwd': 0.009810160860626681, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 6.174745279305475, 'loop': 2, 'loss': 'CE', 'lr': 0.0001582305633803186, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7400666463635582e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009992748625715126
weight_decay:  1.3722712936979595e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4654474039562047
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 94.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  1.2213166810106486
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.8314374808687717
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 92.50
   Final Test: 70.10
run time now: 4.550569295883179
total time:  4.596141719957814
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.95
  Final Train: 95.56 ± 3.94
   Final Test: 69.97 ± 0.61
[I 2023-06-12 00:08:38,426] Trial 865 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.0010019344558467379, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 0.3833371614606853, 'loop': 2, 'loss': 'CE', 'lr': 0.009992748625715126, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.3722712936979595e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008589068229435308
weight_decay:  1.6025771085996558e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2553982569370419
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 67.60
Split: 01, Run: 02
None time:  0.6696854261681437
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  0.8153193239122629
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.60
run time now: 2.772179126739502
total time:  2.824724816950038
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 1.40
  Final Train: 99.72 ± 0.48
   Final Test: 67.77 ± 0.76
[I 2023-06-12 00:08:41,795] Trial 866 finished with value: 72.19998931884766 and parameters: {'Fwd': 4.0229078246189935e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.006435368293585, 'loop': 2, 'loss': 'CE', 'lr': 0.008589068229435308, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6025771085996558e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009219161456182694
weight_decay:  1.3250467389638864e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1944938760716468
None Run 01:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 99.17
   Final Test: 72.60
Split: 01, Run: 02
None time:  0.7756202130112797
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 67.40
Split: 01, Run: 03
None time:  0.711840498028323
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.30
run time now: 2.7123782634735107
total time:  2.7664726960938424
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.47 ± 0.64
  Final Train: 99.72 ± 0.48
   Final Test: 70.43 ± 2.71
[I 2023-06-12 00:08:45,075] Trial 867 finished with value: 74.46666717529297 and parameters: {'Fwd': 4.4130321864348544e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.883480451077916, 'loop': 2, 'loss': 'CE', 'lr': 0.009219161456182694, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3250467389638864e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009972586491311284
weight_decay:  1.421406157493106e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2640351289883256
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 68.30
Split: 01, Run: 02
None time:  0.7424762689042836
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.8772763251326978
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.70
run time now: 2.9222724437713623
total time:  2.983938905177638
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.60
  Final Train: 98.33 ± 2.89
   Final Test: 68.50 ± 0.20
[I 2023-06-12 00:08:48,681] Trial 868 finished with value: 71.20000457763672 and parameters: {'Fwd': 4.778608541597604e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 7.9532899023015124, 'loop': 2, 'loss': 'CE', 'lr': 0.009972586491311284, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.421406157493106e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.05
lr:  0.009993823890145132
weight_decay:  1.2331048574820236e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9432362602092326
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 95.83
   Final Test: 70.70
Split: 01, Run: 02
None time:  0.8574485431890935
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.851360074011609
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 69.10
run time now: 2.69143009185791
total time:  2.746159888105467
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.31
  Final Train: 98.33 ± 2.20
   Final Test: 69.80 ± 0.82
[I 2023-06-12 00:08:51,969] Trial 869 finished with value: 72.13333129882812 and parameters: {'Fwd': 3.227687661735126e-06, 'K': 7, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 7.806258660055397, 'loop': 2, 'loss': 'CE', 'lr': 0.009993823890145132, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2331048574820236e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009027793644809733
weight_decay:  1.0166578269242648e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2012431151233613
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 98.33
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.6963834869675338
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 66.50
Split: 01, Run: 03
None time:  0.6790669248439372
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 2.6093099117279053
total time:  2.6616706799250096
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 0.83
  Final Train: 99.44 ± 0.96
   Final Test: 68.73 ± 1.93
[I 2023-06-12 00:08:55,200] Trial 870 finished with value: 73.66666412353516 and parameters: {'Fwd': 4.746309307429345e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 5.6155118390665475, 'loop': 2, 'loss': 'CE', 'lr': 0.009027793644809733, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0166578269242648e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008550301032711576
weight_decay:  1.880924950282014e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7425433569587767
None Run 01:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 51.20
Split: 01, Run: 02
None time:  0.6652270818594843
None Run 02:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 46.90
Split: 01, Run: 03
None time:  0.7698664488270879
None Run 03:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 43.60
run time now: 2.209503412246704
total time:  2.262718786019832
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 48.93 ± 6.42
  Final Train: 100.00 ± 0.00
   Final Test: 47.23 ± 3.81
[I 2023-06-12 00:08:58,019] Trial 871 finished with value: 48.93333435058594 and parameters: {'Fwd': 8.792432579865852e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 8.16146211369364, 'loop': 2, 'loss': 'CE', 'lr': 0.008550301032711576, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.880924950282014e-06, 'weightedloss': False}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.001687534967696878
weight_decay:  2.1286513929790997e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8141749578062445
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.40
Split: 01, Run: 02
None time:  1.3137586140073836
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 97.50
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.7508728159591556
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 63.30
run time now: 2.9179883003234863
total time:  2.972130059963092
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 3.17
  Final Train: 99.17 ± 1.44
   Final Test: 66.40 ± 3.70
[I 2023-06-12 00:09:01,608] Trial 872 finished with value: 70.0 and parameters: {'Fwd': 3.980173869455174e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 5.876647522601536, 'loop': 2, 'loss': 'CE', 'lr': 0.001687534967696878, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.1286513929790997e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00035425200523581525
weight_decay:  1.7233923864899397e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.596602473873645
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.8579575119074434
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 03
None time:  1.0397606519982219
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 71.80
run time now: 3.525239944458008
total time:  3.5825387958902866
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.61
  Final Train: 99.44 ± 0.48
   Final Test: 71.00 ± 1.39
[I 2023-06-12 00:09:05,762] Trial 873 finished with value: 71.73333740234375 and parameters: {'Fwd': 5.74128360986051e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 6.746075249782412, 'loop': 2, 'loss': 'CE', 'lr': 0.00035425200523581525, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7233923864899397e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.009116897771281966
weight_decay:  1.4302277898044954e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9031993539538234
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 99.17
   Final Test: 67.50
Split: 01, Run: 02
None time:  0.8454239999409765
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  0.7383851280901581
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 99.17
   Final Test: 70.40
run time now: 2.5310168266296387
total time:  2.586158197140321
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.27 ± 0.83
  Final Train: 99.44 ± 0.48
   Final Test: 69.60 ± 1.84
[I 2023-06-12 00:09:09,014] Trial 874 finished with value: 68.26666259765625 and parameters: {'Fwd': 7.468771260545457e-06, 'K': 9, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.573946763369086, 'loop': 2, 'loss': 'CE', 'lr': 0.009116897771281966, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4302277898044954e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008228680088127528
weight_decay:  1.0550364846600253e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2366469569969922
None Run 01:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 96.67
   Final Test: 71.80
Split: 01, Run: 02
None time:  0.7485535920131952
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 65.40
Split: 01, Run: 03
None time:  0.7324968981556594
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 64.80
run time now: 2.7612338066101074
total time:  2.805930939037353
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.27 ± 0.42
  Final Train: 98.89 ± 1.92
   Final Test: 67.33 ± 3.88
[I 2023-06-12 00:09:12,373] Trial 875 finished with value: 74.26666259765625 and parameters: {'Fwd': 4.206869133099737e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 6.256060288368299, 'loop': 2, 'loss': 'CE', 'lr': 0.008228680088127528, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0550364846600253e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.55
lr:  0.0027515028136315266
weight_decay:  1.4890347831607104e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3942210029345006
None Run 01:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 02
None time:  1.336842762073502
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 71.70
Split: 01, Run: 03
None time:  0.8953686230815947
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 73.10
run time now: 3.6595683097839355
total time:  3.7050149000715464
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 1.81
  Final Train: 99.72 ± 0.48
   Final Test: 72.00 ± 0.98
[I 2023-06-12 00:09:16,628] Trial 876 finished with value: 72.53333282470703 and parameters: {'Fwd': 0.04366848300482141, 'K': 1, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 8.280213241349012, 'loop': 2, 'loss': 'CE', 'lr': 0.0027515028136315266, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4890347831607104e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00916546035702036
weight_decay:  2.1808046227290544e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9990072390064597
None Run 01:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 02
None time:  0.679649222875014
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 03
None time:  0.9611384829040617
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.6701180934906006
total time:  2.724030710058287
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.87 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 71.40 ± 0.61
[I 2023-06-12 00:09:19,906] Trial 877 finished with value: 74.86666870117188 and parameters: {'Fwd': 0.019742619072458726, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 6.406651805802848, 'loop': 2, 'loss': 'CE', 'lr': 0.00916546035702036, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.1808046227290544e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009962408980560104
weight_decay:  2.240994054009988e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7611318170093
None Run 01:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 41.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.1028, Train: 91.67%, Valid: 67.40% Test: 71.90%
Split: 01, Run: 02
None time:  1.8758384219836444
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 91.67
   Final Test: 71.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0577, Train: 89.17%, Valid: 68.60% Test: 71.20%
Split: 01, Run: 03
None time:  1.956208738964051
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 90.00
   Final Test: 71.10
run time now: 4.6258604526519775
total time:  4.671684021130204
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.67 ± 16.35
  Final Train: 93.89 ± 5.36
   Final Test: 61.40 ± 17.50
[I 2023-06-12 00:09:25,214] Trial 878 finished with value: 58.66666793823242 and parameters: {'Fwd': 0.0372040717526002, 'K': 1, 'alpha': 0.0, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 6.724706037473859, 'loop': 2, 'loss': 'CE', 'lr': 0.009962408980560104, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.240994054009988e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008194679140626673
weight_decay:  3.357107232407261e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.811137885088101
None Run 01:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 54.00
Split: 01, Run: 02
None time:  0.7566665839403868
None Run 02:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.30
Split: 01, Run: 03
None time:  0.9401043378748
None Run 03:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 62.10
run time now: 2.541624069213867
total time:  2.5948347279336303
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.80 ± 4.85
  Final Train: 100.00 ± 0.00
   Final Test: 59.47 ± 4.74
[I 2023-06-12 00:09:28,325] Trial 879 finished with value: 59.79999923706055 and parameters: {'Fwd': 0.01574218026306239, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 6.489138106604195, 'loop': 2, 'loss': 'MSE', 'lr': 0.008194679140626673, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.357107232407261e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0002919665007466045
weight_decay:  2.086366042473458e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3873978690244257
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.8148287739604712
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.7403812380507588
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.40
run time now: 3.97521710395813
total time:  4.017448446946219
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.37 ± 1.80
[I 2023-06-12 00:09:32,876] Trial 880 finished with value: 72.33333587646484 and parameters: {'Fwd': 0.06767303449788357, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 6.981136445001227, 'loop': 2, 'loss': 'CE', 'lr': 0.0002919665007466045, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.086366042473458e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.0
lr:  0.0005651348777160813
weight_decay:  2.621243028224152e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9115103029180318
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.40
Split: 01, Run: 02
None time:  0.7376704041380435
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.1724098899867386
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 71.10
run time now: 2.8608314990997314
total time:  2.9067456889897585
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 3.08
  Final Train: 99.72 ± 0.48
   Final Test: 68.33 ± 2.85
[I 2023-06-12 00:09:36,273] Trial 881 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.02304237591787494, 'K': 6, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 6.441516349346114, 'loop': 2, 'loss': 'CE', 'lr': 0.0005651348777160813, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.621243028224152e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008847062501662171
weight_decay:  1.7507960738970817e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7687668611761183
None Run 01:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 61.50
Split: 01, Run: 02
None time:  0.6976792900823057
None Run 02:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 51.60
Split: 01, Run: 03
None time:  0.7402503890916705
None Run 03:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 44.90
run time now: 2.2419583797454834
total time:  2.295293637085706
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.67 ± 3.69
  Final Train: 100.00 ± 0.00
   Final Test: 52.67 ± 8.35
[I 2023-06-12 00:09:39,112] Trial 882 finished with value: 56.66666793823242 and parameters: {'Fwd': 0.013207780218764202, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 7.160150236882855, 'loop': 2, 'loss': 'CE', 'lr': 0.008847062501662171, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.7507960738970817e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009249948133318359
weight_decay:  3.1398963349446605e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7558635920286179
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 02
None time:  0.6549841300584376
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 03
None time:  0.6274748309515417
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 67.00
run time now: 2.069671154022217
total time:  2.130338734947145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 1.64
  Final Train: 99.72 ± 0.48
   Final Test: 66.70 ± 0.98
[I 2023-06-12 00:09:41,878] Trial 883 finished with value: 68.80000305175781 and parameters: {'Fwd': 0.029398561809486412, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.257635454097048, 'loop': 0, 'loss': 'CE', 'lr': 0.009249948133318359, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.1398963349446605e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007731091086421081
weight_decay:  1.3338996972795678e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1312943438533694
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 99.17
   Final Test: 64.60
Split: 01, Run: 02
None time:  0.6464210120029747
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.40
Split: 01, Run: 03
None time:  0.81919283606112
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.80
run time now: 2.6266965866088867
total time:  2.668889137916267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.87 ± 1.47
  Final Train: 99.72 ± 0.48
   Final Test: 66.60 ± 1.74
[I 2023-06-12 00:09:45,332] Trial 884 finished with value: 68.86666870117188 and parameters: {'Fwd': 0.0009417640691672375, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 6.0002714143503475, 'loop': 2, 'loss': 'CE', 'lr': 0.007731091086421081, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3338996972795678e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00847131767094578
weight_decay:  2.232023845282079e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.107352243969217
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  2.0440355960745364
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.2037804429419339
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.70
run time now: 4.395888090133667
total time:  4.45791776990518
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 2.01
  Final Train: 99.72 ± 0.48
   Final Test: 69.30 ± 0.79
[I 2023-06-12 00:09:50,353] Trial 885 finished with value: 69.73333740234375 and parameters: {'Fwd': 0.032425359113401706, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 5.679701574564023, 'loop': 2, 'loss': 'CE', 'lr': 0.00847131767094578, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.232023845282079e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009206221869333155
weight_decay:  1.263620608807981e-06
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5995459500700235
None Run 01:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 42.70
Split: 01, Run: 02
None time:  1.4198752560187131
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 93.33
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.6746190648991615
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 63.90
run time now: 2.7272961139678955
total time:  2.7709697280079126
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.33 ± 15.02
  Final Train: 97.78 ± 3.85
   Final Test: 59.00 ± 14.49
[I 2023-06-12 00:09:53,672] Trial 886 finished with value: 62.33333206176758 and parameters: {'Fwd': 0.02435720264362769, 'K': 1, 'alpha': 0.0, 'dropout': 0.1, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 6.518814827722776, 'loop': 2, 'loss': 'CE', 'lr': 0.009206221869333155, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.263620608807981e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0035793802084138097
weight_decay:  2.2591530694500847e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4195670909248292
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.7181589580141008
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 59.80
Split: 01, Run: 03
None time:  0.9954516459256411
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.40
run time now: 3.168755292892456
total time:  3.225176519015804
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 1.22
  Final Train: 98.89 ± 1.92
   Final Test: 65.97 ± 5.38
[I 2023-06-12 00:09:57,446] Trial 887 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.0013342393641473933, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 6.8679473014779795, 'loop': 2, 'loss': 'CE', 'lr': 0.0035793802084138097, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2591530694500847e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.000533560263327069
weight_decay:  1.2749637845777461e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.821118175983429
None Run 01:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.6403, Train: 100.00%, Valid: 72.00% Test: 71.20%
Split: 01, Run: 02
None time:  1.2740310679655522
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.7497580640483648
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 2.8779478073120117
total time:  2.9227676370646805
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.27 ± 4.59
  Final Train: 100.00 ± 0.00
   Final Test: 67.87 ± 5.10
[I 2023-06-12 00:10:00,882] Trial 888 finished with value: 69.26666259765625 and parameters: {'Fwd': 0.04429567290031612, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 4.951621498192584, 'loop': 1, 'loss': 'CE', 'lr': 0.000533560263327069, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2749637845777461e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0018226135361602478
weight_decay:  2.849036418500284e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5161, Train: 99.17%, Valid: 70.00% Test: 69.10%
Split: 01, Run: 01
None time:  1.900288495933637
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.06826888397336
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 72.40
Split: 01, Run: 03
None time:  0.8999623539857566
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.9001615047454834
total time:  3.9476665498223156
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 1.40
  Final Train: 99.44 ± 0.48
   Final Test: 70.43 ± 1.74
[I 2023-06-12 00:10:05,321] Trial 889 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.05446230821697202, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 7.372537909037219, 'loop': 2, 'loss': 'CE', 'lr': 0.0018226135361602478, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.849036418500284e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0001866280442743616
weight_decay:  2.4129315002614873e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0783180899452418
None Run 01:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 53.80
Split: 01, Run: 02
None time:  0.7457980311010033
None Run 02:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 55.70
Split: 01, Run: 03
None time:  0.7023241589777172
None Run 03:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 56.60
run time now: 2.5579404830932617
total time:  2.6000885479152203
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.00 ± 2.46
  Final Train: 100.00 ± 0.00
   Final Test: 55.37 ± 1.43
[I 2023-06-12 00:10:08,469] Trial 890 finished with value: 59.0 and parameters: {'Fwd': 4.5069195015492306e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.075926132086797, 'loop': 2, 'loss': 'CE', 'lr': 0.0001866280442743616, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.4129315002614873e-06, 'weightedloss': False}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.002614185668740223
weight_decay:  2.7212364650632144e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8371344117913395
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.5517013520002365
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 89.17
   Final Test: 71.80
Split: 01, Run: 03
None time:  0.768783493898809
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.30
run time now: 3.1950631141662598
total time:  3.2480490379966795
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 0.50
  Final Train: 96.39 ± 6.25
   Final Test: 69.83 ± 1.79
[I 2023-06-12 00:10:12,232] Trial 891 finished with value: 72.26666259765625 and parameters: {'Fwd': 0.022396176457091202, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 0.9841890367347155, 'loop': 2, 'loss': 'CE', 'lr': 0.002614185668740223, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.7212364650632144e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007973295031722305
weight_decay:  1.7330052902506816e-06
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7448749579489231
None Run 01:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 58.00
Split: 01, Run: 02
None time:  1.2507783300243318
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 88.33
   Final Test: 62.80
Split: 01, Run: 03
None time:  0.881225721212104
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.70
run time now: 2.920206308364868
total time:  2.9753669779747725
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.47 ± 7.68
  Final Train: 96.11 ± 6.74
   Final Test: 63.17 ± 5.36
[I 2023-06-12 00:10:15,784] Trial 892 finished with value: 63.4666633605957 and parameters: {'Fwd': 0.0006776750167214594, 'K': 1, 'alpha': 0.05, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 5.528159329693905, 'loop': 2, 'loss': 'CE', 'lr': 0.007973295031722305, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7330052902506816e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009153179915647059
weight_decay:  4.157051000324999e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0589701728895307
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.7262559549417347
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.7113325109239668
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 2.528167486190796
total time:  2.5802576311398298
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.47 ± 0.83
  Final Train: 99.72 ± 0.48
   Final Test: 70.40 ± 0.60
[I 2023-06-12 00:10:18,990] Trial 893 finished with value: 74.46666717529297 and parameters: {'Fwd': 0.011499028203226111, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 6.336555545169037, 'loop': 2, 'loss': 'CE', 'lr': 0.009153179915647059, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.157051000324999e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008291739060944185
weight_decay:  1.5664567327615427e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1506512358319014
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.7736758659593761
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 03
None time:  0.826996702933684
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.00
run time now: 2.7841649055480957
total time:  2.832616143859923
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 1.36
  Final Train: 99.72 ± 0.48
   Final Test: 68.27 ± 1.45
[I 2023-06-12 00:10:22,375] Trial 894 finished with value: 71.33333587646484 and parameters: {'Fwd': 8.412299572687122e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 6.271333271109497, 'loop': 2, 'loss': 'CE', 'lr': 0.008291739060944185, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.5664567327615427e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0032489758709969736
weight_decay:  1.4163545972081984e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.33052563900128007
None Run 01:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 34.80
Split: 01, Run: 02
None time:  0.805673501919955
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.80
Split: 01, Run: 03
None time:  0.534822970861569
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.70
run time now: 1.7052514553070068
total time:  1.7502005668357015
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.13 ± 21.07
  Final Train: 100.00 ± 0.00
   Final Test: 60.10 ± 21.91
[I 2023-06-12 00:10:24,661] Trial 895 finished with value: 62.133331298828125 and parameters: {'Fwd': 0.008154891018234172, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 10, 'lambda1': 0.35000000000000003, 'lambda2': 9.60951938671815, 'loop': 2, 'loss': 'CE', 'lr': 0.0032489758709969736, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4163545972081984e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00014411091822337624
weight_decay:  1.079399147880569e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4635926000773907
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.00
Split: 01, Run: 02
None time:  0.7985006459057331
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.988432670943439
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.40
run time now: 3.282611608505249
total time:  3.329321570927277
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 67.57 ± 1.36
[I 2023-06-12 00:10:28,582] Trial 896 finished with value: 70.13333892822266 and parameters: {'Fwd': 0.017374091511446695, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 6.01519813489042, 'loop': 2, 'loss': 'CE', 'lr': 0.00014411091822337624, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.079399147880569e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0016446328479986698
weight_decay:  1.9728008882001346e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5453231201972812
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 96.67
   Final Test: 67.40
Split: 01, Run: 02
None time:  0.5881261569447815
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.5196134259458631
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 54.70
run time now: 2.686035394668579
total time:  2.733049366855994
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.07 ± 0.95
  Final Train: 98.89 ± 1.92
   Final Test: 63.57 ± 7.70
[I 2023-06-12 00:10:31,836] Trial 897 finished with value: 68.0666732788086 and parameters: {'Fwd': 0.0011192826595227499, 'K': 1, 'alpha': 0.0, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 6.645036272425211, 'loop': 2, 'loss': 'CE', 'lr': 0.0016446328479986698, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.9728008882001346e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.05
lr:  0.009221361347671923
weight_decay:  4.7600617235381985e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.73343734908849
None Run 01:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 48.00
Split: 01, Run: 02
None time:  0.7072698879055679
None Run 02:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 03
None time:  0.773528034100309
None Run 03:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 62.40
run time now: 2.2570114135742188
total time:  2.3048217750620097
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.53 ± 6.71
  Final Train: 100.00 ± 0.00
   Final Test: 55.80 ± 7.27
[I 2023-06-12 00:10:34,688] Trial 898 finished with value: 53.533329010009766 and parameters: {'Fwd': 0.0771350938012758, 'K': 5, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 2.017385297698058, 'loop': 2, 'loss': 'MSE', 'lr': 0.009221361347671923, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.7600617235381985e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0003541607158234711
weight_decay:  2.9167057766914404e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.122701914049685
None Run 01:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 50.10
Split: 01, Run: 02
None time:  1.2023706419859082
None Run 02:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 50.10
Split: 01, Run: 03
None time:  1.045580707024783
None Run 03:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 50.10
run time now: 3.4020161628723145
total time:  3.454036330105737
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 50.10 ± 0.00
[I 2023-06-12 00:10:38,701] Trial 899 finished with value: 50.59999465942383 and parameters: {'Fwd': 0.018464794087652798, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.0, 'lambda2': 7.4982888182570555, 'loop': 2, 'loss': 'CE', 'lr': 0.0003541607158234711, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.9167057766914404e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0009519921590818696
weight_decay:  1.4393029205114297e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.31622120388783514
None Run 01:
Highest Train: 100.00
Highest Valid: 39.20
  Final Train: 100.00
   Final Test: 34.90
Split: 01, Run: 02
None time:  0.21206522709690034
None Run 02:
Highest Train: 100.00
Highest Valid: 35.40
  Final Train: 100.00
   Final Test: 30.40
Split: 01, Run: 03
None time:  0.19377194391563535
None Run 03:
Highest Train: 100.00
Highest Valid: 37.60
  Final Train: 100.00
   Final Test: 32.60
run time now: 0.7526319026947021
total time:  0.7939010460395366
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 37.40 ± 1.91
  Final Train: 100.00 ± 0.00
   Final Test: 32.63 ± 2.25
[I 2023-06-12 00:10:40,102] Trial 900 finished with value: 37.400001525878906 and parameters: {'Fwd': 0.0027691094399635045, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 0, 'lambda1': 0.25, 'lambda2': 8.48794859625408, 'loop': 2, 'loss': 'CE', 'lr': 0.0009519921590818696, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.4393029205114297e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.05
lr:  0.007574491073047328
weight_decay:  0.04531837194025932
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9540566809009761
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.7597755030728877
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 03
None time:  0.7625439648982137
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.5138912200927734
total time:  2.569321332965046
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 1.33
  Final Train: 99.72 ± 0.48
   Final Test: 71.50 ± 0.89
[I 2023-06-12 00:10:43,169] Trial 901 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.05475776866347411, 'K': 7, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 6.7767597656569, 'loop': 2, 'loss': 'CE', 'lr': 0.007574491073047328, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.04531837194025932, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00012395998016185536
weight_decay:  4.061399263632759e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.9239, Train: 93.33%, Valid: 59.80% Test: 57.60%
Split: 01, Run: 01
None time:  1.950295225949958
None Run 01:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 94.17
   Final Test: 57.40
Split: 01, Run: 02
None time:  0.7739725918509066
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.20
Split: 01, Run: 03
None time:  0.9243516148999333
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 65.90
run time now: 3.681366443634033
total time:  3.7326033061835915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.53 ± 5.06
  Final Train: 98.06 ± 3.37
   Final Test: 62.50 ± 4.50
[I 2023-06-12 00:10:47,426] Trial 902 finished with value: 65.53333282470703 and parameters: {'Fwd': 0.004212633776225618, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 1.2230279985115433, 'loop': 2, 'loss': 'CE', 'lr': 0.00012395998016185536, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.061399263632759e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.05
lr:  0.0007829672986384227
weight_decay:  1.0090673378359906e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8730813709553331
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 90.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.7807887890376151
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  0.7015022418927401
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.10
run time now: 3.3953170776367188
total time:  3.4449132930021733
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 0.81
  Final Train: 96.67 ± 5.77
   Final Test: 67.83 ± 2.05
[I 2023-06-12 00:10:51,403] Trial 903 finished with value: 69.33333587646484 and parameters: {'Fwd': 0.0008143750771860215, 'K': 4, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.6000000000000001, 'lambda2': 7.028371974469237, 'loop': 2, 'loss': 'CE', 'lr': 0.0007829672986384227, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0090673378359906e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009921545942304539
weight_decay:  1.749168298571946e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.436666917987168
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.2059253971092403
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.7805928259622306
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 5.462620496749878
total time:  5.526895130053163
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 1.30
  Final Train: 99.72 ± 0.48
   Final Test: 69.73 ± 0.40
[I 2023-06-12 00:10:57,481] Trial 904 finished with value: 69.93333435058594 and parameters: {'Fwd': 6.26919620971712e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 5.1778521648528555, 'loop': 2, 'loss': 'CE', 'lr': 0.009921545942304539, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.749168298571946e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.009970777266839693
weight_decay:  2.1863121487080435e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.164991986937821
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 02
None time:  0.5522176108788699
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  0.5450023389421403
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.296152353286743
total time:  2.3424755199812353
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 71.37 ± 0.68
[I 2023-06-12 00:11:00,432] Trial 905 finished with value: 74.53333282470703 and parameters: {'Fwd': 0.0004889950270650335, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 5.305963430187432, 'loop': 2, 'loss': 'CE', 'lr': 0.009970777266839693, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.1863121487080435e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0002723044898383313
weight_decay:  2.6183895492209573e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5746855509933084
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 67.80
Split: 01, Run: 02
None time:  0.7740441330242902
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.6687392420135438
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 3.051042318344116
total time:  3.095902127213776
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 1.10
  Final Train: 99.72 ± 0.48
   Final Test: 69.67 ± 1.67
[I 2023-06-12 00:11:04,046] Trial 906 finished with value: 72.0666732788086 and parameters: {'Fwd': 0.0006353447556474944, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 4.876906127737425, 'loop': 2, 'loss': 'CE', 'lr': 0.0002723044898383313, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.6183895492209573e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0008891411801777577
weight_decay:  1.6497765897062526e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9669899868313223
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 02
None time:  0.8337051579728723
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.130607372149825
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.30
run time now: 2.962372303009033
total time:  3.018336071865633
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.81
  Final Train: 99.72 ± 0.48
   Final Test: 68.53 ± 1.57
[I 2023-06-12 00:11:07,560] Trial 907 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.0005836459975472624, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 5.7576350204267825, 'loop': 2, 'loss': 'CE', 'lr': 0.0008891411801777577, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6497765897062526e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0092124005173611
weight_decay:  5.969338162525182e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5149087910540402
None Run 01:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 57.20
Split: 01, Run: 02
None time:  1.1043275010306388
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 93.33
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.45577290118671954
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.108635663986206
total time:  2.1534472501371056
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.53 ± 8.09
  Final Train: 97.78 ± 3.85
   Final Test: 66.07 ± 7.68
[I 2023-06-12 00:11:10,278] Trial 908 finished with value: 65.53333282470703 and parameters: {'Fwd': 0.00045546033492149503, 'K': 1, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.25, 'lambda2': 5.604043028902398, 'loop': 2, 'loss': 'CE', 'lr': 0.0092124005173611, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.969338162525182e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00379860459892915
weight_decay:  3.13137884408958e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.40919685107655823
None Run 01:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 49.20
Split: 01, Run: 02
None time:  1.1420292190741748
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.5666196278762072
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.00
run time now: 2.148695707321167
total time:  2.2027326959650964
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.27 ± 11.49
  Final Train: 99.72 ± 0.48
   Final Test: 64.07 ± 12.88
[I 2023-06-12 00:11:13,098] Trial 909 finished with value: 65.26666259765625 and parameters: {'Fwd': 0.0005308208460175636, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.25, 'lambda2': 5.2303022492297275, 'loop': 2, 'loss': 'CE', 'lr': 0.00379860459892915, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.13137884408958e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.009975006912715753
weight_decay:  3.3695456307316495e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4426548678893596
None Run 01:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 51.40
Split: 01, Run: 02
None time:  0.4437688710168004
None Run 02:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 41.20
Split: 01, Run: 03
None time:  0.5249550850130618
None Run 03:
Highest Train: 100.00
Highest Valid: 40.40
  Final Train: 100.00
   Final Test: 42.20
run time now: 1.444532871246338
total time:  1.5064954571425915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 43.00 ± 6.13
  Final Train: 100.00 ± 0.00
   Final Test: 44.93 ± 5.62
[I 2023-06-12 00:11:15,247] Trial 910 finished with value: 43.0 and parameters: {'Fwd': 0.0007489171936125702, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 5.200297862679343, 'loop': 2, 'loss': 'CE', 'lr': 0.009975006912715753, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.3695456307316495e-06, 'weightedloss': False}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0003677565098029541
weight_decay:  2.4110145325709176e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.461251333821565
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 02
None time:  0.5387233509682119
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  0.6325398131739348
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.50
run time now: 2.6656460762023926
total time:  2.720711105968803
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.33 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 71.37 ± 0.23
[I 2023-06-12 00:11:18,525] Trial 911 finished with value: 73.33333587646484 and parameters: {'Fwd': 0.00032590132089321626, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 8.710217275818216, 'loop': 2, 'loss': 'CE', 'lr': 0.0003677565098029541, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.4110145325709176e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.009212911605768948
weight_decay:  1.976520014368522e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.259139047935605
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 02
None time:  0.4917245120741427
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.4872288650367409
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 67.40
run time now: 2.268801689147949
total time:  2.3113297398667783
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.87 ± 0.23
  Final Train: 99.72 ± 0.48
   Final Test: 69.00 ± 2.12
[I 2023-06-12 00:11:21,424] Trial 912 finished with value: 73.86666870117188 and parameters: {'Fwd': 0.006061715881984593, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 4.898472572002742, 'loop': 2, 'loss': 'CE', 'lr': 0.009212911605768948, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.976520014368522e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00992655326323403
weight_decay:  5.59846870914558e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.41996573098003864
None Run 01:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 45.70
Split: 01, Run: 02
None time:  0.6593817051034421
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  0.40530679398216307
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 73.00
run time now: 1.5416104793548584
total time:  1.6013918949756771
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.40 ± 16.96
  Final Train: 100.00 ± 0.00
   Final Test: 63.27 ± 15.24
[I 2023-06-12 00:11:23,576] Trial 913 finished with value: 64.4000015258789 and parameters: {'Fwd': 0.0004026478678258109, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 40, 'lambda1': 0.30000000000000004, 'lambda2': 4.654740893815082, 'loop': 2, 'loss': 'CE', 'lr': 0.00992655326323403, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.59846870914558e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.8
lr:  0.008546732266495789
weight_decay:  1.7655627706852462e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8126370108220726
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.7660847811494023
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 71.10
Split: 01, Run: 03
None time:  0.6205871440470219
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.230302572250366
total time:  2.2795009119436145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.92
  Final Train: 99.72 ± 0.48
   Final Test: 70.07 ± 1.11
[I 2023-06-12 00:11:26,403] Trial 914 finished with value: 71.79999542236328 and parameters: {'Fwd': 4.8599348577739e-05, 'K': 1, 'alpha': 0.8, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 5.044395085289499, 'loop': 2, 'loss': 'CE', 'lr': 0.008546732266495789, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7655627706852462e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.45
lr:  0.0040748908256056805
weight_decay:  2.1391830432266302e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7907118978910148
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.5896965300198644
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.6202472010627389
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.0310544967651367
total time:  2.073336215922609
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 1.80
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 1.25
[I 2023-06-12 00:11:29,043] Trial 915 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.009999097661124796, 'K': 1, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 5.3151529772607695, 'loop': 2, 'loss': 'CE', 'lr': 0.0040748908256056805, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.1391830432266302e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009943522995781218
weight_decay:  1.2717583230313565e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.45313597889617085
None Run 01:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 46.50
Split: 01, Run: 02
None time:  0.6111816531047225
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.4890865811612457
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.70
run time now: 1.5876047611236572
total time:  1.64513403410092
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.20 ± 15.27
  Final Train: 100.00 ± 0.00
   Final Test: 62.63 ± 14.01
[I 2023-06-12 00:11:31,266] Trial 916 finished with value: 64.20000457763672 and parameters: {'Fwd': 0.0009364529175784377, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.4, 'lambda2': 9.024482810741887, 'loop': 2, 'loss': 'CE', 'lr': 0.009943522995781218, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2717583230313565e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008639432706308906
weight_decay:  1.030937194832596e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7213189611211419
None Run 01:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 61.50
Split: 01, Run: 02
None time:  0.5728302008938044
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.8756762580014765
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.50
run time now: 2.2182533740997314
total time:  2.270217974903062
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.67 ± 3.43
  Final Train: 100.00 ± 0.00
   Final Test: 66.00 ± 3.91
[I 2023-06-12 00:11:34,043] Trial 917 finished with value: 65.66666412353516 and parameters: {'Fwd': 3.6502290191192416e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 0.8414574549755951, 'loop': 2, 'loss': 'MSE', 'lr': 0.008639432706308906, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.030937194832596e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0023402117030192236
weight_decay:  3.2088997426009525e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9972589979879558
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 02
None time:  0.4941350962035358
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.7852725819684565
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.80
run time now: 2.308751344680786
total time:  2.3678644518367946
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 70.37 ± 1.02
[I 2023-06-12 00:11:37,001] Trial 918 finished with value: 71.4000015258789 and parameters: {'Fwd': 8.68022344107639e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 50, 'lambda1': 0.35000000000000003, 'lambda2': 9.506369733118822, 'loop': 2, 'loss': 'CE', 'lr': 0.0023402117030192236, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.2088997426009525e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0006818630679842946
weight_decay:  8.352704102265447e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7362411660142243
None Run 01:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 60.30
Split: 01, Run: 02
None time:  0.5455495158676058
None Run 02:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.90
Split: 01, Run: 03
None time:  0.5789802910294384
None Run 03:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 56.10
run time now: 1.8932199478149414
total time:  1.954994668951258
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.13 ± 2.27
  Final Train: 100.00 ± 0.00
   Final Test: 59.10 ± 2.62
[I 2023-06-12 00:11:39,569] Trial 919 finished with value: 61.133331298828125 and parameters: {'Fwd': 0.004996090542257786, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.357089104738064, 'loop': 2, 'loss': 'CE', 'lr': 0.0006818630679842946, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.352704102265447e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0004934291757489169
weight_decay:  2.096067113457746e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4654565500095487
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 99.17
   Final Test: 68.30
Split: 01, Run: 02
None time:  0.7029718260746449
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.8042066060006618
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.10
run time now: 3.011420249938965
total time:  3.062925199046731
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.56
  Final Train: 99.44 ± 0.48
   Final Test: 69.27 ± 0.91
[I 2023-06-12 00:11:43,205] Trial 920 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.000517664169868498, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 2.3955501523032856, 'loop': 2, 'loss': 'CE', 'lr': 0.0004934291757489169, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.096067113457746e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.65
lr:  0.001046398859213434
weight_decay:  4.186673387353626e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5226034810766578
None Run 01:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 57.80
Split: 01, Run: 02
None time:  0.7744861228857189
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 95.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.9263686649501324
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 90.83
   Final Test: 69.10
run time now: 2.254230260848999
total time:  2.3039602478966117
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.27 ± 5.97
  Final Train: 95.28 ± 4.59
   Final Test: 65.07 ± 6.31
[I 2023-06-12 00:11:46,088] Trial 921 finished with value: 66.26666259765625 and parameters: {'Fwd': 0.0008306100854163375, 'K': 1, 'alpha': 0.65, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 0.21316688169101106, 'loop': 2, 'loss': 'CE', 'lr': 0.001046398859213434, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.186673387353626e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.009973598363148876
weight_decay:  2.677493272177194e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9639202870894223
None Run 01:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 58.40
Split: 01, Run: 02
None time:  0.5310065560042858
None Run 02:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.50
Split: 01, Run: 03
None time:  0.5758541829418391
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.70
run time now: 2.103126287460327
total time:  2.1682652689050883
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.67 ± 5.14
  Final Train: 100.00 ± 0.00
   Final Test: 64.20 ± 5.27
[I 2023-06-12 00:11:49,017] Trial 922 finished with value: 63.66666793823242 and parameters: {'Fwd': 0.03143408435702176, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 5.469092993562404, 'loop': 2, 'loss': 'CE', 'lr': 0.009973598363148876, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.677493272177194e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.004737239285497468
weight_decay:  1.52814895279382e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8654410941526294
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.2209550640545785
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.9418879910372198
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
run time now: 3.071945905685425
total time:  3.1250896649435163
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 70.27 ± 0.75
[I 2023-06-12 00:11:52,670] Trial 923 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0012455887891088542, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.35000000000000003, 'lambda2': 9.65982523271926, 'loop': 2, 'loss': 'CE', 'lr': 0.004737239285497468, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.52814895279382e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007661305438762445
weight_decay:  5.0211633083043285e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3598672118969262
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 80.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.6046194471418858
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 91.67
   Final Test: 66.70
Split: 01, Run: 03
None time:  0.5632002130150795
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 98.33
   Final Test: 67.90
run time now: 2.560631275177002
total time:  2.6149038129951805
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.42
  Final Train: 90.00 ± 9.28
   Final Test: 67.83 ± 1.10
[I 2023-06-12 00:11:55,833] Trial 924 finished with value: 71.13333129882812 and parameters: {'Fwd': 5.976710257946932e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 0.009541504828952885, 'loop': 2, 'loss': 'CE', 'lr': 0.007661305438762445, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.0211633083043285e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0014154101461547155
weight_decay:  1.9289886388189116e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4724666408728808
None Run 01:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 57.10
Split: 01, Run: 02
None time:  1.15407723095268
None Run 02:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 85.83
   Final Test: 59.00
Split: 01, Run: 03
None time:  0.4696872918866575
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.50
run time now: 2.127490758895874
total time:  2.1823162289801985
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.27 ± 3.63
  Final Train: 95.28 ± 8.18
   Final Test: 60.87 ± 4.97
[I 2023-06-12 00:11:58,671] Trial 925 finished with value: 62.26666259765625 and parameters: {'Fwd': 6.870951735648684e-05, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 0.5980901700682919, 'loop': 1, 'loss': 'CE', 'lr': 0.0014154101461547155, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.9289886388189116e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0020881511892171497
weight_decay:  1.3755778974821534e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4786367570050061
None Run 01:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 52.40
Split: 01, Run: 02
None time:  0.9708096229005605
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.6978429390583187
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.20
run time now: 2.1844611167907715
total time:  2.22776314499788
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.13 ± 9.14
  Final Train: 99.72 ± 0.48
   Final Test: 64.70 ± 10.66
[I 2023-06-12 00:12:01,476] Trial 926 finished with value: 67.13333129882812 and parameters: {'Fwd': 0.015174409042392152, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 6.2290640014834135, 'loop': 2, 'loss': 'CE', 'lr': 0.0020881511892171497, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3755778974821534e-06, 'weightedloss': True}. Best is trial 703 with value: 75.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008925072764820742
weight_decay:  6.819732305425645e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.192438503028825
None Run 01:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 91.67
   Final Test: 72.60
Split: 01, Run: 02
None time:  0.6738879301119596
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  0.7272199110593647
None Run 03:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.40
run time now: 2.6242101192474365
total time:  2.6735171540640295
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.53 ± 0.31
  Final Train: 97.22 ± 4.81
   Final Test: 71.77 ± 2.17
[I 2023-06-12 00:12:04,684] Trial 927 finished with value: 75.53333282470703 and parameters: {'Fwd': 0.0017802851681869957, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 2.2479884665779566, 'loop': 2, 'loss': 'CE', 'lr': 0.008925072764820742, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.819732305425645e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00796376190871807
weight_decay:  4.594889453338082e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7174659450538456
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 59.20
Split: 01, Run: 02
None time:  0.6819399339146912
None Run 02:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 58.10
Split: 01, Run: 03
None time:  0.6685766540467739
None Run 03:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 56.30
run time now: 2.0990705490112305
total time:  2.158102496061474
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.53 ± 2.81
  Final Train: 100.00 ± 0.00
   Final Test: 57.87 ± 1.46
[I 2023-06-12 00:12:07,389] Trial 928 finished with value: 57.5333366394043 and parameters: {'Fwd': 0.0020297198712314352, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 1.7291517560226763, 'loop': 2, 'loss': 'CE', 'lr': 0.00796376190871807, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.594889453338082e-06, 'weightedloss': False}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007200375999461595
weight_decay:  8.294423336586471e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.237902974942699
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 94.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.6905635800212622
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 64.00
Split: 01, Run: 03
None time:  0.8326233280822635
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 71.30
run time now: 2.8072967529296875
total time:  2.8591499719768763
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 0.42
  Final Train: 97.78 ± 3.15
   Final Test: 68.37 ± 3.86
[I 2023-06-12 00:12:10,827] Trial 929 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.0018214508374360748, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 4.251857892028697, 'loop': 2, 'loss': 'CE', 'lr': 0.007200375999461595, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.294423336586471e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.00861123197530336
weight_decay:  6.552631797008996e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.097791627049446
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.90
Split: 01, Run: 02
None time:  0.6635788280982524
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.6764534190297127
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.472156524658203
total time:  2.5275317090563476
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.53 ± 1.36
  Final Train: 99.72 ± 0.48
   Final Test: 70.17 ± 1.55
[I 2023-06-12 00:12:13,909] Trial 930 finished with value: 74.53333282470703 and parameters: {'Fwd': 0.0026659398538816177, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 3.6809966268643084, 'loop': 2, 'loss': 'CE', 'lr': 0.00861123197530336, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.552631797008996e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.008702224362108407
weight_decay:  6.690479363836085e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0030215869192034
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 94.17
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.6701117740012705
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.7039180018473417
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.4086949825286865
total time:  2.454762538895011
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 1.51
  Final Train: 98.06 ± 3.37
   Final Test: 68.93 ± 0.75
[I 2023-06-12 00:12:16,890] Trial 931 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.0015976086517903657, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 2.1402165353885083, 'loop': 2, 'loss': 'CE', 'lr': 0.008702224362108407, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.690479363836085e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.009026974469967714
weight_decay:  8.094321601217314e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0002493790816516
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 96.67
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.9526022549252957
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 98.33
   Final Test: 71.70
Split: 01, Run: 03
None time:  0.7004046530928463
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 71.20
run time now: 2.686439037322998
total time:  2.732677330961451
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 1.44
  Final Train: 98.33 ± 1.67
   Final Test: 70.70 ± 1.32
[I 2023-06-12 00:12:20,217] Trial 932 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.002941156751074531, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 3.281869058969612, 'loop': 2, 'loss': 'CE', 'lr': 0.009026974469967714, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.094321601217314e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0006306822385053644
weight_decay:  5.769121268288303e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.529160805977881
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.982976377941668
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.3612828359473497
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.9194564819335938
total time:  4.000276328995824
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 0.12
  Final Train: 99.72 ± 0.48
   Final Test: 70.37 ± 0.83
[I 2023-06-12 00:12:25,120] Trial 933 finished with value: 72.53333282470703 and parameters: {'Fwd': 0.0015091667253602458, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 3.9972233770604166, 'loop': 2, 'loss': 'CE', 'lr': 0.0006306822385053644, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.769121268288303e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.003094620150671876
weight_decay:  6.071551114284078e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3315891679376364
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 95.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1755383340641856
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 03
None time:  1.2385272399988025
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.60
run time now: 4.79688835144043
total time:  4.848452572943643
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.83
  Final Train: 98.33 ± 2.89
   Final Test: 67.97 ± 2.12
[I 2023-06-12 00:12:30,618] Trial 934 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.001967852541859998, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 2.8901036559312567, 'loop': 2, 'loss': 'CE', 'lr': 0.003094620150671876, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.071551114284078e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008365238838796866
weight_decay:  7.066221584157424e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.655485003022477
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 99.17
   Final Test: 65.20
Split: 01, Run: 02
None time:  1.2526904940605164
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  1.719303873134777
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 91.67
   Final Test: 68.80
run time now: 4.667788743972778
total time:  4.7205163720063865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 2.00
  Final Train: 96.94 ± 4.59
   Final Test: 67.20 ± 1.83
[I 2023-06-12 00:12:36,100] Trial 935 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.0023805051347908636, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 2.244837316156639, 'loop': 2, 'loss': 'CE', 'lr': 0.008365238838796866, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.066221584157424e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00022409326172139328
weight_decay:  6.794009260070781e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.131875457940623
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.3925508230458945
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.1123388381674886
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.90
run time now: 5.683152675628662
total time:  5.739508084021509
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 1.30
  Final Train: 99.72 ± 0.48
   Final Test: 69.50 ± 0.87
[I 2023-06-12 00:12:42,519] Trial 936 finished with value: 72.33333587646484 and parameters: {'Fwd': 1.0342676286786456e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 4.539695358343917, 'loop': 2, 'loss': 'CE', 'lr': 0.00022409326172139328, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.794009260070781e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.009163972698734162
weight_decay:  3.686944299751178e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2712714038789272
None Run 01:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 50.00
Split: 01, Run: 02
None time:  1.9029376429971308
None Run 02:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 56.80
Split: 01, Run: 03
None time:  1.2881978538352996
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.50
run time now: 4.503398180007935
total time:  4.552192067960277
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.20 ± 6.63
  Final Train: 100.00 ± 0.00
   Final Test: 56.10 ± 5.78
[I 2023-06-12 00:12:47,642] Trial 937 finished with value: 56.20000076293945 and parameters: {'Fwd': 0.002271079778062983, 'K': 3, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 3.4266271469296385, 'loop': 2, 'loss': 'MSE', 'lr': 0.009163972698734162, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.686944299751178e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008064937608683693
weight_decay:  6.644746755728787e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.289676492800936
None Run 01:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 54.60
Split: 01, Run: 02
None time:  1.2512173240538687
None Run 02:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 49.80
Split: 01, Run: 03
None time:  1.1657613820862025
None Run 03:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 83.33
   Final Test: 43.00
run time now: 3.751612663269043
total time:  3.8005767550785094
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.13 ± 5.31
  Final Train: 94.44 ± 9.62
   Final Test: 49.13 ± 5.83
[I 2023-06-12 00:12:52,032] Trial 938 finished with value: 50.133331298828125 and parameters: {'Fwd': 0.007254944568922787, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 4.248817177175583, 'loop': 2, 'loss': 'CE', 'lr': 0.008064937608683693, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.644746755728787e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.004694620032725478
weight_decay:  5.607263609974926e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2048, Train: 82.50%, Valid: 66.00% Test: 65.80%
Split: 01, Run: 01
None time:  3.162787734065205
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 84.17
   Final Test: 65.20
Split: 01, Run: 02
None time:  1.1551707261241972
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 60.00
Split: 01, Run: 03
None time:  1.3863504801411182
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 97.50
   Final Test: 63.70
run time now: 5.745723009109497
total time:  5.7977845289278775
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.07 ± 0.23
  Final Train: 93.89 ± 8.51
   Final Test: 62.97 ± 2.68
[I 2023-06-12 00:12:58,561] Trial 939 finished with value: 66.06666564941406 and parameters: {'Fwd': 7.387588029958022e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 1.8734691735072793, 'loop': 2, 'loss': 'CE', 'lr': 0.004694620032725478, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.607263609974926e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009207068257718415
weight_decay:  3.7257854372675476e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0734884049743414
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 87.50
   Final Test: 70.80
Split: 01, Run: 02
None time:  0.9848498371429741
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.0656927151139826
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 67.80
run time now: 4.161670684814453
total time:  4.216333949007094
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 0.92
  Final Train: 95.83 ± 7.22
   Final Test: 69.03 ± 1.57
[I 2023-06-12 00:13:03,368] Trial 940 finished with value: 72.4000015258789 and parameters: {'Fwd': 0.001478418259002782, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 1.1963045270819292, 'loop': 2, 'loss': 'CE', 'lr': 0.009207068257718415, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.7257854372675476e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0004239427414640103
weight_decay:  1.0568644820987995e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.174748744117096
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.2963897101581097
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  1.424828669987619
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 4.936424732208252
total time:  4.9921586632262915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 99.72 ± 0.48
   Final Test: 70.40 ± 0.52
[I 2023-06-12 00:13:08,977] Trial 941 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.003711037071879912, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 2.9712344023406527, 'loop': 2, 'loss': 'CE', 'lr': 0.0004239427414640103, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0568644820987995e-05, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.7000000000000001
lr:  0.0073050820377197866
weight_decay:  1.0351838429838574e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8338941868860275
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  4.209209342952818
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.83
   Final Test: 70.60
Split: 01, Run: 03
None time:  2.157210233155638
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.10
run time now: 9.243353128433228
total time:  9.293798542115837
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 1.39
  Final Train: 98.33 ± 2.20
   Final Test: 69.73 ± 1.42
[I 2023-06-12 00:13:18,881] Trial 942 finished with value: 71.0 and parameters: {'Fwd': 2.453033352461059e-06, 'K': 1, 'alpha': 0.7000000000000001, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 4.38241963415982, 'loop': 2, 'loss': 'CE', 'lr': 0.0073050820377197866, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0351838429838574e-05, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00013108606301829993
weight_decay:  6.818350442005722e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.9442, Train: 99.17%, Valid: 60.20% Test: 58.00%
Split: 01, Run: 01
None time:  3.1768695700448006
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 99.17
   Final Test: 57.60
Split: 01, Run: 02
None time:  0.8989220131188631
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 65.30
Split: 01, Run: 03
None time:  1.363297393079847
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 66.10
run time now: 5.638535976409912
total time:  5.7217582010198385
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.80 ± 4.89
  Final Train: 99.72 ± 0.48
   Final Test: 63.00 ± 4.69
[I 2023-06-12 00:13:25,348] Trial 943 finished with value: 65.79999542236328 and parameters: {'Fwd': 0.0028444897528622807, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 3.780771805719755, 'loop': 2, 'loss': 'CE', 'lr': 0.00013108606301829993, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.818350442005722e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00026289065464482056
weight_decay:  2.839617877038171e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.374842967838049
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.444895691005513
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  1.5707362641114742
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.10
run time now: 5.430591344833374
total time:  5.487396955955774
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.90
  Final Train: 99.44 ± 0.48
   Final Test: 69.87 ± 1.76
[I 2023-06-12 00:13:31,367] Trial 944 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.023745936697160405, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 2.7730773334942427, 'loop': 2, 'loss': 'CE', 'lr': 0.00026289065464482056, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.839617877038171e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009993769667964772
weight_decay:  8.744675420144437e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.894579657819122
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 71.30
Split: 01, Run: 02
None time:  1.1344905397854745
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  1.1263531688600779
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 98.33
   Final Test: 71.50
run time now: 4.221187353134155
total time:  4.291001352015883
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 1.64
  Final Train: 97.78 ± 2.55
   Final Test: 71.30 ± 0.20
[I 2023-06-12 00:13:36,341] Trial 945 finished with value: 73.4000015258789 and parameters: {'Fwd': 1.0734290805483163e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 2.6676061809500395, 'loop': 2, 'loss': 'CE', 'lr': 0.009993769667964772, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.744675420144437e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.008628868301977104
weight_decay:  3.6087441856302763e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8176360349170864
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 93.33
   Final Test: 71.40
Split: 01, Run: 02
None time:  1.1005341450218111
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  1.0145369609817863
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 67.50
run time now: 3.970273733139038
total time:  4.023655625060201
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 0.23
  Final Train: 97.78 ± 3.85
   Final Test: 68.80 ± 2.25
[I 2023-06-12 00:13:41,035] Trial 946 finished with value: 73.53333282470703 and parameters: {'Fwd': 3.5758485460288383e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 1.6879161528765874, 'loop': 2, 'loss': 'CE', 'lr': 0.008628868301977104, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.6087441856302763e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0007273585485221135
weight_decay:  4.668881114766741e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4463374221231788
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 95.83
   Final Test: 64.50
Split: 01, Run: 02
None time:  1.3156538028270006
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 98.33
   Final Test: 63.60
Split: 01, Run: 03
None time:  1.2961677380371839
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.30
run time now: 4.098034381866455
total time:  4.146562633803114
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.73 ± 0.46
  Final Train: 98.06 ± 2.10
   Final Test: 63.80 ± 0.62
[I 2023-06-12 00:13:45,815] Trial 947 finished with value: 67.73332977294922 and parameters: {'Fwd': 0.0012076982686248104, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 0.90263225969034, 'loop': 2, 'loss': 'CE', 'lr': 0.0007273585485221135, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.668881114766741e-06, 'weightedloss': False}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008060240069343166
weight_decay:  4.741861096629117e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9675475340336561
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 89.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.0229640789330006
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  1.1566257309168577
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.30
run time now: 4.190846920013428
total time:  4.240530213108286
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 1.59
  Final Train: 96.39 ± 6.25
   Final Test: 68.93 ± 1.29
[I 2023-06-12 00:13:50,612] Trial 948 finished with value: 72.5999984741211 and parameters: {'Fwd': 6.45453730005322e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.5, 'lambda2': 1.4951461672958883, 'loop': 2, 'loss': 'CE', 'lr': 0.008060240069343166, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.741861096629117e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0026510080324043625
weight_decay:  1.0166533268597486e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.503231923794374
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.00
   Final Test: 67.60
Split: 01, Run: 02
None time:  1.4397774890530854
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 97.50
   Final Test: 68.40
Split: 01, Run: 03
None time:  1.0100722529459745
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 60.40
run time now: 5.016714096069336
total time:  5.098994062980637
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.25
  Final Train: 97.50 ± 2.50
   Final Test: 65.47 ± 4.41
[I 2023-06-12 00:13:56,411] Trial 949 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.0017672153154344515, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 3.4430712270320214, 'loop': 2, 'loss': 'CE', 'lr': 0.0026510080324043625, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0166533268597486e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0003173331689464219
weight_decay:  1.9463724042019165e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.230466833105311
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 92.50
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.6548462877981365
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 94.17
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.2810771309304982
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 95.00
   Final Test: 70.50
run time now: 5.205584526062012
total time:  5.252829542849213
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.58
  Final Train: 93.89 ± 1.27
   Final Test: 70.33 ± 0.15
[I 2023-06-12 00:14:02,226] Trial 950 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.00469977037356575, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 0.5267714942289817, 'loop': 2, 'loss': 'CE', 'lr': 0.0003173331689464219, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.9463724042019165e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.55
lr:  0.004079337865895921
weight_decay:  0.0013213737979490033
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1072244790848345
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0660300210583955
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 62.70
Split: 01, Run: 03
None time:  0.836210411041975
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 4.051733732223511
total time:  4.095619922038168
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 1.83
  Final Train: 99.72 ± 0.48
   Final Test: 67.27 ± 3.98
[I 2023-06-12 00:14:07,007] Trial 951 finished with value: 71.0 and parameters: {'Fwd': 1.2626082419682782e-05, 'K': 1, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 9.834047501414718, 'loop': 2, 'loss': 'CE', 'lr': 0.004079337865895921, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0013213737979490033, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00493961214804941
weight_decay:  1.3249275982729398e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2787416779901832
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 72.60
Split: 01, Run: 02
None time:  1.0433865250088274
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.5034881059546024
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.20
run time now: 4.8705151081085205
total time:  4.91692249593325
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 0.58
  Final Train: 99.44 ± 0.48
   Final Test: 71.53 ± 0.95
[I 2023-06-12 00:14:12,593] Trial 952 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.013780541169832695, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 4.790018806329867, 'loop': 2, 'loss': 'CE', 'lr': 0.00493961214804941, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3249275982729398e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.009069547160621264
weight_decay:  8.706436891200742e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.273528594058007
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 94.17
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.441718976944685
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.3308568799402565
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 67.20
run time now: 5.086052417755127
total time:  5.140625968109816
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.73 ± 2.02
  Final Train: 98.06 ± 3.37
   Final Test: 68.87 ± 1.47
[I 2023-06-12 00:14:18,291] Trial 953 finished with value: 72.73332977294922 and parameters: {'Fwd': 0.0009903603093797207, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 2.574693859051345, 'loop': 2, 'loss': 'CE', 'lr': 0.009069547160621264, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.706436891200742e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0003844258726744424
weight_decay:  5.6961515503720935e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5581165738403797
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 99.17
   Final Test: 67.90
Split: 01, Run: 02
None time:  2.2254440139513463
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 97.50
   Final Test: 72.50
Split: 01, Run: 03
None time:  1.7317546780686826
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 70.80
run time now: 6.5596253871917725
total time:  6.6083452720195055
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 1.50
  Final Train: 98.61 ± 0.96
   Final Test: 70.40 ± 2.33
[I 2023-06-12 00:14:25,478] Trial 954 finished with value: 71.13333129882812 and parameters: {'Fwd': 0.003499077657696221, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 3.738205635813433, 'loop': 2, 'loss': 'CE', 'lr': 0.0003844258726744424, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.6961515503720935e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008557561387092304
weight_decay:  0.002221528912514574
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6431855978444219
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.1974370430689305
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.1860409709624946
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.40
run time now: 4.091841459274292
total time:  4.1530686190817505
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 1.31
  Final Train: 99.72 ± 0.48
   Final Test: 68.13 ± 1.21
[I 2023-06-12 00:14:30,289] Trial 955 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.008577278797506001, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 3.1074418746401467, 'loop': 2, 'loss': 'CE', 'lr': 0.008557561387092304, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002221528912514574, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.000236146502938461
weight_decay:  9.135444444124264e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5953522380441427
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 92.50
   Final Test: 68.10
Split: 01, Run: 02
None time:  1.3455985758919269
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  1.4099799499381334
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.40
run time now: 5.398216009140015
total time:  5.45474099018611
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 2.55
  Final Train: 97.22 ± 4.11
   Final Test: 69.73 ± 1.42
[I 2023-06-12 00:14:36,376] Trial 956 finished with value: 71.20000457763672 and parameters: {'Fwd': 8.22132136420353e-06, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 1.3857277814636795, 'loop': 2, 'loss': 'CE', 'lr': 0.000236146502938461, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.135444444124264e-05, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007624590494361892
weight_decay:  7.335654297230356e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0753499430138618
None Run 01:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 57.20
Split: 01, Run: 02
None time:  1.0385181000456214
None Run 02:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 98.33
   Final Test: 54.10
Split: 01, Run: 03
None time:  1.3161452829372138
None Run 03:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 74.17
   Final Test: 51.80
run time now: 3.4714229106903076
total time:  3.5298851609695703
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.13 ± 1.81
  Final Train: 90.83 ± 14.46
   Final Test: 54.37 ± 2.71
[I 2023-06-12 00:14:40,588] Trial 957 finished with value: 56.13333511352539 and parameters: {'Fwd': 0.019110632403950945, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 2.2421851649851754, 'loop': 2, 'loss': 'CE', 'lr': 0.007624590494361892, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.335654297230356e-05, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00016121826559280074
weight_decay:  1.7712636117852856e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8948, Train: 99.17%, Valid: 67.80% Test: 67.20%
Split: 01, Run: 01
None time:  3.3524528660345823
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 99.17
   Final Test: 67.30
Split: 01, Run: 02
None time:  1.6160016069188714
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.6578193169552833
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.20
run time now: 6.669426441192627
total time:  6.736308141145855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 3.18
  Final Train: 99.72 ± 0.48
   Final Test: 69.63 ± 2.06
[I 2023-06-12 00:14:48,026] Trial 958 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.0006529648903199236, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 3.2417666397158964, 'loop': 2, 'loss': 'CE', 'lr': 0.00016121826559280074, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7712636117852856e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009189402884831114
weight_decay:  2.637858666481194e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.800510219996795
None Run 01:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 60.40
Split: 01, Run: 02
None time:  1.8101036970037967
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  1.4569723401218653
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.50
run time now: 5.109016180038452
total time:  5.156405637972057
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.00 ± 4.51
  Final Train: 100.00 ± 0.00
   Final Test: 65.73 ± 4.62
[I 2023-06-12 00:14:53,864] Trial 959 finished with value: 65.0 and parameters: {'Fwd': 0.0012995059812371498, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 2.0353729064927633, 'loop': 2, 'loss': 'MSE', 'lr': 0.009189402884831114, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.637858666481194e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.009962376911169937
weight_decay:  0.006585531587494213
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4965344180818647
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 97.50
   Final Test: 71.20
Split: 01, Run: 02
None time:  0.9992621869314462
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  1.098363815806806
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.6351099014282227
total time:  3.679217947879806
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 1.06
  Final Train: 99.17 ± 1.44
   Final Test: 69.97 ± 1.64
[I 2023-06-12 00:14:58,157] Trial 960 finished with value: 72.5999984741211 and parameters: {'Fwd': 0.0353931497373392, 'K': 2, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.028707964102775, 'loop': 1, 'loss': 'CE', 'lr': 0.009962376911169937, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006585531587494213, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.008180802741471005
weight_decay:  0.0009065016048030359
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7715596610214561
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.70
Split: 01, Run: 02
None time:  1.106166971847415
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.2515425528399646
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.20
run time now: 4.168140649795532
total time:  4.217459675855935
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.90
  Final Train: 99.72 ± 0.48
   Final Test: 70.77 ± 0.40
[I 2023-06-12 00:15:03,304] Trial 961 finished with value: 72.33332824707031 and parameters: {'Fwd': 0.002678955373373452, 'K': 3, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 4.993662110908674, 'loop': 2, 'loss': 'CE', 'lr': 0.008180802741471005, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009065016048030359, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0052166833878403325
weight_decay:  1.0332656739766512e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1622278238646686
None Run 01:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 48.50
Split: 01, Run: 02
None time:  2.570035671815276
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 96.67
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.170300476020202
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 68.80
run time now: 4.940433502197266
total time:  4.991061710054055
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.20 ± 15.25
  Final Train: 98.89 ± 1.92
   Final Test: 62.53 ± 12.18
[I 2023-06-12 00:15:08,978] Trial 962 finished with value: 64.19999694824219 and parameters: {'Fwd': 0.006486017143768021, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 4.47658190170828, 'loop': 2, 'loss': 'CE', 'lr': 0.0052166833878403325, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0332656739766512e-05, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.007113390273620293
weight_decay:  5.477692850504258e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4058881441596895
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 92.50
   Final Test: 70.70
Split: 01, Run: 02
None time:  1.2437699949368834
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 69.40
Split: 01, Run: 03
None time:  1.1050928300246596
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 4.808019161224365
total time:  4.86413669004105
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 0.23
  Final Train: 97.22 ± 4.11
   Final Test: 69.83 ± 0.75
[I 2023-06-12 00:15:14,560] Trial 963 finished with value: 72.26666259765625 and parameters: {'Fwd': 0.01202957174583074, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 2.4029828101309976, 'loop': 2, 'loss': 'CE', 'lr': 0.007113390273620293, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.477692850504258e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.009137088599855703
weight_decay:  0.04164708110776536
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2811692717950791
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 64.40
Split: 01, Run: 02
None time:  1.0621441258117557
None Run 02:
Highest Train: 100.00
Highest Valid: 20.80
  Final Train: 100.00
   Final Test: 24.70
Split: 01, Run: 03
None time:  1.333786799106747
None Run 03:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 99.17
   Final Test: 51.70
run time now: 3.742941379547119
total time:  3.8119958098977804
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 44.87 ± 22.08
  Final Train: 99.72 ± 0.48
   Final Test: 46.93 ± 20.27
[I 2023-06-12 00:15:19,142] Trial 964 finished with value: 44.866668701171875 and parameters: {'Fwd': 0.0007814847716596412, 'K': 1, 'alpha': 0.2, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 1.2875049750853447, 'loop': 0, 'loss': 'CE', 'lr': 0.009137088599855703, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.04164708110776536, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009985315788037727
weight_decay:  1.223336924848369e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9634521170519292
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 67.20
Split: 01, Run: 02
None time:  1.2920224820263684
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  1.1898343788925558
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.60
run time now: 4.486940383911133
total time:  4.5376544708851725
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 67.63 ± 0.84
[I 2023-06-12 00:15:24,375] Trial 965 finished with value: 70.66666412353516 and parameters: {'Fwd': 1.4166687271467641e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.678004872682931, 'loop': 2, 'loss': 'CE', 'lr': 0.009985315788037727, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.223336924848369e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0012679275265263465
weight_decay:  0.0011942290685576513
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9667084182146937
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.5576635068282485
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  2.2338529678527266
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.10
run time now: 6.798609256744385
total time:  6.841981848003343
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.99
[I 2023-06-12 00:15:31,831] Trial 966 finished with value: 70.86666870117188 and parameters: {'Fwd': 3.219401579697773e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 3.685427181909969, 'loop': 2, 'loss': 'CE', 'lr': 0.0012679275265263465, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0011942290685576513, 'weightedloss': False}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.00853254599300141
weight_decay:  0.00010899649007007878
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8780781691893935
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 90.83
   Final Test: 64.80
Split: 01, Run: 02
None time:  2.5342803380917758
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 88.33
   Final Test: 67.20
Split: 01, Run: 03
None time:  1.3013567358721048
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.30
run time now: 5.77344274520874
total time:  5.825758302118629
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.53 ± 2.02
  Final Train: 93.06 ± 6.14
   Final Test: 66.43 ± 1.42
[I 2023-06-12 00:15:38,291] Trial 967 finished with value: 66.53333282470703 and parameters: {'Fwd': 9.984950490932188e-06, 'K': 2, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 3.0985558518090097, 'loop': 2, 'loss': 'CE', 'lr': 0.00853254599300141, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010899649007007878, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00774675396879009
weight_decay:  0.004761920233777586
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6150973830372095
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 72.20
Split: 01, Run: 02
None time:  1.0980018549598753
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.220285417046398
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 4.976582288742065
total time:  5.025770714972168
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.20 ± 0.35
  Final Train: 99.72 ± 0.48
   Final Test: 71.17 ± 0.93
[I 2023-06-12 00:15:43,987] Trial 968 finished with value: 73.20000457763672 and parameters: {'Fwd': 5.17064896057763e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 9.428970115929472, 'loop': 2, 'loss': 'CE', 'lr': 0.00774675396879009, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004761920233777586, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.0004450120551375213
weight_decay:  6.927536060171199e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.6669, Train: 99.17%, Valid: 71.80% Test: 70.60%
Split: 01, Run: 01
None time:  3.617586561013013
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  1.2637940079439431
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.8558418629691005
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.40
run time now: 6.7852396965026855
total time:  6.837311798008159
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 69.77 ± 1.18
[I 2023-06-12 00:15:51,469] Trial 969 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.0016699164851111856, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 9.77493169519661, 'loop': 2, 'loss': 'CE', 'lr': 0.0004450120551375213, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.927536060171199e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0001510241521818076
weight_decay:  2.8728055090234906e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.9558, Train: 99.17%, Valid: 64.00% Test: 63.90%
Split: 01, Run: 01
None time:  3.71857748599723
None Run 01:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 99.17
   Final Test: 63.90
Split: 01, Run: 02
None time:  1.462844128953293
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  1.3868161090649664
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.20
run time now: 6.616091012954712
total time:  6.665364298038185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.40 ± 4.69
  Final Train: 99.72 ± 0.48
   Final Test: 66.60 ± 2.35
[I 2023-06-12 00:15:58,821] Trial 970 finished with value: 69.4000015258789 and parameters: {'Fwd': 0.0009813064536184494, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 8.028822930499961, 'loop': 2, 'loss': 'CE', 'lr': 0.0001510241521818076, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.8728055090234906e-06, 'weightedloss': True}. Best is trial 927 with value: 75.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008978402289542315
weight_decay:  1.5509177427212236e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5217, Train: 100.00%, Valid: 74.20% Test: 72.10%
Split: 01, Run: 01
None time:  3.3665337359998375
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 02
None time:  1.3844197739381343
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 03
None time:  1.2558782529085875
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 72.70
run time now: 6.050352334976196
total time:  6.0955869080498815
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.67 ± 1.62
  Final Train: 100.00 ± 0.00
   Final Test: 72.33 ± 0.32
[I 2023-06-12 00:16:05,587] Trial 971 finished with value: 75.66666412353516 and parameters: {'Fwd': 0.0005006650776715545, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 3.6823556143713487, 'loop': 2, 'loss': 'CE', 'lr': 0.008978402289542315, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.5509177427212236e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0010609221641050713
weight_decay:  2.2502610670109646e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1473984508775175
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  1.3000840009190142
None Run 02:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 56.60
Split: 01, Run: 03
None time:  1.1386472939047962
None Run 03:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 53.30
run time now: 4.6308252811431885
total time:  4.67738925316371
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.00 ± 11.08
  Final Train: 100.00 ± 0.00
   Final Test: 60.27 ± 9.36
[I 2023-06-12 00:16:10,956] Trial 972 finished with value: 59.0 and parameters: {'Fwd': 0.0004017628567069131, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 3.595061923424831, 'loop': 2, 'loss': 'CE', 'lr': 0.0010609221641050713, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2502610670109646e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0008415520940485758
weight_decay:  1.293273590673851e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6581903828773648
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0561796030960977
None Run 02:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 52.40
Split: 01, Run: 03
None time:  1.1723801780026406
None Run 03:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 47.40
run time now: 4.926533222198486
total time:  4.980237577110529
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.67 ± 12.70
  Final Train: 100.00 ± 0.00
   Final Test: 56.47 ± 11.65
[I 2023-06-12 00:16:16,602] Trial 973 finished with value: 56.66666793823242 and parameters: {'Fwd': 0.0004983808993140215, 'K': 1, 'alpha': 0.0, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 4.227513902233426, 'loop': 2, 'loss': 'CE', 'lr': 0.0008415520940485758, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.293273590673851e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0020327467635376543
weight_decay:  1.0018486357222315e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4702207911759615
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  2.3414516791235656
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.5099891969002783
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 69.60
run time now: 5.36442494392395
total time:  5.427998956060037
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.70
  Final Train: 97.78 ± 2.55
   Final Test: 69.60 ± 0.30
[I 2023-06-12 00:16:22,611] Trial 974 finished with value: 71.06666564941406 and parameters: {'Fwd': 0.00035353663732920265, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 3.643273280436784, 'loop': 2, 'loss': 'CE', 'lr': 0.0020327467635376543, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0018486357222315e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009161552052931166
weight_decay:  1.2305145542694871e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.577557701151818
None Run 01:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 54.60
Split: 01, Run: 02
None time:  1.8556200449820608
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.00
Split: 01, Run: 03
None time:  1.7552208330016583
None Run 03:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.30
run time now: 5.229552507400513
total time:  5.279888437129557
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.07 ± 4.36
  Final Train: 100.00 ± 0.00
   Final Test: 61.97 ± 6.39
[I 2023-06-12 00:16:28,609] Trial 975 finished with value: 63.06666946411133 and parameters: {'Fwd': 0.0004926660231213689, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 3.480570589949311, 'loop': 2, 'loss': 'MSE', 'lr': 0.009161552052931166, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2305145542694871e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.009986669185962546
weight_decay:  1.5630192147797293e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.360473182052374
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  1.2026044491212815
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.2278654049150646
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.90
run time now: 4.831710338592529
total time:  4.887704659951851
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 70.43 ± 0.72
[I 2023-06-12 00:16:34,092] Trial 976 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.0006581294916885382, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 5.866443647221114, 'loop': 2, 'loss': 'CE', 'lr': 0.009986669185962546, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.5630192147797293e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008600317204194819
weight_decay:  1.5859330896413378e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.860845590941608
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.00
Split: 01, Run: 02
None time:  2.3735750298947096
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.7504062859807163
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.40
run time now: 7.028659105300903
total time:  7.076858049025759
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 71.77 ± 1.10
[I 2023-06-12 00:16:41,850] Trial 977 finished with value: 73.39999389648438 and parameters: {'Fwd': 9.594154920392028e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 3.7033944122381257, 'loop': 2, 'loss': 'CE', 'lr': 0.008600317204194819, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.5859330896413378e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.002468232852433014
weight_decay:  1.8860882841539123e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1705384771339595
None Run 01:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 39.40
Split: 01, Run: 02
None time:  1.185697651002556
None Run 02:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 49.30
Split: 01, Run: 03
None time:  1.1970566441304982
None Run 03:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 45.40
run time now: 3.5958518981933594
total time:  3.6438382018823177
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 44.33 ± 6.54
  Final Train: 100.00 ± 0.00
   Final Test: 44.70 ± 4.99
[I 2023-06-12 00:16:46,134] Trial 978 finished with value: 44.33333206176758 and parameters: {'Fwd': 0.04395599596346584, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 9.576969849835791, 'loop': 2, 'loss': 'CE', 'lr': 0.002468232852433014, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.8860882841539123e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.009117980181670949
weight_decay:  2.1371101908705103e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.874178904807195
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 88.33
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.2777415439486504
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.1720990990288556
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.30
run time now: 4.368615388870239
total time:  4.427285315934569
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.42
  Final Train: 96.11 ± 6.74
   Final Test: 69.03 ± 0.87
[I 2023-06-12 00:16:51,144] Trial 979 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.000284309794379888, 'K': 3, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 4.065382152979735, 'loop': 2, 'loss': 'CE', 'lr': 0.009117980181670949, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.1371101908705103e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.003776695318950454
weight_decay:  3.1670084347197775e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.0366866721305996
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.2027961099520326
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.5011, Train: 100.00%, Valid: 72.60% Test: 70.90%
Split: 01, Run: 03
None time:  3.4322087159380317
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 8.722005367279053
total time:  8.815647214883938
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 70.73 ± 1.03
[I 2023-06-12 00:17:00,637] Trial 980 finished with value: 71.93334197998047 and parameters: {'Fwd': 0.000501435838941196, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 8.093009227119023, 'loop': 2, 'loss': 'CE', 'lr': 0.003776695318950454, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.1670084347197775e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.0
lr:  0.007868396372121165
weight_decay:  4.515362926758691e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.746962412027642
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 02
None time:  4.641469452995807
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  5.345167170045897
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 12.797961950302124
total time:  12.853307062992826
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.27 ± 0.81
[I 2023-06-12 00:17:14,069] Trial 981 finished with value: 71.13333129882812 and parameters: {'Fwd': 0.009936353725779347, 'K': 4, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 3.7859376026830813, 'loop': 2, 'loss': 'CE', 'lr': 0.007868396372121165, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.515362926758691e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00923413443915098
weight_decay:  1.6158267047144714e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6540307090617716
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 68.20
Split: 01, Run: 02
None time:  1.3305252699647099
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.2398078271653503
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.10
run time now: 4.283720970153809
total time:  4.3308382029645145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 1.90
  Final Train: 99.72 ± 0.48
   Final Test: 69.93 ± 1.53
[I 2023-06-12 00:17:19,129] Trial 982 finished with value: 72.33332824707031 and parameters: {'Fwd': 0.0005860686997177015, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 5.448084609994556, 'loop': 2, 'loss': 'CE', 'lr': 0.00923413443915098, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6158267047144714e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007055762449096394
weight_decay:  9.895741265043571e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.674438628135249
None Run 01:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.90
Split: 01, Run: 02
None time:  1.5537670750636607
None Run 02:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.90
Split: 01, Run: 03
None time:  1.729516349034384
None Run 03:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.90
run time now: 4.997041702270508
total time:  5.045256237965077
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 49.90 ± 0.00
[I 2023-06-12 00:17:24,807] Trial 983 finished with value: 50.59999465942383 and parameters: {'Fwd': 0.02523802034456879, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.0, 'lambda2': 4.723640433483836, 'loop': 1, 'loss': 'CE', 'lr': 0.007055762449096394, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.895741265043571e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008501483217701618
weight_decay:  2.3826766309470483e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7105597350746393
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  2.393915956141427
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 03
None time:  2.6159432458225638
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
run time now: 7.7674033641815186
total time:  7.815183431142941
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.30 ± 0.00
[I 2023-06-12 00:17:33,306] Trial 984 finished with value: 51.20000076293945 and parameters: {'Fwd': 2.9558255462975264e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.0, 'lambda2': 9.33800487343897, 'loop': 2, 'loss': 'CE', 'lr': 0.008501483217701618, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.3826766309470483e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0014849973576521614
weight_decay:  0.0006824910887467368
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.159073675982654
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 02
None time:  2.0510319389868528
None Run 02:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 03
None time:  2.0620850559789687
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
run time now: 6.321100234985352
total time:  6.378995781065896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.50 ± 0.00
[I 2023-06-12 00:17:40,408] Trial 985 finished with value: 51.40000534057617 and parameters: {'Fwd': 0.000370000488160294, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.0, 'lambda2': 7.781524274759919, 'loop': 2, 'loss': 'CE', 'lr': 0.0014849973576521614, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006824910887467368, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009251278706259235
weight_decay:  7.950772231075584e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2468757410533726
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02
None time:  2.0197191338520497
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.2009061072021723
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 67.70
run time now: 5.509659051895142
total time:  5.562887731939554
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.72
  Final Train: 99.72 ± 0.48
   Final Test: 68.27 ± 0.60
[I 2023-06-12 00:17:46,540] Trial 986 finished with value: 71.5999984741211 and parameters: {'Fwd': 8.295401184483808e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 3.914598761545611, 'loop': 2, 'loss': 'CE', 'lr': 0.009251278706259235, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.950772231075584e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007934237158413997
weight_decay:  0.03235707964264776
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1654050149954855
None Run 01:
Highest Train: 100.00
Highest Valid: 31.80
  Final Train: 100.00
   Final Test: 34.30
Split: 01, Run: 02
None time:  2.331012127920985
None Run 02:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 49.30
Split: 01, Run: 03
None time:  1.156442570965737
None Run 03:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 48.60
run time now: 4.745307207107544
total time:  4.804054094944149
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 43.60 ± 10.33
  Final Train: 100.00 ± 0.00
   Final Test: 44.07 ± 8.47
[I 2023-06-12 00:17:52,016] Trial 987 finished with value: 43.60000228881836 and parameters: {'Fwd': 6.182955680247109e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 7.536182658936044, 'loop': 2, 'loss': 'CE', 'lr': 0.007934237158413997, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03235707964264776, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.004441277918168374
weight_decay:  3.7215956691398197e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0065533129964024
None Run 01:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  0.9162935130298138
None Run 02:
Highest Train: 100.00
Highest Valid: 36.80
  Final Train: 100.00
   Final Test: 37.70
Split: 01, Run: 03
None time:  1.2159176219720393
None Run 03:
Highest Train: 100.00
Highest Valid: 30.00
  Final Train: 100.00
   Final Test: 34.60
run time now: 3.1814041137695312
total time:  3.2269491110928357
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 38.53 ± 9.52
  Final Train: 100.00 ± 0.00
   Final Test: 41.20 ± 8.88
[I 2023-06-12 00:17:55,791] Trial 988 finished with value: 38.53333282470703 and parameters: {'Fwd': 0.00450433059425227, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 9.697343604748957, 'loop': 2, 'loss': 'CE', 'lr': 0.004441277918168374, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.7215956691398197e-06, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0017262705082825283
weight_decay:  0.0016744472366478874
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 1.0867, Train: 100.00%, Valid: 51.00% Test: 51.50%
Split: 01, Run: 01
None time:  3.475071884924546
None Run 01:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 51.10
Split: 01, Run: 02, Epoch: 100, Loss: 1.0614, Train: 100.00%, Valid: 51.00% Test: 51.50%
Split: 01, Run: 02
None time:  3.589684254024178
None Run 02:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 51.10
Split: 01, Run: 03, Epoch: 100, Loss: 1.0506, Train: 100.00%, Valid: 51.00% Test: 51.50%
Split: 01, Run: 03
None time:  3.719903978984803
None Run 03:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 51.10
run time now: 10.826298236846924
total time:  10.876492566196248
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.00 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.10 ± 0.00
[I 2023-06-12 00:18:07,308] Trial 989 finished with value: 51.0 and parameters: {'Fwd': 0.018837955540957574, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.0, 'lambda2': 6.563568684211281, 'loop': 2, 'loss': 'CE', 'lr': 0.0017262705082825283, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0016744472366478874, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0005563742078380196
weight_decay:  0.0001307122758307661
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5120711678173393
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.4512602880131453
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.30
Split: 01, Run: 03
None time:  2.48139083199203
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.70
run time now: 6.495198011398315
total time:  6.554525322979316
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.33 ± 2.66
  Final Train: 100.00 ± 0.00
   Final Test: 67.27 ± 3.48
[I 2023-06-12 00:18:14,654] Trial 990 finished with value: 68.33333587646484 and parameters: {'Fwd': 2.301197046696217e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.05, 'lambda2': 8.211679499988858, 'loop': 2, 'loss': 'CE', 'lr': 0.0005563742078380196, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001307122758307661, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009227089134169779
weight_decay:  0.09878357677022669
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.789364442927763
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  2.6778460619971156
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 03
None time:  2.6775093048345298
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
run time now: 8.183794021606445
total time:  8.240570558002219
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.30 ± 0.00
[I 2023-06-12 00:18:23,611] Trial 991 finished with value: 51.20000076293945 and parameters: {'Fwd': 5.236523896608448e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.0, 'lambda2': 4.029436972979169, 'loop': 2, 'loss': 'CE', 'lr': 0.009227089134169779, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.09878357677022669, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0011989092279027513
weight_decay:  0.002559751938843859
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0191477448679507
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.2295026450883597
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 52.10
Split: 01, Run: 03
None time:  1.105652519967407
None Run 03:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 43.70
run time now: 4.396202564239502
total time:  4.4523513610474765
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.00 ± 13.70
  Final Train: 100.00 ± 0.00
   Final Test: 55.03 ± 13.05
[I 2023-06-12 00:18:28,640] Trial 992 finished with value: 55.0 and parameters: {'Fwd': 0.0007550435689058819, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 5.1224615520812655, 'loop': 2, 'loss': 'CE', 'lr': 0.0011989092279027513, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002559751938843859, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0017967959823899577
weight_decay:  1.5897952373373791e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5314495940692723
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  2.3675952979829162
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 93.33
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.293472392950207
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.90
run time now: 5.231130599975586
total time:  5.292864151997492
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 1.91
  Final Train: 97.78 ± 3.85
   Final Test: 68.50 ± 1.35
[I 2023-06-12 00:18:34,633] Trial 993 finished with value: 70.60000610351562 and parameters: {'Fwd': 1.7388555210110654e-05, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 3.8615827209673435, 'loop': 2, 'loss': 'CE', 'lr': 0.0017967959823899577, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.5897952373373791e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007326551060610583
weight_decay:  0.003217289376914148
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8173547550104558
None Run 01:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 53.70
Split: 01, Run: 02
None time:  1.9812636449933052
None Run 02:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 60.30
Split: 01, Run: 03
None time:  1.249921373091638
None Run 03:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 62.90
run time now: 5.107647895812988
total time:  5.1605258928611875
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.00 ± 4.04
  Final Train: 100.00 ± 0.00
   Final Test: 58.97 ± 4.74
[I 2023-06-12 00:18:40,447] Trial 994 finished with value: 57.0 and parameters: {'Fwd': 1.2074402818070214e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 9.47997928535914, 'loop': 2, 'loss': 'MSE', 'lr': 0.007326551060610583, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003217289376914148, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00853354194105709
weight_decay:  1.344484345217915e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6407944071106613
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 96.67
   Final Test: 67.10
Split: 01, Run: 02
None time:  1.2421553540043533
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 03
None time:  1.1368255419656634
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.40
run time now: 5.064936876296997
total time:  5.114266977878287
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 1.17
  Final Train: 98.89 ± 1.92
   Final Test: 67.57 ± 0.72
[I 2023-06-12 00:18:46,087] Trial 995 finished with value: 72.33333587646484 and parameters: {'Fwd': 3.3537795154937575e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 3.445161390765045, 'loop': 2, 'loss': 'CE', 'lr': 0.00853354194105709, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.344484345217915e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0006381992984185106
weight_decay:  1.3609390474523415e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7136040159966797
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.30
Split: 01, Run: 02
None time:  2.2033976800739765
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 69.40
Split: 01, Run: 03
None time:  1.5945369678083807
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 71.40
run time now: 5.550559997558594
total time:  5.596147742122412
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 1.39
  Final Train: 99.44 ± 0.48
   Final Test: 69.03 ± 2.57
[I 2023-06-12 00:18:52,292] Trial 996 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.0006004728858759228, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 4.6831645824862065, 'loop': 2, 'loss': 'CE', 'lr': 0.0006381992984185106, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3609390474523415e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.005345257711725774
weight_decay:  0.05185215137804247
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1775886330287904
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 64.00
Split: 01, Run: 02
None time:  1.2905190461315215
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.10
Split: 01, Run: 03
None time:  1.3203758741728961
None Run 03:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 96.67
   Final Test: 54.60
run time now: 3.8633973598480225
total time:  3.9170383461751044
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.33 ± 4.69
  Final Train: 98.89 ± 1.92
   Final Test: 59.57 ± 4.72
[I 2023-06-12 00:18:56,855] Trial 997 finished with value: 60.33333206176758 and parameters: {'Fwd': 0.0004098534882430692, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 5.646089129005073, 'loop': 2, 'loss': 'CE', 'lr': 0.005345257711725774, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.05185215137804247, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.009301820625133848
weight_decay:  5.487073348572403e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6967853580135852
None Run 01:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 46.80
Split: 01, Run: 02
None time:  1.8900226219557226
None Run 02:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 93.33
   Final Test: 55.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0508, Train: 88.33%, Valid: 68.80% Test: 67.00%
Split: 01, Run: 03
None time:  3.0618283059448004
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 88.33
   Final Test: 66.80
run time now: 5.6919355392456055
total time:  5.736323054879904
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.20 ± 12.40
  Final Train: 93.89 ± 5.85
   Final Test: 56.50 ± 10.01
[I 2023-06-12 00:19:03,478] Trial 998 finished with value: 56.20000076293945 and parameters: {'Fwd': 0.0274549218778904, 'K': 1, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 40, 'lambda1': 0.35000000000000003, 'lambda2': 4.408186002552548, 'loop': 2, 'loss': 'CE', 'lr': 0.009301820625133848, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.487073348572403e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008075588346164276
weight_decay:  1.967038443645616e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.386145676020533
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.4363371490035206
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.2688617780804634
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 67.50
run time now: 5.133994102478027
total time:  5.180907326051965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 68.90 ± 1.35
[I 2023-06-12 00:19:09,316] Trial 999 finished with value: 72.06665802001953 and parameters: {'Fwd': 1.1941085593597687e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 7.746611171253303, 'loop': 2, 'loss': 'CE', 'lr': 0.008075588346164276, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.967038443645616e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0033923565794598894
weight_decay:  0.0010782951090244981
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3320905358996242
None Run 01:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 45.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.1480, Train: 95.00%, Valid: 58.00% Test: 63.50%
Split: 01, Run: 02
None time:  3.404036669060588
None Run 02:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 95.00
   Final Test: 63.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.1378, Train: 94.17%, Valid: 64.60% Test: 70.10%
Split: 01, Run: 03
None time:  3.373517454834655
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 94.17
   Final Test: 70.20
run time now: 8.152867794036865
total time:  8.206216390943155
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.33 ± 9.41
  Final Train: 96.39 ± 3.15
   Final Test: 59.57 ± 12.91
[I 2023-06-12 00:19:18,153] Trial 1000 finished with value: 56.33333206176758 and parameters: {'Fwd': 0.0372646978428446, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.5, 'lambda2': 8.391568338589458, 'loop': 2, 'loss': 'CE', 'lr': 0.0033923565794598894, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0010782951090244981, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0030799705680555805
weight_decay:  1.1860220745065478e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.803631732938811
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.7884047811385244
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.8431707189884037
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 8.490402936935425
total time:  8.546446613967419
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.38
[I 2023-06-12 00:19:27,431] Trial 1001 finished with value: 71.4000015258789 and parameters: {'Fwd': 8.020772035248294e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 6.867133336187813, 'loop': 2, 'loss': 'CE', 'lr': 0.0030799705680555805, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.1860220745065478e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009932256061988175
weight_decay:  0.029534051638356477
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.0282440669834614
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 93.33
   Final Test: 71.40
Split: 01, Run: 02
None time:  1.1851743019651622
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 65.40
Split: 01, Run: 03
None time:  1.0902699530124664
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.10
run time now: 5.3451056480407715
total time:  5.40352641697973
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.07 ± 0.50
  Final Train: 97.78 ± 3.85
   Final Test: 68.97 ± 3.16
[I 2023-06-12 00:19:33,524] Trial 1002 finished with value: 73.0666732788086 and parameters: {'Fwd': 4.341179295576595e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 3.2015056449759953, 'loop': 2, 'loss': 'CE', 'lr': 0.009932256061988175, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.029534051638356477, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.006824213846389834
weight_decay:  0.006394581235804419
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.516743134940043
None Run 01:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 02
None time:  1.3417110370937735
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  1.544733301969245
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.40
run time now: 5.473036050796509
total time:  5.523732251022011
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 3.83
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 2.59
[I 2023-06-12 00:19:39,737] Trial 1003 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.011925301975529969, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.05, 'lambda2': 7.2832879455576025, 'loop': 2, 'loss': 'CE', 'lr': 0.006824213846389834, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006394581235804419, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008409659869048958
weight_decay:  0.012602307140896479
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.299641469027847
None Run 01:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 59.70
Split: 01, Run: 02
None time:  1.3652698697987944
None Run 02:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 58.50
Split: 01, Run: 03
None time:  1.3477227149996907
None Run 03:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 56.50
run time now: 4.053148508071899
total time:  4.099305272800848
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.93 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 58.23 ± 1.62
[I 2023-06-12 00:19:44,408] Trial 1004 finished with value: 55.93333435058594 and parameters: {'Fwd': 0.0023530063236565377, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 6.054144329818145, 'loop': 2, 'loss': 'CE', 'lr': 0.008409659869048958, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.012602307140896479, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.004231861563524757
weight_decay:  2.718612952852374e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2432248170953244
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 71.60
Split: 01, Run: 02
None time:  1.247833229135722
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  1.0882575309369713
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 67.40
run time now: 4.669208288192749
total time:  4.730269521009177
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.46
  Final Train: 99.44 ± 0.96
   Final Test: 68.97 ± 2.29
[I 2023-06-12 00:19:49,921] Trial 1005 finished with value: 72.33333587646484 and parameters: {'Fwd': 6.8444838906977e-06, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.55, 'lambda2': 9.377657913719803, 'loop': 2, 'loss': 'CE', 'lr': 0.004231861563524757, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.718612952852374e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0011503754519503729
weight_decay:  0.004111569011196274
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5977874901145697
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  2.816668034065515
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 72.70
Split: 01, Run: 03
None time:  1.2962604782078415
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 68.10
run time now: 5.7503814697265625
total time:  5.797959722811356
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.73 ± 1.22
  Final Train: 99.72 ± 0.48
   Final Test: 70.23 ± 2.32
[I 2023-06-12 00:19:56,262] Trial 1006 finished with value: 72.73332977294922 and parameters: {'Fwd': 0.006794367104696128, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 7.961188252990529, 'loop': 2, 'loss': 'CE', 'lr': 0.0011503754519503729, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004111569011196274, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0028293193713328766
weight_decay:  7.684572328432573e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5171, Train: 99.17%, Valid: 68.20% Test: 66.60%
Split: 01, Run: 01
None time:  3.2559393730480224
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 99.17
   Final Test: 66.60
Split: 01, Run: 02
None time:  1.5783269619569182
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1598975490778685
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.035825490951538
total time:  6.082811936037615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 2.12
  Final Train: 99.72 ± 0.48
   Final Test: 68.93 ± 2.02
[I 2023-06-12 00:20:02,954] Trial 1007 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.05550550425691208, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 9.20158744981076, 'loop': 2, 'loss': 'CE', 'lr': 0.0028293193713328766, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.684572328432573e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007563844705750766
weight_decay:  0.00011980324724000236
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.601718237856403
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 02
None time:  1.2457615230232477
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.2730552470311522
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 4.155027627944946
total time:  4.205071870936081
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 2.43
  Final Train: 100.00 ± 0.00
   Final Test: 68.77 ± 1.40
[I 2023-06-12 00:20:07,909] Trial 1008 finished with value: 72.4000015258789 and parameters: {'Fwd': 4.987290598570799e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.566035165937989, 'loop': 2, 'loss': 'CE', 'lr': 0.007563844705750766, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011980324724000236, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.009950468134388567
weight_decay:  1.0114606174309726e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1786, Train: 81.67%, Valid: 66.60% Test: 68.50%
Split: 01, Run: 01
None time:  3.7278466580901295
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 83.33
   Final Test: 68.20
Split: 01, Run: 02
None time:  1.4129408551380038
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.5099654360674322
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.50
run time now: 6.694730758666992
total time:  6.740198923973367
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.47 ± 2.31
  Final Train: 94.44 ± 9.62
   Final Test: 68.57 ± 0.40
[I 2023-06-12 00:20:15,321] Trial 1009 finished with value: 69.46666717529297 and parameters: {'Fwd': 0.005686169990699908, 'K': 3, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 9.808680947621875, 'loop': 2, 'loss': 'CE', 'lr': 0.009950468134388567, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0114606174309726e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00020759814210615242
weight_decay:  1.6451364004165337e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9584084539674222
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 99.17
   Final Test: 67.60
Split: 01, Run: 02
None time:  1.4480643428396434
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.6156764749903232
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 6.093059539794922
total time:  6.145287452964112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 1.39
  Final Train: 99.72 ± 0.48
   Final Test: 68.97 ± 1.21
[I 2023-06-12 00:20:22,141] Trial 1010 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.0034642061002334427, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.6000000000000001, 'lambda2': 5.41010613059366, 'loop': 2, 'loss': 'CE', 'lr': 0.00020759814210615242, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6451364004165337e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0013121159554270853
weight_decay:  0.0007931380550086513
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5719, Train: 93.33%, Valid: 70.20% Test: 68.20%
Split: 01, Run: 01
None time:  2.9453049479052424
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 94.17
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.312306695850566
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  1.0850140650290996
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.00
run time now: 5.3862974643707275
total time:  5.434701333986595
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 1.03
  Final Train: 98.06 ± 3.37
   Final Test: 68.43 ± 0.51
[I 2023-06-12 00:20:28,214] Trial 1011 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.00029283282388818, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 7.147893288760006, 'loop': 2, 'loss': 'CE', 'lr': 0.0013121159554270853, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007931380550086513, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.005824147805150534
weight_decay:  0.00010435018284284274
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.225130392005667
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 02
None time:  1.229557374957949
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  1.3939663819037378
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.70
run time now: 4.888959646224976
total time:  4.950061816023663
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.07 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 2.65
[I 2023-06-12 00:20:33,850] Trial 1012 finished with value: 74.06666564941406 and parameters: {'Fwd': 1.8171468209383178e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 9.999287288141467, 'loop': 2, 'loss': 'CE', 'lr': 0.005824147805150534, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010435018284284274, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.8500000000000001
lr:  0.00869895785906372
weight_decay:  3.841996866449154e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.22504804097116
None Run 01:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 62.00
Split: 01, Run: 02
None time:  1.5728865978308022
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 03
None time:  1.241586685879156
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.20
run time now: 4.082838296890259
total time:  4.127281829947606
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.00 ± 3.14
  Final Train: 100.00 ± 0.00
   Final Test: 64.43 ± 2.15
[I 2023-06-12 00:20:38,688] Trial 1013 finished with value: 65.0 and parameters: {'Fwd': 0.0007860134710532613, 'K': 1, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 4.218781445695674, 'loop': 2, 'loss': 'MSE', 'lr': 0.00869895785906372, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.841996866449154e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009259877143872122
weight_decay:  0.004727100690032079
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8676224930677563
None Run 01:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 49.50
Split: 01, Run: 02
None time:  2.0337013120297343
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  0.8778544371016324
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 72.10
run time now: 3.8217852115631104
total time:  3.8730205360334367
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.20 ± 13.26
  Final Train: 100.00 ± 0.00
   Final Test: 64.10 ± 12.66
[I 2023-06-12 00:20:43,210] Trial 1014 finished with value: 66.20000457763672 and parameters: {'Fwd': 9.1423041948341e-06, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.1, 'lambda2': 5.1575482174692056, 'loop': 2, 'loss': 'CE', 'lr': 0.009259877143872122, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004727100690032079, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.007977217448021634
weight_decay:  0.007025586326837744
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.690789365908131
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.1591431279666722
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 99.17
   Final Test: 71.90
Split: 01, Run: 03
None time:  1.3387446021661162
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 99.17
   Final Test: 73.60
run time now: 4.2318174839019775
total time:  4.287155861034989
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.87 ± 1.27
  Final Train: 99.17 ± 0.00
   Final Test: 71.77 ± 1.90
[I 2023-06-12 00:20:48,174] Trial 1015 finished with value: 73.86666870117188 and parameters: {'Fwd': 1.2652446065404492e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 2.970476818892941, 'loop': 2, 'loss': 'CE', 'lr': 0.007977217448021634, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007025586326837744, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009959307977197296
weight_decay:  1.2398120832748451e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.239091802854091
None Run 01:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 53.00
Split: 01, Run: 02
None time:  1.2912855609320104
None Run 02:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 99.17
   Final Test: 49.80
Split: 01, Run: 03
None time:  1.3397025070153177
None Run 03:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 91.67
   Final Test: 45.60
run time now: 3.915818452835083
total time:  3.9618525519035757
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.00 ± 3.12
  Final Train: 96.94 ± 4.59
   Final Test: 49.47 ± 3.71
[I 2023-06-12 00:20:52,799] Trial 1016 finished with value: 49.0 and parameters: {'Fwd': 0.0004669744233358848, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 3.6290095224782926, 'loop': 2, 'loss': 'CE', 'lr': 0.009959307977197296, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.2398120832748451e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0021154417598643342
weight_decay:  5.808553870067808e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9312749300152063
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 02
None time:  2.7893273420631886
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 96.67
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.2683850310277194
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 72.00
run time now: 6.0340821743011475
total time:  6.123264366993681
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 1.06
  Final Train: 98.89 ± 1.92
   Final Test: 69.33 ± 2.60
[I 2023-06-12 00:20:59,739] Trial 1017 finished with value: 69.5999984741211 and parameters: {'Fwd': 6.008368731947277e-05, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 5.8093889686699, 'loop': 2, 'loss': 'CE', 'lr': 0.0021154417598643342, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.808553870067808e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0022118364873317483
weight_decay:  8.455465379244746e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8692837620619684
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  3.2763750650919974
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  4.408497813157737
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 10.591248035430908
total time:  10.635010696016252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.45
[I 2023-06-12 00:21:11,085] Trial 1018 finished with value: 71.4000015258789 and parameters: {'Fwd': 2.0913134310573034e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 8.542834080649072, 'loop': 2, 'loss': 'CE', 'lr': 0.0022118364873317483, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.455465379244746e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.008658233850804662
weight_decay:  0.0001417533401789427
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3441441270988435
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  1.3789479520637542
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 03
None time:  1.1891680790577084
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
run time now: 3.952608585357666
total time:  3.99971871310845
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.30 ± 0.00
[I 2023-06-12 00:21:15,716] Trial 1019 finished with value: 51.20000076293945 and parameters: {'Fwd': 2.9407159908794144e-06, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.0, 'lambda2': 6.415470334966672, 'loop': 0, 'loss': 'CE', 'lr': 0.008658233850804662, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001417533401789427, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0019164402979190728
weight_decay:  2.437978541085313e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3245658138766885
None Run 01:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 50.10
Split: 01, Run: 02
None time:  2.5908074900507927
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 72.00
Split: 01, Run: 03
None time:  1.0752715829294175
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 67.60
run time now: 5.057171821594238
total time:  5.113718116888776
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.00 ± 13.52
  Final Train: 99.72 ± 0.48
   Final Test: 63.23 ± 11.58
[I 2023-06-12 00:21:21,429] Trial 1020 finished with value: 65.0 and parameters: {'Fwd': 0.015631172930225624, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 8.921930247083797, 'loop': 2, 'loss': 'CE', 'lr': 0.0019164402979190728, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.437978541085313e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00017055212955862186
weight_decay:  1.730394160653015e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8868, Train: 99.17%, Valid: 65.00% Test: 64.70%
Split: 01, Run: 01
None time:  3.5607126099057496
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 99.17
   Final Test: 64.40
Split: 01, Run: 02
None time:  1.4226078840438277
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 03
None time:  1.1421787180006504
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 65.60
run time now: 6.167508125305176
total time:  6.217574714217335
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.27 ± 3.59
  Final Train: 99.72 ± 0.48
   Final Test: 65.53 ± 1.10
[I 2023-06-12 00:21:28,353] Trial 1021 finished with value: 69.26667022705078 and parameters: {'Fwd': 1.4432598282763141e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 4.927567192679136, 'loop': 2, 'loss': 'CE', 'lr': 0.00017055212955862186, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.730394160653015e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.006271965504891369
weight_decay:  0.0003306680994823508
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.0658081111032516
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 02
None time:  1.1112695280462503
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  1.1803705608472228
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 68.40
run time now: 5.400165796279907
total time:  5.443079966120422
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 0.95
  Final Train: 99.72 ± 0.48
   Final Test: 69.37 ± 1.42
[I 2023-06-12 00:21:34,438] Trial 1022 finished with value: 72.9333267211914 and parameters: {'Fwd': 0.007983139396828792, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 6.681912716338813, 'loop': 2, 'loss': 'CE', 'lr': 0.006271965504891369, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003306680994823508, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.003698140795395817
weight_decay:  8.409416833322695e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7603680831380188
None Run 01:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 45.90
Split: 01, Run: 02
None time:  1.4325511818751693
None Run 02:
Highest Train: 100.00
Highest Valid: 34.40
  Final Train: 100.00
   Final Test: 35.10
Split: 01, Run: 03
None time:  1.9673502768855542
None Run 03:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 44.20
run time now: 4.237704038619995
total time:  4.322739296127111
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 42.07 ± 6.65
  Final Train: 100.00 ± 0.00
   Final Test: 41.73 ± 5.81
[I 2023-06-12 00:21:39,409] Trial 1023 finished with value: 42.06666946411133 and parameters: {'Fwd': 0.0006219541343153354, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.05, 'lambda2': 9.59114866191792, 'loop': 2, 'loss': 'CE', 'lr': 0.003698140795395817, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.409416833322695e-05, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00029057654203471444
weight_decay:  1.115780054753224e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9133829050697386
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 68.20
Split: 01, Run: 02
None time:  1.384702858980745
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.5007700689602643
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.30
run time now: 5.859261512756348
total time:  5.917089849943295
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 1.20
  Final Train: 99.72 ± 0.48
   Final Test: 68.80 ± 0.95
[I 2023-06-12 00:21:45,922] Trial 1024 finished with value: 71.0 and parameters: {'Fwd': 3.440227544629306e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 3.369340981886806, 'loop': 2, 'loss': 'CE', 'lr': 0.00029057654203471444, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.115780054753224e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0009763982497909844
weight_decay:  0.0005755553606140401
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.614291787846014
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.8343274539802223
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.5472, Train: 99.17%, Valid: 69.60% Test: 70.40%
Split: 01, Run: 03
None time:  3.185181259876117
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 70.00
run time now: 6.675812721252441
total time:  6.725620090030134
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.58
  Final Train: 99.72 ± 0.48
   Final Test: 69.17 ± 0.91
[I 2023-06-12 00:21:53,257] Trial 1025 finished with value: 70.26666259765625 and parameters: {'Fwd': 2.511362582089836e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 7.467281520943454, 'loop': 2, 'loss': 'CE', 'lr': 0.0009763982497909844, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005755553606140401, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009993286609896694
weight_decay:  0.01702814021635252
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1768033059779555
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 99.17
   Final Test: 67.30
Split: 01, Run: 02
None time:  1.101669937139377
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.50
Split: 01, Run: 03
None time:  1.2360939488280565
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.40
run time now: 4.559601545333862
total time:  4.605210958048701
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 0.61
  Final Train: 99.72 ± 0.48
   Final Test: 67.07 ± 0.49
[I 2023-06-12 00:21:58,473] Trial 1026 finished with value: 70.0666732788086 and parameters: {'Fwd': 0.0009040220948376789, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 9.204522589846668, 'loop': 2, 'loss': 'CE', 'lr': 0.009993286609896694, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.01702814021635252, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007638097059558907
weight_decay:  4.759338163292533e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.031678250990808
None Run 01:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 46.60
Split: 01, Run: 02
None time:  1.6684684620704502
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9705695579759777
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.7164716720581055
total time:  3.762840768089518
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.80 ± 14.11
  Final Train: 99.44 ± 0.96
   Final Test: 62.00 ± 13.34
[I 2023-06-12 00:22:02,806] Trial 1027 finished with value: 64.79999542236328 and parameters: {'Fwd': 0.00012089650994354716, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 4.5287762111281324, 'loop': 2, 'loss': 'CE', 'lr': 0.007638097059558907, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.759338163292533e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.008755268624377114
weight_decay:  9.717100418541144e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2066987121943384
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 02
None time:  1.536245936062187
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 68.20
Split: 01, Run: 03
None time:  1.0090472849551588
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.7931272983551025
total time:  3.8421787810511887
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 1.81
  Final Train: 99.72 ± 0.48
   Final Test: 68.50 ± 0.89
[I 2023-06-12 00:22:07,258] Trial 1028 finished with value: 70.93334197998047 and parameters: {'Fwd': 0.0020883418382906397, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 7.887925696903999, 'loop': 2, 'loss': 'CE', 'lr': 0.008755268624377114, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.717100418541144e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.006835665424610022
weight_decay:  0.0015982953155276114
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.48251759889535606
None Run 01:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 45.30
Split: 01, Run: 02
None time:  0.5176288839429617
None Run 02:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 100.00
   Final Test: 36.60
Split: 01, Run: 03
None time:  0.34599916101433337
None Run 03:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 37.00
run time now: 1.3857421875
total time:  1.4319651159457862
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 41.00 ± 6.16
  Final Train: 100.00 ± 0.00
   Final Test: 39.63 ± 4.91
[I 2023-06-12 00:22:09,286] Trial 1029 finished with value: 41.0 and parameters: {'Fwd': 0.029090769947745936, 'K': 1, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 0, 'lambda1': 0.25, 'lambda2': 2.551446699095049, 'loop': 2, 'loss': 'CE', 'lr': 0.006835665424610022, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0015982953155276114, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.0006127064515292915
weight_decay:  2.9081025411284927e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6937207179144025
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.2969981911592185
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.6537916280794889
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.40
run time now: 4.688404321670532
total time:  4.74262424884364
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 70.97 ± 1.24
[I 2023-06-12 00:22:14,730] Trial 1030 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.0010634216608440285, 'K': 3, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 7.104952103144335, 'loop': 2, 'loss': 'CE', 'lr': 0.0006127064515292915, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.9081025411284927e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009066782035916394
weight_decay:  1.8449544669789098e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1044485149905086
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 70.80
Split: 01, Run: 02
None time:  1.0541494798380882
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 71.80
Split: 01, Run: 03
None time:  1.272335943998769
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.20
run time now: 4.474830150604248
total time:  4.526184089016169
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.87 ± 1.33
  Final Train: 99.72 ± 0.48
   Final Test: 71.60 ± 0.72
[I 2023-06-12 00:22:19,876] Trial 1031 finished with value: 74.86666107177734 and parameters: {'Fwd': 0.042725149747160004, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 5.967365666433392, 'loop': 2, 'loss': 'CE', 'lr': 0.009066782035916394, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.8449544669789098e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0003407551130487288
weight_decay:  1.7558724956215678e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1967414231039584
None Run 01:
Highest Train: 100.00
Highest Valid: 29.00
  Final Train: 100.00
   Final Test: 28.30
Split: 01, Run: 02
None time:  1.3025730878580362
None Run 02:
Highest Train: 100.00
Highest Valid: 27.40
  Final Train: 100.00
   Final Test: 27.50
Split: 01, Run: 03
None time:  1.8744091838598251
None Run 03:
Highest Train: 100.00
Highest Valid: 31.60
  Final Train: 100.00
   Final Test: 32.70
run time now: 4.414693355560303
total time:  4.467793638119474
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 29.33 ± 2.12
  Final Train: 100.00 ± 0.00
   Final Test: 29.50 ± 2.80
[I 2023-06-12 00:22:25,006] Trial 1032 finished with value: 29.33333396911621 and parameters: {'Fwd': 0.05636940259618962, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 6.4762484941379155, 'loop': 2, 'loss': 'MSE', 'lr': 0.0003407551130487288, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7558724956215678e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0007290635880049599
weight_decay:  2.318276926862273e-05
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7189175421372056
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.8223365389276296
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.6889229349326342
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 99.17
   Final Test: 70.80
run time now: 5.278862476348877
total time:  5.342931765830144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 2.34
  Final Train: 99.44 ± 0.48
   Final Test: 70.30 ± 0.46
[I 2023-06-12 00:22:31,033] Trial 1033 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.019373539375128365, 'K': 1, 'alpha': 0.0, 'dropout': 0.0, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 6.107678845789614, 'loop': 2, 'loss': 'CE', 'lr': 0.0007290635880049599, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.318276926862273e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009201814498299534
weight_decay:  1.9864307281746365e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2584028569981456
None Run 01:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 59.60
Split: 01, Run: 02
None time:  1.2548895489890128
None Run 02:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 55.90
Split: 01, Run: 03
None time:  1.2363921001087874
None Run 03:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 96.67
   Final Test: 49.00
run time now: 3.793872833251953
total time:  3.844691556878388
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.60 ± 5.37
  Final Train: 98.89 ± 1.92
   Final Test: 54.83 ± 5.38
[I 2023-06-12 00:22:35,582] Trial 1034 finished with value: 54.59999465942383 and parameters: {'Fwd': 0.04978751616729349, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 6.242952329498909, 'loop': 2, 'loss': 'CE', 'lr': 0.009201814498299534, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.9864307281746365e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009989666475912864
weight_decay:  1.6304216822281983e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7015071851201355
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 02
None time:  1.0989233569707721
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  1.3776604980230331
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.60
run time now: 5.220268964767456
total time:  5.2834337670356035
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.87 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 71.83 ± 0.40
[I 2023-06-12 00:22:41,500] Trial 1035 finished with value: 74.86666870117188 and parameters: {'Fwd': 0.040698654175792805, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 5.747019477549731, 'loop': 2, 'loss': 'CE', 'lr': 0.009989666475912864, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6304216822281983e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00803521316058791
weight_decay:  1.5361995564985246e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8799805908929557
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 02
None time:  1.3612309249583632
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  0.8511962159536779
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.20
run time now: 4.134382963180542
total time:  4.178031384013593
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 69.07 ± 1.40
[I 2023-06-12 00:22:46,313] Trial 1036 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.047953412718945224, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 5.991372517062503, 'loop': 2, 'loss': 'CE', 'lr': 0.00803521316058791, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.5361995564985246e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0001005999437710431
weight_decay:  1.4905031879623084e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.9046, Train: 100.00%, Valid: 59.60% Test: 57.90%
Split: 01, Run: 01
None time:  3.4544041040353477
None Run 01:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 58.00
Split: 01, Run: 02
None time:  1.3555013360455632
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.80
Split: 01, Run: 03
None time:  1.3530010029207915
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.50
run time now: 6.211225509643555
total time:  6.275212356122211
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.87 ± 3.70
  Final Train: 100.00 ± 0.00
   Final Test: 61.77 ± 3.37
[I 2023-06-12 00:22:53,472] Trial 1037 finished with value: 63.866668701171875 and parameters: {'Fwd': 0.02451642517993552, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 5.797701851511046, 'loop': 2, 'loss': 'CE', 'lr': 0.0001005999437710431, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4905031879623084e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009267018039997604
weight_decay:  1.5108597468544091e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.4157471859361976
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  4.481910115107894
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  3.0480649899691343
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 10.988105535507202
total time:  11.044653550954536
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.65
[I 2023-06-12 00:23:05,272] Trial 1038 finished with value: 69.73332977294922 and parameters: {'Fwd': 0.03613666922200227, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 6.111549592462404, 'loop': 2, 'loss': 'CE', 'lr': 0.009267018039997604, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.5108597468544091e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.00011327257826226803
weight_decay:  1.829487774362947e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 1.0993, Train: 100.00%, Valid: 57.00% Test: 53.90%
Split: 01, Run: 01
None time:  2.365002977894619
None Run 01:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 53.90
Split: 01, Run: 02
None time:  1.2577998561318964
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.10
Split: 01, Run: 03
None time:  1.2919485801830888
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.70
run time now: 4.949656009674072
total time:  4.997001370880753
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.87 ± 4.23
  Final Train: 100.00 ± 0.00
   Final Test: 59.23 ± 4.69
[I 2023-06-12 00:23:11,097] Trial 1039 finished with value: 61.866668701171875 and parameters: {'Fwd': 0.04027052686222244, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 5.6976227285599235, 'loop': 1, 'loss': 'CE', 'lr': 0.00011327257826226803, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.829487774362947e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00041423731715688113
weight_decay:  2.0936554461982787e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9330748249776661
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 02
None time:  2.0914913199376315
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.364204114070162
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.430137395858765
total time:  6.4853606938850135
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.72
[I 2023-06-12 00:23:18,337] Trial 1040 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.04133570587317598, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 9.671678838338892, 'loop': 2, 'loss': 'CE', 'lr': 0.00041423731715688113, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.0936554461982787e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009968073675590144
weight_decay:  2.6185866885800547e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3945857000071555
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 71.10
Split: 01, Run: 02
None time:  1.806579353986308
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.382976933149621
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.40
run time now: 5.633774042129517
total time:  5.724421305116266
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.31
  Final Train: 99.44 ± 0.48
   Final Test: 71.50 ± 0.78
[I 2023-06-12 00:23:24,877] Trial 1041 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.03190030959108036, 'K': 2, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 5.882970159851872, 'loop': 2, 'loss': 'CE', 'lr': 0.009968073675590144, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.6185866885800547e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0014916640259883345
weight_decay:  2.2283753067647734e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.4735, Train: 100.00%, Valid: 69.40% Test: 67.00%
Split: 01, Run: 01
None time:  3.4349580330308527
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 02
None time:  1.832060483051464
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.6330811299849302
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.10
run time now: 6.940621614456177
total time:  6.9837095679249614
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 2.29
[I 2023-06-12 00:23:32,560] Trial 1042 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.06789325734745637, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 9.431511639130765, 'loop': 2, 'loss': 'CE', 'lr': 0.0014916640259883345, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2283753067647734e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0072929879639893475
weight_decay:  1.2773575202236623e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4389133660588413
None Run 01:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.70
Split: 01, Run: 02
None time:  1.3017612271942198
None Run 02:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 50.10
Split: 01, Run: 03
None time:  1.3406130720395595
None Run 03:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 43.50
run time now: 4.127812385559082
total time:  4.171501637203619
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.13 ± 7.67
  Final Train: 100.00 ± 0.00
   Final Test: 50.77 ± 7.62
[I 2023-06-12 00:23:37,428] Trial 1043 finished with value: 51.133331298828125 and parameters: {'Fwd': 0.04742656454657293, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 8.791764691320198, 'loop': 2, 'loss': 'CE', 'lr': 0.0072929879639893475, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2773575202236623e-05, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008577196698322895
weight_decay:  1.9592563538324585e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.4598, Train: 99.17%, Valid: 73.20% Test: 69.90%
Split: 01, Run: 01
None time:  3.2123277350328863
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.1866402619052678
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.1733262450434268
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 69.10
run time now: 5.611914157867432
total time:  5.664518485078588
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 0.70
[I 2023-06-12 00:23:43,867] Trial 1044 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.06637877671217518, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 6.29460764453146, 'loop': 2, 'loss': 'CE', 'lr': 0.008577196698322895, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.9592563538324585e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.0
lr:  0.009132690733544509
weight_decay:  1.2298002549735891e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9210708600003272
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 02
None time:  1.3275212759617716
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 03
None time:  1.1933800980914384
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.20
run time now: 4.487496376037598
total time:  4.543897311901674
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 0.46
  Final Train: 99.72 ± 0.48
   Final Test: 71.67 ± 0.64
[I 2023-06-12 00:23:49,115] Trial 1045 finished with value: 73.26666259765625 and parameters: {'Fwd': 0.051192907025635455, 'K': 4, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 9.099440792364042, 'loop': 2, 'loss': 'CE', 'lr': 0.009132690733544509, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2298002549735891e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.008026969411573697
weight_decay:  3.0332551101864776e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8741168470587581
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 98.33
   Final Test: 72.50
Split: 01, Run: 02
None time:  1.369434678927064
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 03
None time:  1.2774696331471205
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 4.5665602684021
total time:  4.618253955850378
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.73 ± 0.81
  Final Train: 99.44 ± 0.96
   Final Test: 71.67 ± 1.19
[I 2023-06-12 00:23:54,371] Trial 1046 finished with value: 72.73333740234375 and parameters: {'Fwd': 0.037194968534178245, 'K': 3, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 2.8155549849201633, 'loop': 2, 'loss': 'CE', 'lr': 0.008026969411573697, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.0332551101864776e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.005335123021966956
weight_decay:  1.3121828377656282e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7456147791817784
None Run 01:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.00
Split: 01, Run: 02
None time:  1.5836442930158228
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  1.985758249880746
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.50
run time now: 5.357384920120239
total time:  5.4064042628742754
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.67 ± 7.16
  Final Train: 100.00 ± 0.00
   Final Test: 66.97 ± 6.12
[I 2023-06-12 00:24:00,436] Trial 1047 finished with value: 68.66666412353516 and parameters: {'Fwd': 0.031508706760831465, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 9.351194100792489, 'loop': 2, 'loss': 'CE', 'lr': 0.005335123021966956, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3121828377656282e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00917628478752733
weight_decay:  1.6855697323152618e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.511570437112823
None Run 01:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 99.17
   Final Test: 71.90
Split: 01, Run: 02
None time:  1.4132506621535867
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  1.3044156979303807
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.40
run time now: 5.271836996078491
total time:  5.319457466015592
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.00 ± 0.53
  Final Train: 99.72 ± 0.48
   Final Test: 71.63 ± 0.25
[I 2023-06-12 00:24:06,446] Trial 1048 finished with value: 75.0 and parameters: {'Fwd': 0.029839681265685633, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 8.10622743761503, 'loop': 2, 'loss': 'CE', 'lr': 0.00917628478752733, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6855697323152618e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0008579012340775799
weight_decay:  1.8600449687437076e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2734, Train: 99.17%, Valid: 62.20% Test: 61.50%
Split: 01, Run: 01
None time:  3.4542804600205272
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 99.17
   Final Test: 61.50
Split: 01, Run: 02
None time:  1.6135764149948955
None Run 02:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 62.70
Split: 01, Run: 03
None time:  1.7124650098849088
None Run 03:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 62.30
run time now: 6.819942951202393
total time:  6.864336344180629
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.80 ± 0.53
  Final Train: 99.72 ± 0.48
   Final Test: 62.17 ± 0.61
[I 2023-06-12 00:24:13,935] Trial 1049 finished with value: 62.79999923706055 and parameters: {'Fwd': 0.03967268026465816, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 8.27487704078919, 'loop': 2, 'loss': 'CE', 'lr': 0.0008579012340775799, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.8600449687437076e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0005204778213437111
weight_decay:  1.7579668574150542e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0537201629485935
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.30
Split: 01, Run: 02
None time:  1.3521482411306351
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  1.882634743815288
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 99.17
   Final Test: 69.80
run time now: 5.332414865493774
total time:  5.381819142028689
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.73 ± 2.57
  Final Train: 99.72 ± 0.48
   Final Test: 66.57 ± 3.86
[I 2023-06-12 00:24:20,073] Trial 1050 finished with value: 67.73333740234375 and parameters: {'Fwd': 0.0266708245812076, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 9.769719982154399, 'loop': 2, 'loss': 'CE', 'lr': 0.0005204778213437111, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7579668574150542e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007302708786769894
weight_decay:  1.0133405823801516e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.852718705078587
None Run 01:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 47.50
Split: 01, Run: 02
None time:  2.4571238001808524
None Run 02:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 59.20
Split: 01, Run: 03
None time:  1.4239899879321456
None Run 03:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 60.80
run time now: 5.786933183670044
total time:  5.836548506980762
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.93 ± 7.62
  Final Train: 100.00 ± 0.00
   Final Test: 55.83 ± 7.26
[I 2023-06-12 00:24:26,478] Trial 1051 finished with value: 54.93333435058594 and parameters: {'Fwd': 0.01864002403559792, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.45, 'lambda2': 5.68823745033901, 'loop': 2, 'loss': 'MSE', 'lr': 0.007302708786769894, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0133405823801516e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.5
lr:  0.0023310700324456653
weight_decay:  2.885818816227689e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.99046260304749
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 72.50
Split: 01, Run: 02
None time:  1.6106990091502666
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.2396461891476065
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 68.60
run time now: 5.882908821105957
total time:  5.93075482500717
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.40 ± 0.69
  Final Train: 99.44 ± 0.48
   Final Test: 70.30 ± 2.00
[I 2023-06-12 00:24:33,033] Trial 1052 finished with value: 74.4000015258789 and parameters: {'Fwd': 0.02480179680716187, 'K': 1, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 8.625543726850042, 'loop': 2, 'loss': 'CE', 'lr': 0.0023310700324456653, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.885818816227689e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9500000000000001
lr:  0.0001981801567213441
weight_decay:  1.4036010314061231e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9030280478764325
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.90
Split: 01, Run: 02
None time:  1.5736129411961883
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 65.30
Split: 01, Run: 03
None time:  1.752754407003522
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 64.00
run time now: 5.275963544845581
total time:  5.324373519979417
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.40 ± 1.60
  Final Train: 100.00 ± 0.00
   Final Test: 65.07 ± 0.97
[I 2023-06-12 00:24:38,970] Trial 1053 finished with value: 66.4000015258789 and parameters: {'Fwd': 0.03931555042474794, 'K': 1, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.05, 'lambda2': 8.38167466392678, 'loop': 2, 'loss': 'CE', 'lr': 0.0001981801567213441, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.4036010314061231e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.00044903794534456245
weight_decay:  1.2380039879388154e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.117941793985665
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 02
None time:  1.3038706530351192
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.9414976451080292
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 70.00
run time now: 5.4080634117126465
total time:  5.455619283951819
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.87 ± 0.76
  Final Train: 99.72 ± 0.48
   Final Test: 68.07 ± 1.90
[I 2023-06-12 00:24:45,032] Trial 1054 finished with value: 68.86666107177734 and parameters: {'Fwd': 0.039024369450116975, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 5.999421993924327, 'loop': 2, 'loss': 'CE', 'lr': 0.00044903794534456245, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2380039879388154e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.006522765553965362
weight_decay:  1.0501178150673053e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.432285172166303
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.2918023010715842
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  1.3737987279891968
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.70
run time now: 5.235471248626709
total time:  5.318229773081839
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 68.77 ± 1.00
[I 2023-06-12 00:24:50,939] Trial 1055 finished with value: 72.39999389648438 and parameters: {'Fwd': 0.033302819496032705, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 9.032592256209764, 'loop': 2, 'loss': 'CE', 'lr': 0.006522765553965362, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0501178150673053e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008063747261973005
weight_decay:  6.873066645529286e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.5132725609000772
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 97.50
   Final Test: 72.00
Split: 01, Run: 02
None time:  1.0878194670658559
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 03
None time:  1.4362317079212517
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.074932098388672
total time:  6.122348642209545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 0.12
  Final Train: 99.17 ± 1.44
   Final Test: 69.53 ± 2.86
[I 2023-06-12 00:24:57,667] Trial 1056 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.07554117373427717, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 5.559653342065674, 'loop': 2, 'loss': 'CE', 'lr': 0.008063747261973005, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.873066645529286e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.004394120862008161
weight_decay:  2.1800106514861992e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.162117784144357
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 02
None time:  1.2419742159545422
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 63.10
Split: 01, Run: 03
None time:  1.3898290798533708
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 67.00
run time now: 5.839934825897217
total time:  5.886837644968182
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 65.93 ± 2.48
[I 2023-06-12 00:25:04,248] Trial 1057 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.022636575387152722, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.5, 'lambda2': 9.571321941711338, 'loop': 2, 'loss': 'CE', 'lr': 0.004394120862008161, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.1800106514861992e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0016367060083406328
weight_decay:  1.5268295414521255e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6617922079749405
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  4.446890885010362
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  4.132879612967372
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 11.285921573638916
total time:  11.332289001904428
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.12
[I 2023-06-12 00:25:16,193] Trial 1058 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.0001973170105809999, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 6.313363520313061, 'loop': 2, 'loss': 'CE', 'lr': 0.0016367060083406328, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.5268295414521255e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.008682926681060469
weight_decay:  0.011008977005775559
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.335845615947619
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.4699067939072847
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.5492230621166527
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 5.414776563644409
total time:  5.4741509719751775
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 1.15
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.53
[I 2023-06-12 00:25:22,350] Trial 1059 finished with value: 72.53333282470703 and parameters: {'Fwd': 0.026445033471953712, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.1, 'lambda2': 8.06862248598432, 'loop': 2, 'loss': 'CE', 'lr': 0.008682926681060469, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.011008977005775559, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009072657690128254
weight_decay:  0.021173708744454164
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0396127260755748
None Run 01:
Highest Train: 100.00
Highest Valid: 37.60
  Final Train: 100.00
   Final Test: 37.40
Split: 01, Run: 02
None time:  2.0972401099279523
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 88.33
   Final Test: 67.70
Split: 01, Run: 03
None time:  1.3285436320584267
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 63.00
run time now: 4.514962196350098
total time:  4.565539048053324
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.47 ± 17.23
  Final Train: 96.11 ± 6.74
   Final Test: 56.03 ± 16.31
[I 2023-06-12 00:25:27,557] Trial 1060 finished with value: 57.4666633605957 and parameters: {'Fwd': 1.0536820831715677e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 2.50226256373135, 'loop': 2, 'loss': 'CE', 'lr': 0.009072657690128254, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.021173708744454164, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00013693720969631118
weight_decay:  3.851592811873856e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8451805310323834
None Run 01:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 45.50
Split: 01, Run: 02
None time:  1.3246724631171674
None Run 02:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 46.70
Split: 01, Run: 03
None time:  1.1048880079761147
None Run 03:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 48.00
run time now: 5.316404581069946
total time:  5.367506176931784
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.33 ± 1.68
  Final Train: 100.00 ± 0.00
   Final Test: 46.73 ± 1.25
[I 2023-06-12 00:25:33,557] Trial 1061 finished with value: 49.33333206176758 and parameters: {'Fwd': 0.046647303746190215, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 8.94303336816891, 'loop': 2, 'loss': 'CE', 'lr': 0.00013693720969631118, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.851592811873856e-05, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.004753230906902856
weight_decay:  1.829088690259872e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 1.1036, Train: 100.00%, Valid: 50.60% Test: 50.00%
Split: 01, Run: 01
None time:  3.4163629340473562
None Run 01:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.80
Split: 01, Run: 02, Epoch: 100, Loss: 1.1401, Train: 100.00%, Valid: 50.60% Test: 50.00%
Split: 01, Run: 02
None time:  3.4802131068427116
None Run 02:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.80
Split: 01, Run: 03, Epoch: 100, Loss: 1.1120, Train: 100.00%, Valid: 50.60% Test: 50.00%
Split: 01, Run: 03
None time:  3.471283172024414
None Run 03:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.80
run time now: 10.407744884490967
total time:  10.463386092102155
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 49.80 ± 0.00
[I 2023-06-12 00:25:44,744] Trial 1062 finished with value: 50.59999465942383 and parameters: {'Fwd': 0.056302004015525625, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.0, 'lambda2': 9.32873634352384, 'loop': 2, 'loss': 'CE', 'lr': 0.004753230906902856, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.829088690259872e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.65
lr:  0.007420197208271416
weight_decay:  2.373563582208691e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8693465739488602
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  1.6834626940544695
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.4530468920711428
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 5.045778512954712
total time:  5.094279879005626
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.23
  Final Train: 99.72 ± 0.48
   Final Test: 69.10 ± 0.66
[I 2023-06-12 00:25:50,476] Trial 1063 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.03452007587788289, 'K': 2, 'alpha': 0.65, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.5, 'lambda2': 6.607309442919042, 'loop': 2, 'loss': 'CE', 'lr': 0.007420197208271416, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.373563582208691e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0031205019973093245
weight_decay:  5.1502221360475884e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6809978240635246
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.4801214078906924
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.2806506478227675
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 62.00
run time now: 5.486119270324707
total time:  5.533618075074628
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 0.60
  Final Train: 99.17 ± 0.83
   Final Test: 67.10 ± 4.46
[I 2023-06-12 00:25:56,766] Trial 1064 finished with value: 72.4000015258789 and parameters: {'Fwd': 0.029717538860027103, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 8.489382405886575, 'loop': 2, 'loss': 'CE', 'lr': 0.0031205019973093245, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.1502221360475884e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008229260073783646
weight_decay:  0.0010289530376341545
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 98.33%, Valid: 68.20% Test: 68.70%
Split: 01, Run: 01
None time:  1.3718772260472178
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 99.17
   Final Test: 68.70
Split: 01, Run: 02
None time:  0.9258490370120853
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 96.67
   Final Test: 63.70
Split: 01, Run: 03
None time:  1.2508333518635482
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.00
   Final Test: 67.50
run time now: 3.5883383750915527
total time:  3.632336324080825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.00 ± 0.72
  Final Train: 96.94 ± 2.10
   Final Test: 66.63 ± 2.61
[I 2023-06-12 00:26:01,087] Trial 1065 finished with value: 68.0 and parameters: {'Fwd': 0.02253699306320227, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 2.2358203644791974, 'loop': 0, 'loss': 'CE', 'lr': 0.008229260073783646, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0010289530376341545, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.005932831587250201
weight_decay:  0.0001649741176941426
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1119669368490577
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 99.17
   Final Test: 70.70
Split: 01, Run: 02
None time:  1.5752466330304742
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 65.90
Split: 01, Run: 03
None time:  1.3576688070315868
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.80
run time now: 6.081603765487671
total time:  6.130645994096994
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.13 ± 0.31
  Final Train: 99.72 ± 0.48
   Final Test: 69.13 ± 2.80
[I 2023-06-12 00:26:07,841] Trial 1066 finished with value: 74.13333129882812 and parameters: {'Fwd': 0.0001476137176158567, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 6.026077094957939, 'loop': 2, 'loss': 'CE', 'lr': 0.005932831587250201, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001649741176941426, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.001052526599958181
weight_decay:  1.6176663027991795e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6582498589996248
None Run 01:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 55.80
Split: 01, Run: 02
None time:  3.4433751839678735
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  2.3016727298963815
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.00
run time now: 7.444145202636719
total time:  7.488322722958401
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.80 ± 9.09
  Final Train: 100.00 ± 0.00
   Final Test: 63.93 ± 7.11
[I 2023-06-12 00:26:16,033] Trial 1067 finished with value: 63.79999923706055 and parameters: {'Fwd': 0.030559475728126267, 'K': 2, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 9.787685577392171, 'loop': 2, 'loss': 'CE', 'lr': 0.001052526599958181, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6176663027991795e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00918332144260581
weight_decay:  0.00011330525013567331
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8620741569902748
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 95.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.3300405361223966
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 67.60
Split: 01, Run: 03
None time:  1.1268514308612794
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 66.70
run time now: 4.360630035400391
total time:  4.408468212001026
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 1.73
  Final Train: 98.06 ± 2.68
   Final Test: 67.10 ± 0.46
[I 2023-06-12 00:26:21,119] Trial 1068 finished with value: 72.0 and parameters: {'Fwd': 0.016363367754439966, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 1.9608174693992453, 'loop': 2, 'loss': 'CE', 'lr': 0.00918332144260581, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011330525013567331, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0067963178811485895
weight_decay:  0.00025164159737001645
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5526982080191374
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 70.70
Split: 01, Run: 02
None time:  2.3567903449293226
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.221840641926974
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.10
run time now: 6.17104697227478
total time:  6.217438343912363
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.69
  Final Train: 99.44 ± 0.48
   Final Test: 70.20 ± 0.95
[I 2023-06-12 00:26:28,028] Trial 1069 finished with value: 73.4000015258789 and parameters: {'Fwd': 0.010632032732022165, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 9.219813176435734, 'loop': 2, 'loss': 'CE', 'lr': 0.0067963178811485895, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00025164159737001645, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007957765795778343
weight_decay:  2.4020771770564933e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2502934709191322
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 02
None time:  1.4219915170688182
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.283675218001008
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 4.993941783905029
total time:  5.042040358996019
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 1.31
[I 2023-06-12 00:26:33,775] Trial 1070 finished with value: 72.53333282470703 and parameters: {'Fwd': 0.06357309288409174, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 8.701155601376643, 'loop': 2, 'loss': 'CE', 'lr': 0.007957765795778343, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.4020771770564933e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.00018843854417241663
weight_decay:  0.00035457250050009134
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6643557010684162
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 61.30
Split: 01, Run: 02
None time:  1.322432277025655
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 64.20
Split: 01, Run: 03
None time:  1.29558957205154
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 64.00
run time now: 4.320116996765137
total time:  4.364986461121589
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.47 ± 3.74
  Final Train: 100.00 ± 0.00
   Final Test: 63.17 ± 1.62
[I 2023-06-12 00:26:38,783] Trial 1071 finished with value: 66.46666717529297 and parameters: {'Fwd': 0.00024526164108179565, 'K': 3, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 8.20096429887707, 'loop': 2, 'loss': 'CE', 'lr': 0.00018843854417241663, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00035457250050009134, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.004005512961474762
weight_decay:  0.0007107464628239869
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3140075840055943
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  2.5242727280128747
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  2.802827188046649
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.10
run time now: 7.691400527954102
total time:  7.741486817132682
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 70.87 ± 1.57
[I 2023-06-12 00:26:47,201] Trial 1072 finished with value: 71.13333129882812 and parameters: {'Fwd': 0.0001628953702811092, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.1, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 2.7169103491054436, 'loop': 2, 'loss': 'MSE', 'lr': 0.004005512961474762, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007107464628239869, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.002782462460927381
weight_decay:  7.696559212173351e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.191032957052812
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.3946810050401837
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 03
None time:  1.260388445109129
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 64.90
run time now: 4.892897844314575
total time:  4.943928193999454
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 67.23 ± 2.64
[I 2023-06-12 00:26:52,785] Trial 1073 finished with value: 70.33333587646484 and parameters: {'Fwd': 7.149599206751198e-05, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 9.513055366456673, 'loop': 2, 'loss': 'CE', 'lr': 0.002782462460927381, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.696559212173351e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0003707852640867438
weight_decay:  0.0004589220301901026
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.39492831309326
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 02
None time:  1.7444179391022772
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.2259668027982116
None Run 03:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.40
run time now: 5.406146764755249
total time:  5.458746719872579
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.40 ± 2.43
  Final Train: 100.00 ± 0.00
   Final Test: 67.33 ± 2.64
[I 2023-06-12 00:26:58,867] Trial 1074 finished with value: 69.4000015258789 and parameters: {'Fwd': 9.137502111262205e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 5.411353393916348, 'loop': 2, 'loss': 'CE', 'lr': 0.0003707852640867438, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004589220301901026, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.001261735781015868
weight_decay:  9.228143087682103e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6613198339473456
None Run 01:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 58.60
Split: 01, Run: 02
None time:  2.621588190086186
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 97.50
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.2894985179882497
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 62.30
run time now: 5.6192567348480225
total time:  5.667402297956869
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.40 ± 7.00
  Final Train: 99.17 ± 1.44
   Final Test: 63.40 ± 5.43
[I 2023-06-12 00:27:05,149] Trial 1075 finished with value: 67.4000015258789 and parameters: {'Fwd': 2.0136855897869632e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 6.8426611982913235, 'loop': 2, 'loss': 'CE', 'lr': 0.001261735781015868, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.228143087682103e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009194153443918687
weight_decay:  0.00013698602791118936
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.501998264808208
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  5.493226289050654
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 03
None time:  2.425268505932763
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.00
run time now: 12.462869644165039
total time:  12.508790462044999
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 1.86
  Final Train: 99.44 ± 0.48
   Final Test: 70.50 ± 0.50
[I 2023-06-12 00:27:18,305] Trial 1076 finished with value: 71.33332824707031 and parameters: {'Fwd': 0.04534870016375468, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 3.0309874321306243, 'loop': 2, 'loss': 'CE', 'lr': 0.009194153443918687, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013698602791118936, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00022764327027091676
weight_decay:  0.015371108013438656
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.455107521964237
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 95.83
   Final Test: 67.40
Split: 01, Run: 02
None time:  1.1150164420250803
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.3954197650309652
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 68.10
run time now: 5.044674873352051
total time:  5.10483861900866
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 0.76
  Final Train: 98.33 ± 2.20
   Final Test: 68.13 ± 0.75
[I 2023-06-12 00:27:24,329] Trial 1077 finished with value: 69.86666870117188 and parameters: {'Fwd': 4.500809326652527e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 1.6154287711167097, 'loop': 1, 'loss': 'CE', 'lr': 0.00022764327027091676, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.015371108013438656, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008306256982595805
weight_decay:  0.00019115237236987508
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9831273809541017
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.5901052809786052
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.1226404840126634
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 68.80
run time now: 4.744623422622681
total time:  4.795182281173766
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.93 ± 0.64
  Final Train: 99.72 ± 0.48
   Final Test: 69.73 ± 0.81
[I 2023-06-12 00:27:29,807] Trial 1078 finished with value: 73.93333435058594 and parameters: {'Fwd': 3.837439999063548e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 7.77134628716462, 'loop': 2, 'loss': 'CE', 'lr': 0.008306256982595805, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019115237236987508, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0005516450339665695
weight_decay:  3.398049475975451e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.700513324001804
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 02
None time:  2.9188966390211135
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 72.50
Split: 01, Run: 03
None time:  1.4615898951888084
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.80
run time now: 6.123015880584717
total time:  6.166810730937868
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 2.27
  Final Train: 99.72 ± 0.48
   Final Test: 70.73 ± 3.32
[I 2023-06-12 00:27:36,551] Trial 1079 finished with value: 71.0 and parameters: {'Fwd': 0.004826160186536702, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.91857869341372, 'loop': 2, 'loss': 'CE', 'lr': 0.0005516450339665695, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.398049475975451e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007442719915451733
weight_decay:  1.1370877514881119e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.228773657931015
None Run 01:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 52.20
Split: 01, Run: 02
None time:  1.232343640876934
None Run 02:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 48.00
Split: 01, Run: 03
None time:  1.1702706718351692
None Run 03:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 45.80
run time now: 3.6737406253814697
total time:  3.7256875729653984
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 46.33 ± 4.94
  Final Train: 100.00 ± 0.00
   Final Test: 48.67 ± 3.25
[I 2023-06-12 00:27:40,904] Trial 1080 finished with value: 46.33333206176758 and parameters: {'Fwd': 0.0007499357143637015, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 9.998241703079001, 'loop': 2, 'loss': 'CE', 'lr': 0.007442719915451733, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1370877514881119e-05, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00918982288498738
weight_decay:  0.04702748073306739
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5980414471123368
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.4759142519906163
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  1.5779851151164621
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.50
run time now: 5.7005228996276855
total time:  5.753886207006872
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.33 ± 1.15
  Final Train: 99.72 ± 0.48
   Final Test: 70.87 ± 0.78
[I 2023-06-12 00:27:47,426] Trial 1081 finished with value: 73.33333587646484 and parameters: {'Fwd': 2.769537310442689e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 9.652230983857955, 'loop': 2, 'loss': 'CE', 'lr': 0.00918982288498738, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.04702748073306739, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008559221991946104
weight_decay:  1.6135733618372075e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1118375619407743
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.3794951878953725
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  1.292183408048004
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 67.30
run time now: 4.824573278427124
total time:  4.87002046382986
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.07 ± 0.23
  Final Train: 99.72 ± 0.48
   Final Test: 68.07 ± 1.69
[I 2023-06-12 00:27:52,994] Trial 1082 finished with value: 73.06666564941406 and parameters: {'Fwd': 5.625453752742962e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 6.445699220956025, 'loop': 2, 'loss': 'CE', 'lr': 0.008559221991946104, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6135733618372075e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.001788208849651512
weight_decay:  0.0029989353678652676
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5307738499250263
None Run 01:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 56.10
Split: 01, Run: 02
None time:  2.3634606669656932
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 70.60
Split: 01, Run: 03
None time:  2.533441766863689
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.90
run time now: 6.475287437438965
total time:  6.521448416868225
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.73 ± 6.71
  Final Train: 99.44 ± 0.48
   Final Test: 66.20 ± 8.77
[I 2023-06-12 00:28:00,097] Trial 1083 finished with value: 68.73332977294922 and parameters: {'Fwd': 0.06070734969997859, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 6.172302020293134, 'loop': 2, 'loss': 'CE', 'lr': 0.001788208849651512, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0029989353678652676, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.00010718938082774153
weight_decay:  0.0014389782332042732
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 1.0177, Train: 99.17%, Valid: 62.40% Test: 60.50%
Split: 01, Run: 01
None time:  3.4286654200404882
None Run 01:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 99.17
   Final Test: 59.90
Split: 01, Run: 02
None time:  1.1616250111255795
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  1.3881573711987585
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.10
run time now: 6.030185222625732
total time:  6.095004301983863
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.13 ± 4.80
  Final Train: 99.72 ± 0.48
   Final Test: 64.93 ± 4.41
[I 2023-06-12 00:28:06,778] Trial 1084 finished with value: 68.13333129882812 and parameters: {'Fwd': 1.3877748337546394e-06, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 7.638936471459757, 'loop': 2, 'loss': 'CE', 'lr': 0.00010718938082774153, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0014389782332042732, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.6000000000000001
lr:  0.009981412985249837
weight_decay:  0.002116586600288522
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0439559498336166
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 02
None time:  1.2445828840136528
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 03
None time:  1.7454761089757085
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 5.078090190887451
total time:  5.142205322161317
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 2.48
[I 2023-06-12 00:28:12,585] Trial 1085 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.0008796448319309559, 'K': 1, 'alpha': 0.6000000000000001, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 8.087224545961803, 'loop': 2, 'loss': 'CE', 'lr': 0.009981412985249837, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002116586600288522, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0013498386551776184
weight_decay:  5.869814168007808e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.870604817988351
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 02
None time:  1.889026700053364
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.2093426540959626
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.70
run time now: 5.010142087936401
total time:  5.053660820005462
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 2.60
  Final Train: 99.72 ± 0.48
   Final Test: 68.73 ± 1.65
[I 2023-06-12 00:28:18,414] Trial 1086 finished with value: 70.4000015258789 and parameters: {'Fwd': 3.3349125273414806e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 9.178128230482033, 'loop': 2, 'loss': 'CE', 'lr': 0.0013498386551776184, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.869814168007808e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.00856075739444257
weight_decay:  0.00010713087253274496
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.013129716971889
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 72.00
Split: 01, Run: 02
None time:  1.3979843829292804
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.1991532400716096
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.60
run time now: 4.659392833709717
total time:  4.717335992027074
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.80 ± 0.40
  Final Train: 99.72 ± 0.48
   Final Test: 71.47 ± 0.61
[I 2023-06-12 00:28:23,805] Trial 1087 finished with value: 73.79999542236328 and parameters: {'Fwd': 2.441183294118108e-06, 'K': 3, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 5.872182164988269, 'loop': 2, 'loss': 'CE', 'lr': 0.00856075739444257, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010713087253274496, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009972948048085422
weight_decay:  0.000868845869725237
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.199269566917792
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.2101240018382668
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 03
None time:  1.177103002090007
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 68.50
run time now: 4.648413419723511
total time:  4.699428917141631
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 0.92
  Final Train: 99.72 ± 0.48
   Final Test: 68.20 ± 1.87
[I 2023-06-12 00:28:29,121] Trial 1088 finished with value: 73.26666259765625 and parameters: {'Fwd': 0.00011439854540673182, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 6.958240797283715, 'loop': 2, 'loss': 'CE', 'lr': 0.009972948048085422, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000868845869725237, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0050786041845436655
weight_decay:  1.9848673847677995e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6655845479108393
None Run 01:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 55.00
Split: 01, Run: 02
None time:  1.187941465061158
None Run 02:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 59.70
Split: 01, Run: 03
None time:  1.164391860133037
None Run 03:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 67.20
run time now: 4.064162731170654
total time:  4.112874537007883
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.27 ± 5.16
  Final Train: 100.00 ± 0.00
   Final Test: 60.63 ± 6.15
[I 2023-06-12 00:28:33,783] Trial 1089 finished with value: 59.26667404174805 and parameters: {'Fwd': 0.017160370907929785, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 2.824400744484455, 'loop': 1, 'loss': 'MSE', 'lr': 0.0050786041845436655, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.9848673847677995e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.007595364276090219
weight_decay:  0.0640261891180484
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0978500680066645
None Run 01:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 52.60
Split: 01, Run: 02
None time:  1.1528063411824405
None Run 02:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 99.17
   Final Test: 51.10
Split: 01, Run: 03
None time:  1.1024241789709777
None Run 03:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 95.00
   Final Test: 49.60
run time now: 3.393644332885742
total time:  3.4383778530173004
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.27 ± 0.61
  Final Train: 98.06 ± 2.68
   Final Test: 51.10 ± 1.50
[I 2023-06-12 00:28:37,786] Trial 1090 finished with value: 53.266666412353516 and parameters: {'Fwd': 0.001145236044680831, 'K': 2, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 5.6023586494521025, 'loop': 2, 'loss': 'CE', 'lr': 0.007595364276090219, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0640261891180484, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009145045608221773
weight_decay:  0.0005418411803562321
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7139393012039363
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 02
None time:  1.2802920748945326
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.2837615578901023
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.80
run time now: 5.329634666442871
total time:  5.377439063973725
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 0.42
  Final Train: 99.72 ± 0.48
   Final Test: 71.13 ± 0.76
[I 2023-06-12 00:28:43,897] Trial 1091 finished with value: 73.26666259765625 and parameters: {'Fwd': 0.045633108174989494, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 9.376068622678837, 'loop': 2, 'loss': 'CE', 'lr': 0.009145045608221773, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005418411803562321, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.002944568960189292
weight_decay:  8.88645878492744e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.104085264960304
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 67.10
Split: 01, Run: 02
None time:  1.8284147528465837
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.3935880230274051
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 63.70
run time now: 5.368136882781982
total time:  5.428568774834275
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.35
  Final Train: 99.72 ± 0.48
   Final Test: 66.43 ± 2.47
[I 2023-06-12 00:28:50,096] Trial 1092 finished with value: 70.20000457763672 and parameters: {'Fwd': 4.136418455196829e-05, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 7.304002593057286, 'loop': 2, 'loss': 'CE', 'lr': 0.002944568960189292, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.88645878492744e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.003308279845223221
weight_decay:  0.00028000620671277
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.105667272116989
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 92.50
   Final Test: 63.70
Split: 01, Run: 02
None time:  1.1038287528790534
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 57.50
Split: 01, Run: 03
None time:  1.101750735891983
None Run 03:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 54.90
run time now: 4.361756086349487
total time:  4.448204981163144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.07 ± 1.21
  Final Train: 97.50 ± 4.33
   Final Test: 58.70 ± 4.52
[I 2023-06-12 00:28:55,253] Trial 1093 finished with value: 65.06666564941406 and parameters: {'Fwd': 0.0003367431681537964, 'K': 2, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 3.3033945036349324, 'loop': 2, 'loss': 'CE', 'lr': 0.003308279845223221, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00028000620671277, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0015867741302573837
weight_decay:  0.0001374875228717922
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.660747722024098
None Run 01:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 99.17
   Final Test: 63.00
Split: 01, Run: 02
None time:  1.8934196049813181
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 99.17
   Final Test: 67.30
Split: 01, Run: 03
None time:  1.2392859729006886
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 61.80
run time now: 5.835146427154541
total time:  5.893485907930881
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.13 ± 2.95
  Final Train: 99.44 ± 0.48
   Final Test: 64.03 ± 2.89
[I 2023-06-12 00:29:01,735] Trial 1094 finished with value: 67.13333129882812 and parameters: {'Fwd': 0.012270264101169064, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 8.75991397073968, 'loop': 2, 'loss': 'CE', 'lr': 0.0015867741302573837, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001374875228717922, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.006886813600473717
weight_decay:  4.554492722182452e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9704299790319055
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  4.199145861901343
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 94.17
   Final Test: 70.40
Split: 01, Run: 03
None time:  3.7364703621715307
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 97.50
   Final Test: 71.10
run time now: 10.966389656066895
total time:  11.084054068895057
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.12
  Final Train: 96.94 ± 2.55
   Final Test: 70.57 ± 0.47
[I 2023-06-12 00:29:13,472] Trial 1095 finished with value: 71.73332977294922 and parameters: {'Fwd': 1.7945553308198496e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 2.4243167312603386, 'loop': 2, 'loss': 'CE', 'lr': 0.006886813600473717, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.554492722182452e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0011481332872545658
weight_decay:  2.549151099355788e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0795538199599832
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  2.8151461130473763
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  2.043618965893984
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.9807047843933105
total time:  7.040370885981247
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.67 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 70.63 ± 0.67
[I 2023-06-12 00:29:21,134] Trial 1096 finished with value: 72.66666412353516 and parameters: {'Fwd': 0.07868448531935628, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 8.503226096835126, 'loop': 2, 'loss': 'CE', 'lr': 0.0011481332872545658, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.549151099355788e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.008035664193943835
weight_decay:  1.202377039965913e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9429786698892713
None Run 01:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 46.90
Split: 01, Run: 02
None time:  1.0791100969072431
None Run 02:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 35.10
Split: 01, Run: 03
None time:  1.065216263057664
None Run 03:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 40.30
run time now: 3.129671573638916
total time:  3.18073064298369
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 40.00 ± 5.57
  Final Train: 100.00 ± 0.00
   Final Test: 40.77 ± 5.91
[I 2023-06-12 00:29:24,939] Trial 1097 finished with value: 40.0 and parameters: {'Fwd': 0.02454482836495367, 'K': 1, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 6.6049735430192165, 'loop': 2, 'loss': 'CE', 'lr': 0.008035664193943835, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.202377039965913e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0008992512974496231
weight_decay:  6.668180438578749e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.2036199800204486
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 87.50
   Final Test: 70.70
Split: 01, Run: 02
None time:  1.1707173080649227
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.2467141409870237
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 68.60
run time now: 5.663976430892944
total time:  5.721178225940093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 1.25
  Final Train: 95.83 ± 7.22
   Final Test: 69.37 ± 1.16
[I 2023-06-12 00:29:31,352] Trial 1098 finished with value: 71.79999542236328 and parameters: {'Fwd': 1.615196734574793e-06, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 1.7864493718291987, 'loop': 2, 'loss': 'CE', 'lr': 0.0008992512974496231, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.668180438578749e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.5
lr:  0.00031739469314126366
weight_decay:  9.209163112768168e-06
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7550556191708893
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.5948017148766667
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  1.4917998521123081
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.40
run time now: 4.87922739982605
total time:  4.932304835878313
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 68.20 ± 0.20
[I 2023-06-12 00:29:36,890] Trial 1099 finished with value: 69.26666259765625 and parameters: {'Fwd': 0.015137126316124452, 'K': 1, 'alpha': 0.5, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 8.331992338154741, 'loop': 2, 'loss': 'CE', 'lr': 0.00031739469314126366, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.209163112768168e-06, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0008244432098624608
weight_decay:  0.00827601460532852
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.330175095004961
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  2.2374967630021274
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 73.10
Split: 01, Run: 03
None time:  2.0226772408932447
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 72.60
run time now: 6.633893966674805
total time:  6.691725666867569
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 1.22
  Final Train: 99.44 ± 0.48
   Final Test: 72.13 ± 1.27
[I 2023-06-12 00:29:44,223] Trial 1100 finished with value: 72.79999542236328 and parameters: {'Fwd': 0.03135415745402539, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.496907182603523, 'loop': 2, 'loss': 'CE', 'lr': 0.0008244432098624608, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00827601460532852, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0023880736700182693
weight_decay:  0.00020150880642344696
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7096816790290177
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  2.0544101879931986
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  1.2198400311172009
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.027840614318848
total time:  6.083946380997077
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.67 ± 0.81
[I 2023-06-12 00:29:50,973] Trial 1101 finished with value: 72.0666732788086 and parameters: {'Fwd': 0.0006131244912535176, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.088429498626015, 'loop': 2, 'loss': 'CE', 'lr': 0.0023880736700182693, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00020150880642344696, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.009996709777235416
weight_decay:  0.0012067090658666123
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.995908556971699
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 02
None time:  1.3316096919588745
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 63.90
Split: 01, Run: 03
None time:  1.404451996088028
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 4.769821882247925
total time:  4.822761805029586
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 66.63 ± 2.86
[I 2023-06-12 00:29:56,500] Trial 1102 finished with value: 70.26667022705078 and parameters: {'Fwd': 2.653493632949782e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 9.688264397713874, 'loop': 2, 'loss': 'CE', 'lr': 0.009996709777235416, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0012067090658666123, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0002575907083791141
weight_decay:  1.6270729785710184e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9287061288487166
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 02
None time:  1.4538714590016752
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  3.075974402949214
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 6.503200531005859
total time:  6.550049188081175
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 1.17
  Final Train: 100.00 ± 0.00
   Final Test: 68.93 ± 2.10
[I 2023-06-12 00:30:03,625] Trial 1103 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.02058247792212789, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 9.4422465142544, 'loop': 2, 'loss': 'CE', 'lr': 0.0002575907083791141, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6270729785710184e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.008799152889279882
weight_decay:  8.28291251707117e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.453336485894397
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 98.33
   Final Test: 64.10
Split: 01, Run: 02
None time:  1.2799867349676788
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.2918152031488717
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 4.066436529159546
total time:  4.112232472049072
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 3.42
  Final Train: 99.44 ± 0.96
   Final Test: 67.57 ± 3.01
[I 2023-06-12 00:30:08,361] Trial 1104 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.009796561575502077, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 3.060579586903128, 'loop': 2, 'loss': 'CE', 'lr': 0.008799152889279882, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.28291251707117e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.006425768943417951
weight_decay:  0.00016496775417525563
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8802092249970883
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 90.83
   Final Test: 63.10
Split: 01, Run: 02
None time:  2.0207172189839184
None Run 02:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 93.33
   Final Test: 65.60
Split: 01, Run: 03
None time:  1.282409547129646
None Run 03:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 62.60
run time now: 5.223643064498901
total time:  5.2750156139954925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.00 ± 0.72
  Final Train: 94.72 ± 4.74
   Final Test: 63.77 ± 1.61
[I 2023-06-12 00:30:14,251] Trial 1105 finished with value: 63.0 and parameters: {'Fwd': 0.0012527780843835845, 'K': 1, 'alpha': 0.0, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.65, 'lambda2': 5.945172705147423, 'loop': 2, 'loss': 'CE', 'lr': 0.006425768943417951, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00016496775417525563, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00909761551505021
weight_decay:  0.0006301087409393963
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 1.1337, Train: 100.00%, Valid: 50.60% Test: 49.90%
Split: 01, Run: 01
None time:  3.40848184004426
None Run 01:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.90
Split: 01, Run: 02, Epoch: 100, Loss: 1.1178, Train: 100.00%, Valid: 50.60% Test: 49.90%
Split: 01, Run: 02
None time:  3.266067390097305
None Run 02:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.90
Split: 01, Run: 03, Epoch: 100, Loss: 1.1195, Train: 100.00%, Valid: 50.60% Test: 49.90%
Split: 01, Run: 03
None time:  3.310852891067043
None Run 03:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.90
run time now: 10.026309728622437
total time:  10.074001782108098
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 49.90 ± 0.00
[I 2023-06-12 00:30:25,017] Trial 1106 finished with value: 50.59999465942383 and parameters: {'Fwd': 0.05358146647999923, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.0, 'lambda2': 7.821786339144611, 'loop': 2, 'loss': 'CE', 'lr': 0.00909761551505021, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006301087409393963, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007717399324608137
weight_decay:  2.8535835369720057e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.536260882858187
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 98.33
   Final Test: 67.50
Split: 01, Run: 02
None time:  1.3339574199635535
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 65.10
Split: 01, Run: 03
None time:  1.4609286109916866
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 5.380660533905029
total time:  5.431567988824099
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 1.21
  Final Train: 99.44 ± 0.96
   Final Test: 67.57 ± 2.50
[I 2023-06-12 00:30:31,127] Trial 1107 finished with value: 70.93333435058594 and parameters: {'Fwd': 0.0008968386420477435, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 5.132508338651073, 'loop': 2, 'loss': 'CE', 'lr': 0.007717399324608137, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.8535835369720057e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.005844307545503416
weight_decay:  1.4368139004713193e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.336692423094064
None Run 01:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 54.90
Split: 01, Run: 02
None time:  2.9489986409898847
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 63.40
Split: 01, Run: 03
None time:  1.390825951937586
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.30
run time now: 5.718555212020874
total time:  5.760764362057671
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.80 ± 6.80
  Final Train: 100.00 ± 0.00
   Final Test: 61.53 ± 5.92
[I 2023-06-12 00:30:37,517] Trial 1108 finished with value: 61.79999923706055 and parameters: {'Fwd': 0.00023112204084098465, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 4.6738970183632365, 'loop': 2, 'loss': 'MSE', 'lr': 0.005844307545503416, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4368139004713193e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009989896909760394
weight_decay:  0.00036587552793540616
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0349106008652598
None Run 01:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 56.30
Split: 01, Run: 02
None time:  0.9625302869826555
None Run 02:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 52.00
Split: 01, Run: 03
None time:  1.1615058889146894
None Run 03:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 60.00
   Final Test: 43.90
run time now: 3.1983397006988525
total time:  3.247665263945237
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.80 ± 5.57
  Final Train: 86.67 ± 23.09
   Final Test: 50.73 ± 6.30
[I 2023-06-12 00:30:41,364] Trial 1109 finished with value: 52.79999923706055 and parameters: {'Fwd': 0.007043928000902019, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 2.1933217173238573, 'loop': 2, 'loss': 'CE', 'lr': 0.009989896909760394, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00036587552793540616, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.003601888180736855
weight_decay:  2.0629895794943074e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.764290621969849
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 99.17
   Final Test: 66.10
Split: 01, Run: 02
None time:  1.1334900490473956
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 54.30
Split: 01, Run: 03
None time:  1.9747670479118824
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 68.10
run time now: 5.913119077682495
total time:  5.958321820944548
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.67 ± 2.93
  Final Train: 99.44 ± 0.48
   Final Test: 62.83 ± 7.46
[I 2023-06-12 00:30:48,022] Trial 1110 finished with value: 66.66666412353516 and parameters: {'Fwd': 1.0136958101806427e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 5.4950442725052255, 'loop': 2, 'loss': 'CE', 'lr': 0.003601888180736855, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.0629895794943074e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.008504721894939603
weight_decay:  0.004628158172590101
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3460063671227545
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.00
Split: 01, Run: 02
None time:  1.2486702960450202
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.20
Split: 01, Run: 03
None time:  1.176020901883021
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.20
run time now: 3.8125007152557373
total time:  3.859609661856666
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.67 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 63.47 ± 1.42
[I 2023-06-12 00:30:52,553] Trial 1111 finished with value: 66.66667175292969 and parameters: {'Fwd': 0.0014182781996811692, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 6.293642425030662, 'loop': 2, 'loss': 'CE', 'lr': 0.008504721894939603, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004628158172590101, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.007085881530357457
weight_decay:  8.353846947816013e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9853042468894273
None Run 01:
Highest Train: 100.00
Highest Valid: 42.20
  Final Train: 100.00
   Final Test: 45.90
Split: 01, Run: 02
None time:  1.4073625789023936
None Run 02:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 98.33
   Final Test: 51.60
Split: 01, Run: 03
None time:  2.759519655024633
None Run 03:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 87.50
   Final Test: 69.70
run time now: 5.196689605712891
total time:  5.245120406150818
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.33 ± 12.71
  Final Train: 95.28 ± 6.79
   Final Test: 55.73 ± 12.43
[I 2023-06-12 00:30:58,416] Trial 1112 finished with value: 52.33333206176758 and parameters: {'Fwd': 0.003501343338783339, 'K': 2, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 6.801321025417225, 'loop': 2, 'loss': 'CE', 'lr': 0.007085881530357457, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.353846947816013e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00906602243966436
weight_decay:  0.023513701546210696
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  5.251172428950667
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  4.582085699075833
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  5.703795836074278
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.83
   Final Test: 69.90
run time now: 15.578191757202148
total time:  15.63620920595713
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.40
  Final Train: 98.06 ± 1.92
   Final Test: 70.10 ± 0.35
[I 2023-06-12 00:31:14,756] Trial 1113 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.0007229387925465215, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 7.257170086250413, 'loop': 2, 'loss': 'CE', 'lr': 0.00906602243966436, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.023513701546210696, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00826705793043844
weight_decay:  4.8839551075915936e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.4845, Train: 100.00%, Valid: 74.60% Test: 71.70%
Split: 01, Run: 01
None time:  3.515742049086839
None Run 01:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 02
None time:  1.19804376992397
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 03
None time:  1.2912418409250677
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 71.50
run time now: 6.043643951416016
total time:  6.099229498999193
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 71.73 ± 0.40
[I 2023-06-12 00:31:21,534] Trial 1114 finished with value: 74.73332977294922 and parameters: {'Fwd': 0.03899541281156957, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 9.844723869261081, 'loop': 2, 'loss': 'CE', 'lr': 0.00826705793043844, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.8839551075915936e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00011075023193797715
weight_decay:  5.212511911461814e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8854, Train: 100.00%, Valid: 60.60% Test: 61.10%
Split: 01, Run: 01
None time:  3.499730250798166
None Run 01:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 60.40
Split: 01, Run: 02
None time:  1.3019770940300077
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 62.70
Split: 01, Run: 03
None time:  1.5739012430422008
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.90
run time now: 6.418118000030518
total time:  6.464951052796096
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.87 ± 3.78
  Final Train: 100.00 ± 0.00
   Final Test: 62.67 ± 2.25
[I 2023-06-12 00:31:28,747] Trial 1115 finished with value: 64.86666870117188 and parameters: {'Fwd': 0.034891170364358286, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 9.884676528113912, 'loop': 2, 'loss': 'CE', 'lr': 0.00011075023193797715, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.212511911461814e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.0
lr:  0.0003968978384039964
weight_decay:  5.178315123828935e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4183539079967886
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.4925358009058982
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.8194248189684004
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
run time now: 5.781219005584717
total time:  5.836186120985076
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.59
[I 2023-06-12 00:31:35,433] Trial 1116 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.04252383172673724, 'K': 4, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 5.7397537531413985, 'loop': 2, 'loss': 'CE', 'lr': 0.0003968978384039964, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.178315123828935e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007286431784874704
weight_decay:  6.0956358024201056e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.638966321013868
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.6347604910843074
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.2754183618817478
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.60
run time now: 5.639036417007446
total time:  5.695622259983793
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 70.53 ± 1.05
[I 2023-06-12 00:31:41,834] Trial 1117 finished with value: 73.4000015258789 and parameters: {'Fwd': 0.028701076653043608, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 7.984036751745458, 'loop': 2, 'loss': 'CE', 'lr': 0.007286431784874704, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.0956358024201056e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.007928848316608164
weight_decay:  7.175345603771107e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2546594820450991
None Run 01:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 56.80
Split: 01, Run: 02
None time:  1.2469984430354089
None Run 02:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 52.40
Split: 01, Run: 03
None time:  1.2078766410704702
None Run 03:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 49.20
run time now: 3.7502782344818115
total time:  3.8101502801291645
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.80 ± 5.86
  Final Train: 100.00 ± 0.00
   Final Test: 52.80 ± 3.82
[I 2023-06-12 00:31:46,481] Trial 1118 finished with value: 49.79999923706055 and parameters: {'Fwd': 0.04803874141175938, 'K': 1, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 7.6262791030110755, 'loop': 2, 'loss': 'CE', 'lr': 0.007928848316608164, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.175345603771107e-05, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.006264049779004626
weight_decay:  4.1987604811618386e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.798375790938735
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.9955252998042852
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.3088762979023159
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.60
run time now: 5.146060228347778
total time:  5.191771971993148
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.17 ± 0.81
[I 2023-06-12 00:31:52,423] Trial 1119 finished with value: 72.9333267211914 and parameters: {'Fwd': 0.07554945543444089, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 9.840878509329533, 'loop': 2, 'loss': 'CE', 'lr': 0.006264049779004626, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.1987604811618386e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0002521609638345343
weight_decay:  7.632217793925305e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.196107941912487
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.219980790046975
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.7722902039531618
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.20
run time now: 7.225066423416138
total time:  7.27515685884282
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.93
[I 2023-06-12 00:32:00,425] Trial 1120 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.03165327952999941, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 8.833101606759291, 'loop': 2, 'loss': 'CE', 'lr': 0.0002521609638345343, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.632217793925305e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.0
lr:  0.002019335216859256
weight_decay:  0.00011225195258063054
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5085237030871212
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 02
None time:  2.3204120132140815
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  1.3083723080344498
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 66.70
run time now: 5.190950870513916
total time:  5.235285478178412
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 66.37 ± 0.67
[I 2023-06-12 00:32:06,338] Trial 1121 finished with value: 70.73332977294922 and parameters: {'Fwd': 0.03770230712615776, 'K': 4, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 8.184878837951254, 'loop': 2, 'loss': 'CE', 'lr': 0.002019335216859256, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011225195258063054, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0006851871003214873
weight_decay:  8.851943399671688e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.092096308944747
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 02
None time:  2.663845560979098
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  3.3329819422215223
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.30
run time now: 8.126553535461426
total time:  8.173830081010237
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.67 ± 2.10
  Final Train: 100.00 ± 0.00
   Final Test: 68.50 ± 2.21
[I 2023-06-12 00:32:15,286] Trial 1122 finished with value: 68.66666412353516 and parameters: {'Fwd': 0.06290658379903054, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 7.071510024699318, 'loop': 2, 'loss': 'CE', 'lr': 0.0006851871003214873, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.851943399671688e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.007966103138026669
weight_decay:  3.512902720168811e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2185775679536164
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 70.80
Split: 01, Run: 02
None time:  1.3741544249933213
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.2768653319217265
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 4.958110570907593
total time:  5.020425335969776
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 0.83
  Final Train: 99.72 ± 0.48
   Final Test: 70.13 ± 0.70
[I 2023-06-12 00:32:20,998] Trial 1123 finished with value: 72.53333282470703 and parameters: {'Fwd': 0.026328559728440414, 'K': 3, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 8.60884988200301, 'loop': 2, 'loss': 'CE', 'lr': 0.007966103138026669, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.512902720168811e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0015201608025247981
weight_decay:  6.183863924906678e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8229252439923584
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.90
Split: 01, Run: 02
None time:  3.1385639919899404
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 03
None time:  2.07561774388887
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.30
run time now: 7.0761213302612305
total time:  7.126895779045299
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 3.03
  Final Train: 99.44 ± 0.48
   Final Test: 68.57 ± 2.39
[I 2023-06-12 00:32:28,768] Trial 1124 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.05148661736585428, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 4.971696568523031, 'loop': 2, 'loss': 'CE', 'lr': 0.0015201608025247981, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.183863924906678e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.006919225388968141
weight_decay:  0.06197808499884166
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5952851730398834
None Run 01:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 42.70
Split: 01, Run: 02
None time:  2.4489117620978504
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 94.17
   Final Test: 72.80
Split: 01, Run: 03
None time:  0.48486963799223304
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.5745651721954346
total time:  3.6266305982135236
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.27 ± 18.42
  Final Train: 98.06 ± 3.37
   Final Test: 61.97 ± 16.73
[I 2023-06-12 00:32:33,143] Trial 1125 finished with value: 64.26666259765625 and parameters: {'Fwd': 1.4421973993743802e-05, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 20, 'lambda1': 0.2, 'lambda2': 5.266956067924633, 'loop': 2, 'loss': 'CE', 'lr': 0.006919225388968141, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.06197808499884166, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0026532557497859675
weight_decay:  0.0009279736700983298
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.807873253012076
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 91.67
   Final Test: 67.80
Split: 01, Run: 02
None time:  1.7320813140831888
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 97.50
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.3552856398746371
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 70.60
run time now: 5.936479091644287
total time:  5.988062144024298
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 1.30
  Final Train: 96.11 ± 3.94
   Final Test: 69.57 ± 1.54
[I 2023-06-12 00:32:39,769] Trial 1126 finished with value: 72.53333282470703 and parameters: {'Fwd': 3.8837174657751547e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 1.4150094243011937, 'loop': 2, 'loss': 'CE', 'lr': 0.0026532557497859675, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009279736700983298, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0005074434719238701
weight_decay:  9.4761965469481e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.61995648778975
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.30
Split: 01, Run: 02
None time:  1.5536267249844968
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  2.575895047048107
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 5.795703887939453
total time:  5.839222799055278
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 3.49
  Final Train: 100.00 ± 0.00
   Final Test: 67.50 ± 3.72
[I 2023-06-12 00:32:46,230] Trial 1127 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.021083340413096716, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 9.5190119240112, 'loop': 2, 'loss': 'CE', 'lr': 0.0005074434719238701, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.4761965469481e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.008327327352664542
weight_decay:  4.709959599474226e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.43903476302512
None Run 01:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 02
None time:  1.438292893813923
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 65.00
Split: 01, Run: 03
None time:  1.4287526740226895
None Run 03:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 61.00
run time now: 4.35576605796814
total time:  4.4041540659964085
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.53 ± 4.35
  Final Train: 100.00 ± 0.00
   Final Test: 61.00 ± 4.00
[I 2023-06-12 00:32:51,344] Trial 1128 finished with value: 61.5333366394043 and parameters: {'Fwd': 0.005314394808766019, 'K': 10, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 2.0024390758555057, 'loop': 2, 'loss': 'MSE', 'lr': 0.008327327352664542, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.709959599474226e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.004343399280959516
weight_decay:  0.00012925370135838922
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3142224049661309
None Run 01:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 56.40
Split: 01, Run: 02
None time:  1.3310566621366888
None Run 02:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 55.50
Split: 01, Run: 03
None time:  1.2572110071778297
None Run 03:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 46.70
run time now: 3.943760395050049
total time:  3.9936739960685372
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.47 ± 5.99
  Final Train: 100.00 ± 0.00
   Final Test: 52.87 ± 5.36
[I 2023-06-12 00:32:55,985] Trial 1129 finished with value: 52.4666633605957 and parameters: {'Fwd': 6.012657075702252e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 4.380950747937273, 'loop': 2, 'loss': 'CE', 'lr': 0.004343399280959516, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00012925370135838922, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00015195009546874338
weight_decay:  7.194333372954885e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8102, Train: 100.00%, Valid: 66.20% Test: 65.50%
Split: 01, Run: 01
None time:  3.5006516750436276
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 02
None time:  1.410789897898212
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 66.30
Split: 01, Run: 03
None time:  1.2377119131851941
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.10
run time now: 6.187939882278442
total time:  6.240397193934768
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 2.37
  Final Train: 100.00 ± 0.00
   Final Test: 66.67 ± 1.29
[I 2023-06-12 00:33:02,896] Trial 1130 finished with value: 69.13333129882812 and parameters: {'Fwd': 0.04157049402919183, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 4.125979790562648, 'loop': 2, 'loss': 'CE', 'lr': 0.00015195009546874338, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.194333372954885e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0055614691650925936
weight_decay:  1.0199941378394048e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8165505188517272
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.381829849909991
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 62.90
Split: 01, Run: 03
None time:  1.6317298559006304
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 72.10
run time now: 4.872344970703125
total time:  4.926828935975209
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 1.90
  Final Train: 99.44 ± 0.48
   Final Test: 68.33 ± 4.82
[I 2023-06-12 00:33:08,478] Trial 1131 finished with value: 71.86666870117188 and parameters: {'Fwd': 2.200749877867024e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 3.912975993155519, 'loop': 2, 'loss': 'CE', 'lr': 0.0055614691650925936, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0199941378394048e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0007445935331284833
weight_decay:  0.000220311244713143
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.196083485847339
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  2.612174676032737
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.40
Split: 01, Run: 03
None time:  1.6213959949091077
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.20
run time now: 6.475852966308594
total time:  6.524048233870417
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.53 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 68.13 ± 0.70
[I 2023-06-12 00:33:15,660] Trial 1132 finished with value: 68.53333282470703 and parameters: {'Fwd': 0.0010845845367188352, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 2.578202632045752, 'loop': 2, 'loss': 'CE', 'lr': 0.0007445935331284833, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.000220311244713143, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.0
lr:  0.009171477599038953
weight_decay:  0.08151767698189187
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3246511078905314
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 95.00
   Final Test: 67.60
Split: 01, Run: 02
None time:  1.4049688968807459
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.2915906778071076
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.00
run time now: 5.070093393325806
total time:  5.117066489066929
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 0.60
  Final Train: 98.33 ± 2.89
   Final Test: 68.97 ± 1.35
[I 2023-06-12 00:33:21,445] Trial 1133 finished with value: 68.79999542236328 and parameters: {'Fwd': 0.00040000200865091917, 'K': 5, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 9.22898929960759, 'loop': 2, 'loss': 'CE', 'lr': 0.009171477599038953, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.08151767698189187, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0001630273433073954
weight_decay:  6.825910839145256e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.7576, Train: 100.00%, Valid: 69.80% Test: 66.90%
Split: 01, Run: 01
None time:  3.716963523067534
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.8833281558472663
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.9082269850187004
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 7.593208074569702
total time:  7.6396187911741436
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 68.90 ± 1.65
[I 2023-06-12 00:33:29,778] Trial 1134 finished with value: 71.46666717529297 and parameters: {'Fwd': 7.593220153390133e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.1, 'lambda2': 7.419545679304104, 'loop': 2, 'loss': 'CE', 'lr': 0.0001630273433073954, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.825910839145256e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008500855667481983
weight_decay:  0.009006106937975229
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6639439119026065
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 02
None time:  1.2424340050201863
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  1.281442578183487
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 5.263894319534302
total time:  5.326386659871787
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.00 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 71.60 ± 0.79
[I 2023-06-12 00:33:35,801] Trial 1135 finished with value: 75.0 and parameters: {'Fwd': 0.014556131191049239, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 6.083993909929866, 'loop': 2, 'loss': 'CE', 'lr': 0.008500855667481983, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.009006106937975229, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0009748754953122578
weight_decay:  0.023625972699072156
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.770990716991946
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 02
None time:  2.5800976739265025
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  2.2675889749079943
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.30
run time now: 6.668859958648682
total time:  6.721495951060206
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 1.73
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 2.95
[I 2023-06-12 00:33:43,239] Trial 1136 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.015296923211597159, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 6.058249788521042, 'loop': 2, 'loss': 'CE', 'lr': 0.0009748754953122578, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.023625972699072156, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007656024721559633
weight_decay:  0.0013829639769173383
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.501612114952877
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.324873813893646
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  1.2556386028882116
None Run 03:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 71.60
run time now: 5.125837564468384
total time:  5.173099644947797
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.53 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 71.17 ± 1.12
[I 2023-06-12 00:33:49,045] Trial 1137 finished with value: 74.53333282470703 and parameters: {'Fwd': 0.014867640397343, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 6.154737161645386, 'loop': 2, 'loss': 'CE', 'lr': 0.007656024721559633, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0013829639769173383, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007365253511573408
weight_decay:  0.09965661877358789
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2290530959144235
None Run 01:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 58.40
Split: 01, Run: 02
None time:  2.502776661887765
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.1167981789913028
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.20
run time now: 4.887626647949219
total time:  4.936591133009642
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.47 ± 6.48
  Final Train: 100.00 ± 0.00
   Final Test: 64.87 ± 5.67
[I 2023-06-12 00:33:54,674] Trial 1138 finished with value: 66.46666717529297 and parameters: {'Fwd': 0.008901236870191821, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 6.466180136453474, 'loop': 2, 'loss': 'CE', 'lr': 0.007365253511573408, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.09965661877358789, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.006429663225030167
weight_decay:  0.05780247291696634
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.853177767014131
None Run 01:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 48.90
Split: 01, Run: 02
None time:  1.1281299779657274
None Run 02:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 50.50
Split: 01, Run: 03
None time:  1.0431650730315596
None Run 03:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 53.20
run time now: 3.069643020629883
total time:  3.120529546169564
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.60 ± 4.73
  Final Train: 100.00 ± 0.00
   Final Test: 50.87 ± 2.17
[I 2023-06-12 00:33:58,450] Trial 1139 finished with value: 52.60000228881836 and parameters: {'Fwd': 0.021711847807631187, 'K': 2, 'alpha': 0.0, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 5.914351989647206, 'loop': 0, 'loss': 'CE', 'lr': 0.006429663225030167, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.05780247291696634, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0007691060390527517
weight_decay:  0.010544543891251772
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5788888069801033
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 02
None time:  1.7071169349364936
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.40
Split: 01, Run: 03
None time:  1.2127523098606616
None Run 03:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 56.70
run time now: 5.542794466018677
total time:  5.59901619120501
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.67 ± 5.33
  Final Train: 100.00 ± 0.00
   Final Test: 63.87 ± 6.21
[I 2023-06-12 00:34:04,634] Trial 1140 finished with value: 65.66666412353516 and parameters: {'Fwd': 0.012519845026301121, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 6.352636503210906, 'loop': 2, 'loss': 'CE', 'lr': 0.0007691060390527517, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.010544543891251772, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00017722885526516585
weight_decay:  0.0004149919761655281
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3675646621268243
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 61.80
Split: 01, Run: 02
None time:  1.6854436579160392
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 03
None time:  1.4734498870093375
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.50
run time now: 5.568848609924316
total time:  5.6162400702014565
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.27 ± 3.37
  Final Train: 100.00 ± 0.00
   Final Test: 65.50 ± 3.21
[I 2023-06-12 00:34:10,881] Trial 1141 finished with value: 68.26667022705078 and parameters: {'Fwd': 0.018803855612452184, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 6.096464073281137, 'loop': 2, 'loss': 'CE', 'lr': 0.00017722885526516585, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004149919761655281, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.00020230969046059727
weight_decay:  0.006892030819136705
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.7286, Train: 100.00%, Valid: 68.40% Test: 68.20%
Split: 01, Run: 01
None time:  3.591625876026228
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.5472927938681096
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.3054889098275453
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
run time now: 6.487675428390503
total time:  6.550490546040237
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 1.68
  Final Train: 100.00 ± 0.00
   Final Test: 69.00 ± 0.92
[I 2023-06-12 00:34:18,056] Trial 1142 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.011580591928018788, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 5.754541190866736, 'loop': 2, 'loss': 'CE', 'lr': 0.00020230969046059727, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006892030819136705, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.0019281861437687492
weight_decay:  0.0019391238992219216
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.061945365043357
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  2.004892640048638
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.2379391039721668
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 5.345867872238159
total time:  5.397580149117857
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.79
[I 2023-06-12 00:34:24,161] Trial 1143 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.027216232657000836, 'K': 3, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 8.460654458854059, 'loop': 2, 'loss': 'CE', 'lr': 0.0019281861437687492, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0019391238992219216, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.003416932379918931
weight_decay:  0.001658903765344275
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0469866190105677
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  3.111655123066157
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.3758301821071655
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.20
run time now: 6.577749729156494
total time:  6.636180310044438
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 0.76
  Final Train: 99.72 ± 0.48
   Final Test: 70.63 ± 1.66
[I 2023-06-12 00:34:31,431] Trial 1144 finished with value: 72.86666107177734 and parameters: {'Fwd': 0.020358275785423017, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 5.850895856228542, 'loop': 2, 'loss': 'CE', 'lr': 0.003416932379918931, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001658903765344275, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00029701826336528614
weight_decay:  0.0005429108134838454
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.928897586883977
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 02
None time:  1.6721823217812926
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  2.6468773130327463
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.90
run time now: 6.295397758483887
total time:  6.347975382115692
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 67.57 ± 0.35
[I 2023-06-12 00:34:38,467] Trial 1145 finished with value: 68.53333282470703 and parameters: {'Fwd': 3.133358800356739e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 9.97472460083948, 'loop': 2, 'loss': 'CE', 'lr': 0.00029701826336528614, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005429108134838454, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.008456674685871444
weight_decay:  0.039601864239897144
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.716810849029571
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 02
None time:  1.6486515160650015
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.3540225089527667
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 5.761520147323608
total time:  5.819745756918564
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.60 ± 0.62
[I 2023-06-12 00:34:44,987] Trial 1146 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.0005899969273690062, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 6.299649149495662, 'loop': 2, 'loss': 'CE', 'lr': 0.008456674685871444, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.039601864239897144, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00029051412379007033
weight_decay:  0.0006925017468968133
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8040, Train: 100.00%, Valid: 68.00% Test: 67.10%
Split: 01, Run: 01
None time:  2.5359239119570702
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 02
None time:  1.2252822520677
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  1.6536930818110704
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.80
run time now: 5.457437515258789
total time:  5.513165859039873
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 67.90 ± 1.15
[I 2023-06-12 00:34:51,398] Trial 1147 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.000207801237514268, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 5.558451590704992, 'loop': 1, 'loss': 'CE', 'lr': 0.00029051412379007033, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006925017468968133, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.00693161818911693
weight_decay:  0.005501240032616875
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2996026629116386
None Run 01:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 59.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.3845, Train: 100.00%, Valid: 66.00% Test: 66.00%
Split: 01, Run: 02
None time:  3.5269359131343663
None Run 02:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 03
None time:  1.3170693221036345
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 66.70
run time now: 7.199148654937744
total time:  7.247516241855919
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.13 ± 4.76
  Final Train: 100.00 ± 0.00
   Final Test: 64.00 ± 3.76
[I 2023-06-12 00:34:59,454] Trial 1148 finished with value: 65.13333129882812 and parameters: {'Fwd': 0.0001580853535978131, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 6.731620735235448, 'loop': 2, 'loss': 'MSE', 'lr': 0.00693161818911693, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.005501240032616875, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007845831180754133
weight_decay:  0.01493764614768179
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2716440500225872
None Run 01:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 59.00
Split: 01, Run: 02
None time:  1.2144354111514986
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 61.80
Split: 01, Run: 03
None time:  1.2913622590713203
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 60.90
run time now: 3.825826644897461
total time:  3.8819984688889235
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.80 ± 3.99
  Final Train: 100.00 ± 0.00
   Final Test: 60.57 ± 1.43
[I 2023-06-12 00:35:04,002] Trial 1149 finished with value: 63.79999923706055 and parameters: {'Fwd': 0.0015750003221276917, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 3.503350087783839, 'loop': 2, 'loss': 'CE', 'lr': 0.007845831180754133, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.01493764614768179, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0006560662313704489
weight_decay:  0.003045305944247524
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7519857930019498
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 02
None time:  1.6319406139664352
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.641561612021178
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.40
run time now: 5.070236444473267
total time:  5.141238701995462
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 1.59
  Final Train: 100.00 ± 0.00
   Final Test: 68.63 ± 1.66
[I 2023-06-12 00:35:09,799] Trial 1150 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.0007442596072578868, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 8.297513662752701, 'loop': 2, 'loss': 'CE', 'lr': 0.0006560662313704489, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003045305944247524, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008338161664413575
weight_decay:  0.002725442941510072
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3364082779735327
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 62.00
Split: 01, Run: 02
None time:  2.443864337168634
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.001028820173815
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.00
run time now: 4.820216417312622
total time:  4.865848325192928
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 5.57
  Final Train: 100.00 ± 0.00
   Final Test: 67.70 ± 4.96
[I 2023-06-12 00:35:15,336] Trial 1151 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.00027727671470515245, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 7.794481252598627, 'loop': 2, 'loss': 'CE', 'lr': 0.008338161664413575, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002725442941510072, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.005170936300921079
weight_decay:  0.0055759559934763
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1305804420262575
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.2601219231728464
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.2155464889947325
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.00
run time now: 4.652405261993408
total time:  4.70823192410171
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.67
[I 2023-06-12 00:35:20,742] Trial 1152 finished with value: 72.33333587646484 and parameters: {'Fwd': 5.106235570223905e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 8.170373684553843, 'loop': 2, 'loss': 'CE', 'lr': 0.005170936300921079, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0055759559934763, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.00010248950635157574
weight_decay:  0.005195936649868608
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8918, Train: 100.00%, Valid: 62.80% Test: 62.20%
Split: 01, Run: 01
None time:  3.7780702458694577
None Run 01:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 62.20
Split: 01, Run: 02
None time:  1.4512009108439088
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 63.90
Split: 01, Run: 03
None time:  2.0073996959254146
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.00
run time now: 7.275862216949463
total time:  7.321688786149025
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.47 ± 3.36
  Final Train: 100.00 ± 0.00
   Final Test: 64.70 ± 2.98
[I 2023-06-12 00:35:28,785] Trial 1153 finished with value: 66.46666717529297 and parameters: {'Fwd': 0.031239250560385352, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 6.095763095034054, 'loop': 2, 'loss': 'CE', 'lr': 0.00010248950635157574, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005195936649868608, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007339661800353515
weight_decay:  0.0001236940915761564
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.90492545790039
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  5.3789174009580165
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  3.5028624071273953
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 12.834566831588745
total time:  12.882295564049855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.35
[I 2023-06-12 00:35:42,368] Trial 1154 finished with value: 70.00000762939453 and parameters: {'Fwd': 0.0009175336944380843, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.05, 'lambda2': 2.7387085266160183, 'loop': 2, 'loss': 'CE', 'lr': 0.007339661800353515, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001236940915761564, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0013985488731000988
weight_decay:  0.013865717041851189
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7898136808071285
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.4872014739084989
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.4983427680563182
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 68.10
run time now: 5.826800346374512
total time:  5.888592498842627
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.31
  Final Train: 99.72 ± 0.48
   Final Test: 69.33 ± 1.08
[I 2023-06-12 00:35:49,065] Trial 1155 finished with value: 72.33333587646484 and parameters: {'Fwd': 0.004121939196591525, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 6.56633416084508, 'loop': 2, 'loss': 'CE', 'lr': 0.0013985488731000988, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.013865717041851189, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.008593327874082478
weight_decay:  0.010898922728076847
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2402856908738613
None Run 01:
Highest Train: 100.00
Highest Valid: 44.60
  Final Train: 100.00
   Final Test: 44.10
Split: 01, Run: 02
None time:  1.198693823069334
None Run 02:
Highest Train: 100.00
Highest Valid: 36.40
  Final Train: 100.00
   Final Test: 35.00
Split: 01, Run: 03
None time:  1.1721646999940276
None Run 03:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 33.90
run time now: 3.6607954502105713
total time:  3.719818973913789
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 38.93 ± 4.92
  Final Train: 100.00 ± 0.00
   Final Test: 37.67 ± 5.60
[I 2023-06-12 00:35:53,577] Trial 1156 finished with value: 38.93333435058594 and parameters: {'Fwd': 0.01707826183226601, 'K': 2, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 7.947686046601287, 'loop': 2, 'loss': 'CE', 'lr': 0.008593327874082478, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.010898922728076847, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0006049560068316648
weight_decay:  0.0029864150754046557
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9798902990296483
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.0475796880200505
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.20
Split: 01, Run: 03
None time:  2.289925011107698
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 99.17
   Final Test: 69.10
run time now: 6.359911680221558
total time:  6.406400443986058
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.95
  Final Train: 99.44 ± 0.48
   Final Test: 69.23 ± 0.15
[I 2023-06-12 00:36:00,606] Trial 1157 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.00052292624275306, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 1.0864600484842413, 'loop': 2, 'loss': 'CE', 'lr': 0.0006049560068316648, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0029864150754046557, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.75
lr:  0.009119840248401304
weight_decay:  0.0825870462536874
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1614261288195848
None Run 01:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 59.90
Split: 01, Run: 02
None time:  1.1098678051494062
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 64.20
Split: 01, Run: 03
None time:  2.210609472822398
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 99.17
   Final Test: 68.20
run time now: 4.540360927581787
total time:  4.603860605042428
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.40 ± 2.11
  Final Train: 99.72 ± 0.48
   Final Test: 64.10 ± 4.15
[I 2023-06-12 00:36:05,858] Trial 1158 finished with value: 66.4000015258789 and parameters: {'Fwd': 0.024274823206431644, 'K': 1, 'alpha': 0.75, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 7.629242173357794, 'loop': 2, 'loss': 'CE', 'lr': 0.009119840248401304, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0825870462536874, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007859228898079601
weight_decay:  0.003592495364731788
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4383667069487274
None Run 01:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 63.30
Split: 01, Run: 02
None time:  1.3708146130666137
None Run 02:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 62.20
Split: 01, Run: 03
None time:  2.1788460679817945
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 5.029720067977905
total time:  5.085465196985751
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.33 ± 5.49
  Final Train: 100.00 ± 0.00
   Final Test: 64.90 ± 3.76
[I 2023-06-12 00:36:11,689] Trial 1159 finished with value: 65.33333587646484 and parameters: {'Fwd': 3.707043335096045e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.1, 'lambda2': 6.964655179961376, 'loop': 2, 'loss': 'CE', 'lr': 0.007859228898079601, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003592495364731788, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0065207471977992305
weight_decay:  0.0022900925324837395
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.59399030986242
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.8137992850970477
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 67.50
Split: 01, Run: 03
None time:  1.4069646860007197
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 4.858864068984985
total time:  4.908937365980819
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.60
  Final Train: 99.72 ± 0.48
   Final Test: 69.00 ± 1.55
[I 2023-06-12 00:36:17,197] Trial 1160 finished with value: 71.5999984741211 and parameters: {'Fwd': 8.837192330310671e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 7.175696482385398, 'loop': 2, 'loss': 'CE', 'lr': 0.0065207471977992305, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0022900925324837395, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0085480298026917
weight_decay:  0.0033864962282332722
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9118406660854816
None Run 01:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 91.67
   Final Test: 59.50
Split: 01, Run: 02
None time:  1.904638757929206
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 92.50
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.627860127016902
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 92.50
   Final Test: 70.90
run time now: 6.483588933944702
total time:  6.534861010033637
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.00 ± 7.98
  Final Train: 92.22 ± 0.48
   Final Test: 66.70 ± 6.26
[I 2023-06-12 00:36:24,377] Trial 1161 finished with value: 66.0 and parameters: {'Fwd': 0.09786802123365601, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 2.3122321095876184, 'loop': 2, 'loss': 'CE', 'lr': 0.0085480298026917, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0033864962282332722, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.30000000000000004
lr:  0.00023778323477554976
weight_decay:  0.0005668921804651372
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.53291494701989
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.8456725971773267
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.789808124070987
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 6.218248605728149
total time:  6.277719351928681
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.56
[I 2023-06-12 00:36:31,322] Trial 1162 finished with value: 71.60000610351562 and parameters: {'Fwd': 2.3912919933535924e-05, 'K': 1, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 3.0073994992141104, 'loop': 2, 'loss': 'CE', 'lr': 0.00023778323477554976, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005668921804651372, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00922753355066647
weight_decay:  0.03797206636185716
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.165665776003152
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1776526940520853
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.2374165479559451
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.50
run time now: 4.6202147006988525
total time:  4.668523122090846
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.33 ± 0.57
[I 2023-06-12 00:36:36,587] Trial 1163 finished with value: 73.06666564941406 and parameters: {'Fwd': 0.0012665476886016356, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 4.771844859223839, 'loop': 2, 'loss': 'CE', 'lr': 0.00922753355066647, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03797206636185716, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.007327649603386472
weight_decay:  0.0006790465022188558
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.749483342980966
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 72.10
Split: 01, Run: 02
None time:  1.2861548638902605
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.9464987951796502
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 4.025790214538574
total time:  4.071740380953997
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.73 ± 1.33
  Final Train: 99.72 ± 0.48
   Final Test: 71.07 ± 0.93
[I 2023-06-12 00:36:41,297] Trial 1164 finished with value: 73.73332977294922 and parameters: {'Fwd': 1.8494440315892005e-06, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 3.144952782960512, 'loop': 2, 'loss': 'CE', 'lr': 0.007327649603386472, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006790465022188558, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0047928066225018376
weight_decay:  0.038927273627183914
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3653, Train: 100.00%, Valid: 54.20% Test: 55.00%
Split: 01, Run: 01
None time:  3.607335153967142
None Run 01:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 55.00
Split: 01, Run: 02
None time:  1.3697561889421195
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.50
Split: 01, Run: 03
None time:  1.084461233112961
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.00
run time now: 6.103491306304932
total time:  6.150229709921405
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.67 ± 7.17
  Final Train: 100.00 ± 0.00
   Final Test: 62.50 ± 6.54
[I 2023-06-12 00:36:48,330] Trial 1165 finished with value: 62.66666793823242 and parameters: {'Fwd': 0.00010758188118755652, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.5, 'lambda2': 1.6408234065293472, 'loop': 2, 'loss': 'MSE', 'lr': 0.0047928066225018376, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.038927273627183914, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0025052189593454187
weight_decay:  0.0004376638029570953
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.347538111032918
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 47.20
Split: 01, Run: 02
None time:  1.3987807868979871
None Run 02:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 51.90
Split: 01, Run: 03
None time:  1.365170283941552
None Run 03:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 47.50
run time now: 4.153582334518433
total time:  4.207111943978816
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 47.40 ± 2.75
  Final Train: 100.00 ± 0.00
   Final Test: 48.87 ± 2.63
[I 2023-06-12 00:36:53,190] Trial 1166 finished with value: 47.39999771118164 and parameters: {'Fwd': 0.01375916831867735, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.05, 'lambda2': 5.785299349290639, 'loop': 2, 'loss': 'CE', 'lr': 0.0025052189593454187, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0004376638029570953, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.005854987915212883
weight_decay:  0.0010759912008881664
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.2450125052127987
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 02
None time:  1.3592231080401689
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.614833664149046
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.260403156280518
total time:  6.312970125116408
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 1.10
  Final Train: 99.72 ± 0.48
   Final Test: 70.10 ± 1.25
[I 2023-06-12 00:37:00,250] Trial 1167 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.0017615571676241253, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 6.192125036352428, 'loop': 2, 'loss': 'CE', 'lr': 0.005854987915212883, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0010759912008881664, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0010823476654838644
weight_decay:  0.02775586702213991
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.019381884019822
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  2.9037563398014754
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 03
None time:  2.6865604401100427
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
run time now: 8.650303363800049
total time:  8.707538021029904
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.30 ± 0.00
[I 2023-06-12 00:37:09,622] Trial 1168 finished with value: 51.20000076293945 and parameters: {'Fwd': 0.008262082652558733, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.0, 'lambda2': 3.219688163116757, 'loop': 2, 'loss': 'CE', 'lr': 0.0010823476654838644, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.02775586702213991, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00011622908723429031
weight_decay:  0.0018197635454335803
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.897355118067935
None Run 01:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 57.40
Split: 01, Run: 02
None time:  1.3435031769331545
None Run 02:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 61.70
Split: 01, Run: 03
None time:  1.7845427000429481
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.70
run time now: 6.0728535652160645
total time:  6.146776376059279
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.53 ± 3.52
  Final Train: 100.00 ± 0.00
   Final Test: 60.93 ± 3.22
[I 2023-06-12 00:37:16,432] Trial 1169 finished with value: 63.5333366394043 and parameters: {'Fwd': 0.038277000826488786, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 1.8484241055312114, 'loop': 2, 'loss': 'CE', 'lr': 0.00011622908723429031, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0018197635454335803, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.008240906364256659
weight_decay:  0.003012263956787175
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2199282420333475
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  2.790424434002489
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.2616481750737876
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.80
run time now: 7.3181374073028564
total time:  7.3650417029857635
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.40 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 69.27 ± 0.64
[I 2023-06-12 00:37:24,468] Trial 1170 finished with value: 69.4000015258789 and parameters: {'Fwd': 0.0003570403516791168, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 5.362479146422423, 'loop': 2, 'loss': 'CE', 'lr': 0.008240906364256659, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.003012263956787175, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00999127802543357
weight_decay:  0.08026341401680626
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8758866682182997
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 02
None time:  1.6359753920696676
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  1.3253099210560322
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 67.20
run time now: 4.884431600570679
total time:  4.932234180858359
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 68.60 ± 2.69
[I 2023-06-12 00:37:30,109] Trial 1171 finished with value: 72.9333267211914 and parameters: {'Fwd': 0.0006897370496183966, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 8.701967475115776, 'loop': 2, 'loss': 'CE', 'lr': 0.00999127802543357, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.08026341401680626, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.003983029466869233
weight_decay:  0.024070198664006833
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4591518379747868
None Run 01:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 94.17
   Final Test: 63.10
Split: 01, Run: 02
None time:  1.4641651539132
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.00
Split: 01, Run: 03
None time:  1.4497897918336093
None Run 03:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 99.17
   Final Test: 61.10
run time now: 4.418364524841309
total time:  4.477709198836237
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.67 ± 1.10
  Final Train: 97.78 ± 3.15
   Final Test: 63.07 ± 1.95
[I 2023-06-12 00:37:35,261] Trial 1172 finished with value: 64.66666412353516 and parameters: {'Fwd': 0.0009366650560573064, 'K': 3, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 7.299401537507764, 'loop': 2, 'loss': 'CE', 'lr': 0.003983029466869233, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.024070198664006833, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009152086052598388
weight_decay:  0.01865958213340422
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0258, Train: 90.00%, Valid: 66.20% Test: 66.60%
Split: 01, Run: 01
None time:  3.261244617868215
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 91.67
   Final Test: 66.70
Split: 01, Run: 02
None time:  1.5733722599688917
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  1.3697291468270123
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.90
run time now: 6.246532917022705
total time:  6.2941025090403855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.20 ± 1.00
  Final Train: 97.22 ± 4.81
   Final Test: 67.40 ± 0.62
[I 2023-06-12 00:37:42,188] Trial 1173 finished with value: 67.19999694824219 and parameters: {'Fwd': 5.0899654449722396e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 8.391181670757877, 'loop': 2, 'loss': 'CE', 'lr': 0.009152086052598388, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.01865958213340422, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.00291722946129953
weight_decay:  0.03811849935682255
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.719217883888632
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 02
None time:  1.9708407609723508
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  1.3589208570774645
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.30
run time now: 5.0917274951934814
total time:  5.141311068087816
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 1.62
  Final Train: 100.00 ± 0.00
   Final Test: 70.40 ± 0.98
[I 2023-06-12 00:37:47,921] Trial 1174 finished with value: 72.53333282470703 and parameters: {'Fwd': 0.06092334129123075, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 8.051613129351715, 'loop': 2, 'loss': 'CE', 'lr': 0.00291722946129953, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03811849935682255, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0012307129007616416
weight_decay:  0.036165654693508714
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8988727789837867
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.80
Split: 01, Run: 02
None time:  1.3470986171159893
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.40
Split: 01, Run: 03
None time:  1.9293281419668347
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 95.00
   Final Test: 64.20
run time now: 5.2186057567596436
total time:  5.284938188968226
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.47 ± 0.46
  Final Train: 98.33 ± 2.89
   Final Test: 64.47 ± 0.31
[I 2023-06-12 00:37:53,932] Trial 1175 finished with value: 65.46666717529297 and parameters: {'Fwd': 1.7277649034434928e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.6000000000000001, 'lambda2': 4.59993247767689, 'loop': 2, 'loss': 'CE', 'lr': 0.0012307129007616416, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.036165654693508714, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0077407353940219786
weight_decay:  0.0013074771739979955
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.792200705036521
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 02
None time:  1.0428555069956928
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.1243120690342039
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 71.30
run time now: 4.000953435897827
total time:  4.05551749211736
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.13 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 70.83 ± 0.99
[I 2023-06-12 00:37:58,604] Trial 1176 finished with value: 74.13333892822266 and parameters: {'Fwd': 0.025498531109364873, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 4.308976716749983, 'loop': 2, 'loss': 'CE', 'lr': 0.0077407353940219786, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0013074771739979955, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008608712421910903
weight_decay:  0.004541552867077822
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9240272319875658
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 96.67
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.3302183009218425
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  1.1387014391366392
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 65.70
run time now: 5.438251495361328
total time:  5.490235117031261
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 1.11
  Final Train: 98.89 ± 1.92
   Final Test: 68.07 ± 2.12
[I 2023-06-12 00:38:04,765] Trial 1177 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.002163808648649694, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.55, 'lambda2': 9.857955795248047, 'loop': 2, 'loss': 'CE', 'lr': 0.008608712421910903, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004541552867077822, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0001330729142876046
weight_decay:  0.00048762360513946313
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8959, Train: 100.00%, Valid: 63.40% Test: 63.20%
Split: 01, Run: 01
None time:  3.808886274928227
None Run 01:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 62.60
Split: 01, Run: 02
None time:  1.5226772651076317
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  1.7858926830813289
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.50
run time now: 7.163310289382935
total time:  7.216337495017797
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 4.68
  Final Train: 100.00 ± 0.00
   Final Test: 65.97 ± 3.04
[I 2023-06-12 00:38:12,614] Trial 1178 finished with value: 68.79999542236328 and parameters: {'Fwd': 0.00046612121504031266, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 5.9697125288159185, 'loop': 2, 'loss': 'CE', 'lr': 0.0001330729142876046, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00048762360513946313, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00685183805422695
weight_decay:  0.0021277709506089108
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5241, Train: 99.17%, Valid: 70.60% Test: 68.30%
Split: 01, Run: 01
None time:  3.5751025839708745
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 68.10
Split: 01, Run: 02
None time:  1.0430026398971677
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 03
None time:  1.1754001369699836
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.20
run time now: 5.847111701965332
total time:  5.911458405898884
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.36
  Final Train: 99.72 ± 0.48
   Final Test: 67.17 ± 1.70
[I 2023-06-12 00:38:19,221] Trial 1179 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.005865305828364122, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 7.432372229349523, 'loop': 2, 'loss': 'CE', 'lr': 0.00685183805422695, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0021277709506089108, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0017808334988844415
weight_decay:  0.07257517897324603
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6861327190417796
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 95.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.151514211902395
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 63.90
Split: 01, Run: 03
None time:  1.225606082007289
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 62.40
run time now: 5.101375341415405
total time:  5.148266447009519
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.33 ± 0.70
  Final Train: 98.33 ± 2.89
   Final Test: 65.37 ± 3.91
[I 2023-06-12 00:38:25,054] Trial 1180 finished with value: 72.33333587646484 and parameters: {'Fwd': 0.0033085716191931873, 'K': 1, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 4.097046221744028, 'loop': 2, 'loss': 'CE', 'lr': 0.0017808334988844415, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.07257517897324603, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.009254607513867768
weight_decay:  0.029256199749112293
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.516449362039566
None Run 01:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 94.17
   Final Test: 49.70
Split: 01, Run: 02
None time:  2.463561068987474
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 91.67
   Final Test: 67.70
Split: 01, Run: 03
None time:  1.57243416714482
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 95.83
   Final Test: 67.60
run time now: 5.599299907684326
total time:  5.714263434056193
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.07 ± 8.93
  Final Train: 93.89 ± 2.10
   Final Test: 61.67 ± 10.36
[I 2023-06-12 00:38:31,468] Trial 1181 finished with value: 62.06666564941406 and parameters: {'Fwd': 0.020113472166086787, 'K': 2, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 3.5083934370102656, 'loop': 2, 'loss': 'CE', 'lr': 0.009254607513867768, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.029256199749112293, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0021912889758533846
weight_decay:  0.004659268512370711
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8518387768417597
None Run 01:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 75.00
   Final Test: 62.30
Split: 01, Run: 02
None time:  2.7610462869051844
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.3566368450410664
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 65.30
run time now: 7.01238751411438
total time:  7.060732275946066
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.67 ± 2.84
  Final Train: 89.44 ± 12.95
   Final Test: 65.63 ± 3.51
[I 2023-06-12 00:38:39,270] Trial 1182 finished with value: 67.66666412353516 and parameters: {'Fwd': 0.0010984552840245128, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 2.3868063035312965, 'loop': 2, 'loss': 'CE', 'lr': 0.0021912889758533846, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004659268512370711, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008024183087394873
weight_decay:  0.003976528541222587
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5808347431011498
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 61.90
Split: 01, Run: 02
None time:  1.2780116160865873
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 62.70
Split: 01, Run: 03
None time:  1.125511999009177
None Run 03:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 64.90
run time now: 4.029428005218506
total time:  4.086495511000976
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.47 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 63.17 ± 1.55
[I 2023-06-12 00:38:43,988] Trial 1183 finished with value: 62.4666633605957 and parameters: {'Fwd': 0.032820460378872526, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 1.0743243752391483, 'loop': 2, 'loss': 'CE', 'lr': 0.008024183087394873, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003976528541222587, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0009445302778033129
weight_decay:  0.00035669911541396694
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5522211489733309
None Run 01:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 43.50
Split: 01, Run: 02
None time:  1.595100374193862
None Run 02:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 46.00
Split: 01, Run: 03
None time:  2.282935020979494
None Run 03:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 52.30
run time now: 5.472278833389282
total time:  5.522576071089134
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 45.87 ± 3.23
  Final Train: 100.00 ± 0.00
   Final Test: 47.27 ± 4.53
[I 2023-06-12 00:38:50,365] Trial 1184 finished with value: 45.866668701171875 and parameters: {'Fwd': 3.3556428998435193e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 8.932014089187104, 'loop': 2, 'loss': 'MSE', 'lr': 0.0009445302778033129, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00035669911541396694, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.008642076845004683
weight_decay:  0.0027630059186262257
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3518620741087943
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.10
Split: 01, Run: 02
None time:  1.4331823559477925
None Run 02:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 53.50
Split: 01, Run: 03
None time:  1.3759059039875865
None Run 03:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 42.90
run time now: 4.203559398651123
total time:  4.254156157840043
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.67 ± 9.29
  Final Train: 100.00 ± 0.00
   Final Test: 53.50 ± 10.60
[I 2023-06-12 00:38:55,303] Trial 1185 finished with value: 54.66666793823242 and parameters: {'Fwd': 0.010176856395626226, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.2, 'lambda2': 6.435696869276025, 'loop': 2, 'loss': 'CE', 'lr': 0.008642076845004683, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0027630059186262257, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.00048800830280771695
weight_decay:  9.36694509354978e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.6848, Train: 99.17%, Valid: 71.20% Test: 70.30%
Split: 01, Run: 01
None time:  3.6726509060245007
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.5233886938076466
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 03
None time:  1.4537051811348647
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.90
run time now: 6.69391393661499
total time:  6.743982659187168
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 1.01
  Final Train: 99.72 ± 0.48
   Final Test: 70.10 ± 1.31
[I 2023-06-12 00:39:02,739] Trial 1186 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.0005935249311390927, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 5.546156250478711, 'loop': 2, 'loss': 'CE', 'lr': 0.00048800830280771695, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.36694509354978e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009980920834386117
weight_decay:  5.336822981295738e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.241914886981249
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 70.80
Split: 01, Run: 02
None time:  1.3668244171421975
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.5038661921862513
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.156347751617432
total time:  6.2274203391280025
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 70.50 ± 0.26
[I 2023-06-12 00:39:09,658] Trial 1187 finished with value: 72.26667022705078 and parameters: {'Fwd': 0.045010261150278064, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 4.847995264381227, 'loop': 2, 'loss': 'CE', 'lr': 0.009980920834386117, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.336822981295738e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007460546955413168
weight_decay:  0.00010082778877972342
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.141454905970022
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 99.17
   Final Test: 67.30
Split: 01, Run: 02
None time:  1.3992424039170146
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  1.2227428439073265
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.10
run time now: 4.80666184425354
total time:  4.869794183876365
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 2.91
  Final Train: 99.72 ± 0.48
   Final Test: 69.70 ± 2.09
[I 2023-06-12 00:39:15,155] Trial 1188 finished with value: 71.73332977294922 and parameters: {'Fwd': 6.908859209427068e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 9.753226737520759, 'loop': 2, 'loss': 'CE', 'lr': 0.007460546955413168, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010082778877972342, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0002754768860275123
weight_decay:  0.010241874811285658
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3557844450697303
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 02
None time:  1.5224037999287248
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 03
None time:  2.2875667170155793
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.70
run time now: 6.207230567932129
total time:  6.262571214931086
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 65.70 ± 1.05
[I 2023-06-12 00:39:22,076] Trial 1189 finished with value: 67.20000457763672 and parameters: {'Fwd': 2.640217018424285e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.777783870907595, 'loop': 2, 'loss': 'CE', 'lr': 0.0002754768860275123, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.010241874811285658, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009231957264688844
weight_decay:  0.005268159965245881
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0685119500849396
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.2593858509790152
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 99.17
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.1519510010257363
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 72.20
run time now: 4.531724452972412
total time:  4.585555476136506
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 2.36
  Final Train: 99.17 ± 0.83
   Final Test: 70.70 ± 1.61
[I 2023-06-12 00:39:27,454] Trial 1190 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.00014027609785338495, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 2.9351835282034004, 'loop': 2, 'loss': 'CE', 'lr': 0.009231957264688844, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005268159965245881, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.0084476851418371
weight_decay:  0.008124276888300017
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.154347114963457
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  1.2266622809693217
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.2174666069913656
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.30
run time now: 4.64003586769104
total time:  4.695404190104455
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 70.97 ± 1.19
[I 2023-06-12 00:39:32,832] Trial 1191 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.07414506697753141, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 9.571894765364432, 'loop': 2, 'loss': 'CE', 'lr': 0.0084476851418371, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008124276888300017, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00625828951092158
weight_decay:  0.0007541806220030295
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6480621548835188
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.6178295859135687
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 99.17
   Final Test: 71.90
Split: 01, Run: 03
None time:  1.3231268168892711
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 69.10
run time now: 4.627237558364868
total time:  4.670912287896499
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 1.40
  Final Train: 99.72 ± 0.48
   Final Test: 70.17 ± 1.51
[I 2023-06-12 00:39:38,142] Trial 1192 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.0007977164370290221, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 6.655452170814931, 'loop': 2, 'loss': 'CE', 'lr': 0.00625828951092158, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007541806220030295, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.006924925481385705
weight_decay:  0.0014063407611330941
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6961890489328653
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  2.8840581448748708
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 03
None time:  2.8614071619231254
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
run time now: 8.483091115951538
total time:  8.53020656388253
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.30 ± 0.00
[I 2023-06-12 00:39:47,250] Trial 1193 finished with value: 51.20000076293945 and parameters: {'Fwd': 0.0014367919415216096, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.0, 'lambda2': 8.613793299440609, 'loop': 2, 'loss': 'CE', 'lr': 0.006924925481385705, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0014063407611330941, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0033449316981336973
weight_decay:  0.001964753261517765
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.993287602905184
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 94.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.3367647090926766
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.2289859890006483
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 4.606439590454102
total time:  4.664415318984538
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 1.11
  Final Train: 98.06 ± 3.37
   Final Test: 69.63 ± 0.23
[I 2023-06-12 00:39:52,506] Trial 1194 finished with value: 73.0 and parameters: {'Fwd': 4.40445293354973e-05, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 3.3607850117829754, 'loop': 2, 'loss': 'CE', 'lr': 0.0033449316981336973, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001964753261517765, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.003683725470267865
weight_decay:  0.025614701866047637
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9074251549318433
None Run 01:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 51.90
Split: 01, Run: 02
None time:  0.9989500639494509
None Run 02:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 45.80
Split: 01, Run: 03
None time:  0.9743673200719059
None Run 03:
Highest Train: 100.00
Highest Valid: 42.00
  Final Train: 100.00
   Final Test: 42.80
run time now: 2.9242146015167236
total time:  2.9820297539699823
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 46.67 ± 5.15
  Final Train: 100.00 ± 0.00
   Final Test: 46.83 ± 4.64
[I 2023-06-12 00:39:56,122] Trial 1195 finished with value: 46.66666793823242 and parameters: {'Fwd': 1.931914514953158e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 5.052785556757102, 'loop': 1, 'loss': 'CE', 'lr': 0.003683725470267865, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.025614701866047637, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.00220205590523232
weight_decay:  0.0039343672083115575
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5120, Train: 82.50%, Valid: 66.80% Test: 67.00%
Split: 01, Run: 01
None time:  3.6463279630988836
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 82.50
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.715442119864747
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 94.17
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.5386960108298808
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 95.83
   Final Test: 69.20
run time now: 6.941148519515991
total time:  6.9896567419636995
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 2.25
  Final Train: 90.83 ± 7.26
   Final Test: 68.73 ± 1.55
[I 2023-06-12 00:40:03,707] Trial 1196 finished with value: 69.79999542236328 and parameters: {'Fwd': 0.03516073941225095, 'K': 3, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 0.2608983944977714, 'loop': 2, 'loss': 'CE', 'lr': 0.00220205590523232, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0039343672083115575, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0055159588639734055
weight_decay:  7.673908409468565e-05
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0299231810495257
None Run 01:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 48.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0258, Train: 99.17%, Valid: 71.20% Test: 71.30%
Split: 01, Run: 02
None time:  3.344430783065036
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.416323642944917
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 5.831714630126953
total time:  5.87711059092544
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.07 ± 13.92
  Final Train: 99.72 ± 0.48
   Final Test: 63.10 ± 12.74
[I 2023-06-12 00:40:10,265] Trial 1197 finished with value: 64.06666564941406 and parameters: {'Fwd': 0.014925934384778766, 'K': 1, 'alpha': 0.0, 'dropout': 0.0, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 6.935752774347069, 'loop': 2, 'loss': 'CE', 'lr': 0.0055159588639734055, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.673908409468565e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0001251664225870176
weight_decay:  0.00762976697739042
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.7919, Train: 100.00%, Valid: 69.00% Test: 66.20%
Split: 01, Run: 01
None time:  3.331679998198524
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 02
None time:  1.6740242191590369
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  2.171581553062424
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 7.219872236251831
total time:  7.268393591046333
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 67.93 ± 2.25
[I 2023-06-12 00:40:18,152] Trial 1198 finished with value: 69.73332977294922 and parameters: {'Fwd': 0.05469542518482137, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 2.6239757867951905, 'loop': 2, 'loss': 'CE', 'lr': 0.0001251664225870176, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00762976697739042, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0004444816790198905
weight_decay:  0.013067680343817945
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.371248187031597
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.8497810629196465
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.679277224931866
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
run time now: 5.943532943725586
total time:  5.990998263005167
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 1.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.70
[I 2023-06-12 00:40:24,914] Trial 1199 finished with value: 71.26666259765625 and parameters: {'Fwd': 0.00753888532362317, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 5.64695224922245, 'loop': 2, 'loss': 'CE', 'lr': 0.0004444816790198905, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.013067680343817945, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009204428614621216
weight_decay:  0.059338350122132504
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2406739168800414
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 94.17
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.4249117688741535
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.3104292920324951
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 68.00
run time now: 5.017345666885376
total time:  5.06826291186735
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 1.14
  Final Train: 98.06 ± 3.37
   Final Test: 68.80 ± 0.72
[I 2023-06-12 00:40:30,628] Trial 1200 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.004424903853622415, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 7.510749537623364, 'loop': 2, 'loss': 'CE', 'lr': 0.009204428614621216, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.059338350122132504, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007633278642101972
weight_decay:  0.00031243253752945077
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.382892844034359
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 02
None time:  1.0634084921330214
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.1463992858771235
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 65.10
run time now: 4.63503098487854
total time:  4.686785487923771
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 68.57 ± 3.23
[I 2023-06-12 00:40:36,076] Trial 1201 finished with value: 74.26667022705078 and parameters: {'Fwd': 0.0010228711110348055, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 8.072530829377941, 'loop': 2, 'loss': 'CE', 'lr': 0.007633278642101972, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00031243253752945077, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00014594461746153197
weight_decay:  0.008916404800604922
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.9162, Train: 99.17%, Valid: 64.80% Test: 64.60%
Split: 01, Run: 01
None time:  3.6073089628480375
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 99.17
   Final Test: 64.40
Split: 01, Run: 02
None time:  1.4403066369704902
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  1.3497283158358186
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 6.441074371337891
total time:  6.486692831851542
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.67 ± 4.24
  Final Train: 99.72 ± 0.48
   Final Test: 67.47 ± 2.69
[I 2023-06-12 00:40:43,459] Trial 1202 finished with value: 69.66666412353516 and parameters: {'Fwd': 2.8442600119917446e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 4.4926026269954455, 'loop': 2, 'loss': 'CE', 'lr': 0.00014594461746153197, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008916404800604922, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.004430270787641882
weight_decay:  0.017957834904579823
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6134224589914083
None Run 01:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 52.30
Split: 01, Run: 02
None time:  1.4756091858725995
None Run 02:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.70
Split: 01, Run: 03
None time:  1.6587171941064298
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.70
run time now: 4.805993556976318
total time:  4.904587435070425
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.67 ± 7.33
  Final Train: 100.00 ± 0.00
   Final Test: 59.23 ± 6.33
[I 2023-06-12 00:40:48,938] Trial 1203 finished with value: 58.66666793823242 and parameters: {'Fwd': 0.00038697513027887126, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.35000000000000003, 'lambda2': 5.203246784687847, 'loop': 2, 'loss': 'MSE', 'lr': 0.004430270787641882, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.017957834904579823, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0001192678555050868
weight_decay:  0.0008877385170979628
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.9318, Train: 100.00%, Valid: 61.60% Test: 60.00%
Split: 01, Run: 01
None time:  3.5772982051130384
None Run 01:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.00
Split: 01, Run: 02
None time:  1.5164264279883355
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.80
Split: 01, Run: 03
None time:  1.6826236869674176
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.00
run time now: 6.817955493927002
total time:  6.872458919184282
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.27 ± 3.30
  Final Train: 100.00 ± 0.00
   Final Test: 63.60 ± 3.17
[I 2023-06-12 00:40:56,379] Trial 1204 finished with value: 65.26666259765625 and parameters: {'Fwd': 0.027474769705979514, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 9.998548148781866, 'loop': 2, 'loss': 'CE', 'lr': 0.0001192678555050868, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008877385170979628, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00837974727041062
weight_decay:  0.04535825675777938
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1692730879876763
None Run 01:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 51.10
Split: 01, Run: 02
None time:  1.2013815259560943
None Run 02:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 50.10
Split: 01, Run: 03
None time:  1.0591335180215538
None Run 03:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 39.80
run time now: 3.4763638973236084
total time:  3.5322204099502414
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.27 ± 5.64
  Final Train: 100.00 ± 0.00
   Final Test: 47.00 ± 6.26
[I 2023-06-12 00:41:00,576] Trial 1205 finished with value: 49.266666412353516 and parameters: {'Fwd': 0.002513613632799249, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 2.088826840529789, 'loop': 2, 'loss': 'CE', 'lr': 0.00837974727041062, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.04535825675777938, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009979895239136647
weight_decay:  0.010035072243695483
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2702126319054514
None Run 01:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 99.17
   Final Test: 61.70
Split: 01, Run: 02
None time:  0.8981470540165901
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 97.50
   Final Test: 67.10
Split: 01, Run: 03
None time:  1.0378109798766673
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 67.40
run time now: 3.2502214908599854
total time:  3.3043536930345
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.93 ± 5.19
  Final Train: 97.78 ± 1.27
   Final Test: 65.40 ± 3.21
[I 2023-06-12 00:41:04,605] Trial 1206 finished with value: 66.93333435058594 and parameters: {'Fwd': 0.00028151193403267143, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 1.3937433134352273, 'loop': 0, 'loss': 'CE', 'lr': 0.009979895239136647, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.010035072243695483, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009188055501416008
weight_decay:  0.0001761198794478934
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3916394251864403
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.1660840099211782
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 65.40
Split: 01, Run: 03
None time:  1.0579975538421422
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 4.6617021560668945
total time:  4.708875922951847
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 0.92
  Final Train: 98.33 ± 2.89
   Final Test: 68.67 ± 2.84
[I 2023-06-12 00:41:09,913] Trial 1207 finished with value: 72.79999542236328 and parameters: {'Fwd': 0.017674936070565264, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 2.8038114592070156, 'loop': 2, 'loss': 'CE', 'lr': 0.009188055501416008, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001761198794478934, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0003684122511912343
weight_decay:  4.219065152457458e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4913298150058836
None Run 01:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 65.10
Split: 01, Run: 02
None time:  1.5180002979468554
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  3.32957025594078
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 71.20
run time now: 7.381011724472046
total time:  7.427790886024013
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.27 ± 3.41
  Final Train: 98.33 ± 2.89
   Final Test: 68.10 ± 3.05
[I 2023-06-12 00:41:17,973] Trial 1208 finished with value: 68.26667022705078 and parameters: {'Fwd': 0.00020714359831072526, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 8.241024500747494, 'loop': 2, 'loss': 'CE', 'lr': 0.0003684122511912343, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.219065152457458e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.2
lr:  0.008068306778778194
weight_decay:  0.0011125266818751444
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.022404592949897
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 93.33
   Final Test: 69.90
Split: 01, Run: 02
None time:  3.247992797056213
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 92.50
   Final Test: 70.20
Split: 01, Run: 03
None time:  3.561667496105656
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 91.67
   Final Test: 69.70
run time now: 9.919584274291992
total time:  9.988616181071848
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.31
  Final Train: 92.50 ± 0.83
   Final Test: 69.93 ± 0.25
[I 2023-06-12 00:41:28,706] Trial 1209 finished with value: 70.93334197998047 and parameters: {'Fwd': 0.000660714369672652, 'K': 4, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 0.8218678374059367, 'loop': 2, 'loss': 'CE', 'lr': 0.008068306778778194, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0011125266818751444, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0028248181148113265
weight_decay:  0.00013522775905044584
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.67787249898538
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 02
None time:  1.20693589001894
None Run 02:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 62.30
Split: 01, Run: 03
None time:  1.7385662661399692
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 5.669332265853882
total time:  5.718849760014564
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.27 ± 5.61
  Final Train: 100.00 ± 0.00
   Final Test: 66.23 ± 3.68
[I 2023-06-12 00:41:35,032] Trial 1210 finished with value: 67.26667022705078 and parameters: {'Fwd': 2.9564806369953903e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 3.8349389192106282, 'loop': 2, 'loss': 'CE', 'lr': 0.0028248181148113265, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00013522775905044584, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00033000388409851054
weight_decay:  6.969480235492528e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7050681989639997
None Run 01:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 64.30
Split: 01, Run: 02
None time:  1.3795012240298092
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  2.1311855579260737
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.80
run time now: 6.25821328163147
total time:  6.3132054100278765
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.13 ± 3.97
  Final Train: 100.00 ± 0.00
   Final Test: 67.17 ± 2.49
[I 2023-06-12 00:41:41,920] Trial 1211 finished with value: 68.13333892822266 and parameters: {'Fwd': 0.0016800416450502699, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 6.265865200390281, 'loop': 2, 'loss': 'CE', 'lr': 0.00033000388409851054, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.969480235492528e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.008675155787835427
weight_decay:  0.0059795200484872284
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.607615021057427
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.1159856249578297
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1873731340747327
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.40
run time now: 3.954802989959717
total time:  4.012305361917242
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 70.40 ± 1.83
[I 2023-06-12 00:41:46,574] Trial 1212 finished with value: 72.93333435058594 and parameters: {'Fwd': 2.3174556399283756e-06, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.667877019264044, 'loop': 2, 'loss': 'CE', 'lr': 0.008675155787835427, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0059795200484872284, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.0
lr:  0.009983976168470932
weight_decay:  0.00011592430581787327
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3619337838608772
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02
None time:  1.3397063901647925
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  1.2360897108446807
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.9850800037384033
total time:  4.030138578964397
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 1.33
[I 2023-06-12 00:41:51,305] Trial 1213 finished with value: 69.46666717529297 and parameters: {'Fwd': 0.042124247177705514, 'K': 5, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 9.078192533453045, 'loop': 2, 'loss': 'CE', 'lr': 0.009983976168470932, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011592430581787327, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007193612733435231
weight_decay:  0.004845731918579188
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3855819879099727
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 97.50
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.504904825007543
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 98.33
   Final Test: 68.40
Split: 01, Run: 03
None time:  1.4052185739856213
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 68.90
run time now: 5.336377143859863
total time:  5.384917357005179
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 1.22
  Final Train: 98.61 ± 1.27
   Final Test: 69.17 ± 0.93
[I 2023-06-12 00:41:57,388] Trial 1214 finished with value: 72.4000015258789 and parameters: {'Fwd': 0.00016635554586652337, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 5.941744429429551, 'loop': 2, 'loss': 'CE', 'lr': 0.007193612733435231, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004845731918579188, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.0012935167813619675
weight_decay:  0.000562702031109666
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5236834010574967
None Run 01:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 63.10
Split: 01, Run: 02
None time:  2.5316451189573854
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.123076245887205
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
run time now: 5.238043785095215
total time:  5.2949484451673925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.27 ± 5.22
  Final Train: 99.72 ± 0.48
   Final Test: 67.30 ± 3.66
[I 2023-06-12 00:42:03,464] Trial 1215 finished with value: 68.26666259765625 and parameters: {'Fwd': 1.2382202955603413e-05, 'K': 3, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 7.105913881444188, 'loop': 1, 'loss': 'CE', 'lr': 0.0012935167813619675, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000562702031109666, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0014649999896395646
weight_decay:  0.0003007956871270888
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8195969318039715
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  1.6806599430274218
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.10
Split: 01, Run: 03
None time:  0.8036382629070431
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.50
run time now: 5.344817638397217
total time:  5.389153227908537
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 71.73 ± 1.27
[I 2023-06-12 00:42:09,603] Trial 1216 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.0008854242024747152, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 30, 'lambda1': 0.25, 'lambda2': 9.688148462648957, 'loop': 2, 'loss': 'CE', 'lr': 0.0014649999896395646, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003007956871270888, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0007687834321669541
weight_decay:  0.010201173097199139
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.505867124069482
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.70
Split: 01, Run: 02
None time:  3.2196115378756076
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 98.33
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.4402257860638201
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 67.90
run time now: 6.201132535934448
total time:  6.26403020019643
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.67 ± 3.70
  Final Train: 99.44 ± 0.96
   Final Test: 67.53 ± 3.66
[I 2023-06-12 00:42:16,550] Trial 1217 finished with value: 69.66667175292969 and parameters: {'Fwd': 0.0005158257307987196, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 8.911339456543844, 'loop': 2, 'loss': 'CE', 'lr': 0.0007687834321669541, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.010201173097199139, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0016651373833437364
weight_decay:  0.030056264794322152
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.706251161172986
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.30
Split: 01, Run: 02
None time:  2.7215138939209282
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.9928678078576922
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.00
run time now: 6.462669610977173
total time:  6.517156117130071
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 68.17 ± 1.62
[I 2023-06-12 00:42:23,715] Trial 1218 finished with value: 70.13333892822266 and parameters: {'Fwd': 0.012421180615957853, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 9.417333691576369, 'loop': 2, 'loss': 'CE', 'lr': 0.0016651373833437364, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.030056264794322152, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.0008407303971441132
weight_decay:  3.204083741373477e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.93894587084651
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 95.00
   Final Test: 70.40
Split: 01, Run: 02
None time:  1.285384097136557
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 98.33
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.7696236988995224
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 67.00
run time now: 5.035857200622559
total time:  5.081440001958981
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 1.33
  Final Train: 97.22 ± 1.92
   Final Test: 69.47 ± 2.16
[I 2023-06-12 00:42:29,424] Trial 1219 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.0012957271791065052, 'K': 1, 'alpha': 0.25, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 1.5578382351937567, 'loop': 2, 'loss': 'CE', 'lr': 0.0008407303971441132, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.204083741373477e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009137823149336904
weight_decay:  8.789490735448019e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5473443057853729
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.20
Split: 01, Run: 02
None time:  1.0865389481186867
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.1239264868199825
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.800513982772827
total time:  3.847470660926774
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 0.72
  Final Train: 99.72 ± 0.48
   Final Test: 70.63 ± 0.67
[I 2023-06-12 00:42:33,890] Trial 1220 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.0001086962450442125, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 8.398185385050564, 'loop': 2, 'loss': 'CE', 'lr': 0.009137823149336904, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.789490735448019e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007750179947185729
weight_decay:  0.0019444966561883035
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4596395681146532
None Run 01:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 54.50
Split: 01, Run: 02
None time:  1.6342307119630277
None Run 02:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 61.30
Split: 01, Run: 03
None time:  1.4357392590027303
None Run 03:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 62.40
run time now: 4.574877500534058
total time:  4.622991682961583
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.00 ± 4.23
  Final Train: 100.00 ± 0.00
   Final Test: 59.40 ± 4.28
[I 2023-06-12 00:42:39,173] Trial 1221 finished with value: 59.0 and parameters: {'Fwd': 4.4386010978745865e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 4.175691817569372, 'loop': 2, 'loss': 'MSE', 'lr': 0.007750179947185729, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0019444966561883035, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.004850624275142503
weight_decay:  5.66573726489468e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.444587833015248
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.298450964037329
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  1.2051135709043592
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 64.20
run time now: 4.9866437911987305
total time:  5.041506541194394
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.72
  Final Train: 99.72 ± 0.48
   Final Test: 66.73 ± 2.37
[I 2023-06-12 00:42:45,091] Trial 1222 finished with value: 70.4000015258789 and parameters: {'Fwd': 2.152394835720038e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 7.919334821811988, 'loop': 2, 'loss': 'CE', 'lr': 0.004850624275142503, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.66573726489468e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.0005224286779211012
weight_decay:  0.007919820052259588
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.237897781888023
None Run 01:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.20
Split: 01, Run: 02
None time:  1.2308742960449308
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.30
Split: 01, Run: 03
None time:  1.1847994669806212
None Run 03:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 58.20
run time now: 3.695423126220703
total time:  3.7883988379035145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.40 ± 3.08
  Final Train: 100.00 ± 0.00
   Final Test: 60.90 ± 3.11
[I 2023-06-12 00:42:49,630] Trial 1223 finished with value: 62.39999771118164 and parameters: {'Fwd': 0.022635321890807886, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.45, 'lambda2': 6.818736480823464, 'loop': 2, 'loss': 'CE', 'lr': 0.0005224286779211012, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.007919820052259588, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.0011127174057703204
weight_decay:  0.009867640271810803
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.375287096016109
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 61.60
Split: 01, Run: 02
None time:  2.8185860340017825
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.3144489719998091
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 64.90
run time now: 5.559551477432251
total time:  5.605812015011907
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.87 ± 5.83
  Final Train: 99.44 ± 0.96
   Final Test: 65.27 ± 3.86
[I 2023-06-12 00:42:55,847] Trial 1224 finished with value: 68.86666870117188 and parameters: {'Fwd': 6.19211678654107e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.309658273760091, 'loop': 2, 'loss': 'CE', 'lr': 0.0011127174057703204, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.009867640271810803, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.008492357073835485
weight_decay:  0.008521870352055587
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9148837560787797
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  1.4882411148864776
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.3638227821793407
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 5.812972068786621
total time:  5.863173032877967
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.73 ± 1.15
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.81
[I 2023-06-12 00:43:02,369] Trial 1225 finished with value: 73.73332977294922 and parameters: {'Fwd': 0.050719833516082266, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 6.463202872763008, 'loop': 2, 'loss': 'CE', 'lr': 0.008492357073835485, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008521870352055587, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009242763807872778
weight_decay:  1.2780772056550035e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1675366410054266
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 95.83
   Final Test: 65.30
Split: 01, Run: 02
None time:  1.3142174819950014
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 03
None time:  1.249561829958111
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.40
run time now: 4.775932788848877
total time:  4.857414334081113
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.87 ± 1.14
  Final Train: 98.61 ± 2.41
   Final Test: 66.37 ± 1.05
[I 2023-06-12 00:43:07,837] Trial 1226 finished with value: 68.86666107177734 and parameters: {'Fwd': 1.0207340127238432e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 3.8212640061220053, 'loop': 2, 'loss': 'CE', 'lr': 0.009242763807872778, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2780772056550035e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.006639599595929078
weight_decay:  0.0037652724091511167
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.884209976065904
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 69.70
Split: 01, Run: 02
None time:  4.6560117120388895
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 92.50
   Final Test: 70.10
Split: 01, Run: 03
None time:  3.5402618979569525
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 94.17
   Final Test: 71.70
run time now: 11.122878789901733
total time:  11.166802101070061
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.35
  Final Train: 95.00 ± 3.00
   Final Test: 70.50 ± 1.06
[I 2023-06-12 00:43:19,623] Trial 1227 finished with value: 71.0 and parameters: {'Fwd': 0.000792110520339997, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 0.6699463150177065, 'loop': 2, 'loss': 'CE', 'lr': 0.006639599595929078, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0037652724091511167, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  1.0
lr:  0.009987149683090845
weight_decay:  0.01549374526614235
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1461801959667355
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 98.33
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.3157497378997505
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 99.17
   Final Test: 66.70
Split: 01, Run: 03
None time:  1.4191912550013512
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.60
run time now: 4.93125057220459
total time:  4.978494735900313
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 2.12
  Final Train: 98.89 ± 0.48
   Final Test: 68.67 ± 1.70
[I 2023-06-12 00:43:25,235] Trial 1228 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.07603926016460776, 'K': 1, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 1.917851424289039, 'loop': 2, 'loss': 'CE', 'lr': 0.009987149683090845, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.01549374526614235, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.007950523654678866
weight_decay:  0.0035982639412661037
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1136362859979272
None Run 01:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.50
Split: 01, Run: 02
None time:  1.1697753719054163
None Run 02:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 60.80
Split: 01, Run: 03
None time:  1.0374636601191014
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 64.90
run time now: 3.3689663410186768
total time:  3.4184977661352605
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.33 ± 3.70
  Final Train: 100.00 ± 0.00
   Final Test: 62.07 ± 2.46
[I 2023-06-12 00:43:29,303] Trial 1229 finished with value: 65.33333587646484 and parameters: {'Fwd': 1.6706420162909116e-05, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 0.3448405871468734, 'loop': 2, 'loss': 'CE', 'lr': 0.007950523654678866, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0035982639412661037, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008466967876400366
weight_decay:  0.013886387327066008
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3098259018734097
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 95.00
   Final Test: 70.80
Split: 01, Run: 02
None time:  1.7347316050436348
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 98.33
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.1289124889299273
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 67.00
run time now: 5.215054035186768
total time:  5.262577133951709
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.80 ± 0.53
  Final Train: 97.78 ± 2.55
   Final Test: 69.53 ± 2.19
[I 2023-06-12 00:43:35,220] Trial 1230 finished with value: 73.79999542236328 and parameters: {'Fwd': 1.3743075944731945e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 2.541816734613083, 'loop': 2, 'loss': 'CE', 'lr': 0.008466967876400366, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.013886387327066008, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009259349890437094
weight_decay:  0.0004143003833867508
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.516781650017947
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.3738858019933105
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.194160730112344
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 5.13066554069519
total time:  5.182330436073244
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.35
[I 2023-06-12 00:43:41,097] Trial 1231 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.03205137079236532, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 8.691206974416925, 'loop': 2, 'loss': 'CE', 'lr': 0.009259349890437094, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004143003833867508, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0026536215709253123
weight_decay:  1.0649173311050069e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2844563520047814
None Run 01:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 53.00
Split: 01, Run: 02
None time:  1.2739147879183292
None Run 02:
Highest Train: 100.00
Highest Valid: 38.20
  Final Train: 100.00
   Final Test: 38.60
Split: 01, Run: 03
None time:  1.222068347968161
None Run 03:
Highest Train: 100.00
Highest Valid: 35.80
  Final Train: 100.00
   Final Test: 34.70
run time now: 3.8877384662628174
total time:  3.9637370298150927
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 44.00 ± 12.18
  Final Train: 100.00 ± 0.00
   Final Test: 42.10 ± 9.64
[I 2023-06-12 00:43:45,771] Trial 1232 finished with value: 44.0 and parameters: {'Fwd': 0.005423314329862203, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 5.735659395018608, 'loop': 2, 'loss': 'CE', 'lr': 0.0026536215709253123, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0649173311050069e-05, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0006132907680359785
weight_decay:  0.0025972416919257447
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8490418791770935
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 02
None time:  2.9143230160698295
None Run 02:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
Split: 01, Run: 03
None time:  2.2949263798072934
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.30
run time now: 8.10108232498169
total time:  8.166914782021195
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.30 ± 0.00
[I 2023-06-12 00:43:54,592] Trial 1233 finished with value: 51.20000076293945 and parameters: {'Fwd': 0.002080769187624384, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.0, 'lambda2': 3.5299858533872324, 'loop': 2, 'loss': 'CE', 'lr': 0.0006132907680359785, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0025972416919257447, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.002514706330251869
weight_decay:  0.0017238929126682642
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7338460579048842
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.5074, Train: 99.17%, Valid: 69.80% Test: 68.70%
Split: 01, Run: 02
None time:  3.763223011046648
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.2419078389648348
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
run time now: 6.782763481140137
total time:  6.845605839043856
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 2.27
  Final Train: 99.72 ± 0.48
   Final Test: 67.83 ± 2.31
[I 2023-06-12 00:44:02,140] Trial 1234 finished with value: 69.13333129882812 and parameters: {'Fwd': 0.0030016683168554463, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.1, 'lambda2': 6.182840938214568, 'loop': 2, 'loss': 'CE', 'lr': 0.002514706330251869, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0017238929126682642, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.005768637476193871
weight_decay:  0.017008108227433878
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.741025102091953
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 02
None time:  1.337306722998619
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.5132252660114318
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.80
run time now: 5.634434461593628
total time:  5.685966941062361
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 70.60 ± 0.62
[I 2023-06-12 00:44:08,653] Trial 1235 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.09798744803075647, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 9.528932094009832, 'loop': 2, 'loss': 'CE', 'lr': 0.005768637476193871, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.017008108227433878, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0020804245032799867
weight_decay:  0.00014519852197181305
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4323339599650353
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 02
None time:  1.472737040836364
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.3910310210194439
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 5.337924242019653
total time:  5.386648145969957
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 68.40 ± 2.86
[I 2023-06-12 00:44:14,676] Trial 1236 finished with value: 71.13333129882812 and parameters: {'Fwd': 3.5668390147492646e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 9.245846408814046, 'loop': 2, 'loss': 'CE', 'lr': 0.0020804245032799867, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00014519852197181305, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007320027194212779
weight_decay:  4.9890085356171365e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8757654200308025
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.3719692891463637
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.3052689689211547
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 4.629152297973633
total time:  4.692930959863588
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.60 ± 0.53
  Final Train: 99.72 ± 0.48
   Final Test: 70.43 ± 0.32
[I 2023-06-12 00:44:20,043] Trial 1237 finished with value: 74.5999984741211 and parameters: {'Fwd': 0.010200890625930643, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 7.525105597243825, 'loop': 2, 'loss': 'CE', 'lr': 0.007320027194212779, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.9890085356171365e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.6000000000000001
lr:  0.008637488631485989
weight_decay:  3.7274794802694955e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2941342431586236
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 96.67
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.229220086010173
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 03
None time:  1.3886999341193587
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.70
run time now: 4.956668138504028
total time:  5.0047240210697055
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 1.81
  Final Train: 98.89 ± 1.92
   Final Test: 67.57 ± 1.95
[I 2023-06-12 00:44:25,715] Trial 1238 finished with value: 69.73333740234375 and parameters: {'Fwd': 0.0011389750964254503, 'K': 1, 'alpha': 0.6000000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 2.210520309531293, 'loop': 2, 'loss': 'CE', 'lr': 0.008637488631485989, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.7274794802694955e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00013072651253828285
weight_decay:  7.428365661898394e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8570, Train: 100.00%, Valid: 65.80% Test: 63.90%
Split: 01, Run: 01
None time:  3.626516541931778
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.30
Split: 01, Run: 02
None time:  2.1922166778240353
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 03
None time:  1.820577205857262
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.30
run time now: 7.729104518890381
total time:  7.780006846878678
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.40 ± 2.25
  Final Train: 100.00 ± 0.00
   Final Test: 65.67 ± 2.10
[I 2023-06-12 00:44:34,083] Trial 1239 finished with value: 68.4000015258789 and parameters: {'Fwd': 0.061005825353028155, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.15000000000000002, 'lambda2': 5.426699281405624, 'loop': 2, 'loss': 'CE', 'lr': 0.00013072651253828285, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.428365661898394e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0038120652829869836
weight_decay:  0.000763282337943961
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3853567019104958
None Run 01:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 54.80
Split: 01, Run: 02
None time:  1.2545981009025127
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.40
Split: 01, Run: 03
None time:  2.0321926809847355
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.30
run time now: 4.72505259513855
total time:  4.773109469097108
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.67 ± 8.15
  Final Train: 100.00 ± 0.00
   Final Test: 61.83 ± 6.77
[I 2023-06-12 00:44:39,441] Trial 1240 finished with value: 61.66666793823242 and parameters: {'Fwd': 0.0006566767024893827, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 7.735678692212956, 'loop': 2, 'loss': 'MSE', 'lr': 0.0038120652829869836, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000763282337943961, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.003015075182281955
weight_decay:  0.00010167831476509097
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.029923949856311
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 98.33
   Final Test: 71.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.5148, Train: 86.67%, Valid: 70.80% Test: 70.10%
Split: 01, Run: 02
None time:  3.3356120390817523
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 86.67
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.248215412022546
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 65.30
run time now: 6.653185606002808
total time:  6.710528805153444
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 2.47
  Final Train: 95.00 ± 7.26
   Final Test: 69.00 ± 3.29
[I 2023-06-12 00:44:46,836] Trial 1241 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.017495926001934187, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 1.2853338693159557, 'loop': 2, 'loss': 'CE', 'lr': 0.003015075182281955, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010167831476509097, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0078548855498031
weight_decay:  0.0004945148836685922
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.053899910999462
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 66.90
Split: 01, Run: 02
None time:  1.081871845992282
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 03
None time:  1.088334911968559
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.90
run time now: 4.26646876335144
total time:  4.310582607984543
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 2.01
  Final Train: 99.72 ± 0.48
   Final Test: 67.20 ± 1.57
[I 2023-06-12 00:44:51,802] Trial 1242 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.04186336881161284, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 6.688492432755032, 'loop': 2, 'loss': 'CE', 'lr': 0.0078548855498031, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004945148836685922, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.8
lr:  0.009312482229932362
weight_decay:  0.006067030549291043
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2659415530506521
None Run 01:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 63.00
Split: 01, Run: 02
None time:  1.197034243028611
None Run 02:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 54.20
Split: 01, Run: 03
None time:  1.3030047740321606
None Run 03:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 95.00
   Final Test: 50.70
run time now: 3.807202100753784
total time:  3.8526200959458947
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.80 ± 6.52
  Final Train: 98.33 ± 2.89
   Final Test: 55.97 ± 6.34
[I 2023-06-12 00:44:56,380] Trial 1243 finished with value: 56.79999923706055 and parameters: {'Fwd': 0.0249006217927304, 'K': 1, 'alpha': 0.8, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 3.1631781417508984, 'loop': 2, 'loss': 'CE', 'lr': 0.009312482229932362, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.006067030549291043, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0019348645271186058
weight_decay:  0.012941935711299493
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0820790040306747
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 02
None time:  2.1420021359808743
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 03
None time:  1.0772053990513086
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 63.30
run time now: 5.339120149612427
total time:  5.391274348832667
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 1.63
  Final Train: 99.72 ± 0.48
   Final Test: 68.67 ± 4.65
[I 2023-06-12 00:45:02,439] Trial 1244 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.00037279401591589704, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 4.861201714182057, 'loop': 2, 'loss': 'CE', 'lr': 0.0019348645271186058, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.012941935711299493, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0005723750818947732
weight_decay:  7.319720533463819e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6026318999938667
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.1289942399598658
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.7917565568350255
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 71.50
run time now: 5.574113607406616
total time:  5.632497016806155
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.76
  Final Train: 99.44 ± 0.48
   Final Test: 70.17 ± 1.19
[I 2023-06-12 00:45:08,782] Trial 1245 finished with value: 71.86666107177734 and parameters: {'Fwd': 3.4330169905691515e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.55, 'lambda2': 9.008075914828982, 'loop': 2, 'loss': 'CE', 'lr': 0.0005723750818947732, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.319720533463819e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.2
lr:  0.006110569969328234
weight_decay:  4.6555020920788347e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.967349338112399
None Run 01:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 88.33
   Final Test: 57.10
Split: 01, Run: 02
None time:  1.7196832371409982
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 94.17
   Final Test: 64.00
Split: 01, Run: 03
None time:  1.367953757988289
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 63.00
run time now: 5.099655389785767
total time:  5.151494551915675
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.67 ± 3.19
  Final Train: 94.17 ± 5.83
   Final Test: 61.37 ± 3.73
[I 2023-06-12 00:45:14,571] Trial 1246 finished with value: 64.66666412353516 and parameters: {'Fwd': 2.4475066454785646e-05, 'K': 2, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.6000000000000001, 'lambda2': 8.470834912545788, 'loop': 2, 'loss': 'CE', 'lr': 0.006110569969328234, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.6555020920788347e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.006868870147193578
weight_decay:  0.002389907767873499
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.063067575916648
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  2.153502813074738
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.06542912684381
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.60
run time now: 7.324392318725586
total time:  7.372286644997075
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 1.67
  Final Train: 99.72 ± 0.48
   Final Test: 69.53 ± 0.83
[I 2023-06-12 00:45:22,686] Trial 1247 finished with value: 69.73332977294922 and parameters: {'Fwd': 8.572523447491001e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 5.293250612268885, 'loop': 2, 'loss': 'CE', 'lr': 0.006868870147193578, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.002389907767873499, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008554880102830762
weight_decay:  0.02331461848842189
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5976867880672216
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 95.83
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.2452552041504532
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  1.3158707958646119
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.20024847984314
total time:  4.249672302976251
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 1.01
  Final Train: 98.61 ± 2.41
   Final Test: 68.93 ± 0.91
[I 2023-06-12 00:45:27,877] Trial 1248 finished with value: 71.13333892822266 and parameters: {'Fwd': 5.2335672031148415e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.5, 'lambda2': 4.427162770397189, 'loop': 1, 'loss': 'CE', 'lr': 0.008554880102830762, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.02331461848842189, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.004238161512788724
weight_decay:  0.0009289925438599156
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.268162381835282
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 99.17
   Final Test: 63.80
Split: 01, Run: 02
None time:  1.5369141248520464
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 67.40
Split: 01, Run: 03
None time:  1.4825037829577923
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.10
run time now: 5.328680515289307
total time:  5.39300705306232
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 2.31
  Final Train: 99.72 ± 0.48
   Final Test: 66.77 ± 2.71
[I 2023-06-12 00:45:34,019] Trial 1249 finished with value: 70.00000762939453 and parameters: {'Fwd': 0.006410735861000211, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 5.962497511129461, 'loop': 2, 'loss': 'CE', 'lr': 0.004238161512788724, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009289925438599156, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009211874504100121
weight_decay:  0.04921128329031465
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8425199929624796
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 02
None time:  1.3140772378537804
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  1.478912116959691
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 71.60
run time now: 4.681199789047241
total time:  4.73360041109845
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.53 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 71.57 ± 0.15
[I 2023-06-12 00:45:39,410] Trial 1250 finished with value: 74.53333282470703 and parameters: {'Fwd': 0.0014108657095606447, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.35000000000000003, 'lambda2': 9.700300853460142, 'loop': 2, 'loss': 'CE', 'lr': 0.009211874504100121, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.04921128329031465, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9500000000000001
lr:  0.007923543972623192
weight_decay:  0.00023131097412889566
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2396253529004753
None Run 01:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 59.10
Split: 01, Run: 02
None time:  1.24240254284814
None Run 02:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 53.50
Split: 01, Run: 03
None time:  1.204231787007302
None Run 03:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 52.00
run time now: 3.7290971279144287
total time:  3.7791539379395545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.60 ± 6.35
  Final Train: 100.00 ± 0.00
   Final Test: 54.87 ± 3.74
[I 2023-06-12 00:45:43,979] Trial 1251 finished with value: 55.60000228881836 and parameters: {'Fwd': 0.0004568037057878325, 'K': 1, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.065746176704693, 'loop': 2, 'loss': 'CE', 'lr': 0.007923543972623192, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00023131097412889566, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009981750374832923
weight_decay:  1.0013521252826764e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8213852120097727
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 99.17
   Final Test: 71.40
Split: 01, Run: 02
None time:  2.3305033009964973
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.2942860370967537
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.00
run time now: 6.48818826675415
total time:  6.534137148177251
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 1.42
  Final Train: 99.44 ± 0.48
   Final Test: 69.80 ± 1.39
[I 2023-06-12 00:45:51,169] Trial 1252 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.000858887593083018, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 2.879726087575417, 'loop': 2, 'loss': 'CE', 'lr': 0.009981750374832923, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0013521252826764e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00102051722693218
weight_decay:  0.021802251407310267
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.599749807966873
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 02
None time:  2.5227243348490447
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 71.50
Split: 01, Run: 03
None time:  1.1948850189801306
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.3612284660339355
total time:  6.414487080881372
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.90
  Final Train: 99.72 ± 0.48
   Final Test: 71.00 ± 0.46
[I 2023-06-12 00:45:58,236] Trial 1253 finished with value: 72.0666732788086 and parameters: {'Fwd': 1.5048979356367624e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 8.18377424956521, 'loop': 2, 'loss': 'CE', 'lr': 0.00102051722693218, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.021802251407310267, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0006720905165874515
weight_decay:  0.00016345462808451018
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5600684711243957
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 02
None time:  2.3742675739340484
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.254458922194317
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.90
run time now: 6.23201584815979
total time:  6.279711517039686
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.60 ± 0.53
  Final Train: 99.72 ± 0.48
   Final Test: 68.03 ± 2.10
[I 2023-06-12 00:46:05,146] Trial 1254 finished with value: 68.5999984741211 and parameters: {'Fwd': 0.008482308650210707, 'K': 2, 'alpha': 0.05, 'dropout': 0.7000000000000001, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 7.908250963395723, 'loop': 2, 'loss': 'CE', 'lr': 0.0006720905165874515, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00016345462808451018, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007352088192578193
weight_decay:  5.90444618039493e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7387286929879338
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.1183994351886213
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 65.10
Split: 01, Run: 03
None time:  1.1171127469278872
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.10
run time now: 4.014529705047607
total time:  4.060068615945056
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 67.40 ± 2.07
[I 2023-06-12 00:46:09,851] Trial 1255 finished with value: 72.39999389648438 and parameters: {'Fwd': 0.003825914172639996, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 9.310231938140866, 'loop': 2, 'loss': 'CE', 'lr': 0.007352088192578193, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.90444618039493e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00022664822600141068
weight_decay:  0.018305164750044484
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.7777, Train: 100.00%, Valid: 68.80% Test: 68.20%
Split: 01, Run: 01
None time:  3.347084235167131
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 02
None time:  1.3143942079041153
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.4170794098172337
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.60
run time now: 6.130155086517334
total time:  6.175878099864349
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 1.48
[I 2023-06-12 00:46:16,651] Trial 1256 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.03081944580262838, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 8.749544160537967, 'loop': 2, 'loss': 'CE', 'lr': 0.00022664822600141068, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.018305164750044484, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009982016839576408
weight_decay:  5.985675964959985e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1939387298189104
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 71.20
Split: 01, Run: 02
None time:  1.2471503070555627
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.2286126788239926
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 70.50
run time now: 4.724849462509155
total time:  4.773838830878958
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.87 ± 0.76
  Final Train: 99.72 ± 0.48
   Final Test: 70.57 ± 0.60
[I 2023-06-12 00:46:22,175] Trial 1257 finished with value: 74.86666870117188 and parameters: {'Fwd': 0.0002944645626946908, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 7.3527139241823605, 'loop': 2, 'loss': 'CE', 'lr': 0.009982016839576408, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.985675964959985e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.009986308041476571
weight_decay:  5.898719866073629e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8642584539484233
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 64.70
Split: 01, Run: 02
None time:  1.1807188021484762
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 65.70
Split: 01, Run: 03
None time:  1.1302563650533557
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.20
run time now: 4.21919584274292
total time:  4.268078583991155
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 65.53 ± 0.76
[I 2023-06-12 00:46:27,172] Trial 1258 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.00014663635041746884, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 7.331083309269539, 'loop': 2, 'loss': 'CE', 'lr': 0.009986308041476571, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.898719866073629e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.009020360139004212
weight_decay:  1.248743052254461e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7397671400103718
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.3877177729737014
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.2925083360169083
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.70
run time now: 4.4634809494018555
total time:  4.5162393450737
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.20 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 70.70 ± 0.95
[I 2023-06-12 00:46:32,303] Trial 1259 finished with value: 73.19999694824219 and parameters: {'Fwd': 7.178636866975783e-05, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 7.226101545496805, 'loop': 2, 'loss': 'CE', 'lr': 0.009020360139004212, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.248743052254461e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009187010843944467
weight_decay:  0.050171115297408524
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3640314161311835
None Run 01:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 50.60
Split: 01, Run: 02
None time:  1.7186414601746947
None Run 02:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.40
Split: 01, Run: 03
None time:  1.5878534349612892
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.30
run time now: 4.70972752571106
total time:  4.761507023824379
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.13 ± 6.35
  Final Train: 100.00 ± 0.00
   Final Test: 58.43 ± 6.78
[I 2023-06-12 00:46:37,757] Trial 1260 finished with value: 58.133331298828125 and parameters: {'Fwd': 0.00010107487060176554, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 7.551736184667884, 'loop': 2, 'loss': 'MSE', 'lr': 0.009187010843944467, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.050171115297408524, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0051591184330379855
weight_decay:  3.132980651433257e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2470866839867085
None Run 01:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 61.40
Split: 01, Run: 02
None time:  1.371654162881896
None Run 02:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 50.80
Split: 01, Run: 03
None time:  1.4299968159757555
None Run 03:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 99.17
   Final Test: 46.80
run time now: 4.08721399307251
total time:  4.131704335100949
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.93 ± 4.29
  Final Train: 99.72 ± 0.48
   Final Test: 53.00 ± 7.54
[I 2023-06-12 00:46:42,605] Trial 1261 finished with value: 52.93333435058594 and parameters: {'Fwd': 0.0002768677298595466, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 7.46149874810898, 'loop': 2, 'loss': 'CE', 'lr': 0.0051591184330379855, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.132980651433257e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009222046403658134
weight_decay:  0.00038771856175813323
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2628332460299134
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.1942285778932273
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  1.2724111860152334
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.60
run time now: 4.774356365203857
total time:  4.820325643988326
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.20 ± 1.25
  Final Train: 99.72 ± 0.48
   Final Test: 69.87 ± 1.99
[I 2023-06-12 00:46:48,187] Trial 1262 finished with value: 73.19999694824219 and parameters: {'Fwd': 0.00014352026819552585, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 7.11613193348779, 'loop': 2, 'loss': 'CE', 'lr': 0.009222046403658134, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00038771856175813323, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00030974105605904466
weight_decay:  4.038350620804334e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.4006473037879914
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 99.17
   Final Test: 68.40
Split: 01, Run: 02
None time:  1.3478733100928366
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  2.365457581123337
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 70.80
run time now: 7.201886415481567
total time:  7.262473445851356
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 1.17
  Final Train: 99.44 ± 0.48
   Final Test: 69.23 ± 1.36
[I 2023-06-12 00:46:56,133] Trial 1263 finished with value: 69.73333740234375 and parameters: {'Fwd': 0.0001864600293883281, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 6.850599990142539, 'loop': 2, 'loss': 'CE', 'lr': 0.00030974105605904466, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.038350620804334e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009961594310810092
weight_decay:  8.320516233028097e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6932959000114352
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 02
None time:  1.3978737040888518
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.0953569770790637
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 4.230028390884399
total time:  4.273691643029451
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 1.29
  Final Train: 100.00 ± 0.00
   Final Test: 68.93 ± 0.65
[I 2023-06-12 00:47:00,996] Trial 1264 finished with value: 72.0666732788086 and parameters: {'Fwd': 0.00012871006771190393, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 7.583798416626905, 'loop': 2, 'loss': 'CE', 'lr': 0.009961594310810092, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.320516233028097e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009987157096240352
weight_decay:  1.0044209907570266e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.623135183937848
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.4619083020370454
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  4.266549438005313
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.80
run time now: 11.391902446746826
total time:  11.437346403952688
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 1.20
  Final Train: 99.44 ± 0.48
   Final Test: 69.93 ± 0.12
[I 2023-06-12 00:47:13,050] Trial 1265 finished with value: 70.0 and parameters: {'Fwd': 0.0002135514690977512, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 7.276251200763858, 'loop': 2, 'loss': 'CE', 'lr': 0.009987157096240352, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0044209907570266e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.0004498379313928963
weight_decay:  0.0002845779189050704
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0318077579140663
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 92.50
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.4903784268535674
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.674638006137684
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.20
run time now: 5.244056224822998
total time:  5.3071069431025535
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.35
  Final Train: 97.22 ± 4.11
   Final Test: 69.57 ± 0.64
[I 2023-06-12 00:47:19,062] Trial 1266 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.0018774946315965881, 'K': 3, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 1.7300793299593242, 'loop': 2, 'loss': 'CE', 'lr': 0.0004498379313928963, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002845779189050704, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.7000000000000001
lr:  0.0008894806822516983
weight_decay:  0.07862623399159314
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.0742410190869123
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.190567780053243
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 64.60
Split: 01, Run: 03
None time:  1.6608076619450003
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.90
run time now: 5.968044757843018
total time:  6.022670338861644
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.69
  Final Train: 99.72 ± 0.48
   Final Test: 67.57 ± 2.81
[I 2023-06-12 00:47:25,903] Trial 1267 finished with value: 70.4000015258789 and parameters: {'Fwd': 4.215485023589253e-05, 'K': 1, 'alpha': 0.7000000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 6.57942671300655, 'loop': 2, 'loss': 'CE', 'lr': 0.0008894806822516983, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.07862623399159314, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0023214561747515665
weight_decay:  0.06505833533165857
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5911285511683673
None Run 01:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 50.90
Split: 01, Run: 02
None time:  1.929726734990254
None Run 02:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 51.20
Split: 01, Run: 03
None time:  1.4381944900378585
None Run 03:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 55.70
run time now: 5.004405498504639
total time:  5.057200215989724
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.93 ± 4.24
  Final Train: 100.00 ± 0.00
   Final Test: 52.60 ± 2.69
[I 2023-06-12 00:47:31,669] Trial 1268 finished with value: 51.93333435058594 and parameters: {'Fwd': 6.0978432218111444e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 7.733262466242627, 'loop': 2, 'loss': 'CE', 'lr': 0.0023214561747515665, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.06505833533165857, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.008456575397611668
weight_decay:  0.00415462396388753
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7489157898817211
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.2688457819167525
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.409339620033279
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 4.470590114593506
total time:  4.515950266038999
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.60
[I 2023-06-12 00:47:36,880] Trial 1269 finished with value: 72.66666412353516 and parameters: {'Fwd': 0.00035402780821665346, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 7.406852761663432, 'loop': 2, 'loss': 'CE', 'lr': 0.008456575397611668, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00415462396388753, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.008542252394807682
weight_decay:  8.581241799262053e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3316158088855445
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.1443025581538677
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1439806919079274
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 99.17
   Final Test: 65.00
run time now: 3.6588780879974365
total time:  3.707097094040364
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 3.12
  Final Train: 99.72 ± 0.48
   Final Test: 68.40 ± 2.95
[I 2023-06-12 00:47:41,270] Trial 1270 finished with value: 69.5999984741211 and parameters: {'Fwd': 0.00011808349088895911, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 6.963943457198304, 'loop': 0, 'loss': 'CE', 'lr': 0.008542252394807682, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.581241799262053e-06, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.0015311342623512073
weight_decay:  0.029964080214748178
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.581824024906382
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.70
Split: 01, Run: 02
None time:  3.1648654430173337
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 97.50
   Final Test: 72.40
Split: 01, Run: 03
None time:  1.2626578740309924
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.30
run time now: 6.05128812789917
total time:  6.0967085640877485
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 3.00
  Final Train: 99.17 ± 1.44
   Final Test: 68.13 ± 4.35
[I 2023-06-12 00:47:48,069] Trial 1271 finished with value: 70.06666564941406 and parameters: {'Fwd': 7.75653194374987e-05, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 7.907071975193307, 'loop': 2, 'loss': 'CE', 'lr': 0.0015311342623512073, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.029964080214748178, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009104028687805077
weight_decay:  2.58668404399008e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7669216960202903
None Run 01:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 02
None time:  1.5441800910048187
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.4123774270992726
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 4.771349668502808
total time:  4.823844044003636
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.40 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 70.63 ± 0.32
[I 2023-06-12 00:47:53,542] Trial 1272 finished with value: 74.39999389648438 and parameters: {'Fwd': 0.00032716184842629647, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 6.338300066304512, 'loop': 2, 'loss': 'CE', 'lr': 0.009104028687805077, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.58668404399008e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0002537913478235222
weight_decay:  0.0016780498370752056
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.09010973200202
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 68.60
Split: 01, Run: 02
None time:  1.8204490749631077
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  2.891172908945009
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 97.50
   Final Test: 70.40
run time now: 7.884309530258179
total time:  7.9360064240172505
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.50
  Final Train: 98.89 ± 1.27
   Final Test: 69.83 ± 1.07
[I 2023-06-12 00:48:02,155] Trial 1273 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.00024401486421301495, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 5.0921195033404025, 'loop': 2, 'loss': 'CE', 'lr': 0.0002537913478235222, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0016780498370752056, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00017168948180740947
weight_decay:  0.0011331840601774713
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8892, Train: 99.17%, Valid: 65.40% Test: 66.20%
Split: 01, Run: 01
None time:  3.5455666289199144
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 99.17
   Final Test: 66.00
Split: 01, Run: 02
None time:  1.4951038011349738
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.6857227529399097
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 67.40
run time now: 6.768319368362427
total time:  6.821383879054338
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 4.22
  Final Train: 99.72 ± 0.48
   Final Test: 67.63 ± 1.76
[I 2023-06-12 00:48:09,582] Trial 1274 finished with value: 70.26666259765625 and parameters: {'Fwd': 3.069998706371852e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 4.110025980703432, 'loop': 2, 'loss': 'CE', 'lr': 0.00017168948180740947, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0011331840601774713, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0001886635424471733
weight_decay:  1.2997977392729593e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.8921, Train: 99.17%, Valid: 65.40% Test: 66.50%
Split: 01, Run: 01
None time:  3.5431167639326304
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 99.17
   Final Test: 66.40
Split: 01, Run: 02
None time:  1.3681433429010212
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  1.4893961269408464
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.10
run time now: 6.446418046951294
total time:  6.496008740970865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.40 ± 3.49
  Final Train: 99.72 ± 0.48
   Final Test: 66.87 ± 0.40
[I 2023-06-12 00:48:16,737] Trial 1275 finished with value: 69.4000015258789 and parameters: {'Fwd': 0.00021232760159172452, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 4.704119250123746, 'loop': 2, 'loss': 'CE', 'lr': 0.0001886635424471733, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2997977392729593e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.004714333933113675
weight_decay:  0.00011193858735639788
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1456901859492064
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 97.50
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.4783268868923187
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.219449761789292
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 4.883559942245483
total time:  4.933875613147393
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 0.40
  Final Train: 99.17 ± 1.44
   Final Test: 69.63 ± 0.42
[I 2023-06-12 00:48:22,374] Trial 1276 finished with value: 72.19999694824219 and parameters: {'Fwd': 0.0030328932246071194, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 5.584079099962685, 'loop': 2, 'loss': 'CE', 'lr': 0.004714333933113675, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011193858735639788, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.0
lr:  0.0018753617670143373
weight_decay:  4.53011595831699e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7585843740962446
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  2.7136699471157044
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 95.83
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.3745108200237155
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 5.894376754760742
total time:  5.941183512099087
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.31
  Final Train: 98.61 ± 2.41
   Final Test: 70.33 ± 0.12
[I 2023-06-12 00:48:29,025] Trial 1277 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.00264903472422719, 'K': 4, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 8.055540044373158, 'loop': 2, 'loss': 'CE', 'lr': 0.0018753617670143373, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.53011595831699e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007945686841853632
weight_decay:  0.0006293835371393244
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5967257691081613
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 66.50
Split: 01, Run: 02
None time:  1.7600655718706548
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 99.17
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.4055590038187802
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 68.80
run time now: 4.807751893997192
total time:  4.8553934779483825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 1.86
  Final Train: 99.44 ± 0.48
   Final Test: 68.03 ± 1.33
[I 2023-06-12 00:48:34,680] Trial 1278 finished with value: 72.26666259765625 and parameters: {'Fwd': 0.000166279670621577, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 2.6943961481101857, 'loop': 2, 'loss': 'CE', 'lr': 0.007945686841853632, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006293835371393244, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.009984925047085008
weight_decay:  0.00019220484106581142
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.908112752949819
None Run 01:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 47.90
Split: 01, Run: 02
None time:  1.7052794590126723
None Run 02:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 60.30
Split: 01, Run: 03
None time:  1.542995355091989
None Run 03:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 63.20
run time now: 5.199564456939697
total time:  5.2539310129359365
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.80 ± 8.19
  Final Train: 100.00 ± 0.00
   Final Test: 57.13 ± 8.13
[I 2023-06-12 00:48:40,795] Trial 1279 finished with value: 55.79999923706055 and parameters: {'Fwd': 5.4338311351989276e-05, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.3011670008255214, 'loop': 2, 'loss': 'MSE', 'lr': 0.009984925047085008, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00019220484106581142, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008595254384903658
weight_decay:  1.9098022415085263e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.267975531052798
None Run 01:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 02
None time:  1.014743987005204
None Run 02:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 03
None time:  1.277560805203393
None Run 03:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 97.50
   Final Test: 51.60
run time now: 3.6102354526519775
total time:  3.694144709035754
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.20 ± 3.90
  Final Train: 99.17 ± 1.44
   Final Test: 55.20 ± 3.12
[I 2023-06-12 00:48:45,203] Trial 1280 finished with value: 56.20000076293945 and parameters: {'Fwd': 2.0502944668223845e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 7.703860364200734, 'loop': 2, 'loss': 'CE', 'lr': 0.008595254384903658, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.9098022415085263e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.55
lr:  0.006526732689680322
weight_decay:  0.002394294585871597
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8935781358741224
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.7534520060289651
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.2966165521647781
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.40
run time now: 4.9845781326293945
total time:  5.039066276047379
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 1.01
  Final Train: 99.72 ± 0.48
   Final Test: 70.87 ± 0.61
[I 2023-06-12 00:48:50,841] Trial 1281 finished with value: 72.53333282470703 and parameters: {'Fwd': 0.0018348635561974084, 'K': 1, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 7.22075649117681, 'loop': 2, 'loss': 'CE', 'lr': 0.006526732689680322, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002394294585871597, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.45
lr:  0.009093189992725575
weight_decay:  1.484206358831852e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.387201654026285
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.1879277171101421
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  1.3445911509916186
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 4.96169114112854
total time:  5.0146171930246055
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 1.18
[I 2023-06-12 00:48:56,512] Trial 1282 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.0002888319684936539, 'K': 2, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.05, 'lambda2': 5.856899895180279, 'loop': 2, 'loss': 'CE', 'lr': 0.009093189992725575, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.484206358831852e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0005604125107841633
weight_decay:  5.8598635667711045e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.569588236976415
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.5910149170085788
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  1.7524013640359044
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.80
run time now: 5.955219507217407
total time:  6.015823926078156
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 1.10
  Final Train: 99.72 ± 0.48
   Final Test: 69.60 ± 1.57
[I 2023-06-12 00:49:03,291] Trial 1283 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.0013874588436215988, 'K': 1, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 120, 'lambda1': 0.35000000000000003, 'lambda2': 6.11294986650947, 'loop': 2, 'loss': 'CE', 'lr': 0.0005604125107841633, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.8598635667711045e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007667787376720631
weight_decay:  6.88738960415077e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.8854214348830283
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  5.680933121126145
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.70
Split: 01, Run: 03
None time:  3.517328877002001
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.10
run time now: 13.122094631195068
total time:  13.171694720163941
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 99.72 ± 0.48
   Final Test: 70.67 ± 0.45
[I 2023-06-12 00:49:17,181] Trial 1284 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.01278559526577791, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 8.528720915522316, 'loop': 2, 'loss': 'CE', 'lr': 0.007667787376720631, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.88738960415077e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.30000000000000004
lr:  0.00037760317914779996
weight_decay:  9.212617664885519e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.080053246812895
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.3495027860626578
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.6810273588635027
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.30
run time now: 5.155735492706299
total time:  5.200807253830135
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 1.40
  Final Train: 99.72 ± 0.48
   Final Test: 70.50 ± 0.69
[I 2023-06-12 00:49:23,051] Trial 1285 finished with value: 71.53333282470703 and parameters: {'Fwd': 3.756574248399223e-05, 'K': 2, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 7.099833315560847, 'loop': 2, 'loss': 'CE', 'lr': 0.00037760317914779996, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.212617664885519e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.001354873990194215
weight_decay:  3.511433555514769e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5613, Train: 90.00%, Valid: 67.80% Test: 66.40%
Split: 01, Run: 01
None time:  3.308231503935531
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 90.83
   Final Test: 66.40
Split: 01, Run: 02
None time:  1.4085454200394452
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  1.4523921529762447
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 66.60
run time now: 6.215250730514526
total time:  6.269838628126308
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 2.16
  Final Train: 96.94 ± 5.29
   Final Test: 66.70 ± 0.36
[I 2023-06-12 00:49:29,954] Trial 1286 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.00010285704123875043, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 7.388696628396936, 'loop': 2, 'loss': 'CE', 'lr': 0.001354873990194215, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.511433555514769e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.009160035131781775
weight_decay:  3.766521198174104e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9914757970254868
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 97.50
   Final Test: 71.90
Split: 01, Run: 02
None time:  1.5936795049346983
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  1.3356519490480423
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 68.30
run time now: 4.9660484790802
total time:  5.018964728107676
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.20 ± 0.35
  Final Train: 99.17 ± 1.44
   Final Test: 69.27 ± 2.31
[I 2023-06-12 00:49:35,714] Trial 1287 finished with value: 74.20000457763672 and parameters: {'Fwd': 2.707158102738809e-05, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 3.989457947967882, 'loop': 2, 'loss': 'CE', 'lr': 0.009160035131781775, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.766521198174104e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.15000000000000002
lr:  0.00014573144028222305
weight_decay:  0.0008356195124659928
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 1.0519, Train: 99.17%, Valid: 62.60% Test: 60.90%
Split: 01, Run: 01
None time:  2.4617118530441076
None Run 01:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 99.17
   Final Test: 60.90
Split: 01, Run: 02
None time:  0.9109577548224479
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 64.90
Split: 01, Run: 03
None time:  1.162321805022657
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 66.30
run time now: 4.57674765586853
total time:  4.632891991175711
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.20 ± 4.85
  Final Train: 99.72 ± 0.48
   Final Test: 64.03 ± 2.80
[I 2023-06-12 00:49:41,016] Trial 1288 finished with value: 68.20000457763672 and parameters: {'Fwd': 1.326216749033046e-05, 'K': 1, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 2.0255188804284368, 'loop': 1, 'loss': 'CE', 'lr': 0.00014573144028222305, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008356195124659928, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.00805526489885106
weight_decay:  0.00013519100771459415
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4300915258936584
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.30
Split: 01, Run: 02
None time:  1.2870164308696985
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.50
Split: 01, Run: 03
None time:  1.3769118529744446
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 99.17
   Final Test: 66.30
run time now: 4.141323089599609
total time:  4.19347724202089
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.07 ± 1.36
  Final Train: 99.72 ± 0.48
   Final Test: 65.37 ± 0.90
[I 2023-06-12 00:49:45,884] Trial 1289 finished with value: 66.0666732788086 and parameters: {'Fwd': 0.0009744079810949038, 'K': 3, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 6.752482812620858, 'loop': 2, 'loss': 'CE', 'lr': 0.00805526489885106, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00013519100771459415, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0054769894843039605
weight_decay:  1.4797482744887643e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4248704782221466
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.3297143729869276
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.247016442939639
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.00
run time now: 5.0518128871917725
total time:  5.109606041107327
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 1.22
  Final Train: 99.72 ± 0.48
   Final Test: 68.60 ± 0.52
[I 2023-06-12 00:49:51,630] Trial 1290 finished with value: 72.20000457763672 and parameters: {'Fwd': 0.004613351778280166, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 8.320954472783134, 'loop': 2, 'loss': 'CE', 'lr': 0.0054769894843039605, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4797482744887643e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.001216883305789957
weight_decay:  1.0663906941901668e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.919958048965782
None Run 01:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 93.33
   Final Test: 65.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.2271, Train: 86.67%, Valid: 66.80% Test: 66.10%
Split: 01, Run: 02
None time:  3.6010669129900634
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 86.67
   Final Test: 66.10
Split: 01, Run: 03
None time:  1.2569108719471842
None Run 03:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 61.80
run time now: 6.828392028808594
total time:  6.880614533089101
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.27 ± 2.27
  Final Train: 93.33 ± 6.67
   Final Test: 64.33 ± 2.25
[I 2023-06-12 00:49:59,209] Trial 1291 finished with value: 64.26666259765625 and parameters: {'Fwd': 0.00046607052733534034, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.1, 'lambda2': 0.3749932598714798, 'loop': 2, 'loss': 'CE', 'lr': 0.001216883305789957, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0663906941901668e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008506765359908363
weight_decay:  0.008652152415027333
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9565813129302114
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 95.00
   Final Test: 66.40
Split: 01, Run: 02
None time:  1.8693550571333617
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 90.83
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.3902577159460634
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 66.00
run time now: 5.256366968154907
total time:  5.313463109079748
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 1.44
  Final Train: 95.28 ± 4.59
   Final Test: 67.20 ± 1.74
[I 2023-06-12 00:50:05,159] Trial 1292 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0023352349639937475, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 1.2048544003600181, 'loop': 2, 'loss': 'CE', 'lr': 0.008506765359908363, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008652152415027333, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.007071918743484938
weight_decay:  0.00035246075365262357
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2180733499117196
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.60
Split: 01, Run: 02
None time:  2.5646605170331895
None Run 02:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.60
Split: 01, Run: 03
None time:  2.514588245889172
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.60
run time now: 7.342458248138428
total time:  7.393318635877222
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.60 ± 0.00
[I 2023-06-12 00:50:13,252] Trial 1293 finished with value: 51.40000534057617 and parameters: {'Fwd': 8.225499239763922e-05, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.0, 'lambda2': 3.713875102991627, 'loop': 2, 'loss': 'CE', 'lr': 0.007071918743484938, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00035246075365262357, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009989727179826675
weight_decay:  0.0004870447935785106
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.569745633052662
None Run 01:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 71.50
Split: 01, Run: 02
None time:  1.960021787090227
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.2530896191019565
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 68.00
run time now: 4.834315061569214
total time:  4.886362304911017
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 1.75
[I 2023-06-12 00:50:18,880] Trial 1294 finished with value: 74.20000457763672 and parameters: {'Fwd': 0.05627078688453962, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 5.313196743493472, 'loop': 2, 'loss': 'CE', 'lr': 0.009989727179826675, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004870447935785106, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009170910487238521
weight_decay:  1.3308426670406692e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.878893081098795
None Run 01:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 99.17
   Final Test: 70.70
Split: 01, Run: 02
None time:  1.923062421148643
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 96.67
   Final Test: 72.10
Split: 01, Run: 03
None time:  1.3751372040715069
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 72.00
run time now: 5.217875719070435
total time:  5.265033924020827
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.20 ± 0.72
  Final Train: 98.61 ± 1.73
   Final Test: 71.60 ± 0.78
[I 2023-06-12 00:50:24,801] Trial 1295 finished with value: 75.20000457763672 and parameters: {'Fwd': 0.07621883702325652, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 2.2773983211315265, 'loop': 2, 'loss': 'CE', 'lr': 0.009170910487238521, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3308426670406692e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0034527806028057445
weight_decay:  1.1752031660461976e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0286263208836317
None Run 01:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 99.17
   Final Test: 71.70
Split: 01, Run: 02
None time:  2.4212987991049886
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 96.67
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.5594940891023725
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 98.33
   Final Test: 70.60
run time now: 6.050666093826294
total time:  6.1022860910743475
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.73 ± 1.70
  Final Train: 98.06 ± 1.27
   Final Test: 70.93 ± 0.67
[I 2023-06-12 00:50:31,586] Trial 1296 finished with value: 73.73332977294922 and parameters: {'Fwd': 0.065825150314957, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 2.3794570232388854, 'loop': 2, 'loss': 'CE', 'lr': 0.0034527806028057445, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1752031660461976e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.003299374627159783
weight_decay:  1.4190050792873244e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.911590380128473
None Run 01:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 94.17
   Final Test: 50.60
Split: 01, Run: 02
None time:  2.0728896758519113
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 96.67
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.6631600419059396
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 97.50
   Final Test: 70.10
run time now: 5.698058605194092
total time:  5.749806914012879
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.33 ± 12.96
  Final Train: 96.11 ± 1.73
   Final Test: 63.47 ± 11.14
[I 2023-06-12 00:50:38,041] Trial 1297 finished with value: 65.33333587646484 and parameters: {'Fwd': 0.07742678775852105, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 1.6479290965582596, 'loop': 2, 'loss': 'CE', 'lr': 0.003299374627159783, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4190050792873244e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009252212743139088
weight_decay:  2.389093298585216e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6174974080640823
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 97.50
   Final Test: 71.00
Split: 01, Run: 02
None time:  1.888370503904298
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 97.50
   Final Test: 72.60
Split: 01, Run: 03
None time:  1.2975519779138267
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.00
run time now: 5.8411290645599365
total time:  5.889631055062637
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.67 ± 0.42
  Final Train: 98.33 ± 1.44
   Final Test: 71.53 ± 0.92
[I 2023-06-12 00:50:44,659] Trial 1298 finished with value: 74.66666412353516 and parameters: {'Fwd': 0.07893920200430773, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 2.2976764301709065, 'loop': 2, 'loss': 'CE', 'lr': 0.009252212743139088, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.389093298585216e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.001625846327304055
weight_decay:  1.598970089158413e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4292250231374055
None Run 01:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 42.40
Split: 01, Run: 02
None time:  1.589830419048667
None Run 02:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 53.30
Split: 01, Run: 03
None time:  1.5054382069502026
None Run 03:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 57.70
run time now: 4.5671608448028564
total time:  4.622931177029386
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.53 ± 6.27
  Final Train: 100.00 ± 0.00
   Final Test: 51.13 ± 7.88
[I 2023-06-12 00:50:50,258] Trial 1299 finished with value: 49.533329010009766 and parameters: {'Fwd': 0.08134310929556239, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 2.5883340453880885, 'loop': 2, 'loss': 'MSE', 'lr': 0.001625846327304055, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.598970089158413e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009997695275539027
weight_decay:  8.560821920695032e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2442849369253963
None Run 01:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 60.80
Split: 01, Run: 02
None time:  1.3548729128669947
None Run 02:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 96.67
   Final Test: 51.60
Split: 01, Run: 03
None time:  1.531427786918357
None Run 03:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 54.17
   Final Test: 41.20
run time now: 4.171072959899902
total time:  4.22073007398285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.87 ± 8.37
  Final Train: 83.61 ± 25.55
   Final Test: 51.20 ± 9.81
[I 2023-06-12 00:50:55,126] Trial 1300 finished with value: 53.866668701171875 and parameters: {'Fwd': 0.043700754901130776, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 0.49174318304262243, 'loop': 2, 'loss': 'CE', 'lr': 0.009997695275539027, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.560821920695032e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.000756212503112486
weight_decay:  1.2400007145413943e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.262606522999704
None Run 01:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 98.33
   Final Test: 61.60
Split: 01, Run: 02
None time:  2.2689595131669194
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 98.33
   Final Test: 68.50
Split: 01, Run: 03
None time:  2.9006085600703955
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.83
   Final Test: 68.50
run time now: 7.477943420410156
total time:  7.538467667996883
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.73 ± 3.23
  Final Train: 97.50 ± 1.44
   Final Test: 66.20 ± 3.98
[I 2023-06-12 00:51:03,313] Trial 1301 finished with value: 66.73333740234375 and parameters: {'Fwd': 0.05444099276396099, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 3.0746966179163633, 'loop': 2, 'loss': 'CE', 'lr': 0.000756212503112486, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2400007145413943e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008613228988994737
weight_decay:  9.33108762868574e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3545421748422086
None Run 01:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 99.17
   Final Test: 52.20
Split: 01, Run: 02
None time:  1.3175051489379257
None Run 02:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 44.70
Split: 01, Run: 03
None time:  2.5758431691210717
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 89.17
   Final Test: 62.70
run time now: 5.288092851638794
total time:  5.336361734895036
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.47 ± 9.10
  Final Train: 96.11 ± 6.03
   Final Test: 53.20 ± 9.04
[I 2023-06-12 00:51:09,352] Trial 1302 finished with value: 56.4666633605957 and parameters: {'Fwd': 0.06953315120634668, 'K': 1, 'alpha': 0.0, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 1.9169784191616939, 'loop': 2, 'loss': 'CE', 'lr': 0.008613228988994737, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.33108762868574e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009079964614839772
weight_decay:  0.0013593606824043407
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.7196135208942
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 94.17
   Final Test: 70.10
Split: 01, Run: 02
None time:  5.069193630013615
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.83
   Final Test: 70.90
Split: 01, Run: 03
None time:  5.171998589998111
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 93.33
   Final Test: 70.00
run time now: 15.009961366653442
total time:  15.068849439034238
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.12
  Final Train: 94.44 ± 1.27
   Final Test: 70.33 ± 0.49
[I 2023-06-12 00:51:25,101] Trial 1303 finished with value: 71.26667022705078 and parameters: {'Fwd': 3.801822264946213e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 2.17847976090991, 'loop': 2, 'loss': 'CE', 'lr': 0.009079964614839772, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0013593606824043407, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0001936939698175322
weight_decay:  1.8615254702284085e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.7213, Train: 100.00%, Valid: 71.00% Test: 70.20%
Split: 01, Run: 01
None time:  3.75301908608526
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.4536398688796908
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.966296758968383
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.40
run time now: 8.214303016662598
total time:  8.26105295913294
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.69
[I 2023-06-12 00:51:34,150] Trial 1304 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.09409136285272586, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 2.14307845366448, 'loop': 2, 'loss': 'CE', 'lr': 0.0001936939698175322, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.8615254702284085e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0017141411266655751
weight_decay:  0.007347112803152135
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4535925381351262
None Run 01:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 49.80
Split: 01, Run: 02
None time:  3.4512812281027436
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 95.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  2.2297445798758417
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 96.67
   Final Test: 71.20
run time now: 7.176034212112427
total time:  7.2210273668169975
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.73 ± 11.20
  Final Train: 97.22 ± 2.55
   Final Test: 64.30 ± 12.56
[I 2023-06-12 00:51:42,037] Trial 1305 finished with value: 66.73332977294922 and parameters: {'Fwd': 0.09779977702156209, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 1.8465802802586926, 'loop': 2, 'loss': 'CE', 'lr': 0.0017141411266655751, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007347112803152135, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008060342951328287
weight_decay:  1.4203821976264776e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6271087320055813
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.4234937708824873
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 64.80
Split: 01, Run: 03
None time:  1.2983633868861943
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.40
run time now: 4.387652397155762
total time:  4.430507982848212
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 1.68
  Final Train: 99.72 ± 0.48
   Final Test: 67.40 ± 2.36
[I 2023-06-12 00:51:47,207] Trial 1306 finished with value: 71.26667022705078 and parameters: {'Fwd': 5.246490972389088e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 2.7528256113877756, 'loop': 2, 'loss': 'CE', 'lr': 0.008060342951328287, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4203821976264776e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0009071812271316889
weight_decay:  0.0006183591264231669
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5698402940761298
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 02
None time:  2.93140950310044
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 92.50
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.861669196980074
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 95.00
   Final Test: 71.50
run time now: 6.4466047286987305
total time:  6.501260478980839
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 2.00
  Final Train: 95.83 ± 3.82
   Final Test: 69.70 ± 2.70
[I 2023-06-12 00:51:54,423] Trial 1307 finished with value: 70.86666107177734 and parameters: {'Fwd': 0.00017638983337038712, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 2.446255167753815, 'loop': 2, 'loss': 'CE', 'lr': 0.0009071812271316889, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006183591264231669, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00015383553871760463
weight_decay:  5.456499984229488e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8371479879133403
None Run 01:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 99.17
   Final Test: 52.20
Split: 01, Run: 02
None time:  1.3277898931410164
None Run 02:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 53.60
Split: 01, Run: 03
None time:  1.2576287211850286
None Run 03:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 54.20
run time now: 5.464971303939819
total time:  5.515667062019929
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.13 ± 2.19
  Final Train: 99.72 ± 0.48
   Final Test: 53.33 ± 1.03
[I 2023-06-12 00:52:00,594] Trial 1308 finished with value: 57.133331298828125 and parameters: {'Fwd': 1.7356419514880928e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 2.339286443276528, 'loop': 2, 'loss': 'CE', 'lr': 0.00015383553871760463, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.456499984229488e-05, 'weightedloss': False}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0014395017036440852
weight_decay:  7.571380678239364e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9069179128855467
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 90.83
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.4947666830848902
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.490080103976652
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.70
run time now: 5.9314799308776855
total time:  5.988418708089739
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.23
  Final Train: 96.67 ± 5.07
   Final Test: 69.97 ± 0.25
[I 2023-06-12 00:52:07,201] Trial 1309 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.034894561196587515, 'K': 1, 'alpha': 0.05, 'dropout': 0.1, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 2.115573932622318, 'loop': 2, 'loss': 'CE', 'lr': 0.0014395017036440852, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.571380678239364e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00010869233094387495
weight_decay:  0.0009980415972333642
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.6963, Train: 99.17%, Valid: 65.00% Test: 65.00%
Split: 01, Run: 01
None time:  3.678361074998975
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 99.17
   Final Test: 64.40
Split: 01, Run: 02
None time:  1.5219868759158999
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.5710141800809652
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.00
run time now: 6.813234567642212
total time:  6.868489691987634
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 3.12
  Final Train: 99.72 ± 0.48
   Final Test: 67.50 ± 2.69
[I 2023-06-12 00:52:14,746] Trial 1310 finished with value: 69.20000457763672 and parameters: {'Fwd': 2.05425269911958e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 3.4921947824729807, 'loop': 2, 'loss': 'CE', 'lr': 0.00010869233094387495, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009980415972333642, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0006875614464949817
weight_decay:  3.602070766596176e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2966248551383615
None Run 01:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 99.17
   Final Test: 61.80
Split: 01, Run: 02
None time:  2.5090696869883686
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 03
None time:  2.248621157137677
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 98.33
   Final Test: 70.20
run time now: 7.093604803085327
total time:  7.146642556879669
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 5.08
  Final Train: 98.89 ± 0.48
   Final Test: 67.47 ± 4.91
[I 2023-06-12 00:52:22,601] Trial 1311 finished with value: 68.46666717529297 and parameters: {'Fwd': 1.2016434424219913e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 4.5116009624598385, 'loop': 2, 'loss': 'CE', 'lr': 0.0006875614464949817, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.602070766596176e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.00034441097849055656
weight_decay:  5.495883270881783e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5950, Train: 100.00%, Valid: 70.80% Test: 69.00%
Split: 01, Run: 01
None time:  3.549338618060574
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.5925304850097746
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.8982414400670677
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 7.081516265869141
total time:  7.131261182948947
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.70
[I 2023-06-12 00:52:30,461] Trial 1312 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0609133142178116, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 5.730378760609383, 'loop': 2, 'loss': 'CE', 'lr': 0.00034441097849055656, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.495883270881783e-06, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.009216341275237025
weight_decay:  2.105870120212407e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6344912599306554
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 02
None time:  1.5272734190803021
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.6085492460988462
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 99.17
   Final Test: 70.40
run time now: 4.830833196640015
total time:  4.889417241094634
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 1.25
  Final Train: 99.72 ± 0.48
   Final Test: 69.70 ± 1.39
[I 2023-06-12 00:52:36,039] Trial 1313 finished with value: 69.80000305175781 and parameters: {'Fwd': 2.7526562748422365e-05, 'K': 10, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 7.666691075933316, 'loop': 2, 'loss': 'CE', 'lr': 0.009216341275237025, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.105870120212407e-05, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.008358514525561517
weight_decay:  0.006433605878309308
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.007648854982108
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 94.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.3469288910273463
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 03
None time:  1.3696013500448316
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 68.90
run time now: 4.759920597076416
total time:  4.806674772873521
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 0.35
  Final Train: 98.06 ± 3.37
   Final Test: 68.30 ± 2.26
[I 2023-06-12 00:52:41,501] Trial 1314 finished with value: 73.0 and parameters: {'Fwd': 0.0002423401504199502, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 2.4765039232271806, 'loop': 2, 'loss': 'CE', 'lr': 0.008358514525561517, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006433605878309308, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0005073367277875682
weight_decay:  0.0007697171624102268
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1883840321097523
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.80
Split: 01, Run: 02
None time:  1.3223818549886346
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.2405770120676607
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 72.20
run time now: 6.789292335510254
total time:  6.833651005057618
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 0.69
  Final Train: 99.44 ± 0.48
   Final Test: 70.90 ± 1.25
[I 2023-06-12 00:52:48,959] Trial 1315 finished with value: 72.20000457763672 and parameters: {'Fwd': 6.642117894522605e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 6.449614639789765, 'loop': 2, 'loss': 'CE', 'lr': 0.0005073367277875682, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007697171624102268, 'weightedloss': True}. Best is trial 971 with value: 75.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009010156787048196
weight_decay:  4.6620923955169614e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7688770520035177
None Run 01:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 02
None time:  1.2164227850735188
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 03
None time:  1.3736751331016421
None Run 03:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 72.70
run time now: 4.400270462036133
total time:  4.4471826471854
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.07 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 72.30 ± 0.53
[I 2023-06-12 00:52:54,137] Trial 1316 finished with value: 76.06666564941406 and parameters: {'Fwd': 0.021201552658633535, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 4.966143048491846, 'loop': 2, 'loss': 'CE', 'lr': 0.009010156787048196, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.6620923955169614e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00020467601471057536
weight_decay:  4.201353482683492e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.332750217989087
None Run 01:
Highest Train: 100.00
Highest Valid: 27.60
  Final Train: 100.00
   Final Test: 28.30
Split: 01, Run: 02
None time:  1.287162068998441
None Run 02:
Highest Train: 100.00
Highest Valid: 28.40
  Final Train: 100.00
   Final Test: 29.00
Split: 01, Run: 03
None time:  1.2615347318351269
None Run 03:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 34.20
run time now: 3.9302382469177246
total time:  3.993098472012207
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 29.93 ± 3.37
  Final Train: 100.00 ± 0.00
   Final Test: 30.50 ± 3.22
[I 2023-06-12 00:52:58,741] Trial 1317 finished with value: 29.933334350585938 and parameters: {'Fwd': 0.0189679975873639, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 4.975342993836052, 'loop': 2, 'loss': 'MSE', 'lr': 0.00020467601471057536, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.201353482683492e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007642503787957492
weight_decay:  4.9492861189975966e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9677732430864125
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 02
None time:  1.276630052831024
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  1.3060483599547297
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 4.594388008117676
total time:  4.639522405108437
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 1.06
  Final Train: 99.72 ± 0.48
   Final Test: 70.10 ± 0.61
[I 2023-06-12 00:53:04,048] Trial 1318 finished with value: 72.0 and parameters: {'Fwd': 0.020287010812311504, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 5.225651808940306, 'loop': 1, 'loss': 'CE', 'lr': 0.007642503787957492, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.9492861189975966e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00037894274269483185
weight_decay:  6.233816860753555e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9143268528860062
None Run 01:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 61.40
Split: 01, Run: 02
None time:  1.3896133890375495
None Run 02:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 57.20
Split: 01, Run: 03
None time:  1.4766730179544538
None Run 03:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 99.17
   Final Test: 56.00
run time now: 4.819195985794067
total time:  4.863510318100452
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.33 ± 2.01
  Final Train: 99.72 ± 0.48
   Final Test: 58.20 ± 2.84
[I 2023-06-12 00:53:09,705] Trial 1319 finished with value: 59.33333206176758 and parameters: {'Fwd': 1.615757194350712e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 4.604569002139008, 'loop': 2, 'loss': 'CE', 'lr': 0.00037894274269483185, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.233816860753555e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0022034180380006868
weight_decay:  4.1986294276296806e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5517621929757297
None Run 01:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 02
None time:  2.024040065938607
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 98.33
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.4536228680517524
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 63.80
run time now: 5.069437742233276
total time:  5.1257564960978925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.93 ± 2.19
  Final Train: 99.44 ± 0.96
   Final Test: 67.13 ± 3.06
[I 2023-06-12 00:53:15,558] Trial 1320 finished with value: 67.93333435058594 and parameters: {'Fwd': 3.6297035298361123e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 5.960950390841117, 'loop': 2, 'loss': 'CE', 'lr': 0.0022034180380006868, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.1986294276296806e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007942580994053657
weight_decay:  2.6971633990699257e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7224728839937598
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 99.17
   Final Test: 64.50
Split: 01, Run: 02
None time:  0.7760078180581331
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 03
None time:  1.1910642480943352
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.7372868061065674
total time:  3.7845015430357307
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.44
  Final Train: 99.72 ± 0.48
   Final Test: 66.73 ± 2.30
[I 2023-06-12 00:53:19,961] Trial 1321 finished with value: 70.20000457763672 and parameters: {'Fwd': 3.053890027276883e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 4.209330421774588, 'loop': 2, 'loss': 'CE', 'lr': 0.007942580994053657, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.6971633990699257e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0002712326678917906
weight_decay:  5.288956174574698e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7654698719270527
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 99.17
   Final Test: 65.20
Split: 01, Run: 02
None time:  1.4323656880296767
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  1.2842448600567877
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.70
run time now: 5.549494504928589
total time:  5.595272310078144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.60 ± 2.25
  Final Train: 99.72 ± 0.48
   Final Test: 66.40 ± 1.08
[I 2023-06-12 00:53:26,234] Trial 1322 finished with value: 68.5999984741211 and parameters: {'Fwd': 1.4144090790971413e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 4.782995060533408, 'loop': 2, 'loss': 'CE', 'lr': 0.0002712326678917906, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.288956174574698e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0026340280272716086
weight_decay:  3.294327888441763e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9961093550082296
None Run 01:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 61.50
Split: 01, Run: 02
None time:  1.181293549016118
None Run 02:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 56.30
Split: 01, Run: 03
None time:  0.9257648079656065
None Run 03:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 51.60
run time now: 3.144207000732422
total time:  3.2053985588718206
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.67 ± 6.59
  Final Train: 100.00 ± 0.00
   Final Test: 56.47 ± 4.95
[I 2023-06-12 00:53:30,116] Trial 1323 finished with value: 55.66666793823242 and parameters: {'Fwd': 8.356500878391231e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 4.423288670997209, 'loop': 0, 'loss': 'CE', 'lr': 0.0026340280272716086, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.294327888441763e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008654397678143091
weight_decay:  7.653585491971033e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.5545171671546996
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  2.5637836968526244
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.520067910896614
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.70
run time now: 8.681591987609863
total time:  8.730846766848117
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.27 ± 2.19
  Final Train: 99.72 ± 0.48
   Final Test: 70.00 ± 0.44
[I 2023-06-12 00:53:39,590] Trial 1324 finished with value: 69.26667022705078 and parameters: {'Fwd': 0.014574373022714837, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 5.021273443369368, 'loop': 2, 'loss': 'CE', 'lr': 0.008654397678143091, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.653585491971033e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0037550268043990997
weight_decay:  0.09641634696670631
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4105159412138164
None Run 01:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 54.40
Split: 01, Run: 02
None time:  2.3569374110084027
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.5288441311568022
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 5.340220212936401
total time:  5.398595278849825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.73 ± 12.60
  Final Train: 99.72 ± 0.48
   Final Test: 64.97 ± 9.18
[I 2023-06-12 00:53:45,981] Trial 1325 finished with value: 64.73332977294922 and parameters: {'Fwd': 0.02334470992223595, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 3.9941611230658505, 'loop': 2, 'loss': 'CE', 'lr': 0.0037550268043990997, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.09641634696670631, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0007879708970196118
weight_decay:  0.00587113179589405
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.634792560013011
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.5512471951078624
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  1.998343924060464
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 95.83
   Final Test: 71.20
run time now: 5.2320966720581055
total time:  5.282133337110281
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.40 ± 1.64
  Final Train: 98.61 ± 2.41
   Final Test: 68.50 ± 2.34
[I 2023-06-12 00:53:52,014] Trial 1326 finished with value: 69.4000015258789 and parameters: {'Fwd': 0.02935983496073066, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 3.822484772057793, 'loop': 2, 'loss': 'CE', 'lr': 0.0007879708970196118, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00587113179589405, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007348892845049046
weight_decay:  6.225068871955966e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7957613149192184
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 67.30
Split: 01, Run: 02
None time:  1.3988690651021898
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  1.315240953816101
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.5540361404418945
total time:  4.6010102508589625
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 1.30
  Final Train: 99.72 ± 0.48
   Final Test: 68.23 ± 1.45
[I 2023-06-12 00:53:57,343] Trial 1327 finished with value: 71.73333740234375 and parameters: {'Fwd': 5.288150956544966e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 5.5162333268350725, 'loop': 2, 'loss': 'CE', 'lr': 0.007348892845049046, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.225068871955966e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.35000000000000003
lr:  0.0005977137397245537
weight_decay:  4.769036054045294e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.951120634097606
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.5370442618150264
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.4082786550279707
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.938483715057373
total time:  4.986958364024758
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.67
[I 2023-06-12 00:54:02,957] Trial 1328 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.0001145166515601979, 'K': 1, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 5.641538076693326, 'loop': 2, 'loss': 'CE', 'lr': 0.0005977137397245537, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.769036054045294e-05, 'weightedloss': False}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009214128185818498
weight_decay:  2.999959993336635e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0402984658721834
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 72.10
Split: 01, Run: 02
None time:  1.4345074440352619
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 99.17
   Final Test: 72.00
Split: 01, Run: 03
None time:  1.4302616871427745
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 67.70
run time now: 4.950490951538086
total time:  5.015741724986583
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 0.61
  Final Train: 99.44 ± 0.48
   Final Test: 70.60 ± 2.51
[I 2023-06-12 00:54:08,662] Trial 1329 finished with value: 73.53333282470703 and parameters: {'Fwd': 8.885560895513837e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 4.851618847864623, 'loop': 2, 'loss': 'CE', 'lr': 0.009214128185818498, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.999959993336635e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008388030734193674
weight_decay:  0.016979089301466584
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.263614360941574
None Run 01:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 72.10
Split: 01, Run: 02
None time:  0.9886583699844778
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.9822691148146987
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 4.2765727043151855
total time:  4.326428965898231
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.93 ± 0.76
  Final Train: 99.72 ± 0.48
   Final Test: 70.90 ± 1.04
[I 2023-06-12 00:54:13,719] Trial 1330 finished with value: 73.93333435058594 and parameters: {'Fwd': 0.022390701653617482, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 5.460297977665195, 'loop': 2, 'loss': 'CE', 'lr': 0.008388030734193674, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.016979089301466584, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009109771010945828
weight_decay:  7.093158385886837e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6599845059681684
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 95.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.6835497519932687
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.3721708790399134
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 69.60
run time now: 5.763864278793335
total time:  5.811022071866319
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.53 ± 2.54
  Final Train: 98.33 ± 2.89
   Final Test: 69.37 ± 0.78
[I 2023-06-12 00:54:20,237] Trial 1331 finished with value: 72.53333282470703 and parameters: {'Fwd': 2.118564749181348e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 6.9276272852227665, 'loop': 2, 'loss': 'CE', 'lr': 0.009109771010945828, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.093158385886837e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.007827687509430277
weight_decay:  0.03206224176615409
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0703265310730785
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  2.0427136830985546
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 99.17
   Final Test: 71.30
Split: 01, Run: 03
None time:  1.2295633659232408
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 67.80
run time now: 5.388355493545532
total time:  5.442797899944708
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 0.40
  Final Train: 99.72 ± 0.48
   Final Test: 69.93 ± 1.87
[I 2023-06-12 00:54:26,486] Trial 1332 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.01006275410709315, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 6.216821931511566, 'loop': 2, 'loss': 'CE', 'lr': 0.007827687509430277, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03206224176615409, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.000889046910562594
weight_decay:  1.1676626366190846e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4862894979305565
None Run 01:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 54.20
Split: 01, Run: 02
None time:  2.253363247960806
None Run 02:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 99.17
   Final Test: 63.40
Split: 01, Run: 03
None time:  1.3937579561024904
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 99.17
   Final Test: 63.20
run time now: 6.175775766372681
total time:  6.237205903045833
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.80 ± 5.29
  Final Train: 99.44 ± 0.48
   Final Test: 60.27 ± 5.25
[I 2023-06-12 00:54:33,368] Trial 1333 finished with value: 60.80000305175781 and parameters: {'Fwd': 4.5726061576601534e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 6.602182494403708, 'loop': 2, 'loss': 'CE', 'lr': 0.000889046910562594, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1676626366190846e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0013319483494756935
weight_decay:  1.8022654861564865e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.480514865135774
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 60.60
Split: 01, Run: 02
None time:  2.939656457863748
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.3077535119373351
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 5.770493984222412
total time:  5.822569251991808
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 7.93
  Final Train: 99.72 ± 0.48
   Final Test: 66.80 ± 5.37
[I 2023-06-12 00:54:39,831] Trial 1334 finished with value: 69.33333587646484 and parameters: {'Fwd': 0.03633105354353722, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 5.799587038931503, 'loop': 2, 'loss': 'CE', 'lr': 0.0013319483494756935, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.8022654861564865e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009995661932860313
weight_decay:  0.06825487922373998
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.533592338208109
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 97.50
   Final Test: 70.40
Split: 01, Run: 02
None time:  1.1485479951370507
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.08364392304793
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 68.90
run time now: 4.808495044708252
total time:  4.865500471089035
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.80 ± 0.53
  Final Train: 99.17 ± 1.44
   Final Test: 69.27 ± 1.00
[I 2023-06-12 00:54:45,432] Trial 1335 finished with value: 72.79999542236328 and parameters: {'Fwd': 0.0001331086103884211, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 4.603611880187637, 'loop': 2, 'loss': 'CE', 'lr': 0.009995661932860313, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.06825487922373998, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0010332069541701156
weight_decay:  8.05334509566368e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1623442589771003
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 02
None time:  2.694614434847608
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 94.17
   Final Test: 71.50
Split: 01, Run: 03
None time:  1.2493896631058306
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 69.20
run time now: 5.147729158401489
total time:  5.207118151010945
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 1.11
  Final Train: 98.06 ± 3.37
   Final Test: 69.47 ± 1.91
[I 2023-06-12 00:54:51,342] Trial 1336 finished with value: 72.0 and parameters: {'Fwd': 0.01743580040487059, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 4.294047969341342, 'loop': 2, 'loss': 'CE', 'lr': 0.0010332069541701156, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.05334509566368e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00010029698286631705
weight_decay:  0.04549072913014982
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7154359528794885
None Run 01:
Highest Train: 100.00
Highest Valid: 25.40
  Final Train: 100.00
   Final Test: 25.20
Split: 01, Run: 02
None time:  1.1112900900188833
None Run 02:
Highest Train: 100.00
Highest Valid: 27.20
  Final Train: 100.00
   Final Test: 28.40
Split: 01, Run: 03
None time:  1.6083903438411653
None Run 03:
Highest Train: 100.00
Highest Valid: 28.80
  Final Train: 100.00
   Final Test: 31.90
run time now: 4.478439807891846
total time:  4.525087354937568
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 27.13 ± 1.70
  Final Train: 100.00 ± 0.00
   Final Test: 28.50 ± 3.35
[I 2023-06-12 00:54:56,519] Trial 1337 finished with value: 27.133333206176758 and parameters: {'Fwd': 0.0501046445660323, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 5.352556424146111, 'loop': 2, 'loss': 'MSE', 'lr': 0.00010029698286631705, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.04549072913014982, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.008535321781951238
weight_decay:  4.1522296826161726e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3888305639848113
None Run 01:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 35.30
Split: 01, Run: 02
None time:  0.3397782670799643
None Run 02:
Highest Train: 100.00
Highest Valid: 11.20
  Final Train: 100.00
   Final Test: 13.70
Split: 01, Run: 03
None time:  0.3298125129658729
None Run 03:
Highest Train: 100.00
Highest Valid: 11.20
  Final Train: 100.00
   Final Test: 13.70
run time now: 1.1000211238861084
total time:  1.1473251769784838
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 20.73 ± 16.51
  Final Train: 100.00 ± 0.00
   Final Test: 20.90 ± 12.47
[I 2023-06-12 00:54:58,276] Trial 1338 finished with value: 20.733333587646484 and parameters: {'Fwd': 2.3389936745828786e-06, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 0, 'lambda1': 0.65, 'lambda2': 6.070700949236026, 'loop': 2, 'loss': 'CE', 'lr': 0.008535321781951238, 'softmaxF': False, 'useGCN': False, 'weight_decay': 4.1522296826161726e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0070707207254076644
weight_decay:  8.82828024779859e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.284252200042829
None Run 01:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 55.80
Split: 01, Run: 02
None time:  1.5944348420016468
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 99.17
   Final Test: 65.40
Split: 01, Run: 03
None time:  1.3457467940170318
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 66.20
run time now: 4.26469349861145
total time:  4.31377257197164
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.40 ± 7.66
  Final Train: 99.72 ± 0.48
   Final Test: 62.47 ± 5.79
[I 2023-06-12 00:55:03,352] Trial 1339 finished with value: 65.4000015258789 and parameters: {'Fwd': 0.0067566268278205265, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 5.1521016802012785, 'loop': 2, 'loss': 'CE', 'lr': 0.0070707207254076644, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.82828024779859e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.009190616480860643
weight_decay:  2.758450143233915e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2190443840809166
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 71.50
Split: 01, Run: 02
None time:  1.1024541889782995
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  1.3090060469694436
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 71.00
run time now: 4.672099590301514
total time:  4.723250033799559
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.40 ± 0.40
  Final Train: 99.72 ± 0.48
   Final Test: 71.50 ± 0.50
[I 2023-06-12 00:55:08,681] Trial 1340 finished with value: 74.4000015258789 and parameters: {'Fwd': 0.01449609449600261, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 8.626580937230646, 'loop': 2, 'loss': 'CE', 'lr': 0.009190616480860643, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.758450143233915e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.001589631304189454
weight_decay:  1.55681681079492e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.393518699798733
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 64.30
Split: 01, Run: 02
None time:  2.2513594389893115
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 97.50
   Final Test: 71.60
Split: 01, Run: 03
None time:  1.2347573428414762
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.50
run time now: 4.92200231552124
total time:  4.972870699129999
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 2.32
  Final Train: 99.17 ± 1.44
   Final Test: 69.13 ± 4.19
[I 2023-06-12 00:55:14,274] Trial 1341 finished with value: 71.66666412353516 and parameters: {'Fwd': 3.286581246906248e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 6.331668392205187, 'loop': 2, 'loss': 'CE', 'lr': 0.001589631304189454, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.55681681079492e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.45
lr:  0.00999529909732135
weight_decay:  0.010873364193632268
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.125175157096237
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 95.83
   Final Test: 70.70
Split: 01, Run: 02
None time:  1.3682303589303046
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.5054941398557276
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.70
run time now: 5.039804697036743
total time:  5.088631474180147
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.27 ± 0.90
  Final Train: 98.61 ± 2.41
   Final Test: 70.47 ± 0.40
[I 2023-06-12 00:55:20,349] Trial 1342 finished with value: 72.26667022705078 and parameters: {'Fwd': 1.6188974829646118e-06, 'K': 1, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 3.669865316686776, 'loop': 2, 'loss': 'CE', 'lr': 0.00999529909732135, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.010873364193632268, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0006380338113269064
weight_decay:  2.301432251807173e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3854742569383234
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  2.3088634060695767
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  2.4674551237840205
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.30
run time now: 7.199434757232666
total time:  7.246728870086372
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 68.73 ± 0.40
[I 2023-06-12 00:55:28,356] Trial 1343 finished with value: 69.93333435058594 and parameters: {'Fwd': 2.931864344933977e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 4.366717094507612, 'loop': 2, 'loss': 'CE', 'lr': 0.0006380338113269064, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.301432251807173e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0012202629283417916
weight_decay:  0.0028081230510280516
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6166091030463576
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.5344261080026627
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.097697147866711
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.10
run time now: 5.292070388793945
total time:  5.33776082796976
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.81
  Final Train: 99.72 ± 0.48
   Final Test: 69.60 ± 0.56
[I 2023-06-12 00:55:34,420] Trial 1344 finished with value: 70.73333740234375 and parameters: {'Fwd': 4.066980148898302e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 6.735834643034697, 'loop': 2, 'loss': 'CE', 'lr': 0.0012202629283417916, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0028081230510280516, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.008021323288291887
weight_decay:  6.35101613339402e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.036440866999328
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 02
None time:  1.210047088097781
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 03
None time:  1.3925288759637624
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.30
run time now: 4.681646823883057
total time:  4.73125267890282
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.80 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 71.87 ± 0.38
[I 2023-06-12 00:55:39,812] Trial 1345 finished with value: 74.79999542236328 and parameters: {'Fwd': 0.02640471463010782, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 8.820962777068278, 'loop': 2, 'loss': 'CE', 'lr': 0.008021323288291887, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.35101613339402e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.007478813605966623
weight_decay:  6.471720061214892e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3842423709575087
None Run 01:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 56.60
Split: 01, Run: 02
None time:  2.17907816497609
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.3527012530248612
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.10
run time now: 4.9595441818237305
total time:  5.003507791087031
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.53 ± 7.93
  Final Train: 100.00 ± 0.00
   Final Test: 64.57 ± 6.92
[I 2023-06-12 00:55:45,424] Trial 1346 finished with value: 63.5333366394043 and parameters: {'Fwd': 0.02524019585248088, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 8.828206994088825, 'loop': 2, 'loss': 'CE', 'lr': 0.007478813605966623, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.471720061214892e-05, 'weightedloss': False}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.00862401123382119
weight_decay:  0.00010222807937585625
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9302169170696288
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  1.2488600881770253
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  1.3225266782101244
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 4.544792413711548
total time:  4.595677029108629
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.77 ± 0.50
[I 2023-06-12 00:55:50,639] Trial 1347 finished with value: 72.9333267211914 and parameters: {'Fwd': 0.020302569507381334, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 8.655622157922078, 'loop': 2, 'loss': 'CE', 'lr': 0.00862401123382119, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010222807937585625, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.003324965608448202
weight_decay:  6.748959486922242e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.872721201973036
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 02
None time:  1.368912423029542
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.527978427009657
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 5.809990167617798
total time:  5.858210970181972
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.13 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 70.53 ± 0.86
[I 2023-06-12 00:55:57,180] Trial 1348 finished with value: 73.13333129882812 and parameters: {'Fwd': 0.01626187491229718, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 8.883531228637377, 'loop': 2, 'loss': 'CE', 'lr': 0.003324965608448202, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.748959486922242e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.007835803550103068
weight_decay:  8.608775351783936e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.318006191868335
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.4016611769329756
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  1.2917130140122026
None Run 03:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 68.40
run time now: 5.052354574203491
total time:  5.102745758136734
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.73 ± 1.22
  Final Train: 99.72 ± 0.48
   Final Test: 69.10 ± 1.04
[I 2023-06-12 00:56:03,027] Trial 1349 finished with value: 72.73332977294922 and parameters: {'Fwd': 0.026114143026793733, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 8.546300245632043, 'loop': 2, 'loss': 'CE', 'lr': 0.007835803550103068, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.608775351783936e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.006773697462308824
weight_decay:  9.991827369245579e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.234367053024471
None Run 01:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 02
None time:  1.4997856840491295
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.4255404809955508
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 5.203728675842285
total time:  5.255361567018554
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.33 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 70.53 ± 0.45
[I 2023-06-12 00:56:09,028] Trial 1350 finished with value: 73.33332824707031 and parameters: {'Fwd': 0.010742863404095918, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 8.483508288514098, 'loop': 2, 'loss': 'CE', 'lr': 0.006773697462308824, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.991827369245579e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.00020848503584805576
weight_decay:  0.0043467481002395746
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0480507430620492
None Run 01:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 59.20
Split: 01, Run: 02
None time:  1.4323151500429958
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 03
None time:  2.1967411590740085
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 4.737945079803467
total time:  4.812612059991807
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.07 ± 5.83
  Final Train: 100.00 ± 0.00
   Final Test: 65.43 ± 5.71
[I 2023-06-12 00:56:14,600] Trial 1351 finished with value: 67.0666732788086 and parameters: {'Fwd': 0.00029873375451206467, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 8.208383561812804, 'loop': 2, 'loss': 'CE', 'lr': 0.00020848503584805576, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0043467481002395746, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.00023660708059788322
weight_decay:  1.2672340761950764e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8415668890811503
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.30
Split: 01, Run: 02
None time:  1.4247047919780016
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.705626999028027
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
run time now: 6.0226359367370605
total time:  6.070023425156251
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 3.33
  Final Train: 100.00 ± 0.00
   Final Test: 68.00 ± 2.34
[I 2023-06-12 00:56:21,413] Trial 1352 finished with value: 69.5999984741211 and parameters: {'Fwd': 0.00010039920880003783, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 8.844026879814587, 'loop': 2, 'loss': 'CE', 'lr': 0.00023660708059788322, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2672340761950764e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0027554388852824596
weight_decay:  4.476951875223459e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.6205, Train: 91.67%, Valid: 69.20% Test: 68.10%
Split: 01, Run: 01
None time:  3.3575452091172338
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 91.67
   Final Test: 68.10
Split: 01, Run: 02
None time:  2.29949839389883
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 90.83
   Final Test: 68.20
Split: 01, Run: 03
None time:  1.992896320996806
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 92.50
   Final Test: 69.30
run time now: 7.693214416503906
total time:  7.751238072058186
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.47 ± 0.46
  Final Train: 91.67 ± 0.83
   Final Test: 68.53 ± 0.67
[I 2023-06-12 00:56:29,779] Trial 1353 finished with value: 69.46666717529297 and parameters: {'Fwd': 0.003925917451482441, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 2.919704194988393, 'loop': 2, 'loss': 'CE', 'lr': 0.0027554388852824596, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.476951875223459e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009174277476046624
weight_decay:  0.011767392233531446
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7717963738832623
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 02
None time:  1.0937778169754893
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.410861566197127
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.00
run time now: 4.319863319396973
total time:  4.36479207011871
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.20 ± 0.87
  Final Train: 99.72 ± 0.48
   Final Test: 69.93 ± 0.81
[I 2023-06-12 00:56:34,861] Trial 1354 finished with value: 73.19998931884766 and parameters: {'Fwd': 0.0016069269106277228, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 8.732200988773803, 'loop': 2, 'loss': 'CE', 'lr': 0.009174277476046624, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.011767392233531446, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.003167234007875466
weight_decay:  1.6702001619276105e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6028132170904428
None Run 01:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 62.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.2672, Train: 100.00%, Valid: 67.20% Test: 66.00%
Split: 01, Run: 02
None time:  3.4670155260246247
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 03
None time:  1.592444349778816
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 64.90
run time now: 6.7105653285980225
total time:  6.76285036187619
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.80 ± 4.85
  Final Train: 100.00 ± 0.00
   Final Test: 64.27 ± 1.93
[I 2023-06-12 00:56:42,327] Trial 1355 finished with value: 65.79999542236328 and parameters: {'Fwd': 6.033535424760613e-05, 'K': 2, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 8.371982003430482, 'loop': 2, 'loss': 'MSE', 'lr': 0.003167234007875466, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6702001619276105e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009997203828889875
weight_decay:  6.63621768621081e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4410553160123527
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.3963318220339715
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  1.3929772099945694
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.271393299102783
total time:  4.323477440048009
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 70.23 ± 0.85
[I 2023-06-12 00:56:47,350] Trial 1356 finished with value: 73.5999984741211 and parameters: {'Fwd': 4.273244913057759e-05, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 4.874256362303588, 'loop': 2, 'loss': 'CE', 'lr': 0.009997203828889875, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.63621768621081e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0082397651499693
weight_decay:  0.00010369079662807569
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3553536459803581
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 62.00
Split: 01, Run: 02
None time:  1.3275706570129842
None Run 02:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 59.00
Split: 01, Run: 03
None time:  1.2069758719298989
None Run 03:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 95.00
   Final Test: 50.80
run time now: 3.9362566471099854
total time:  3.9840392279438674
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.13 ± 7.46
  Final Train: 98.33 ± 2.89
   Final Test: 57.27 ± 5.80
[I 2023-06-12 00:56:52,095] Trial 1357 finished with value: 60.13333511352539 and parameters: {'Fwd': 0.00017007210083814635, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 6.919938802387119, 'loop': 2, 'loss': 'CE', 'lr': 0.0082397651499693, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00010369079662807569, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0020895439149449693
weight_decay:  0.0015310626095510174
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7488627831917256
None Run 01:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.40
Split: 01, Run: 02
None time:  2.411590269068256
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 95.00
   Final Test: 65.10
Split: 01, Run: 03
None time:  1.3862650198861957
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.90
run time now: 5.594843864440918
total time:  5.654317374108359
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.53 ± 0.58
  Final Train: 98.33 ± 2.89
   Final Test: 64.47 ± 0.93
[I 2023-06-12 00:56:58,572] Trial 1358 finished with value: 65.53333282470703 and parameters: {'Fwd': 6.894793130313044e-05, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.35000000000000003, 'lambda2': 4.144698898231571, 'loop': 2, 'loss': 'CE', 'lr': 0.0020895439149449693, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0015310626095510174, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.25
lr:  0.0004455399738781854
weight_decay:  1.3180313363462866e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.385662930086255
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.9345258781686425
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.0457457730080932
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 98.33
   Final Test: 71.50
run time now: 6.408905744552612
total time:  6.459811845095828
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.58
  Final Train: 98.89 ± 0.48
   Final Test: 70.17 ± 1.26
[I 2023-06-12 00:57:05,740] Trial 1359 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.02767488717591929, 'K': 2, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 3.291915089443536, 'loop': 2, 'loss': 'CE', 'lr': 0.0004455399738781854, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3180313363462866e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.009277710196902416
weight_decay:  0.00027612510999321246
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.7720409110188484
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 97.50
   Final Test: 70.00
Split: 01, Run: 02
None time:  4.458390262909234
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  3.915604416979477
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 97.50
   Final Test: 70.30
run time now: 12.19002103805542
total time:  12.24519927520305
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.31
  Final Train: 96.67 ± 1.44
   Final Test: 70.27 ± 0.25
[I 2023-06-12 00:57:18,601] Trial 1360 finished with value: 70.93334197998047 and parameters: {'Fwd': 0.014081248715336019, 'K': 2, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 3.5405400738765054, 'loop': 2, 'loss': 'CE', 'lr': 0.009277710196902416, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00027612510999321246, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.001000901491411118
weight_decay:  0.00012409453292636175
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.568511510035023
None Run 01:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 54.50
Split: 01, Run: 02
None time:  2.547164333984256
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 93.33
   Final Test: 65.70
Split: 01, Run: 03
None time:  1.464256210019812
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 66.70
run time now: 5.622876882553101
total time:  5.6693179230205715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.33 ± 9.87
  Final Train: 97.78 ± 3.85
   Final Test: 62.30 ± 6.77
[I 2023-06-12 00:57:24,953] Trial 1361 finished with value: 63.33333206176758 and parameters: {'Fwd': 4.922498003727054e-06, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 3.968032110073092, 'loop': 2, 'loss': 'CE', 'lr': 0.001000901491411118, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012409453292636175, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0002482756760346108
weight_decay:  1.7690131949344275e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.790919409831986
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 02
None time:  1.3185995800886303
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.5380991981364787
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 5.689354658126831
total time:  5.734508091816679
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 1.27
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 1.27
[I 2023-06-12 00:57:31,331] Trial 1362 finished with value: 71.06666564941406 and parameters: {'Fwd': 0.018511781392484772, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 9.021445886291223, 'loop': 2, 'loss': 'CE', 'lr': 0.0002482756760346108, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7690131949344275e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.00046724125881266533
weight_decay:  0.0022521691299164644
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8631342169828713
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.175444443942979
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 67.40
Split: 01, Run: 03
None time:  1.605265905149281
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 5.7295637130737305
total time:  5.779686109861359
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.42
  Final Train: 99.72 ± 0.48
   Final Test: 68.93 ± 1.39
[I 2023-06-12 00:57:37,750] Trial 1363 finished with value: 71.26666259765625 and parameters: {'Fwd': 0.0004049840981258847, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 5.778046280313174, 'loop': 2, 'loss': 'CE', 'lr': 0.00046724125881266533, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0022521691299164644, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.007391957935617761
weight_decay:  5.7144228429858505e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8623956858646125
None Run 01:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 93.33
   Final Test: 53.20
Split: 01, Run: 02
None time:  1.1113486899994314
None Run 02:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 59.40
Split: 01, Run: 03
None time:  2.465876065194607
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 92.50
   Final Test: 68.10
run time now: 5.482161045074463
total time:  5.536059499019757
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.07 ± 6.80
  Final Train: 95.28 ± 4.11
   Final Test: 60.23 ± 7.48
[I 2023-06-12 00:57:43,944] Trial 1364 finished with value: 61.0666618347168 and parameters: {'Fwd': 0.008519730177986965, 'K': 2, 'alpha': 0.0, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 5.475022533074592, 'loop': 2, 'loss': 'CE', 'lr': 0.007391957935617761, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.7144228429858505e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.006360669199322279
weight_decay:  7.518966358579451e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3636488888878375
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.50
Split: 01, Run: 02
None time:  1.4113674140535295
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  1.4266417268663645
None Run 03:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 65.40
run time now: 4.261747598648071
total time:  4.317451094975695
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.07 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 65.57 ± 1.16
[I 2023-06-12 00:57:48,949] Trial 1365 finished with value: 65.06666564941406 and parameters: {'Fwd': 0.0029299940049436015, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.35000000000000003, 'lambda2': 6.426483199131594, 'loop': 2, 'loss': 'CE', 'lr': 0.006360669199322279, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.518966358579451e-05, 'weightedloss': False}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.4
lr:  0.003885623574209916
weight_decay:  1.014266440515049e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5475676611531526
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02
None time:  1.1945566160138696
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  1.2831523318309337
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.90
run time now: 4.12562894821167
total time:  4.187353746034205
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 2.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.10 ± 1.61
[I 2023-06-12 00:57:53,905] Trial 1366 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0020502242340576606, 'K': 2, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 5.186457102120512, 'loop': 1, 'loss': 'CE', 'lr': 0.003885623574209916, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.014266440515049e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.003995285168713816
weight_decay:  0.0030851689195843064
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.562327811960131
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 71.00
Split: 01, Run: 02
None time:  1.7927083109971136
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.4151332071051002
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 68.30
run time now: 4.835816144943237
total time:  4.889040631009266
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 0.87
  Final Train: 99.44 ± 0.48
   Final Test: 69.67 ± 1.35
[I 2023-06-12 00:57:59,616] Trial 1367 finished with value: 72.20000457763672 and parameters: {'Fwd': 4.271223327829938e-05, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 4.6811235219807985, 'loop': 2, 'loss': 'CE', 'lr': 0.003995285168713816, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0030851689195843064, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.000136666078706312
weight_decay:  9.432753794590519e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.168286870000884
None Run 01:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 36.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.9034, Train: 90.00%, Valid: 67.80% Test: 66.80%
Split: 01, Run: 02
None time:  3.387829156126827
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 90.83
   Final Test: 67.10
Split: 01, Run: 03
None time:  1.2443792019039392
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 98.33
   Final Test: 70.30
run time now: 5.843385457992554
total time:  5.896204160992056
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.00 ± 18.33
  Final Train: 96.39 ± 4.88
   Final Test: 57.80 ± 18.95
[I 2023-06-12 00:58:06,205] Trial 1368 finished with value: 60.0 and parameters: {'Fwd': 0.005384779394045658, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 0.7639120349601498, 'loop': 2, 'loss': 'CE', 'lr': 0.000136666078706312, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.432753794590519e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.05
lr:  0.009999413588414677
weight_decay:  0.03530213715881006
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.6024424058850855
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 88.33
   Final Test: 67.60
Split: 01, Run: 02
None time:  1.484540100907907
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 98.33
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.390776992077008
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.30
run time now: 6.523838520050049
total time:  6.573642823146656
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.60 ± 0.87
  Final Train: 95.56 ± 6.31
   Final Test: 68.00 ± 0.96
[I 2023-06-12 00:58:13,406] Trial 1369 finished with value: 68.5999984741211 and parameters: {'Fwd': 3.318687419910895e-05, 'K': 5, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 8.334152207381525, 'loop': 2, 'loss': 'CE', 'lr': 0.009999413588414677, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03530213715881006, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.008580510853901952
weight_decay:  3.005433207462262e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0424395580776036
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.142091364134103
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  1.339185280026868
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.00
run time now: 4.571662187576294
total time:  4.623745830031112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 1.22
  Final Train: 99.72 ± 0.48
   Final Test: 68.90 ± 0.78
[I 2023-06-12 00:58:18,822] Trial 1370 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.00022192837473921357, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 6.0030534867854595, 'loop': 2, 'loss': 'CE', 'lr': 0.008580510853901952, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.005433207462262e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0028969969058018157
weight_decay:  7.313031405403363e-06
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7448156508617103
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 87.50
   Final Test: 62.20
Split: 01, Run: 02
None time:  2.2470149169676006
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 88.33
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.861309623112902
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 64.80
run time now: 4.894404649734497
total time:  4.949052439071238
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 4.11
  Final Train: 91.94 ± 6.99
   Final Test: 66.07 ± 4.63
[I 2023-06-12 00:58:24,422] Trial 1371 finished with value: 69.33333587646484 and parameters: {'Fwd': 0.0012697671357813135, 'K': 1, 'alpha': 0.05, 'dropout': 0.0, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 1.0727953518975903, 'loop': 2, 'loss': 'CE', 'lr': 0.0028969969058018157, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.313031405403363e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.007998983836020513
weight_decay:  0.00021164024638462218
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.615402830997482
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.9491186027880758
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.433854659087956
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 99.17
   Final Test: 71.70
run time now: 5.04201865196228
total time:  5.103399086045101
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 1.33
  Final Train: 99.44 ± 0.48
   Final Test: 70.63 ± 0.95
[I 2023-06-12 00:58:30,583] Trial 1372 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.02161116130902119, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 5.034743008488978, 'loop': 2, 'loss': 'CE', 'lr': 0.007998983836020513, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00021164024638462218, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.0
lr:  0.00048510020152851846
weight_decay:  5.741790522281143e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5760232280008495
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.248533609090373
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0683854080270976
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.00
run time now: 4.941042423248291
total time:  4.989676228957251
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 1.22
  Final Train: 99.72 ± 0.48
   Final Test: 69.97 ± 1.11
[I 2023-06-12 00:58:36,374] Trial 1373 finished with value: 72.5999984741211 and parameters: {'Fwd': 2.380244623826136e-05, 'K': 6, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.45, 'lambda2': 6.610651575503727, 'loop': 2, 'loss': 'CE', 'lr': 0.00048510020152851846, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.741790522281143e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009159724471714559
weight_decay:  8.871236415481005e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4262376269325614
None Run 01:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 52.20
Split: 01, Run: 02
None time:  2.6094671098981053
None Run 02:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.10
Split: 01, Run: 03
None time:  1.2230644968803972
None Run 03:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 59.90
run time now: 5.295499324798584
total time:  5.346756255021319
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.53 ± 6.33
  Final Train: 100.00 ± 0.00
   Final Test: 59.07 ± 6.49
[I 2023-06-12 00:58:42,465] Trial 1374 finished with value: 57.533329010009766 and parameters: {'Fwd': 0.011927811210553294, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 7.062455719648983, 'loop': 2, 'loss': 'MSE', 'lr': 0.009159724471714559, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.871236415481005e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007404007781165067
weight_decay:  0.019842943614688753
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.083527458133176
None Run 01:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 48.60
Split: 01, Run: 02
None time:  1.1204775599762797
None Run 02:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 50.80
Split: 01, Run: 03
None time:  1.2167266230098903
None Run 03:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 84.17
   Final Test: 46.50
run time now: 3.471066474914551
total time:  3.526446533156559
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 46.67 ± 2.02
  Final Train: 94.72 ± 9.14
   Final Test: 48.63 ± 2.15
[I 2023-06-12 00:58:46,670] Trial 1375 finished with value: 46.66666793823242 and parameters: {'Fwd': 0.028620735209463424, 'K': 1, 'alpha': 0.05, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 2.6083688056190244, 'loop': 2, 'loss': 'CE', 'lr': 0.007404007781165067, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.019842943614688753, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.1
lr:  0.008560060039423303
weight_decay:  2.1352429600997603e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3110454361885786
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 96.67
   Final Test: 67.90
Split: 01, Run: 02
None time:  1.279070275137201
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.10
Split: 01, Run: 03
None time:  1.4613256282173097
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.20
run time now: 5.091854572296143
total time:  5.1429678509011865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 2.32
  Final Train: 98.89 ± 1.92
   Final Test: 70.07 ± 1.88
[I 2023-06-12 00:58:52,566] Trial 1376 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.0015631879613907777, 'K': 1, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 3.155114491668804, 'loop': 2, 'loss': 'CE', 'lr': 0.008560060039423303, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.1352429600997603e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.25
lr:  0.0002742919475846827
weight_decay:  1.5039315666178574e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.776658810907975
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 96.67
   Final Test: 68.70
Split: 01, Run: 02
None time:  1.3517430669162422
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.433119839988649
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 95.00
   Final Test: 70.20
run time now: 6.605953216552734
total time:  6.659393563168123
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 1.44
  Final Train: 97.22 ± 2.55
   Final Test: 69.63 ± 0.81
[I 2023-06-12 00:58:59,827] Trial 1377 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.0005427400419886927, 'K': 1, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 1.954363078471709, 'loop': 2, 'loss': 'CE', 'lr': 0.0002742919475846827, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.5039315666178574e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0026195200499737523
weight_decay:  2.154157558161056e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5727941358927637
None Run 01:
Highest Train: 100.00
Highest Valid: 34.60
  Final Train: 100.00
   Final Test: 33.50
Split: 01, Run: 02
None time:  2.7173602590337396
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 84.17
   Final Test: 67.60
Split: 01, Run: 03
None time:  0.9284698939882219
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 90.83
   Final Test: 69.60
run time now: 4.260343551635742
total time:  4.309781949967146
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.13 ± 19.55
  Final Train: 91.67 ± 7.95
   Final Test: 56.90 ± 20.29
[I 2023-06-12 00:59:04,817] Trial 1378 finished with value: 57.133331298828125 and parameters: {'Fwd': 0.000307564876808407, 'K': 2, 'alpha': 0.0, 'dropout': 0.7000000000000001, 'gnnepoch': 20, 'lambda1': 0.5, 'lambda2': 1.5596912333618262, 'loop': 2, 'loss': 'CE', 'lr': 0.0026195200499737523, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.154157558161056e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.0001618816398321833
weight_decay:  0.014753110035628873
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.583426252938807
None Run 01:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 60.40
Split: 01, Run: 02
None time:  1.9726234059780836
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.40
Split: 01, Run: 03
None time:  1.7057797000743449
None Run 03:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 62.90
run time now: 5.304853439331055
total time:  5.358372014015913
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.33 ± 1.29
  Final Train: 100.00 ± 0.00
   Final Test: 62.23 ± 1.61
[I 2023-06-12 00:59:10,756] Trial 1379 finished with value: 64.33333587646484 and parameters: {'Fwd': 6.391760353109957e-05, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 6.237292898456285, 'loop': 2, 'loss': 'CE', 'lr': 0.0001618816398321833, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.014753110035628873, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0018001723803752988
weight_decay:  0.021322183859385578
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8856723608914763
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02
None time:  2.666837730910629
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.764248276129365
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 6.387060880661011
total time:  6.448231468908489
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.50
  Final Train: 99.72 ± 0.48
   Final Test: 69.23 ± 0.60
[I 2023-06-12 00:59:17,840] Trial 1380 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.03515464221614745, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 8.84066591168571, 'loop': 2, 'loss': 'CE', 'lr': 0.0018001723803752988, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.021322183859385578, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.009162929649173807
weight_decay:  3.562946708324804e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0617549591697752
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 02
None time:  1.5652507671620697
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 03
None time:  1.155477788997814
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 68.80
run time now: 4.825985670089722
total time:  4.881825683871284
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.87 ± 1.79
  Final Train: 100.00 ± 0.00
   Final Test: 70.50 ± 1.47
[I 2023-06-12 00:59:23,393] Trial 1381 finished with value: 73.86666870117188 and parameters: {'Fwd': 0.0035732371640718533, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.152668476479299, 'loop': 2, 'loss': 'CE', 'lr': 0.009162929649173807, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.562946708324804e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.007870045584152415
weight_decay:  1.1944506906689146e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9992883959785104
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.70
Split: 01, Run: 02
None time:  1.4352042321115732
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.525199790019542
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 99.17
   Final Test: 70.90
run time now: 5.0068957805633545
total time:  5.065522238146514
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.13 ± 1.70
  Final Train: 99.44 ± 0.48
   Final Test: 70.43 ± 0.64
[I 2023-06-12 00:59:29,189] Trial 1382 finished with value: 73.13333129882812 and parameters: {'Fwd': 1.3560752521336864e-06, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 3.8114852349348913, 'loop': 2, 'loss': 'CE', 'lr': 0.007870045584152415, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1944506906689146e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.0
lr:  0.0005839069211287055
weight_decay:  0.006656265426477975
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0961673811543733
None Run 01:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 54.50
Split: 01, Run: 02
None time:  1.200035837944597
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.50
Split: 01, Run: 03
None time:  1.0028744349256158
None Run 03:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 52.80
run time now: 3.338468551635742
total time:  3.402563529089093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.07 ± 6.97
  Final Train: 100.00 ± 0.00
   Final Test: 55.93 ± 4.05
[I 2023-06-12 00:59:33,193] Trial 1383 finished with value: 55.06666564941406 and parameters: {'Fwd': 0.08020814184018818, 'K': 2, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 8.564358515236501, 'loop': 0, 'loss': 'CE', 'lr': 0.0005839069211287055, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006656265426477975, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0020061160757198406
weight_decay:  0.00015792744051839374
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8490248240996152
None Run 01:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 38.40
Split: 01, Run: 02
None time:  0.7409491641446948
None Run 02:
Highest Train: 100.00
Highest Valid: 32.00
  Final Train: 100.00
   Final Test: 32.60
Split: 01, Run: 03
None time:  0.6616834590677172
None Run 03:
Highest Train: 100.00
Highest Valid: 31.20
  Final Train: 100.00
   Final Test: 31.00
run time now: 2.293001651763916
total time:  2.3437451999634504
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 34.60 ± 5.21
  Final Train: 100.00 ± 0.00
   Final Test: 34.00 ± 3.89
[I 2023-06-12 00:59:36,135] Trial 1384 finished with value: 34.60000228881836 and parameters: {'Fwd': 2.1196186437782694e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 30, 'lambda1': 0.25, 'lambda2': 4.340077128828003, 'loop': 2, 'loss': 'CE', 'lr': 0.0020061160757198406, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00015792744051839374, 'weightedloss': False}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.0014456668553960743
weight_decay:  1.4495519108403665e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5540, Train: 93.33%, Valid: 65.40% Test: 64.40%
Split: 01, Run: 01
None time:  3.4933916991576552
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 94.17
   Final Test: 64.60
Split: 01, Run: 02
None time:  1.3704780600965023
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.5106, Train: 90.83%, Valid: 67.60% Test: 68.60%
Split: 01, Run: 03
None time:  3.5848994550760835
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 94.17
   Final Test: 67.30
run time now: 8.496767520904541
total time:  8.554541595978662
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.67 ± 1.01
  Final Train: 96.11 ± 3.37
   Final Test: 65.87 ± 1.36
[I 2023-06-12 00:59:45,331] Trial 1385 finished with value: 66.66666412353516 and parameters: {'Fwd': 0.0011074068634855522, 'K': 2, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 9.031486821350363, 'loop': 2, 'loss': 'CE', 'lr': 0.0014456668553960743, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.4495519108403665e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0017979834287823724
weight_decay:  0.00011103737728130418
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5853, Train: 99.17%, Valid: 68.20% Test: 66.10%
Split: 01, Run: 01
None time:  3.7356074419803917
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 99.17
   Final Test: 66.10
Split: 01, Run: 02
None time:  2.330692138057202
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.8306768590118736
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 70.50
run time now: 7.945349454879761
total time:  8.003171500982717
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 2.05
  Final Train: 99.17 ± 0.00
   Final Test: 68.90 ± 2.43
[I 2023-06-12 00:59:54,199] Trial 1386 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.023336888848273687, 'K': 1, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 8.05713932182337, 'loop': 2, 'loss': 'CE', 'lr': 0.0017979834287823724, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011103737728130418, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.05
lr:  0.004850011195993294
weight_decay:  3.353190670835766e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2497455100528896
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1285167089663446
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 64.40
Split: 01, Run: 03
None time:  1.1341604779008776
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 68.40
run time now: 4.554054498672485
total time:  4.600806321948767
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 98.33 ± 2.89
   Final Test: 67.43 ± 2.68
[I 2023-06-12 00:59:59,383] Trial 1387 finished with value: 71.86666107177734 and parameters: {'Fwd': 0.0025300230205712367, 'K': 1, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 2.2702517860043656, 'loop': 2, 'loss': 'CE', 'lr': 0.004850011195993294, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.353190670835766e-06, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.2
lr:  0.006819564723061286
weight_decay:  5.320298060655693e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.129783679964021
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.2829687618650496
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  1.3898640079423785
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
run time now: 4.84585165977478
total time:  4.890184730058536
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.46
  Final Train: 99.72 ± 0.48
   Final Test: 69.23 ± 1.42
[I 2023-06-12 01:00:04,963] Trial 1388 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.00018085873886675228, 'K': 1, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 5.74620633268038, 'loop': 2, 'loss': 'CE', 'lr': 0.006819564723061286, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.320298060655693e-05, 'weightedloss': True}. Best is trial 1316 with value: 76.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.00927964849341382
weight_decay:  4.167903099696203e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3413532311096787
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 95.83
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.54471933003515
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 98.33
   Final Test: 68.80
