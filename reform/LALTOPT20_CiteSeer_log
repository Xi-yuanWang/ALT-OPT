[I 2023-06-11 23:21:26,029] A new study created in RDB with name: CiteSeer_ALTOPT
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.45
lr:  0.006420635334837568
weight_decay:  3.4933171759920454e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1004960050340742
None Run 01:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 37.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.1211, Train: 100.00%, Valid: 67.40% Test: 67.50%
Split: 01, Run: 02
None time:  0.8433673018589616
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  0.1714683030731976
None Run 03:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 60.20
run time now: 2.1524081230163574
total time:  3.8022965569980443
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.67 ± 12.87
  Final Train: 100.00 ± 0.00
   Final Test: 55.20 ± 15.42
[I 2023-06-11 23:21:30,385] Trial 0 finished with value: 56.66666793823242 and parameters: {'Fwd': 3.5355145717963133e-06, 'K': 1, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 10, 'lambda1': 0.2, 'lambda2': 8.148698370728935, 'loop': 1, 'loss': 'MSE', 'lr': 0.006420635334837568, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.4933171759920454e-05, 'weightedloss': False}. Best is trial 0 with value: 56.66666793823242.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.35000000000000003
lr:  0.0004892449562421338
weight_decay:  0.015932180107326145
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3508059149608016
None Run 01:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 43.40
Split: 01, Run: 02
None time:  0.46827091998420656
None Run 02:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 50.20
Split: 01, Run: 03
None time:  0.4027395450975746
None Run 03:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 49.20
run time now: 1.2597146034240723
total time:  1.3160164540167898
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 48.80 ± 2.46
  Final Train: 100.00 ± 0.00
   Final Test: 47.60 ± 3.67
[I 2023-06-11 23:21:32,038] Trial 1 finished with value: 48.79999923706055 and parameters: {'Fwd': 5.766419694714932e-06, 'K': 5, 'alpha': 0.35000000000000003, 'dropout': 0.5, 'gnnepoch': 40, 'lambda1': 0.6000000000000001, 'lambda2': 0.49656273974382326, 'loop': 2, 'loss': 'CE', 'lr': 0.0004892449562421338, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.015932180107326145, 'weightedloss': False}. Best is trial 0 with value: 56.66666793823242.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.0
lr:  0.0002753256083832034
weight_decay:  0.002836951146949014
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3573334019165486
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.60
Split: 01, Run: 02
None time:  0.4795722831040621
None Run 02:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.60
Split: 01, Run: 03
None time:  0.4760174690745771
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.60
run time now: 1.3507964611053467
total time:  1.4061265420168638
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.60 ± 0.00
[I 2023-06-11 23:21:33,779] Trial 2 finished with value: 51.40000534057617 and parameters: {'Fwd': 2.792204508492434e-05, 'K': 5, 'alpha': 0.0, 'dropout': 0.1, 'gnnepoch': 20, 'lambda1': 0.0, 'lambda2': 3.285284561213305, 'loop': 1, 'loss': 'CE', 'lr': 0.0002753256083832034, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.002836951146949014, 'weightedloss': True}. Best is trial 0 with value: 56.66666793823242.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0049180594086789525
weight_decay:  0.0001482863192561436
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2964983191341162
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 95.00
   Final Test: 68.10
Split: 01, Run: 02
None time:  1.1832810118794441
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 92.50
   Final Test: 67.90
Split: 01, Run: 03
None time:  1.2255786920432001
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 91.67
   Final Test: 68.60
run time now: 3.7480146884918213
total time:  3.803995468886569
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.42
  Final Train: 93.06 ± 1.73
   Final Test: 68.20 ± 0.36
[I 2023-06-11 23:21:37,929] Trial 3 finished with value: 70.13333892822266 and parameters: {'Fwd': 1.54370177862792e-06, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.1, 'gnnepoch': 80, 'lambda1': 0.8500000000000001, 'lambda2': 3.438940754130917, 'loop': 2, 'loss': 'CE', 'lr': 0.0049180594086789525, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001482863192561436, 'weightedloss': True}. Best is trial 3 with value: 70.13333892822266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.0038512691231938644
weight_decay:  0.09481142078311784
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6286036339588463
None Run 01:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 53.00
Split: 01, Run: 02
None time:  0.6310402119997889
None Run 02:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 53.20
Split: 01, Run: 03
None time:  1.7578219920396805
None Run 03:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 89.17
   Final Test: 52.10
run time now: 3.0597481727600098
total time:  3.1161161998752505
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.80 ± 2.03
  Final Train: 96.39 ± 6.25
   Final Test: 52.77 ± 0.59
[I 2023-06-11 23:21:41,352] Trial 4 finished with value: 54.79999923706055 and parameters: {'Fwd': 0.00033837367052010796, 'K': 9, 'alpha': 0.75, 'dropout': 0.0, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 7.070191506528128, 'loop': 2, 'loss': 'CE', 'lr': 0.0038512691231938644, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.09481142078311784, 'weightedloss': False}. Best is trial 3 with value: 70.13333892822266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.00024172529381933508
weight_decay:  3.0918662635095624e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5337, Train: 100.00%, Valid: 56.00% Test: 55.90%
Split: 01, Run: 01
None time:  2.4139677511993796
None Run 01:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 55.90
Split: 01, Run: 02
None time:  0.9221836649812758
None Run 02:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 45.90
Split: 01, Run: 03
None time:  1.0569677979219705
None Run 03:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 49.90
run time now: 4.435431003570557
total time:  4.4949717100244015
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.27 ± 4.70
  Final Train: 100.00 ± 0.00
   Final Test: 50.57 ± 5.03
[I 2023-06-11 23:21:46,203] Trial 5 finished with value: 51.266666412353516 and parameters: {'Fwd': 0.0003964788373686253, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.9500000000000001, 'lambda2': 4.73225951567425, 'loop': 1, 'loss': 'MSE', 'lr': 0.00024172529381933508, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.0918662635095624e-06, 'weightedloss': True}. Best is trial 3 with value: 70.13333892822266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.006929645438291059
weight_decay:  0.00048357365075880367
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8479085508733988
None Run 01:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 53.10
Split: 01, Run: 02
None time:  1.0514008670579642
None Run 02:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 85.83
   Final Test: 53.50
Split: 01, Run: 03
None time:  0.9246250940486789
None Run 03:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 98.33
   Final Test: 51.50
run time now: 2.8629209995269775
total time:  2.93192889704369
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.80 ± 2.51
  Final Train: 94.72 ± 7.74
   Final Test: 52.70 ± 1.06
[I 2023-06-11 23:21:49,470] Trial 6 finished with value: 54.80000305175781 and parameters: {'Fwd': 1.5527125283508268e-06, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 6.744083368510293, 'loop': 2, 'loss': 'CE', 'lr': 0.006929645438291059, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00048357365075880367, 'weightedloss': True}. Best is trial 3 with value: 70.13333892822266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.00028452034473771046
weight_decay:  1.697776798286908e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7862587310373783
None Run 01:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 58.90
Split: 01, Run: 02
None time:  0.8250788459554315
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 61.40
Split: 01, Run: 03
None time:  0.6961030929815024
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.40
run time now: 2.34828519821167
total time:  2.4057847252115607
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.07 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 60.90 ± 1.80
[I 2023-06-11 23:21:52,274] Trial 7 finished with value: 61.06666564941406 and parameters: {'Fwd': 0.0004234375735540433, 'K': 8, 'alpha': 0.0, 'dropout': 0.1, 'gnnepoch': 120, 'lambda1': 0.5, 'lambda2': 9.220462206550188, 'loop': 1, 'loss': 'CE', 'lr': 0.00028452034473771046, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.697776798286908e-05, 'weightedloss': False}. Best is trial 3 with value: 70.13333892822266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.009663075999838653
weight_decay:  5.803888314026306e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8663752630818635
None Run 01:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 51.80
Split: 01, Run: 02
None time:  0.8884411209728569
None Run 02:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 51.80
Split: 01, Run: 03
None time:  0.8890501440037042
None Run 03:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 51.80
run time now: 2.6877615451812744
total time:  2.7447529518976808
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.00 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.80 ± 0.00
[I 2023-06-11 23:21:55,385] Trial 8 finished with value: 52.0 and parameters: {'Fwd': 0.00022098430744692984, 'K': 8, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.0, 'lambda2': 0.6687038782162369, 'loop': 2, 'loss': 'MSE', 'lr': 0.009663075999838653, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.803888314026306e-05, 'weightedloss': False}. Best is trial 3 with value: 70.13333892822266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.8
lr:  0.00016699048609123692
weight_decay:  3.230372102091691e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.10190773103386164
None Run 01:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 41.90
Split: 01, Run: 02
None time:  0.1268375450745225
None Run 02:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 41.90
Split: 01, Run: 03
None time:  0.12079188390634954
None Run 03:
Highest Train: 100.00
Highest Valid: 43.00
  Final Train: 100.00
   Final Test: 41.90
run time now: 0.3856174945831299
total time:  0.44326884509064257
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 43.00 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 41.90 ± 0.00
[I 2023-06-11 23:21:56,196] Trial 9 finished with value: 43.0 and parameters: {'Fwd': 2.933401159313363e-06, 'K': 4, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 0, 'lambda1': 0.8, 'lambda2': 1.0694472901612229, 'loop': 1, 'loss': 'MSE', 'lr': 0.00016699048609123692, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.230372102091691e-05, 'weightedloss': True}. Best is trial 3 with value: 70.13333892822266.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0020242411378393593
weight_decay:  1.081208054806456e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8867555791512132
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.9078025061171502
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.9451280881185085
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.00
run time now: 2.7840347290039062
total time:  2.8488526600413024
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.03 ± 0.35
[I 2023-06-11 23:21:59,485] Trial 10 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.015899769877339973, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.55, 'lambda2': 3.5957016852401176, 'loop': 0, 'loss': 'CE', 'lr': 0.0020242411378393593, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.081208054806456e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0015912044694296238
weight_decay:  3.9599473903908694e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8516441159881651
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9015728470403701
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.9960274109616876
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.8053622245788574
total time:  2.8672576658427715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.15
[I 2023-06-11 23:22:02,781] Trial 11 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.022168569287272386, 'K': 10, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 4.034557310068713, 'loop': 0, 'loss': 'CE', 'lr': 0.0015912044694296238, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.9599473903908694e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.0016989967027862274
weight_decay:  1.6286323333249697e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9226669569034129
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9080144290346652
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.9238731698133051
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.7950263023376465
total time:  2.8546862930525094
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.27 ± 0.35
[I 2023-06-11 23:22:06,028] Trial 12 finished with value: 71.13333892822266 and parameters: {'Fwd': 0.041336999354261265, 'K': 7, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 4.6228914483915, 'loop': 0, 'loss': 'CE', 'lr': 0.0016989967027862274, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.6286323333249697e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0014684229987594836
weight_decay:  1.075866621184343e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8428652880247682
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9183936619665474
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.9707106680143625
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.20
run time now: 2.7763829231262207
total time:  2.8329628030769527
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 0.53
[I 2023-06-11 23:22:09,318] Trial 13 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.03846323110299057, 'K': 10, 'alpha': 1.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 2.6821173906779316, 'loop': 0, 'loss': 'CE', 'lr': 0.0014684229987594836, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.075866621184343e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.55
lr:  0.0025166267739454855
weight_decay:  5.779174672323165e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4507816119585186
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  0.49642288591712713
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.45820933184586465
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 1.4413480758666992
total time:  1.503613508073613
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.57
[I 2023-06-11 23:22:11,255] Trial 14 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.009717555844564487, 'K': 3, 'alpha': 0.55, 'dropout': 0.30000000000000004, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 5.912184676546965, 'loop': 0, 'loss': 'CE', 'lr': 0.0025166267739454855, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.779174672323165e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.0008349203940688631
weight_decay:  9.583835422895096e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9171040370129049
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.8674601828679442
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 03
None time:  0.8898371651303023
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.7220888137817383
total time:  2.7865068570245057
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 68.70 ± 1.31
[I 2023-06-11 23:22:14,528] Trial 15 finished with value: 69.86666870117188 and parameters: {'Fwd': 0.005490996698626357, 'K': 10, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 2.009819213914621, 'loop': 0, 'loss': 'CE', 'lr': 0.0008349203940688631, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.583835422895096e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.25
lr:  0.000982824479563858
weight_decay:  5.552812535841586e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9704739791341126
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 69.40%
Split: 01, Run: 02
None time:  1.7042361591011286
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.8920020980294794
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.00
run time now: 3.606992483139038
total time:  3.6631962980609387
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.91
[I 2023-06-11 23:22:18,657] Trial 16 finished with value: 70.0 and parameters: {'Fwd': 0.08798295137724872, 'K': 7, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 4.121183524948027, 'loop': 0, 'loss': 'CE', 'lr': 0.000982824479563858, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.552812535841586e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.002623280933550487
weight_decay:  1.1993324664610628e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5928666279651225
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.5828732610680163
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.6197247579693794
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.70
run time now: 1.8384602069854736
total time:  1.9013009211048484
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.03 ± 0.76
[I 2023-06-11 23:22:20,997] Trial 17 finished with value: 71.0 and parameters: {'Fwd': 0.006682135605435782, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 5.354920935160459, 'loop': 0, 'loss': 'CE', 'lr': 0.002623280933550487, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.1993324664610628e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.55
lr:  0.0005974178224721904
weight_decay:  4.050910034298201e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8117681439034641
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  0.8797791039105505
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.60% Test: 67.50%
Split: 01, Run: 03
None time:  1.2061793010216206
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.50
run time now: 2.932828903198242
total time:  2.988885710015893
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 67.70 ± 0.82
[I 2023-06-11 23:22:24,425] Trial 18 finished with value: 68.46666717529297 and parameters: {'Fwd': 0.0022254004917289867, 'K': 2, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 2.0357529616150813, 'loop': 0, 'loss': 'MSE', 'lr': 0.0005974178224721904, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.050910034298201e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.001538113606229107
weight_decay:  1.3161801509478503e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.41081307106651366
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02
None time:  0.41687674005515873
None Run 02:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.20
Split: 01, Run: 03
None time:  0.3992290480528027
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 1.2655885219573975
total time:  1.3126585020218045
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.73 ± 2.37
  Final Train: 100.00 ± 0.00
   Final Test: 67.37 ± 2.76
[I 2023-06-11 23:22:26,190] Trial 19 finished with value: 68.73333740234375 and parameters: {'Fwd': 0.01953592908537317, 'K': 6, 'alpha': 0.9, 'dropout': 0.2, 'gnnepoch': 40, 'lambda1': 0.6000000000000001, 'lambda2': 3.997011873527059, 'loop': 0, 'loss': 'CE', 'lr': 0.001538113606229107, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.3161801509478503e-05, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.002924939131548646
weight_decay:  1.0447229400867712e-06
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0166842211037874
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.0016817818395793
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 67.60
Split: 01, Run: 03
None time:  1.0243250541388988
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 67.70
run time now: 3.0849249362945557
total time:  3.1358287599869072
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.87
  Final Train: 99.44 ± 0.48
   Final Test: 68.10 ± 0.78
[I 2023-06-11 23:22:29,723] Trial 20 finished with value: 70.19999694824219 and parameters: {'Fwd': 0.0028881918828035555, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.0, 'gnnepoch': 110, 'lambda1': 0.45, 'lambda2': 5.6661662603254825, 'loop': 0, 'loss': 'CE', 'lr': 0.002924939131548646, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0447229400867712e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.5
lr:  0.0024081970682931788
weight_decay:  3.8034040817096363e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4397624309640378
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.49466848908923566
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.4537948879878968
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 1.4230151176452637
total time:  1.4889973849058151
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.55
[I 2023-06-11 23:22:31,696] Trial 21 finished with value: 71.0 and parameters: {'Fwd': 0.01304995194935924, 'K': 3, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 5.717145477681354, 'loop': 0, 'loss': 'CE', 'lr': 0.0024081970682931788, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.8034040817096363e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.0018252483592470236
weight_decay:  8.744950118085825e-06
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6042628569994122
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  0.5953496990259737
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.5576433690730482
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.00
run time now: 1.804938554763794
total time:  1.8573781470768154
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 68.20 ± 0.53
[I 2023-06-11 23:22:34,146] Trial 22 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.0993218182526545, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.2, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.271032050830806, 'loop': 0, 'loss': 'CE', 'lr': 0.0018252483592470236, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.744950118085825e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.5
lr:  0.0034644988369427723
weight_decay:  2.894541714792608e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.2960274040233344
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.32446467294357717
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.3364980719052255
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
run time now: 0.9906342029571533
total time:  1.0341152288019657
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.23 ± 0.21
[I 2023-06-11 23:22:35,637] Trial 23 finished with value: 70.93333435058594 and parameters: {'Fwd': 0.01643178367283551, 'K': 2, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 30, 'lambda1': 0.75, 'lambda2': 4.966069668205394, 'loop': 0, 'loss': 'CE', 'lr': 0.0034644988369427723, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.894541714792608e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.7000000000000001
lr:  0.001199639544443569
weight_decay:  7.049237487049798e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.785068109864369
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.8025039189960808
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  0.751560288015753
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.60
run time now: 2.376192569732666
total time:  2.4249006339814514
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.00 ± 2.27
  Final Train: 100.00 ± 0.00
   Final Test: 67.17 ± 1.72
[I 2023-06-11 23:22:38,456] Trial 24 finished with value: 68.0 and parameters: {'Fwd': 0.0021057295196421667, 'K': 4, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 3.880988026732163, 'loop': 1, 'loss': 'CE', 'lr': 0.001199639544443569, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.049237487049798e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.8500000000000001
lr:  0.002083120153546534
weight_decay:  1.8197381038339595e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4666124249342829
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.5426240859087557
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.4746121410280466
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 1.5162503719329834
total time:  1.5727262729778886
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.84
[I 2023-06-11 23:22:40,426] Trial 25 finished with value: 70.93333435058594 and parameters: {'Fwd': 0.007788839447145419, 'K': 1, 'alpha': 0.8500000000000001, 'dropout': 0.2, 'gnnepoch': 50, 'lambda1': 1.0, 'lambda2': 3.0273140816895623, 'loop': 0, 'loss': 'CE', 'lr': 0.002083120153546534, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8197381038339595e-05, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.6000000000000001
lr:  0.0036264365066789443
weight_decay:  2.7456996816491036e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.80% Test: 66.50%
Split: 01, Run: 01
None time:  1.3968295771628618
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.20% Test: 66.90%
Split: 01, Run: 02
None time:  1.3737852710764855
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.40% Test: 66.10%
Split: 01, Run: 03
None time:  1.460870943032205
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 66.10
run time now: 4.269821643829346
total time:  4.32599872793071
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.13 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 66.47 ± 0.40
[I 2023-06-11 23:22:45,154] Trial 26 finished with value: 66.13333129882812 and parameters: {'Fwd': 0.03187082359424061, 'K': 6, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 4.475665867746036, 'loop': 0, 'loss': 'MSE', 'lr': 0.0036264365066789443, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.7456996816491036e-06, 'weightedloss': False}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.4
lr:  0.002241158785083253
weight_decay:  8.680431100449985e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7619797689840198
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.7375925730448216
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.7614115560427308
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.29636287689209
total time:  2.347475458867848
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 69.23 ± 0.55
[I 2023-06-11 23:22:47,920] Trial 27 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.04510348383616077, 'K': 3, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.40035184176363, 'loop': 1, 'loss': 'CE', 'lr': 0.002241158785083253, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.680431100449985e-05, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.0012783952985468468
weight_decay:  2.2598211157228172e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7897036201320589
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  0.8125402890145779
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.8541866738814861
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.50
run time now: 2.498948812484741
total time:  2.555413037771359
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.10 ± 0.79
[I 2023-06-11 23:22:50,886] Trial 28 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.011789453735034875, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 6.237015877184054, 'loop': 0, 'loss': 'CE', 'lr': 0.0012783952985468468, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.2598211157228172e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.45
lr:  0.005740673594795228
weight_decay:  2.901496999022837e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3862289199605584
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  0.3929734551347792
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.3241007619071752
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 66.60
run time now: 1.13608980178833
total time:  1.1950099649839103
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 67.77 ± 1.01
[I 2023-06-11 23:22:52,504] Trial 29 finished with value: 69.73333740234375 and parameters: {'Fwd': 0.0011815909908377085, 'K': 1, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 20, 'lambda1': 0.25, 'lambda2': 7.550103808861229, 'loop': 1, 'loss': 'MSE', 'lr': 0.005740673594795228, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.901496999022837e-05, 'weightedloss': False}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0009687684558468798
weight_decay:  1.0321076410338516e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0025707948952913
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9561531930230558
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  1.0753678530454636
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.0778276920318604
total time:  3.1411258410662413
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 68.73 ± 1.24
[I 2023-06-11 23:22:56,059] Trial 30 finished with value: 70.0 and parameters: {'Fwd': 0.004659849677350294, 'K': 10, 'alpha': 0.55, 'dropout': 0.1, 'gnnepoch': 110, 'lambda1': 0.45, 'lambda2': 8.240740881032965, 'loop': 0, 'loss': 'CE', 'lr': 0.0009687684558468798, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0321076410338516e-05, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.001406148235133464
weight_decay:  1.8433239470947709e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8338224468752742
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9558342949021608
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.9718434019014239
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
run time now: 2.802191972732544
total time:  2.8599395940545946
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.17 ± 0.47
[I 2023-06-11 23:22:59,341] Trial 31 finished with value: 70.9333267211914 and parameters: {'Fwd': 0.023979912916201468, 'K': 7, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 4.606389411707437, 'loop': 0, 'loss': 'CE', 'lr': 0.001406148235133464, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8433239470947709e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0018316610204900236
weight_decay:  1.0503575657682308e-06
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9084804130252451
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9188871411606669
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.9224358210340142
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.78993821144104
total time:  2.84624219709076
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.07 ± 0.38
[I 2023-06-11 23:23:02,636] Trial 32 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.04608914172069539, 'K': 8, 'alpha': 0.65, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 4.8385472892445405, 'loop': 0, 'loss': 'CE', 'lr': 0.0018316610204900236, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0503575657682308e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.45
lr:  0.001909934233243353
weight_decay:  5.247728668840667e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0898809228092432
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0664717420004308
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.0383564250078052
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.80
run time now: 3.232060194015503
total time:  3.293735750950873
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.70
[I 2023-06-11 23:23:06,408] Trial 33 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.013110701152987366, 'K': 5, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 3.779996880120024, 'loop': 0, 'loss': 'CE', 'lr': 0.001909934233243353, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.247728668840667e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.55
lr:  0.002837804357143556
weight_decay:  2.064516853578985e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.47826120001263916
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.4822995748836547
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.48274311516433954
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 1.4821898937225342
total time:  1.5385967150796205
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.37 ± 0.55
[I 2023-06-11 23:23:08,338] Trial 34 finished with value: 71.0 and parameters: {'Fwd': 0.06356977704432952, 'K': 6, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 3.4293430323554723, 'loop': 0, 'loss': 'CE', 'lr': 0.002837804357143556, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.064516853578985e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.004144298495195237
weight_decay:  1.856683534111956e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 69.50%
Split: 01, Run: 01
None time:  1.6632639260496944
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.70%
Split: 01, Run: 02
None time:  1.706215123878792
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 68.90%
Split: 01, Run: 03
None time:  1.630890010856092
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.80
run time now: 5.043700456619263
total time:  5.095595933962613
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.65
[I 2023-06-11 23:23:13,857] Trial 35 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.031078975265994818, 'K': 10, 'alpha': 0.8, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 5.144623838332326, 'loop': 0, 'loss': 'CE', 'lr': 0.004144298495195237, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.856683534111956e-06, 'weightedloss': False}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.0006915669867447982
weight_decay:  5.7881686004073e-06
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9868372019845992
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.90
Split: 01, Run: 02
None time:  1.0076739909127355
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 99.17
   Final Test: 67.70
Split: 01, Run: 03
None time:  0.6556444459129125
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 64.10
run time now: 2.6928820610046387
total time:  2.752056155120954
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.27 ± 2.66
  Final Train: 99.72 ± 0.48
   Final Test: 65.90 ± 1.80
[I 2023-06-11 23:23:17,075] Trial 36 finished with value: 65.26666259765625 and parameters: {'Fwd': 0.09540307816728166, 'K': 9, 'alpha': 0.65, 'dropout': 0.2, 'gnnepoch': 80, 'lambda1': 0.55, 'lambda2': 4.335795120400479, 'loop': 1, 'loss': 'CE', 'lr': 0.0006915669867447982, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.7881686004073e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.75
lr:  0.003018556887060834
weight_decay:  2.3778049660057047e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3800713249947876
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  0.4718076619319618
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.50
Split: 01, Run: 03
None time:  0.4573748221155256
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.80
run time now: 1.3465993404388428
total time:  1.4061518358066678
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.27
  Final Train: 100.00 ± 0.00
   Final Test: 67.90 ± 1.23
[I 2023-06-11 23:23:18,973] Trial 37 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.023600029940019678, 'K': 3, 'alpha': 0.75, 'dropout': 0.1, 'gnnepoch': 40, 'lambda1': 0.65, 'lambda2': 2.95096653378408, 'loop': 0, 'loss': 'CE', 'lr': 0.003018556887060834, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3778049660057047e-05, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.55
lr:  0.0045889583021127235
weight_decay:  0.00028846953963415726
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2816016061697155
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 98.33
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.5427511830348521
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  1.53562076902017
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 92.50
   Final Test: 69.60
run time now: 4.397920608520508
total time:  4.44500407599844
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.12
  Final Train: 95.28 ± 2.93
   Final Test: 69.50 ± 0.10
[I 2023-06-11 23:23:23,836] Trial 38 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.01010655307757448, 'K': 5, 'alpha': 0.55, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 3.4773377929789318, 'loop': 1, 'loss': 'CE', 'lr': 0.0045889583021127235, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00028846953963415726, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.35000000000000003
lr:  0.0018080745444032616
weight_decay:  1.3087938715290484e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.20% Test: 64.00%
Split: 01, Run: 01
None time:  1.0292999821249396
None Run 01:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 68.80%
Split: 01, Run: 02
None time:  1.0070551191456616
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.5096084380056709
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.00
run time now: 2.5863375663757324
total time:  2.642958328826353
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.33 ± 1.89
  Final Train: 100.00 ± 0.00
   Final Test: 67.30 ± 2.77
[I 2023-06-11 23:23:26,901] Trial 39 finished with value: 68.33333587646484 and parameters: {'Fwd': 0.055579714413653517, 'K': 7, 'alpha': 0.35000000000000003, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 4.423399782037232, 'loop': 0, 'loss': 'MSE', 'lr': 0.0018080745444032616, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.3087938715290484e-05, 'weightedloss': False}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0011156938652293466
weight_decay:  5.3965552331741544e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5122954549733549
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  0.43555732583627105
None Run 02:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 62.80
Split: 01, Run: 03
None time:  0.5028164240065962
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.10
run time now: 1.4908177852630615
total time:  1.5475583111401647
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.13 ± 3.26
  Final Train: 100.00 ± 0.00
   Final Test: 66.77 ± 3.45
[I 2023-06-11 23:23:28,892] Trial 40 finished with value: 67.13333129882812 and parameters: {'Fwd': 0.021090734117366818, 'K': 8, 'alpha': 0.75, 'dropout': 0.1, 'gnnepoch': 30, 'lambda1': 0.45, 'lambda2': 5.83853548824832, 'loop': 1, 'loss': 'CE', 'lr': 0.0011156938652293466, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.3965552331741544e-05, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0014775633747922121
weight_decay:  1.3684127231522182e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9079392030835152
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9568232039455324
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.8991842670366168
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.8087916374206543
total time:  2.854360549012199
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.51
[I 2023-06-11 23:23:32,220] Trial 41 finished with value: 71.13333892822266 and parameters: {'Fwd': 0.038608299294220084, 'K': 10, 'alpha': 1.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 2.6562427119027388, 'loop': 0, 'loss': 'CE', 'lr': 0.0014775633747922121, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.3684127231522182e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002530940869305609
weight_decay:  3.6754433850689236e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8856670369859785
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.8479498419910669
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.8845078339800239
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.00
run time now: 2.6661598682403564
total time:  2.7213636469095945
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.40
[I 2023-06-11 23:23:35,363] Trial 42 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.03815951414195069, 'K': 10, 'alpha': 1.0, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 2.6604564849175882, 'loop': 0, 'loss': 'CE', 'lr': 0.002530940869305609, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.6754433850689236e-06, 'weightedloss': True}. Best is trial 10 with value: 71.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0014772591296656346
weight_decay:  1.7563309432509368e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.057078069075942
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.02357134106569
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.0434118111152202
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.1653778553009033
total time:  3.2198388730175793
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.35
[I 2023-06-11 23:23:39,005] Trial 43 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.01052743512172137, 'K': 9, 'alpha': 0.9, 'dropout': 0.5, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 4.9179824137633865, 'loop': 0, 'loss': 'CE', 'lr': 0.0014772591296656346, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.7563309432509368e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.001617704939688715
weight_decay:  1.9727908193400475e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7716667200438678
None Run 01:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 97.50
   Final Test: 49.40
Split: 01, Run: 02
None time:  0.7522973380982876
None Run 02:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 98.33
   Final Test: 50.60
Split: 01, Run: 03
None time:  0.866198870819062
None Run 03:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 98.33
   Final Test: 53.10
run time now: 2.4325175285339355
total time:  2.4814847020898014
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.73 ± 2.20
  Final Train: 98.06 ± 0.48
   Final Test: 51.03 ± 1.89
[I 2023-06-11 23:23:41,914] Trial 44 finished with value: 51.733333587646484 and parameters: {'Fwd': 0.008978089255924734, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 4.627525778698063, 'loop': 0, 'loss': 'CE', 'lr': 0.001617704939688715, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.9727908193400475e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0011891220986020978
weight_decay:  4.722763051519333e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1738828730303794
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.9196621850132942
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.1763877340126783
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 4.312298059463501
total time:  4.3689733480568975
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.23
  Final Train: 99.72 ± 0.48
   Final Test: 69.40 ± 0.30
[I 2023-06-11 23:23:46,677] Trial 45 finished with value: 71.13333129882812 and parameters: {'Fwd': 0.0046863199555681224, 'K': 9, 'alpha': 0.9, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 5.120969822323227, 'loop': 2, 'loss': 'CE', 'lr': 0.0011891220986020978, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.722763051519333e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.002194257819123407
weight_decay:  7.4860485448046295e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0612850908655673
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.0452841070946306
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0759449540637434
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.224769115447998
total time:  3.2775032240897417
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.47
[I 2023-06-11 23:23:50,348] Trial 46 finished with value: 71.13333892822266 and parameters: {'Fwd': 0.015425942658171241, 'K': 9, 'alpha': 0.05, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 4.10410967677396, 'loop': 0, 'loss': 'CE', 'lr': 0.002194257819123407, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.4860485448046295e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0008558491175741993
weight_decay:  3.024590133894275e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4786707579623908
None Run 01:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 46.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.80% Test: 68.80%
Split: 01, Run: 02
None time:  1.0692943991161883
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.40% Test: 65.10%
Split: 01, Run: 03
None time:  1.0179418199695647
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.10
run time now: 2.6115243434906006
total time:  2.6641654069535434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.87 ± 11.66
  Final Train: 100.00 ± 0.00
   Final Test: 60.00 ± 12.27
[I 2023-06-11 23:23:53,423] Trial 47 finished with value: 59.86666488647461 and parameters: {'Fwd': 0.0066881776381487665, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 3.730971871717765, 'loop': 0, 'loss': 'MSE', 'lr': 0.0008558491175741993, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.024590133894275e-06, 'weightedloss': False}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.0033761225306590333
weight_decay:  1.5649949741515958e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7185228990856558
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.8266617869958282
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 70.30%
Split: 01, Run: 03
None time:  1.576749854022637
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.1622581481933594
total time:  3.2179509410634637
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.06
[I 2023-06-11 23:23:57,241] Trial 48 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.058323615631870336, 'K': 8, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.45, 'lambda2': 4.769944497376803, 'loop': 0, 'loss': 'CE', 'lr': 0.0033761225306590333, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.5649949741515958e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.001523626337247665
weight_decay:  1.0547760833233447e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.64845763402991
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.5559550269972533
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  0.5987016640137881
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.00
run time now: 1.8457231521606445
total time:  1.8971458079759032
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 68.33 ± 0.67
[I 2023-06-11 23:23:59,551] Trial 49 finished with value: 70.0666732788086 and parameters: {'Fwd': 0.023157749759342258, 'K': 9, 'alpha': 0.4, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 6.2399972184401395, 'loop': 0, 'loss': 'CE', 'lr': 0.001523626337247665, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0547760833233447e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0024821158112342642
weight_decay:  1.80766135123186e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.957942564971745
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.9919481829274446
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.979160716990009
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 68.20
run time now: 2.984011173248291
total time:  3.042539204005152
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.60
  Final Train: 99.44 ± 0.48
   Final Test: 68.93 ± 0.64
[I 2023-06-11 23:24:03,039] Trial 50 finished with value: 70.80001068115234 and parameters: {'Fwd': 0.0035116660403878347, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.2, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 5.276469762938231, 'loop': 0, 'loss': 'CE', 'lr': 0.0024821158112342642, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.80766135123186e-05, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.001465494941202136
weight_decay:  1.625051931009778e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9048086879774928
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.8626337950117886
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.9055801399517804
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.7162957191467285
total time:  2.781101631000638
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 0.50
[I 2023-06-11 23:24:06,242] Trial 51 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.010025060713042851, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 4.14052423024847, 'loop': 0, 'loss': 'CE', 'lr': 0.001465494941202136, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.625051931009778e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.001052797581658519
weight_decay:  2.950318583906963e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.866702264174819
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.9503114419057965
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.8683941159397364
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.729649782180786
total time:  2.786562397144735
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 69.07 ± 0.32
[I 2023-06-11 23:24:09,446] Trial 52 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.027557828000509575, 'K': 10, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.2, 'lambda2': 3.337844827961835, 'loop': 0, 'loss': 'CE', 'lr': 0.001052797581658519, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.950318583906963e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.0017194995354140258
weight_decay:  1.5047296262065971e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0745127550326288
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.9521822689566761
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.9959087900351733
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.065483570098877
total time:  3.116296375868842
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.38
[I 2023-06-11 23:24:13,009] Trial 53 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.015468977023093144, 'K': 10, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 2.3319592877620567, 'loop': 0, 'loss': 'CE', 'lr': 0.0017194995354140258, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.5047296262065971e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0021017272479541362
weight_decay:  4.514462903618602e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0996509930118918
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.1429691661614925
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.0686153180431575
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.353337049484253
total time:  3.412250286899507
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.56
[I 2023-06-11 23:24:16,873] Trial 54 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.03870769237252128, 'K': 9, 'alpha': 0.9, 'dropout': 0.5, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 3.6436183918904383, 'loop': 0, 'loss': 'CE', 'lr': 0.0021017272479541362, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.514462903618602e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.001310280444884375
weight_decay:  1.0500162898282214e-06
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8476761800702661
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.80%
Split: 01, Run: 02
None time:  1.8336139349266887
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  0.8752298098988831
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.80
run time now: 3.6119544506073
total time:  3.679773753043264
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.13 ± 0.35
[I 2023-06-11 23:24:21,048] Trial 55 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.06669208522456845, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 1.4687778342969793, 'loop': 0, 'loss': 'CE', 'lr': 0.001310280444884375, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0500162898282214e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.0016372845101015163
weight_decay:  7.2921095440052405e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7589357900433242
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.7898005610331893
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.7393079460598528
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.90
run time now: 2.329573631286621
total time:  2.3852819679304957
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.23 ± 0.29
[I 2023-06-11 23:24:23,916] Trial 56 finished with value: 70.66667175292969 and parameters: {'Fwd': 0.0064795953005829824, 'K': 9, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 3.0221170815400855, 'loop': 0, 'loss': 'CE', 'lr': 0.0016372845101015163, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.2921095440052405e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0021063023031032903
weight_decay:  2.6879437056894033e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.80% Test: 68.50%
Split: 01, Run: 01
None time:  1.5153627109248191
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.60% Test: 68.30%
Split: 01, Run: 02
None time:  1.634095752146095
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.60% Test: 68.10%
Split: 01, Run: 03
None time:  1.568526108050719
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.10
run time now: 4.757350921630859
total time:  4.815703527070582
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.33 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 68.27 ± 0.21
[I 2023-06-11 23:24:29,165] Trial 57 finished with value: 67.33333587646484 and parameters: {'Fwd': 0.017339251732507208, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.5, 'lambda2': 4.166224273669282, 'loop': 0, 'loss': 'MSE', 'lr': 0.0021063023031032903, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.6879437056894033e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.002990927424897835
weight_decay:  3.889821533840429e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 52.00% Test: 53.00%
Split: 01, Run: 01
None time:  1.3921398129314184
None Run 01:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 52.90
Split: 01, Run: 02
None time:  0.7224926631897688
None Run 02:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 54.00
Split: 01, Run: 03
None time:  0.7937244260683656
None Run 03:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 46.70
run time now: 2.9518821239471436
total time:  3.0034244949929416
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.80 ± 4.50
  Final Train: 100.00 ± 0.00
   Final Test: 51.20 ± 3.94
[I 2023-06-11 23:24:32,601] Trial 58 finished with value: 51.79999923706055 and parameters: {'Fwd': 0.07128541548549518, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 4.846626080372298, 'loop': 0, 'loss': 'CE', 'lr': 0.002990927424897835, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.889821533840429e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.75
lr:  0.0014225745188597779
weight_decay:  9.90460014369509e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.129993150010705
None Run 01:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 50.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.00% Test: 49.30%
Split: 01, Run: 02
None time:  0.6400502629112452
None Run 02:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 49.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.80% Test: 53.40%
Split: 01, Run: 03
None time:  0.6678198268637061
None Run 03:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 52.80
run time now: 1.4755079746246338
total time:  1.5338285388424993
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 50.67 ± 1.89
[I 2023-06-11 23:24:34,506] Trial 59 finished with value: 51.60000228881836 and parameters: {'Fwd': 0.036052661448961534, 'K': 4, 'alpha': 0.75, 'dropout': 0.30000000000000004, 'gnnepoch': 0, 'lambda1': 0.55, 'lambda2': 5.520828158550007, 'loop': 0, 'loss': 'CE', 'lr': 0.0014225745188597779, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.90460014369509e-06, 'weightedloss': False}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.65
lr:  0.001216429908405978
weight_decay:  1.5130570190007354e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9455519178882241
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.924837184837088
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.8690774091519415
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.774390697479248
total time:  2.828582762973383
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.35
  Final Train: 99.72 ± 0.48
   Final Test: 69.03 ± 0.40
[I 2023-06-11 23:24:37,841] Trial 60 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.09942273205169604, 'K': 2, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 0.07975090531475004, 'loop': 2, 'loss': 'CE', 'lr': 0.001216429908405978, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.5130570190007354e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.002214162365474469
weight_decay:  7.1814038698280754e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9565765319857746
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.9438368640840054
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.078386059962213
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.20
run time now: 3.027038097381592
total time:  3.0874142420943826
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.52
[I 2023-06-11 23:24:41,479] Trial 61 finished with value: 71.00000762939453 and parameters: {'Fwd': 0.015296325547385872, 'K': 9, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 4.224317834690916, 'loop': 0, 'loss': 'CE', 'lr': 0.002214162365474469, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.1814038698280754e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0023464773146322205
weight_decay:  2.5668487686349097e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9767926861532032
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0167241028975695
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.0087561919353902
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.0447568893432617
total time:  3.0991955699864775
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.35
[I 2023-06-11 23:24:44,994] Trial 62 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.00855402978603928, 'K': 9, 'alpha': 0.1, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 3.8248112560931196, 'loop': 0, 'loss': 'CE', 'lr': 0.0023464773146322205, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.5668487686349097e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.0019234751131926606
weight_decay:  2.602974366076645e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9766742228530347
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0241980149876326
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.9984900529962033
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.0499448776245117
total time:  3.1167755268979818
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 1.05
[I 2023-06-11 23:24:48,544] Trial 63 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.00795477600751653, 'K': 10, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 3.7235618725463793, 'loop': 0, 'loss': 'CE', 'lr': 0.0019234751131926606, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.602974366076645e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0027142422420850256
weight_decay:  2.153303968690215e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.911764521850273
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9550466497894377
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.8941118179354817
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.800935983657837
total time:  2.856796353124082
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.53
  Final Train: 99.72 ± 0.48
   Final Test: 69.83 ± 0.55
[I 2023-06-11 23:24:51,879] Trial 64 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.010174476691686635, 'K': 8, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 3.2373601390990734, 'loop': 0, 'loss': 'CE', 'lr': 0.0027142422420850256, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.153303968690215e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.002604039480226568
weight_decay:  2.2409516875999517e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9719804839696735
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0165140361059457
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  0.9333796878345311
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.963019371032715
total time:  3.0178281320258975
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 1.11
[I 2023-06-11 23:24:55,349] Trial 65 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.004430017832501441, 'K': 8, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 3.890948523840204, 'loop': 0, 'loss': 'CE', 'lr': 0.002604039480226568, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2409516875999517e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0027596855431409406
weight_decay:  5.0447886058229285e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9297231349628419
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9765586170833558
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 67.80
Split: 01, Run: 03
None time:  1.0687251018825918
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.021385669708252
total time:  3.08010006416589
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.61
  Final Train: 99.72 ± 0.48
   Final Test: 69.10 ± 1.14
[I 2023-06-11 23:24:58,881] Trial 66 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.004170099359762041, 'K': 8, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 3.2456442457308157, 'loop': 0, 'loss': 'CE', 'lr': 0.0027596855431409406, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.0447886058229285e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.0033862176760667195
weight_decay:  3.7909233347045787e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8953113460447639
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.9709207022096962
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.028644774807617
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.935373306274414
total time:  2.9896877971477807
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.07 ± 1.01
[I 2023-06-11 23:25:02,277] Trial 67 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.0034978658340070654, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 3.2409344201440895, 'loop': 0, 'loss': 'CE', 'lr': 0.0033862176760667195, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.7909233347045787e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.002669876057920695
weight_decay:  5.412768392750876e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.40% Test: 68.50%
Split: 01, Run: 01
None time:  1.6636178460903466
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.20% Test: 69.30%
Split: 01, Run: 02
None time:  1.698547445004806
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.40% Test: 68.30%
Split: 01, Run: 03
None time:  1.6507643649820238
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 68.20
run time now: 5.06403112411499
total time:  5.119060091208667
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.33 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 68.57 ± 0.55
[I 2023-06-11 23:25:07,794] Trial 68 finished with value: 67.33333587646484 and parameters: {'Fwd': 0.0015841352573933377, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 3.817175805188477, 'loop': 0, 'loss': 'MSE', 'lr': 0.002669876057920695, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.412768392750876e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0031367596461155892
weight_decay:  2.2134554571643665e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0333621299359947
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0093166697770357
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.0592343718744814
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.1427793502807617
total time:  3.193257451057434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.55
[I 2023-06-11 23:25:11,421] Trial 69 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.005144563635258102, 'K': 8, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.1386252269948383, 'loop': 0, 'loss': 'CE', 'lr': 0.0031367596461155892, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2134554571643665e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.0040548002488196505
weight_decay:  2.3426589609920833e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9936040230095387
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.103152381023392
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.033797790063545
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.20
run time now: 3.1759302616119385
total time:  3.2283001409377903
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.12
  Final Train: 99.44 ± 0.48
   Final Test: 69.93 ± 0.38
[I 2023-06-11 23:25:15,062] Trial 70 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.004558458402117302, 'K': 7, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.3910834013645736, 'loop': 0, 'loss': 'CE', 'lr': 0.0040548002488196505, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3426589609920833e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.004281485300690869
weight_decay:  2.2754691604826635e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0719319970812649
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0690348269417882
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.131652053911239
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 70.40
run time now: 3.3140108585357666
total time:  3.371447436977178
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.12
  Final Train: 98.89 ± 0.96
   Final Test: 70.37 ± 0.15
[I 2023-06-11 23:25:18,887] Trial 71 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.0038000257861523614, 'K': 7, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.1792566983865647, 'loop': 0, 'loss': 'CE', 'lr': 0.004281485300690869, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2754691604826635e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.004294603298381671
weight_decay:  2.3041113011937206e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0190935030113906
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0358121001627296
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.142840376822278
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 98.33
   Final Test: 70.50
run time now: 3.2383389472961426
total time:  3.294227105099708
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.12
  Final Train: 99.44 ± 0.96
   Final Test: 70.27 ± 0.21
[I 2023-06-11 23:25:22,729] Trial 72 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0053326156180993674, 'K': 7, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.15041340494554, 'loop': 0, 'loss': 'CE', 'lr': 0.004294603298381671, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3041113011937206e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.4
lr:  0.00449330889723915
weight_decay:  2.2811185882175555e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9679953299928457
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.9231034670956433
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0770777268335223
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 70.30
run time now: 3.008174180984497
total time:  3.0548533988185227
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.50
  Final Train: 98.61 ± 0.48
   Final Test: 70.17 ± 0.15
[I 2023-06-11 23:25:26,205] Trial 73 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.0026732335330348286, 'K': 7, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.151738200562359, 'loop': 0, 'loss': 'CE', 'lr': 0.00449330889723915, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2811185882175555e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.4
lr:  0.005257661300829245
weight_decay:  2.26213001378252e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.080472273984924
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 97.50
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.2348401271738112
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 95.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.0797733119688928
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 93.33
   Final Test: 69.30
run time now: 3.4359993934631348
total time:  3.494674094952643
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.40
  Final Train: 95.28 ± 2.10
   Final Test: 69.70 ± 0.46
[I 2023-06-11 23:25:30,143] Trial 74 finished with value: 70.80001068115234 and parameters: {'Fwd': 0.0022377272898116292, 'K': 7, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.862103152187424, 'loop': 0, 'loss': 'CE', 'lr': 0.005257661300829245, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.26213001378252e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.30000000000000004
lr:  0.0041965970514823234
weight_decay:  3.245705220588152e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0444908009376377
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.031755224103108
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.9898673770949244
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 70.40
run time now: 3.1107044219970703
total time:  3.1743233469314873
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.12
  Final Train: 98.61 ± 0.48
   Final Test: 70.17 ± 0.32
[I 2023-06-11 23:25:33,782] Trial 75 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0059136680569116615, 'K': 6, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.5112778780997207, 'loop': 0, 'loss': 'CE', 'lr': 0.0041965970514823234, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.245705220588152e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.30000000000000004
lr:  0.004120506298298244
weight_decay:  3.4644007482112784e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.028044112958014
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 97.50
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0385150199290365
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 95.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0737028729636222
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 98.33
   Final Test: 69.80
run time now: 3.179201364517212
total time:  3.2352341760415584
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.23
  Final Train: 96.94 ± 1.73
   Final Test: 69.97 ± 0.21
[I 2023-06-11 23:25:37,461] Trial 76 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.0058895370399784175, 'K': 6, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.3716274897441036, 'loop': 0, 'loss': 'CE', 'lr': 0.004120506298298244, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.4644007482112784e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.15000000000000002
lr:  0.006010476281860966
weight_decay:  1.4348161478266182e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.096560758072883
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.023330416996032
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.1863975878804922
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.00
   Final Test: 69.80
run time now: 3.3445777893066406
total time:  3.398271454963833
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.20
  Final Train: 97.78 ± 2.41
   Final Test: 69.93 ± 0.42
[I 2023-06-11 23:25:41,273] Trial 77 finished with value: 70.80000305175781 and parameters: {'Fwd': 0.005955750338343579, 'K': 6, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.44603319635788, 'loop': 0, 'loss': 'CE', 'lr': 0.006010476281860966, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4348161478266182e-06, 'weightedloss': False}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.007014287997873564
weight_decay:  1.0592798553470758e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8173438350204378
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 95.83
   Final Test: 66.20
Split: 01, Run: 02
None time:  0.707874980987981
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 95.83
   Final Test: 63.80
Split: 01, Run: 03
None time:  0.738404574804008
None Run 03:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 96.67
   Final Test: 57.70
run time now: 2.303647756576538
total time:  2.3516680682078004
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.87 ± 6.05
  Final Train: 96.11 ± 0.48
   Final Test: 62.57 ± 4.38
[I 2023-06-11 23:25:44,036] Trial 78 finished with value: 63.866668701171875 and parameters: {'Fwd': 0.009601575943033697, 'K': 7, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 2.699229004442966, 'loop': 0, 'loss': 'CE', 'lr': 0.007014287997873564, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.0592798553470758e-05, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.30000000000000004
lr:  0.0037697229237077055
weight_decay:  1.3321304771327547e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.156241161050275
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.83
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.164187079994008
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 95.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.171577522996813
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 98.33
   Final Test: 69.30
run time now: 3.536189556121826
total time:  3.5808589209336787
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.42
  Final Train: 96.39 ± 1.73
   Final Test: 69.57 ± 0.46
[I 2023-06-11 23:25:48,039] Trial 79 finished with value: 70.13333892822266 and parameters: {'Fwd': 0.0011807751856593473, 'K': 6, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 1.9191113030793483, 'loop': 1, 'loss': 'CE', 'lr': 0.0037697229237077055, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3321304771327547e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.0
lr:  0.0037838008146809728
weight_decay:  2.8649948217563266e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8939201890025288
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0177202990744263
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.9162844379898161
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 69.70
run time now: 2.8692240715026855
total time:  2.938838941976428
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.92
  Final Train: 99.17 ± 0.00
   Final Test: 69.63 ± 0.60
[I 2023-06-11 23:25:51,439] Trial 80 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.007571076033266116, 'K': 7, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 3.059045269957788, 'loop': 0, 'loss': 'CE', 'lr': 0.0037838008146809728, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8649948217563266e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.4
lr:  0.004499485192758015
weight_decay:  2.0652904390944794e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9795123699586838
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.127287448151037
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1214718869887292
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.70
run time now: 3.2684361934661865
total time:  3.3271165969781578
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.40
  Final Train: 98.89 ± 0.48
   Final Test: 70.00 ± 0.30
[I 2023-06-11 23:25:55,289] Trial 81 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.003376320299937784, 'K': 7, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.1994392033809342, 'loop': 0, 'loss': 'CE', 'lr': 0.004499485192758015, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.0652904390944794e-06, 'weightedloss': True}. Best is trial 43 with value: 71.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.0032709413044576838
weight_decay:  1.9919692960118806e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9634201051667333
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0176099129021168
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.0954134019557387
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.1168127059936523
total time:  3.177680940134451
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.25
[I 2023-06-11 23:25:58,881] Trial 82 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.002589510934790701, 'K': 7, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.5360658606644852, 'loop': 0, 'loss': 'CE', 'lr': 0.0032709413044576838, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.9919692960118806e-06, 'weightedloss': True}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.35000000000000003
lr:  0.004907099508669079
weight_decay:  3.31896365530331e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1132482609245926
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  1.1482456380035728
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 98.33
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.9904839990194887
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.70
run time now: 3.2923502922058105
total time:  3.3491410380229354
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.42
  Final Train: 99.17 ± 0.83
   Final Test: 70.27 ± 0.51
[I 2023-06-11 23:26:02,659] Trial 83 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.011412901729039747, 'K': 7, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.49821066003298, 'loop': 0, 'loss': 'CE', 'lr': 0.004907099508669079, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.31896365530331e-06, 'weightedloss': True}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.45
lr:  0.003362385037005218
weight_decay:  1.8370609778781698e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0162488911300898
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0449315400328487
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0403718880843371
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.140720844268799
total time:  3.196949982084334
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.06
[I 2023-06-11 23:26:06,283] Trial 84 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.005232210780078319, 'K': 6, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.565783041579019, 'loop': 0, 'loss': 'CE', 'lr': 0.003362385037005218, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.8370609778781698e-06, 'weightedloss': True}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.55
lr:  0.003232002648705019
weight_decay:  1.2789251904708043e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.976257607107982
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  0.9732514340430498
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.0551688359118998
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.051597833633423
total time:  3.110176313202828
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.75
[I 2023-06-11 23:26:09,899] Trial 85 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.005195443857161989, 'K': 5, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 4.445131428814211, 'loop': 0, 'loss': 'CE', 'lr': 0.003232002648705019, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2789251904708043e-06, 'weightedloss': True}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.5
lr:  0.0036421244638164102
weight_decay:  1.7752564046339343e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1552520040422678
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.1322829599957913
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1089535360224545
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.4348199367523193
total time:  3.4890223438851535
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 1.10
  Final Train: 99.72 ± 0.48
   Final Test: 70.13 ± 0.35
[I 2023-06-11 23:26:13,850] Trial 86 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.012128614548802685, 'K': 6, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.6370303564696527, 'loop': 1, 'loss': 'CE', 'lr': 0.0036421244638164102, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.7752564046339343e-06, 'weightedloss': True}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.35000000000000003
lr:  0.0031033892647863224
weight_decay:  1.0040517648808668e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.60% Test: 66.60%
Split: 01, Run: 01
None time:  1.6048203059472144
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.60% Test: 67.50%
Split: 01, Run: 02
None time:  1.5594440649729222
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.40% Test: 67.80%
Split: 01, Run: 03
None time:  1.6266426539514214
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 67.90
run time now: 4.829950332641602
total time:  4.883979809936136
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 67.33 ± 0.74
[I 2023-06-11 23:26:19,136] Trial 87 finished with value: 65.53333282470703 and parameters: {'Fwd': 0.00819512668739742, 'K': 6, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 3.9882504062083646, 'loop': 0, 'loss': 'MSE', 'lr': 0.0031033892647863224, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0040517648808668e-06, 'weightedloss': True}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.003163471070166898
weight_decay:  4.645468212780108e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.001134549966082
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.9621371899265796
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.076179115101695
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.081282138824463
total time:  3.1319329279940575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.12
  Final Train: 99.72 ± 0.48
   Final Test: 69.77 ± 0.55
[I 2023-06-11 23:26:22,713] Trial 88 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.0050719703501266675, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.8860853323126325, 'loop': 0, 'loss': 'CE', 'lr': 0.003163471070166898, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.645468212780108e-06, 'weightedloss': True}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.003899241932102862
weight_decay:  5.779780505060882e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.116169209126383
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.0157795110717416
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.1072927981149405
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 96.67
   Final Test: 70.40
run time now: 3.285984516143799
total time:  3.3440059300046414
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.23
  Final Train: 98.33 ± 1.44
   Final Test: 70.07 ± 0.31
[I 2023-06-11 23:26:26,464] Trial 89 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0026705857788126026, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.3811310309361544, 'loop': 0, 'loss': 'CE', 'lr': 0.003899241932102862, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.779780505060882e-06, 'weightedloss': False}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.25
lr:  0.003944160553010243
weight_decay:  5.698649847692983e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6966583498287946
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 97.50
   Final Test: 62.70
Split: 01, Run: 02
None time:  0.7120681849773973
None Run 02:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 97.50
   Final Test: 61.60
Split: 01, Run: 03
None time:  0.64678072812967
None Run 03:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 99.17
   Final Test: 59.90
run time now: 2.0921921730041504
total time:  2.1412703988607973
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.40 ± 2.99
  Final Train: 98.06 ± 0.96
   Final Test: 61.40 ± 1.41
[I 2023-06-11 23:26:29,122] Trial 90 finished with value: 62.39999771118164 and parameters: {'Fwd': 0.0027079863590264556, 'K': 5, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.3847262110335614, 'loop': 0, 'loss': 'CE', 'lr': 0.003944160553010243, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.698649847692983e-06, 'weightedloss': False}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.0033552333214701643
weight_decay:  4.354623118916161e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0336068461183459
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0356610619928688
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0071892340201885
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.118429660797119
total time:  3.1735563401598483
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 99.72 ± 0.48
   Final Test: 69.77 ± 0.15
[I 2023-06-11 23:26:32,725] Trial 91 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.005386706133654164, 'K': 8, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 2.8438913072491916, 'loop': 0, 'loss': 'CE', 'lr': 0.0033552333214701643, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.354623118916161e-06, 'weightedloss': False}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.003351589957395604
weight_decay:  4.131484476396944e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9827156979590654
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.056701106019318
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.077694769948721
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.162973165512085
total time:  3.2182312570512295
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 99.72 ± 0.48
   Final Test: 69.77 ± 0.12
[I 2023-06-11 23:26:36,367] Trial 92 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.005589128629062403, 'K': 8, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.774575474177046, 'loop': 0, 'loss': 'CE', 'lr': 0.003351589957395604, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.131484476396944e-06, 'weightedloss': False}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.0032519550663333576
weight_decay:  4.382800661528447e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0719487939495593
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0389516158029437
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.9492106479592621
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.80
run time now: 3.101243495941162
total time:  3.146709294989705
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.12
  Final Train: 99.44 ± 0.48
   Final Test: 69.47 ± 0.59
[I 2023-06-11 23:26:39,975] Trial 93 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.005614087804198717, 'K': 8, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.833926802355343, 'loop': 0, 'loss': 'CE', 'lr': 0.0032519550663333576, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.382800661528447e-06, 'weightedloss': False}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.2
lr:  0.005108859269958477
weight_decay:  3.279024562662068e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.072795628104359
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.073939923895523
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.063034184044227
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 70.40
run time now: 3.2506775856018066
total time:  3.299459938891232
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.12
  Final Train: 98.61 ± 0.48
   Final Test: 70.23 ± 0.15
[I 2023-06-11 23:26:43,760] Trial 94 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.005236598428009651, 'K': 7, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 2.83457144350296, 'loop': 0, 'loss': 'CE', 'lr': 0.005108859269958477, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.279024562662068e-06, 'weightedloss': False}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.0036073340313046583
weight_decay:  8.032411239580695e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0262182510923594
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.9320164369419217
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.9412027557846159
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.9418153762817383
total time:  3.0012809329200536
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.40
  Final Train: 99.17 ± 0.83
   Final Test: 69.27 ± 0.91
[I 2023-06-11 23:26:47,196] Trial 95 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.0018058845918618577, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 2.5857244788735345, 'loop': 0, 'loss': 'CE', 'lr': 0.0036073340313046583, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.032411239580695e-06, 'weightedloss': False}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.15000000000000002
lr:  0.0029677575467501926
weight_decay:  4.0574336487320995e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9663996419403702
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9880976770073175
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.161155115114525
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.83
   Final Test: 69.50
run time now: 3.1554172039031982
total time:  3.217387279961258
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.61
  Final Train: 98.06 ± 1.92
   Final Test: 69.80 ± 0.26
[I 2023-06-11 23:26:50,857] Trial 96 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.004483334460355599, 'K': 7, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.0640966699905974, 'loop': 0, 'loss': 'CE', 'lr': 0.0029677575467501926, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.0574336487320995e-06, 'weightedloss': False}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.2
lr:  0.0033724796576560818
weight_decay:  1.6711815456728843e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9284986290149391
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0874760570004582
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.1374532638583332
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.1916685104370117
total time:  3.2499266790691763
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.40
[I 2023-06-11 23:26:54,525] Trial 97 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.007064071142353733, 'K': 6, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.452669463298691, 'loop': 0, 'loss': 'CE', 'lr': 0.0033724796576560818, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6711815456728843e-06, 'weightedloss': False}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.0033474915507598945
weight_decay:  1.5884674430447137e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9989526579156518
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9921473988797516
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  0.9445442659780383
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.977301597595215
total time:  3.041711066151038
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.17 ± 1.14
[I 2023-06-11 23:26:58,022] Trial 98 finished with value: 71.06666564941406 and parameters: {'Fwd': 0.00322488470796984, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 3.5184379264016665, 'loop': 0, 'loss': 'CE', 'lr': 0.0033474915507598945, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5884674430447137e-06, 'weightedloss': False}. Best is trial 82 with value: 71.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.2
lr:  0.00238080727422466
weight_decay:  1.7234387994422928e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9711604549083859
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0944796530529857
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.060389898950234
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.171638250350952
total time:  3.231178304878995
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.53
[I 2023-06-11 23:27:01,717] Trial 99 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.007413521486039155, 'K': 7, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 2.962586284983743, 'loop': 0, 'loss': 'CE', 'lr': 0.00238080727422466, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.7234387994422928e-06, 'weightedloss': False}. Best is trial 99 with value: 71.73333740234375.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.2
lr:  0.0023582018550421828
weight_decay:  1.7497293488454578e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9186684449668974
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9801011579111218
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.9421161741483957
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.882319211959839
total time:  2.9456007229164243
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.50
  Final Train: 99.72 ± 0.48
   Final Test: 69.57 ± 0.78
[I 2023-06-11 23:27:05,223] Trial 100 finished with value: 71.06666564941406 and parameters: {'Fwd': 0.007104401203677022, 'K': 6, 'alpha': 0.2, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 2.9855640315537597, 'loop': 0, 'loss': 'CE', 'lr': 0.0023582018550421828, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.7497293488454578e-06, 'weightedloss': False}. Best is trial 99 with value: 71.73333740234375.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.1
lr:  0.0029241000733346385
weight_decay:  1.3289725809676534e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.043144135037437
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.9972312378231436
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1337108600419015
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.2146987915039062
total time:  3.264396301936358
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.52
[I 2023-06-11 23:27:08,933] Trial 101 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.013838560373903769, 'K': 7, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.4107890520929813, 'loop': 0, 'loss': 'CE', 'lr': 0.0029241000733346385, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3289725809676534e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.0028877769915696353
weight_decay:  1.231380008654693e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1471214040648192
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.0873044258914888
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0630097799003124
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.3382198810577393
total time:  3.393099620938301
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.64
[I 2023-06-11 23:27:12,731] Trial 102 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.013337967693017039, 'K': 8, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.4281497734961484, 'loop': 0, 'loss': 'CE', 'lr': 0.0028877769915696353, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.231380008654693e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.0029494631968552923
weight_decay:  1.2769155465795745e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.06139948614873
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0801844869274646
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0754885817877948
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.25821852684021
total time:  3.3160515800118446
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.80
  Final Train: 99.72 ± 0.48
   Final Test: 69.67 ± 0.49
[I 2023-06-11 23:27:16,490] Trial 103 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.013336121686491387, 'K': 8, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 2.7495503438630706, 'loop': 0, 'loss': 'CE', 'lr': 0.0029494631968552923, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2769155465795745e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.002555269320547148
weight_decay:  1.2244617440188075e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9937053150497377
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.9478731960989535
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  1.0510577319655567
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.0342750549316406
total time:  3.0883272390346974
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 1.05
[I 2023-06-11 23:27:19,966] Trial 104 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.01846597634128563, 'K': 8, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 3.5731482835319928, 'loop': 0, 'loss': 'CE', 'lr': 0.002555269320547148, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2244617440188075e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.003092377558302704
weight_decay:  1.035745319264066e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.093012924073264
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0362060109619051
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.0296460350509733
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.2005269527435303
total time:  3.2577017380390316
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.50
[I 2023-06-11 23:27:23,707] Trial 105 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.01210310186022907, 'K': 8, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 2.925146795368745, 'loop': 0, 'loss': 'CE', 'lr': 0.003092377558302704, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.035745319264066e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0028144609501111017
weight_decay:  1.0018525489560979e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.40% Test: 68.60%
Split: 01, Run: 01
None time:  1.8834215940441936
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.60% Test: 69.10%
Split: 01, Run: 02
None time:  1.8779117250815034
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.00% Test: 68.80%
Split: 01, Run: 03
None time:  1.8613282919395715
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 68.80
run time now: 5.667402267456055
total time:  5.738178187981248
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 68.83 ± 0.25
[I 2023-06-11 23:27:30,057] Trial 106 finished with value: 67.0 and parameters: {'Fwd': 0.01342187054479745, 'K': 9, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 2.9961957984719363, 'loop': 0, 'loss': 'MSE', 'lr': 0.0028144609501111017, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0018525489560979e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.002037727326621574
weight_decay:  1.276362635390008e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.2102441149763763
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 02
None time:  0.19823092897422612
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.30
Split: 01, Run: 03
None time:  0.22731462307274342
None Run 03:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 64.60
run time now: 0.6763949394226074
total time:  0.7344751851633191
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.73 ± 2.47
  Final Train: 100.00 ± 0.00
   Final Test: 65.70 ± 1.35
[I 2023-06-11 23:27:31,237] Trial 107 finished with value: 64.73332977294922 and parameters: {'Fwd': 0.021132751084388925, 'K': 8, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 10, 'lambda1': 1.0, 'lambda2': 3.964883409064626, 'loop': 0, 'loss': 'CE', 'lr': 0.002037727326621574, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.276362635390008e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.002789384727419729
weight_decay:  1.9182129540043663e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9659416968934238
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9966658719349653
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.9859833118971437
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.989555835723877
total time:  3.0506770631764084
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.61
  Final Train: 99.72 ± 0.48
   Final Test: 69.20 ± 1.06
[I 2023-06-11 23:27:34,748] Trial 108 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.010364893685829482, 'K': 8, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 2.8791108076480514, 'loop': 0, 'loss': 'CE', 'lr': 0.002789384727419729, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.9182129540043663e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.0034763488368759954
weight_decay:  2.8080188325640513e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7008395728189498
None Run 01:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 99.17
   Final Test: 49.00
Split: 01, Run: 02
None time:  0.7250332091934979
None Run 02:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 99.17
   Final Test: 53.10
Split: 01, Run: 03
None time:  0.7236386178992689
None Run 03:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 98.33
   Final Test: 59.60
run time now: 2.1910383701324463
total time:  2.244055744027719
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.33 ± 4.88
  Final Train: 98.89 ± 0.48
   Final Test: 53.90 ± 5.35
[I 2023-06-11 23:27:37,528] Trial 109 finished with value: 52.33333206176758 and parameters: {'Fwd': 0.025689056131549877, 'K': 8, 'alpha': 0.05, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 2.5473920673033907, 'loop': 0, 'loss': 'CE', 'lr': 0.0034763488368759954, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.8080188325640513e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0024016296955250934
weight_decay:  1.726266260914432e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9109474520664662
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.968143719015643
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.9772481108084321
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.8973464965820312
total time:  2.960144381970167
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 0.89
[I 2023-06-11 23:27:40,916] Trial 110 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.017382111257209995, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 3.305156686496748, 'loop': 0, 'loss': 'CE', 'lr': 0.0024016296955250934, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.726266260914432e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.2
lr:  0.0031653607235820557
weight_decay:  1.5899526256576156e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9943739189766347
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0344383229967207
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0699908779934049
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.70
run time now: 3.1397194862365723
total time:  3.197288481052965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.12
  Final Train: 99.72 ± 0.48
   Final Test: 70.03 ± 0.65
[I 2023-06-11 23:27:44,512] Trial 111 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.007423931827729318, 'K': 7, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.667192127587407, 'loop': 0, 'loss': 'CE', 'lr': 0.0031653607235820557, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5899526256576156e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.003075031271871134
weight_decay:  1.2089031517093976e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0328785669989884
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0960220959968865
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.01345861912705
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.1839311122894287
total time:  3.238006839994341
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.36
[I 2023-06-11 23:27:48,189] Trial 112 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.009162510419850762, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.3372576122050814, 'loop': 0, 'loss': 'CE', 'lr': 0.003075031271871134, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2089031517093976e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.0023119297110995316
weight_decay:  1.2742566717567054e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9692001140210778
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0726218440104276
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.11036064196378
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.1933746337890625
total time:  3.2446138439700007
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.68
[I 2023-06-11 23:27:51,847] Trial 113 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.008755204149272085, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.202027393925308, 'loop': 0, 'loss': 'CE', 'lr': 0.0023119297110995316, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2742566717567054e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.003063475149131127
weight_decay:  1.0480638145675519e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0844782767817378
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0347749348729849
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.059208489023149
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.2205567359924316
total time:  3.2786007209215313
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 99.72 ± 0.48
   Final Test: 69.80 ± 0.62
[I 2023-06-11 23:27:55,577] Trial 114 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.015610841567806264, 'K': 9, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.8847852090620933, 'loop': 0, 'loss': 'CE', 'lr': 0.003063475149131127, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0480638145675519e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.0025835923370300853
weight_decay:  1.0248481961434332e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0735900248400867
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.0339997329283506
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.1002833091188222
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.24861478805542
total time:  3.3006018311716616
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.35
  Final Train: 99.72 ± 0.48
   Final Test: 69.97 ± 0.84
[I 2023-06-11 23:27:59,434] Trial 115 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.013256076491607111, 'K': 9, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.7883801825541155, 'loop': 0, 'loss': 'CE', 'lr': 0.0025835923370300853, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0248481961434332e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0029833733366881176
weight_decay:  1.339057887234159e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0002690728288144
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9571616149041802
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.9793572081252933
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.992345094680786
total time:  3.069489432964474
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.53
  Final Train: 99.72 ± 0.48
   Final Test: 69.60 ± 0.69
[I 2023-06-11 23:28:02,945] Trial 116 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.029926158132469245, 'K': 9, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 3.012054082218701, 'loop': 0, 'loss': 'CE', 'lr': 0.0029833733366881176, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.339057887234159e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.002221808528629483
weight_decay:  4.446867585945911e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2200023930054158
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.2552116960287094
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.2522521729115397
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.7912867069244385
total time:  3.842276613926515
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 0.61
[I 2023-06-11 23:28:07,332] Trial 117 finished with value: 71.13333892822266 and parameters: {'Fwd': 0.018615268538506844, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 2.2190662598712483, 'loop': 2, 'loss': 'CE', 'lr': 0.002221808528629483, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.446867585945911e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.0028032766135280924
weight_decay:  2.6606168407867755e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0189653169363737
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.0228738570585847
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.9919819249771535
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.70
run time now: 3.0768587589263916
total time:  3.1335648300591856
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.53
  Final Train: 98.89 ± 0.48
   Final Test: 69.43 ± 0.74
[I 2023-06-11 23:28:10,923] Trial 118 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.011118316112819892, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 2.5300769499448204, 'loop': 0, 'loss': 'CE', 'lr': 0.0028032766135280924, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.6606168407867755e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.0018222525375077437
weight_decay:  3.6770818545930856e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1026471450459212
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0503519200719893
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9706144488882273
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.1657562255859375
total time:  3.223691347055137
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.53
[I 2023-06-11 23:28:14,569] Trial 119 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.009357623317876169, 'K': 8, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 2.6833335081752816, 'loop': 0, 'loss': 'CE', 'lr': 0.0018222525375077437, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.6770818545930856e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.00201417366023407
weight_decay:  1.9793554107448294e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 70.30%
Split: 01, Run: 01
None time:  1.8330642147921026
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 70.00%
Split: 01, Run: 02
None time:  1.8721728390082717
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.30%
Split: 01, Run: 03
None time:  1.8112603779882193
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
run time now: 5.566213607788086
total time:  5.639826234895736
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.51
[I 2023-06-11 23:28:20,683] Trial 120 finished with value: 69.33333587646484 and parameters: {'Fwd': 0.015262198975301507, 'K': 9, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.3323785321735304, 'loop': 0, 'loss': 'MSE', 'lr': 0.00201417366023407, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.9793554107448294e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.0019179303953471977
weight_decay:  3.796566845234747e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0762816660571843
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.0524819260463119
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0947188320569694
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.2651479244232178
total time:  3.3207223250065
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.64
[I 2023-06-11 23:28:24,467] Trial 121 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.008909289709148076, 'K': 8, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 2.6658083024322488, 'loop': 0, 'loss': 'CE', 'lr': 0.0019179303953471977, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.796566845234747e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.0017156762924254358
weight_decay:  3.113285138160977e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1019123462028801
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 02
None time:  1.0970156439580023
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9856902989558876
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.2287099361419678
total time:  3.2809996139258146
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.84
[I 2023-06-11 23:28:28,198] Trial 122 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.010882528247458445, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.138159006884579, 'loop': 0, 'loss': 'CE', 'lr': 0.0017156762924254358, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.113285138160977e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.002465123422422608
weight_decay:  6.507189570903828e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9159500610549003
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.9465786200016737
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.935068140970543
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.846376419067383
total time:  2.901406046934426
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.23 ± 0.90
[I 2023-06-11 23:28:31,511] Trial 123 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.02225138443949028, 'K': 8, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 2.914382069236502, 'loop': 0, 'loss': 'CE', 'lr': 0.002465123422422608, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.507189570903828e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.003037303378698427
weight_decay:  1.405804423748842e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0424254280515015
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.115961944218725
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0536459521390498
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.254396438598633
total time:  3.311204956145957
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 99.44 ± 0.48
   Final Test: 69.67 ± 0.49
[I 2023-06-11 23:28:35,299] Trial 124 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0068197253124635746, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 2.179572812395075, 'loop': 0, 'loss': 'CE', 'lr': 0.003037303378698427, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.405804423748842e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.003566491234557583
weight_decay:  2.509194836235073e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.142884546192363
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.1144106979481876
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0007266958709806
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.299391269683838
total time:  3.347944187000394
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.29
[I 2023-06-11 23:28:39,136] Trial 125 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.004047059128079103, 'K': 9, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.880289102166552, 'loop': 0, 'loss': 'CE', 'lr': 0.003566491234557583, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.509194836235073e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.15000000000000002
lr:  0.0025510779908712073
weight_decay:  1.0210070059604421e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0110235360916704
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.053952060872689
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.0121988579630852
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.20
run time now: 3.1213581562042236
total time:  3.1760375818703324
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.42
  Final Train: 99.44 ± 0.48
   Final Test: 69.57 ± 0.35
[I 2023-06-11 23:28:42,762] Trial 126 finished with value: 71.13333892822266 and parameters: {'Fwd': 0.008446736282847119, 'K': 7, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 1.90400281466599, 'loop': 0, 'loss': 'CE', 'lr': 0.0025510779908712073, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0210070059604421e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.002263368547722688
weight_decay:  1.864694943060526e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.002337460173294
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 67.90%
Split: 01, Run: 02
None time:  1.7240516419988126
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.9979300119448453
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.7768609523773193
total time:  3.8405849949922413
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.70
[I 2023-06-11 23:28:47,145] Trial 127 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.014193299470610423, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.05, 'lambda2': 2.714271700075576, 'loop': 0, 'loss': 'CE', 'lr': 0.002263368547722688, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.864694943060526e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.0030834910008074768
weight_decay:  4.9174147546208655e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9838206968270242
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.1205231579951942
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.092365249991417
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.23891282081604
total time:  3.297904703998938
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.50
[I 2023-06-11 23:28:50,873] Trial 128 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.011291244932624088, 'K': 8, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.33265478897672, 'loop': 0, 'loss': 'CE', 'lr': 0.0030834910008074768, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.9174147546208655e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.003166494900179204
weight_decay:  1.4038861686003985e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0095114361029118
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9179425190668553
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.9287859841715544
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.9010164737701416
total time:  2.9622076200321317
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.61
[I 2023-06-11 23:28:54,277] Trial 129 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.030066893123810546, 'K': 9, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 3.3492927639563335, 'loop': 0, 'loss': 'CE', 'lr': 0.003166494900179204, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4038861686003985e-05, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.003937601802139707
weight_decay:  5.003169689590817e-06
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7787532729562372
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.40
Split: 01, Run: 02
None time:  0.6684933400247246
None Run 02:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.40
Split: 01, Run: 03
None time:  0.7260500229895115
None Run 03:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.40
run time now: 2.2147560119628906
total time:  2.2707609499339014
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.60 ± 11.78
  Final Train: 100.00 ± 0.00
   Final Test: 52.73 ± 10.97
[I 2023-06-11 23:28:57,096] Trial 130 finished with value: 53.60000228881836 and parameters: {'Fwd': 0.017719252119191432, 'K': 8, 'alpha': 0.0, 'dropout': 0.0, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.1185659251563203, 'loop': 0, 'loss': 'CE', 'lr': 0.003937601802139707, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.003169689590817e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.002641971573884788
weight_decay:  3.781859244194284e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.026248054811731
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0366149700712413
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.0703773400746286
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.1956663131713867
total time:  3.258259331807494
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.67
[I 2023-06-11 23:29:00,801] Trial 131 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.010977476951139402, 'K': 8, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 2.968281734649455, 'loop': 0, 'loss': 'CE', 'lr': 0.002641971573884788, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.781859244194284e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.002839527026694611
weight_decay:  9.172195618942907e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1543737889733166
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1445534219965339
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.065814866218716
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.405243396759033
total time:  3.4560416869353503
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.46
  Final Train: 99.72 ± 0.48
   Final Test: 69.90 ± 0.26
[I 2023-06-11 23:29:04,653] Trial 132 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.012680801165968753, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.464064789251545, 'loop': 0, 'loss': 'CE', 'lr': 0.002839527026694611, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.172195618942907e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.2
lr:  0.003621848246223172
weight_decay:  2.6640859222620555e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.052925077965483
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.003542382037267
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.15842067101039
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.2540199756622314
total time:  3.309188730083406
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.35
[I 2023-06-11 23:29:08,344] Trial 133 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.0071408372818448146, 'K': 7, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.6737702683884974, 'loop': 0, 'loss': 'CE', 'lr': 0.003621848246223172, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.6640859222620555e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.003120534213365718
weight_decay:  1.4703473204866355e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0314324861392379
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.1268026388715953
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.059882977977395
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.2586288452148438
total time:  3.321554738096893
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.45
[I 2023-06-11 23:29:12,081] Trial 134 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.009562951772612368, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.338246909565933, 'loop': 0, 'loss': 'CE', 'lr': 0.003120534213365718, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4703473204866355e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.25
lr:  0.003251728242115117
weight_decay:  1.4931649926801262e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9471781780011952
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.986527593806386
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.9597196390386671
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.9336636066436768
total time:  2.992625006940216
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.00 ± 1.11
[I 2023-06-11 23:29:15,527] Trial 135 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.003647371761766464, 'K': 7, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 3.312867508528864, 'loop': 0, 'loss': 'CE', 'lr': 0.003251728242115117, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4931649926801262e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.30000000000000004
lr:  0.0036954963040622926
weight_decay:  1.8800778559756331e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9586972300894558
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.074204911943525
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.1024519230704755
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.177191972732544
total time:  3.2334303988609463
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.20
  Final Train: 99.72 ± 0.48
   Final Test: 69.70 ± 0.10
[I 2023-06-11 23:29:19,297] Trial 136 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.005642377951984775, 'K': 9, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.7757897862024885, 'loop': 0, 'loss': 'CE', 'lr': 0.0036954963040622926, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.8800778559756331e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.002967378548890684
weight_decay:  1.2473832035406712e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0520101129077375
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.0129010360687971
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0430509771686047
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.1504557132720947
total time:  3.2069820838514715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 1.01
[I 2023-06-11 23:29:22,906] Trial 137 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.015982115088451706, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.088908374610364, 'loop': 0, 'loss': 'CE', 'lr': 0.002967378548890684, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2473832035406712e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.003012725193611652
weight_decay:  1.2447312219852035e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.068437912967056
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0661301440559328
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.103192080045119
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.2802364826202393
total time:  3.3343008051160723
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.51
[I 2023-06-11 23:29:26,659] Trial 138 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.019216934386351407, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.016919371075641, 'loop': 0, 'loss': 'CE', 'lr': 0.003012725193611652, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2447312219852035e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.30000000000000004
lr:  0.0026452475014170423
weight_decay:  1.0199195591822606e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0126393740065396
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9113066419959068
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.937237607082352
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.9014532566070557
total time:  2.9474187789019197
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.37 ± 1.04
[I 2023-06-11 23:29:30,056] Trial 139 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.024640343930519296, 'K': 7, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 4.343040590402623, 'loop': 0, 'loss': 'CE', 'lr': 0.0026452475014170423, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0199195591822606e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.00463282119154112
weight_decay:  1.5506542316482092e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0671512039843947
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 02
None time:  1.0779096530750394
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.0593298689927906
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.90
run time now: 3.2523515224456787
total time:  3.3077411430422217
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.23
  Final Train: 99.17 ± 0.83
   Final Test: 70.37 ± 0.40
[I 2023-06-11 23:29:33,794] Trial 140 finished with value: 71.26666259765625 and parameters: {'Fwd': 0.013066770570095015, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.4757609717570777, 'loop': 0, 'loss': 'CE', 'lr': 0.00463282119154112, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5506542316482092e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.0031857107916689604
weight_decay:  2.0824246522281723e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0504522880073637
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0139303910546005
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.136864006984979
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.2514877319335938
total time:  3.2995110990013927
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.12
  Final Train: 99.72 ± 0.48
   Final Test: 69.63 ± 0.55
[I 2023-06-11 23:29:37,512] Trial 141 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.015293573076046124, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.0058378228950495, 'loop': 0, 'loss': 'CE', 'lr': 0.0031857107916689604, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.0824246522281723e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.0029109805251058716
weight_decay:  2.0818259458126994e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0121803518850356
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.1215762519277632
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1235966419335455
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.300021171569824
total time:  3.3476724829524755
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.91
[I 2023-06-11 23:29:41,314] Trial 142 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.010232174499958335, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.047726238854929, 'loop': 0, 'loss': 'CE', 'lr': 0.0029109805251058716, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.0818259458126994e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.0028880724188138102
weight_decay:  2.266598265164211e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.084715876961127
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.0669939517974854
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.153659856878221
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.345998525619507
total time:  3.393924256786704
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.61
[I 2023-06-11 23:29:45,142] Trial 143 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.014503368593785104, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.287249765643951, 'loop': 0, 'loss': 'CE', 'lr': 0.0028880724188138102, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.266598265164211e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.0027616805342311774
weight_decay:  2.205150367449761e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.067188112065196
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0205025568138808
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0492286030203104
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.176992416381836
total time:  3.227520567830652
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.59
[I 2023-06-11 23:29:48,787] Trial 144 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.021901935649491083, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.138323649582419, 'loop': 0, 'loss': 'CE', 'lr': 0.0027616805342311774, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.205150367449761e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.30000000000000004
lr:  0.002374841132465236
weight_decay:  2.242772068813548e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.31767559610307217
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.410109766991809
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.35676826094277203
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 70.90
run time now: 1.1313450336456299
total time:  1.1895854228641838
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 1.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.91
[I 2023-06-11 23:29:50,425] Trial 145 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.015616316541776079, 'K': 7, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 30, 'lambda1': 0.7000000000000001, 'lambda2': 3.0790683000688865, 'loop': 0, 'loss': 'CE', 'lr': 0.002374841132465236, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.242772068813548e-06, 'weightedloss': False}. Best is trial 101 with value: 71.79999542236328.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.00215354486816777
weight_decay:  2.97022728687483e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.072344862157479
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.992259917082265
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0728648868389428
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.1793248653411865
total time:  3.237862005829811
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.46
[I 2023-06-11 23:29:54,144] Trial 146 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.015280242112499284, 'K': 8, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.6121353692168916, 'loop': 0, 'loss': 'CE', 'lr': 0.00215354486816777, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.97022728687483e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.0020632089827433775
weight_decay:  3.2502958381020674e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9709733300842345
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0885998921003193
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.9664727719500661
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.0674173831939697
total time:  3.129810177953914
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.97
[I 2023-06-11 23:29:57,724] Trial 147 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.028861330006738857, 'K': 8, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 3.7421893429136266, 'loop': 0, 'loss': 'CE', 'lr': 0.0020632089827433775, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.2502958381020674e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.0021293037565000153
weight_decay:  2.8018939564088708e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.80% Test: 69.30%
Split: 01, Run: 01
None time:  1.834923068061471
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.00% Test: 69.60%
Split: 01, Run: 02
None time:  1.7154459999874234
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.20% Test: 69.60%
Split: 01, Run: 03
None time:  1.7294749508146197
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.60
run time now: 5.324219226837158
total time:  5.386264626868069
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.17
[I 2023-06-11 23:30:03,517] Trial 148 finished with value: 67.99999237060547 and parameters: {'Fwd': 0.01169421775836363, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.5294519864937137, 'loop': 0, 'loss': 'MSE', 'lr': 0.0021293037565000153, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8018939564088708e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.0025091918039692723
weight_decay:  1.970911007347368e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9444473839830607
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0214197800960392
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.9906358141452074
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 2.997556209564209
total time:  3.048499464057386
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.37 ± 0.55
[I 2023-06-11 23:30:07,016] Trial 149 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.019367883552244, 'K': 8, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 4.547999192398249, 'loop': 0, 'loss': 'CE', 'lr': 0.0025091918039692723, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.970911007347368e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.35000000000000003
lr:  0.00282876755740134
weight_decay:  1.3004291588321764e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0436206969898194
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.090764407068491
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0836394729558378
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.2590396404266357
total time:  3.3265371988527477
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.10
[I 2023-06-11 23:30:10,777] Trial 150 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.042814420397537856, 'K': 7, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 3.304252719770911, 'loop': 0, 'loss': 'CE', 'lr': 0.00282876755740134, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3004291588321764e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.0029922683464962147
weight_decay:  1.2504347321480166e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9909876929596066
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.0412736320868134
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.0847089630551636
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.158855438232422
total time:  3.2193069278728217
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 99.72 ± 0.48
   Final Test: 69.70 ± 0.75
[I 2023-06-11 23:30:14,413] Trial 151 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.015184302255119705, 'K': 9, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.119560131624738, 'loop': 0, 'loss': 'CE', 'lr': 0.0029922683464962147, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2504347321480166e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.003766950736110841
weight_decay:  1.6855920957868735e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0619264030829072
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0246133541222662
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.0042970750946552
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.1318721771240234
total time:  3.1921453829854727
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.12
  Final Train: 99.72 ± 0.48
   Final Test: 69.87 ± 0.29
[I 2023-06-11 23:30:18,057] Trial 152 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.014982727182949209, 'K': 8, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.5396202822771725, 'loop': 0, 'loss': 'CE', 'lr': 0.003766950736110841, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6855920957868735e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.0023643253352633323
weight_decay:  2.446781642956351e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0722237271256745
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.143140940926969
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1310797040350735
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 3.3899526596069336
total time:  3.4455867169890553
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.44
[I 2023-06-11 23:30:21,996] Trial 153 finished with value: 70.93334197998047 and parameters: {'Fwd': 0.007889532059513375, 'K': 9, 'alpha': 0.4, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.145478736512186, 'loop': 0, 'loss': 'CE', 'lr': 0.0023643253352633323, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.446781642956351e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.0028336917245098134
weight_decay:  1.464461018655495e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1444597290828824
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0704309889115393
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.091813012957573
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.3476996421813965
total time:  3.408148783026263
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.47
[I 2023-06-11 23:30:25,882] Trial 154 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.01077980818805587, 'K': 8, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.805666720403662, 'loop': 0, 'loss': 'CE', 'lr': 0.0028336917245098134, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.464461018655495e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.00350108814277948
weight_decay:  2.1855610175630184e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0584060449618846
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0315204290673137
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.097954324213788
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.60
run time now: 3.228951930999756
total time:  3.284650241024792
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.12
  Final Train: 99.72 ± 0.48
   Final Test: 69.97 ± 0.60
[I 2023-06-11 23:30:29,634] Trial 155 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.01995740688666291, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.064719597453668, 'loop': 0, 'loss': 'CE', 'lr': 0.00350108814277948, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.1855610175630184e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.002587511553209876
weight_decay:  1.2920329265010552e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.083034954033792
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.153319955104962
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1222898189444095
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.20
run time now: 3.3998541831970215
total time:  3.4670204669237137
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.49
[I 2023-06-11 23:30:33,648] Trial 156 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.025640823898613614, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 2.963961187718018, 'loop': 0, 'loss': 'CE', 'lr': 0.002587511553209876, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2920329265010552e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.05
lr:  0.004015796241517216
weight_decay:  1.811802423849988e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7761824869085103
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 99.17
   Final Test: 64.70
Split: 01, Run: 02
None time:  0.7095639759209007
None Run 02:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 99.17
   Final Test: 58.30
Split: 01, Run: 03
None time:  0.6808340270072222
None Run 03:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 98.33
   Final Test: 47.40
run time now: 2.2051937580108643
total time:  2.257230076007545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.80 ± 9.71
  Final Train: 98.89 ± 0.48
   Final Test: 56.80 ± 8.75
[I 2023-06-11 23:30:36,379] Trial 157 finished with value: 56.79999923706055 and parameters: {'Fwd': 0.012295246527466764, 'K': 7, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 3.4038944037062184, 'loop': 0, 'loss': 'CE', 'lr': 0.004015796241517216, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.811802423849988e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.0022139271470579896
weight_decay:  3.252226295899526e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0335683531593531
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.050915758823976
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.088451422052458
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.213646411895752
total time:  3.2695557849947363
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.72
[I 2023-06-11 23:30:40,104] Trial 158 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.008617712791569919, 'K': 8, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.207180110169804, 'loop': 0, 'loss': 'CE', 'lr': 0.0022139271470579896, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.252226295899526e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.0030964340417578323
weight_decay:  4.398775758813102e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3080981699749827
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.2858814711216837
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.2379050550516695
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.873227834701538
total time:  3.9301261021755636
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.47
[I 2023-06-11 23:30:44,489] Trial 159 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.016224914044730827, 'K': 9, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.647834260741795, 'loop': 2, 'loss': 'CE', 'lr': 0.0030964340417578323, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.398775758813102e-05, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.0015747201655595766
weight_decay:  1.2483946912650884e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4388174710329622
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.4567539489362389
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03
None time:  0.4137598080560565
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 1.350846529006958
total time:  1.3993822569027543
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 68.87 ± 1.79
[I 2023-06-11 23:30:46,429] Trial 160 finished with value: 69.9333267211914 and parameters: {'Fwd': 0.0070251663691641405, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 0.9500000000000001, 'lambda2': 2.510646013548409, 'loop': 0, 'loss': 'CE', 'lr': 0.0015747201655595766, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2483946912650884e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.0030543954556622515
weight_decay:  1.0084017316557759e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.000806377036497
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.028799792053178
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.1397369240876287
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.2108287811279297
total time:  3.2664135270752013
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 99.72 ± 0.48
   Final Test: 69.80 ± 0.70
[I 2023-06-11 23:30:50,146] Trial 161 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.014376576564175021, 'K': 9, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.8628539712803542, 'loop': 0, 'loss': 'CE', 'lr': 0.0030543954556622515, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0084017316557759e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.0032185874043456123
weight_decay:  1.1577202748650186e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0259346140082926
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0807261769659817
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.0453691210132092
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.1944494247436523
total time:  3.246749831130728
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 99.72 ± 0.48
   Final Test: 69.73 ± 0.59
[I 2023-06-11 23:30:53,825] Trial 162 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.016272445010874718, 'K': 9, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.9823887859790683, 'loop': 0, 'loss': 'CE', 'lr': 0.0032185874043456123, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.1577202748650186e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.30000000000000004
lr:  0.003384157559786909
weight_decay:  9.447544422675577e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0164286729414016
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0650813200045377
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 97.50%, Valid: 71.40% Test: 70.60%
Split: 01, Run: 03
None time:  1.9166971880476922
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
run time now: 4.039908170700073
total time:  4.087374974042177
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.23
  Final Train: 99.72 ± 0.48
   Final Test: 69.60 ± 0.44
[I 2023-06-11 23:30:58,389] Trial 163 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.03330364630764672, 'K': 9, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.0680503155899026, 'loop': 0, 'loss': 'CE', 'lr': 0.003384157559786909, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.447544422675577e-05, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.002809353129622483
weight_decay:  1.716980111761874e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0001050571445376
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0348435919731855
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0895179759245366
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.1661336421966553
total time:  3.226861735805869
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.49
[I 2023-06-11 23:31:02,142] Trial 164 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.01014877980290503, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.3896836336909186, 'loop': 0, 'loss': 'CE', 'lr': 0.002809353129622483, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.716980111761874e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.002486056301390585
weight_decay:  2.54628859167389e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0830230589490384
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.1359978090040386
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0475356029346585
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.3075637817382812
total time:  3.3631035429425538
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.51
[I 2023-06-11 23:31:05,980] Trial 165 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.02212808537304722, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 2.6167037216171396, 'loop': 0, 'loss': 'CE', 'lr': 0.002486056301390585, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.54628859167389e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.002414673579553877
weight_decay:  2.6438028169983855e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0237670198548585
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.9463127320632339
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.9023258620873094
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.9110677242279053
total time:  2.967631316045299
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 0.95
[I 2023-06-11 23:31:09,418] Trial 166 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.02535438225216575, 'K': 7, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 2.625097662563545, 'loop': 0, 'loss': 'CE', 'lr': 0.002414673579553877, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.6438028169983855e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.00194316914145447
weight_decay:  2.1711072416136603e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0758780199103057
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.101537172915414
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0355611559934914
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.256312131881714
total time:  3.323754983022809
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.67
[I 2023-06-11 23:31:13,300] Trial 167 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.01944137693059134, 'K': 9, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 2.7213344775163377, 'loop': 0, 'loss': 'CE', 'lr': 0.00194316914145447, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.1711072416136603e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.002518565715169744
weight_decay:  6.076458671005576e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9896068850066513
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.0973576849792153
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1039512199349701
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.2320311069488525
total time:  3.2845840649679303
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.64
[I 2023-06-11 23:31:17,044] Trial 168 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.01300628162448507, 'K': 8, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.979301160727599, 'loop': 0, 'loss': 'CE', 'lr': 0.002518565715169744, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.076458671005576e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0027072388939903087
weight_decay:  5.872204860908292e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9925839579664171
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.021283637965098
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.951094102114439
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.0059337615966797
total time:  3.0522225580643862
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.42
  Final Train: 99.72 ± 0.48
   Final Test: 69.07 ± 0.95
[I 2023-06-11 23:31:20,550] Trial 169 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.012692765375455514, 'K': 8, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 3.027607594187832, 'loop': 0, 'loss': 'CE', 'lr': 0.0027072388939903087, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.872204860908292e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.0035724402331388967
weight_decay:  0.0010231652466994666
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.90%
Split: 01, Run: 01
None time:  1.3415225390344858
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 70.00%
Split: 01, Run: 02
None time:  1.376815577968955
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 69.40%
Split: 01, Run: 03
None time:  1.3064767469186336
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 4.070080757141113
total time:  4.126158786006272
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.32
[I 2023-06-11 23:31:25,250] Trial 170 finished with value: 69.93334197998047 and parameters: {'Fwd': 0.016488952542180735, 'K': 9, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 1.0, 'lambda2': 3.627000072305777, 'loop': 0, 'loss': 'MSE', 'lr': 0.0035724402331388967, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0010231652466994666, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.002541748336235583
weight_decay:  3.0958455977967846e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0707102019805461
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.9456272390671074
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1208567300345749
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.1890618801116943
total time:  3.244184438837692
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 99.72 ± 0.48
   Final Test: 69.83 ± 0.67
[I 2023-06-11 23:31:28,923] Trial 171 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.022414092042107765, 'K': 8, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.2784874628289895, 'loop': 0, 'loss': 'CE', 'lr': 0.002541748336235583, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.0958455977967846e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.002212410377438246
weight_decay:  6.6212994854953145e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0273502359632403
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.0436863040085882
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0212345740292221
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.1321330070495605
total time:  3.1947612268850207
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.69
[I 2023-06-11 23:31:32,567] Trial 172 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.012048142321519139, 'K': 8, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.8958429445895195, 'loop': 0, 'loss': 'CE', 'lr': 0.002212410377438246, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.6212994854953145e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.0032839052120195596
weight_decay:  4.587211432633404e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0705901479814202
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.9466350341681391
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0508144767954946
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.110275983810425
total time:  3.169663993176073
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.35
[I 2023-06-11 23:31:36,289] Trial 173 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.017454881596339455, 'K': 8, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 5.052876544433137, 'loop': 0, 'loss': 'CE', 'lr': 0.0032839052120195596, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.587211432633404e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.0029733250045401666
weight_decay:  1.6401685273807903e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1092660499271005
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.9677236538846046
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0012323420960456
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.1232244968414307
total time:  3.173890566918999
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.52
[I 2023-06-11 23:31:39,946] Trial 174 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.03001860865516318, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.163185962263947, 'loop': 0, 'loss': 'CE', 'lr': 0.0029733250045401666, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6401685273807903e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.0027024471772974343
weight_decay:  2.551894771417788e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0276009349618107
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0660067780409008
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0487364172004163
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 97.50
   Final Test: 70.90
run time now: 3.188887357711792
total time:  3.24520320398733
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.42
  Final Train: 99.17 ± 1.44
   Final Test: 70.07 ± 0.80
[I 2023-06-11 23:31:43,621] Trial 175 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0065762368265787925, 'K': 8, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 2.782960132357182, 'loop': 0, 'loss': 'CE', 'lr': 0.0027024471772974343, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.551894771417788e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.1
lr:  0.0024330109785023492
weight_decay:  2.089688828550243e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9937932079192251
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.036019089864567
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0161553889047354
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.0859241485595703
total time:  3.144197568995878
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.36
[I 2023-06-11 23:31:47,198] Trial 176 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.010510088013727065, 'K': 7, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.4618935819196297, 'loop': 0, 'loss': 'CE', 'lr': 0.0024330109785023492, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.089688828550243e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.0037983113272353703
weight_decay:  1.5539818525592502e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0664645968936384
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.080021157860756
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.08150061708875
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.40
run time now: 3.2761905193328857
total time:  3.337871190859005
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.12
  Final Train: 99.44 ± 0.48
   Final Test: 70.00 ± 0.40
[I 2023-06-11 23:31:50,946] Trial 177 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.01392829561364131, 'K': 9, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.2098891029086523, 'loop': 0, 'loss': 'CE', 'lr': 0.0037983113272353703, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5539818525592502e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0016844938755317547
weight_decay:  3.3163277418741537e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0697872380260378
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.9453411039430648
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 99.17
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.8975068600848317
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.959901809692383
total time:  3.0143708910327405
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 1.04
  Final Train: 99.72 ± 0.48
   Final Test: 69.63 ± 0.85
[I 2023-06-11 23:31:54,389] Trial 178 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.00852538047716825, 'K': 8, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 2.606304116191394, 'loop': 0, 'loss': 'CE', 'lr': 0.0016844938755317547, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.3163277418741537e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.001337349687677668
weight_decay:  1.2634613437191103e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0377010439988226
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 02
None time:  1.016178318997845
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.061450146138668
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.1568613052368164
total time:  3.216365342028439
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 1.00
[I 2023-06-11 23:31:58,078] Trial 179 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.04828709295898107, 'K': 8, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.981941458658585, 'loop': 0, 'loss': 'CE', 'lr': 0.001337349687677668, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2634613437191103e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.35000000000000003
lr:  0.001839294592515296
weight_decay:  4.6666850029683435e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0714818860869855
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9835339169949293
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1304693550337106
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 70.30
run time now: 3.2253577709198
total time:  3.281648064032197
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 99.72 ± 0.48
   Final Test: 70.00 ± 0.30
[I 2023-06-11 23:32:01,868] Trial 180 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.022700480386653572, 'K': 7, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.489812696473786, 'loop': 0, 'loss': 'CE', 'lr': 0.001839294592515296, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.6666850029683435e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.0031768292034594983
weight_decay:  2.832210894129754e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0664130640216172
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0280419560149312
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0549176139757037
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.197540760040283
total time:  3.261726405005902
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.56
[I 2023-06-11 23:32:05,625] Trial 181 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.009207696013036976, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.2869995877346154, 'loop': 0, 'loss': 'CE', 'lr': 0.0031768292034594983, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.832210894129754e-05, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.0031952833507484773
weight_decay:  7.267321265745574e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.022146720904857
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.9699310490395874
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1067442768253386
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.140251636505127
total time:  3.1929925200529397
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.45
[I 2023-06-11 23:32:09,229] Trial 182 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.011247762253742587, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.283336332081794, 'loop': 0, 'loss': 'CE', 'lr': 0.0031952833507484773, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.267321265745574e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.002867872401522305
weight_decay:  1.9754569143085747e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0658489991910756
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.1243375879712403
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.066087184008211
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.00
run time now: 3.2991819381713867
total time:  3.3448868659324944
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.81
[I 2023-06-11 23:32:13,144] Trial 183 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.01606450940277375, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.25, 'lambda2': 3.065593682814801, 'loop': 0, 'loss': 'CE', 'lr': 0.002867872401522305, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.9754569143085747e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.0034061304232534968
weight_decay:  2.635613793580518e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.069555148947984
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0298407019581646
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.0533339160028845
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.193791151046753
total time:  3.2508257960435003
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.26
[I 2023-06-11 23:32:16,879] Trial 184 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.007124260371659006, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.8873015914760396, 'loop': 0, 'loss': 'CE', 'lr': 0.0034061304232534968, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.635613793580518e-05, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.0026389187617057177
weight_decay:  1.227151151278793e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0349141610786319
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.063734307186678
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.1166965439915657
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.256660223007202
total time:  3.302771506132558
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.75
[I 2023-06-11 23:32:20,691] Trial 185 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.004266479592520025, 'K': 9, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 4.768346547221186, 'loop': 0, 'loss': 'CE', 'lr': 0.0026389187617057177, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.227151151278793e-05, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.002963516187700166
weight_decay:  2.809551004551836e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7240450310055166
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.40
Split: 01, Run: 02
None time:  0.73024758300744
None Run 02:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 57.30
Split: 01, Run: 03
None time:  0.8174577159807086
None Run 03:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 97.50
   Final Test: 60.10
run time now: 2.3123159408569336
total time:  2.3762487310450524
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.80 ± 7.00
  Final Train: 99.17 ± 1.44
   Final Test: 54.60 ± 7.24
[I 2023-06-11 23:32:23,475] Trial 186 finished with value: 54.79999923706055 and parameters: {'Fwd': 0.012705041984424664, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.9761332180223645, 'loop': 0, 'loss': 'CE', 'lr': 0.002963516187700166, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.809551004551836e-06, 'weightedloss': True}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.0022235210620715753
weight_decay:  8.842616717183928e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9910621969029307
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.9780668700113893
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.9695604259613901
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.9800822734832764
total time:  3.039211052004248
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.23 ± 1.01
[I 2023-06-11 23:32:26,930] Trial 187 finished with value: 71.13333129882812 and parameters: {'Fwd': 0.00850448784924296, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 3.5286032050787086, 'loop': 0, 'loss': 'CE', 'lr': 0.0022235210620715753, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.842616717183928e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.004194192721802844
weight_decay:  1.5990016981579974e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0647902598138899
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0453466300386935
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0761483719106764
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 70.40
run time now: 3.230163812637329
total time:  3.2877887380309403
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.20
  Final Train: 98.89 ± 0.48
   Final Test: 70.13 ± 0.25
[I 2023-06-11 23:32:30,677] Trial 188 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.00015320333375839782, 'K': 9, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 2.871661785776714, 'loop': 0, 'loss': 'CE', 'lr': 0.004194192721802844, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5990016981579974e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.1
lr:  0.0035677088614102055
weight_decay:  1.001624103681445e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.998571481090039
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.9270367741119117
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  0.9874533999245614
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 2.9547970294952393
total time:  3.0004253471270204
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.10 ± 0.92
[I 2023-06-11 23:32:34,142] Trial 189 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.034945722008192126, 'K': 8, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 3.246053401649912, 'loop': 0, 'loss': 'CE', 'lr': 0.0035677088614102055, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.001624103681445e-06, 'weightedloss': True}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.4
lr:  0.0031774099473014924
weight_decay:  3.843056738241274e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0345266521908343
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.1540077289100736
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0081380039919168
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.2362446784973145
total time:  3.2912037931382656
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.20
[I 2023-06-11 23:32:38,014] Trial 190 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.018939850542806058, 'K': 7, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 2.7401255424722253, 'loop': 0, 'loss': 'CE', 'lr': 0.0031774099473014924, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.843056738241274e-05, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.002957145833721536
weight_decay:  1.2501105567201892e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9681431970093399
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.046825640834868
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.096027655992657
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.1570053100585938
total time:  3.2167720519937575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 1.01
[I 2023-06-11 23:32:41,646] Trial 191 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.008675385573156768, 'K': 8, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.3916330965342807, 'loop': 0, 'loss': 'CE', 'lr': 0.002957145833721536, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2501105567201892e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.002827108001974896
weight_decay:  1.2931734109226235e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9843464659061283
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0967455469071865
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.183889291016385
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.3064751625061035
total time:  3.356659024953842
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.46
[I 2023-06-11 23:32:45,526] Trial 192 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.01001890554378883, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.42094249217268, 'loop': 0, 'loss': 'CE', 'lr': 0.002827108001974896, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2931734109226235e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.002512487965480981
weight_decay:  1.6669285808131572e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0244432971812785
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0847945271525532
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0180375829804689
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.177884817123413
total time:  3.2335220240056515
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.64
[I 2023-06-11 23:32:49,220] Trial 193 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.013941678710344052, 'K': 8, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.050687889793702, 'loop': 0, 'loss': 'CE', 'lr': 0.002512487965480981, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6669285808131572e-05, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.0032524308866675213
weight_decay:  1.991650916606543e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0430395419243723
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0575141401495785
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.1107948189601302
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.255950689315796
total time:  3.3123759811278433
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.30
[I 2023-06-11 23:32:52,977] Trial 194 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.006478509464198805, 'K': 8, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.437373378280959, 'loop': 0, 'loss': 'CE', 'lr': 0.0032524308866675213, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.991650916606543e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.0027320223015852517
weight_decay:  1.505364425570898e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0376181399915367
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0866138860583305
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0668099001049995
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.2598748207092285
total time:  3.314085539896041
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.47
[I 2023-06-11 23:32:56,758] Trial 195 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.009689672217834887, 'K': 8, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.7835979824100483, 'loop': 0, 'loss': 'CE', 'lr': 0.0027320223015852517, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.505364425570898e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.002376458276764837
weight_decay:  2.4402048355655675e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.627136531053111
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.6333046229556203
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  0.7064584749750793
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.0107409954071045
total time:  2.06682018795982
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.10
[I 2023-06-11 23:32:59,338] Trial 196 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.0051737109283488, 'K': 8, 'alpha': 0.2, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 3.258889226585804, 'loop': 0, 'loss': 'CE', 'lr': 0.002376458276764837, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.4402048355655675e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.002083303658187548
weight_decay:  3.9436117632177055e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0108677248936146
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0741200330667198
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0390453799627721
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.1657145023345947
total time:  3.2139717279933393
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.46
[I 2023-06-11 23:33:03,159] Trial 197 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.015186704047679914, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.135460879992241, 'loop': 0, 'loss': 'CE', 'lr': 0.002083303658187548, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.9436117632177055e-06, 'weightedloss': False}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.0020356624859294782
weight_decay:  5.398117988642621e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1089930250309408
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0707155889831483
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0520522659644485
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.275028944015503
total time:  3.332773922011256
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.17
[I 2023-06-11 23:33:06,986] Trial 198 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.015569175111510486, 'K': 9, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.175456096048813, 'loop': 0, 'loss': 'CE', 'lr': 0.0020356624859294782, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.398117988642621e-06, 'weightedloss': True}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.0019283904695221062
weight_decay:  5.123798406778958e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0373707129620016
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0268983629066497
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0192811649758369
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.1230859756469727
total time:  3.1814931409899145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.25
[I 2023-06-11 23:33:10,615] Trial 199 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.007812415687886636, 'K': 7, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.341241228614998, 'loop': 0, 'loss': 'CE', 'lr': 0.0019283904695221062, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.123798406778958e-06, 'weightedloss': True}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.002061965000405183
weight_decay:  3.674872633784233e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.087195924948901
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.067683655070141
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0500429209787399
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.2467739582061768
total time:  3.304509675130248
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.17
[I 2023-06-11 23:33:14,368] Trial 200 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.011537121888285883, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.138076408770105, 'loop': 0, 'loss': 'CE', 'lr': 0.002061965000405183, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.674872633784233e-06, 'weightedloss': True}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.002068733515132956
weight_decay:  3.967945045119802e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0154270799830556
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.030185349052772
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1015143049880862
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.187506914138794
total time:  3.235859242035076
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.46
[I 2023-06-11 23:33:18,149] Trial 201 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.011817098474083925, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.228328452665436, 'loop': 0, 'loss': 'CE', 'lr': 0.002068733515132956, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.967945045119802e-06, 'weightedloss': True}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0021565972416674574
weight_decay:  5.724581286003647e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0256335658486933
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.08361985697411
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.044178965035826
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.195282220840454
total time:  3.2602830878458917
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.46
[I 2023-06-11 23:33:21,905] Trial 202 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.010908038919856559, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.024423156438563, 'loop': 0, 'loss': 'CE', 'lr': 0.0021565972416674574, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.724581286003647e-06, 'weightedloss': True}. Best is trial 146 with value: 71.86666870117188.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.002095568068393024
weight_decay:  3.998632452987121e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1118394029326737
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0488693921361119
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0536376868840307
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.2601773738861084
total time:  3.308930719969794
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.36
[I 2023-06-11 23:33:25,718] Trial 203 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.009492722637669027, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.143064932481709, 'loop': 0, 'loss': 'CE', 'lr': 0.002095568068393024, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.998632452987121e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0020875483491736607
weight_decay:  3.7996917530901136e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0146478570532054
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.06546820118092
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0139998320955783
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.13616681098938
total time:  3.1940350430086255
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.47
[I 2023-06-11 23:33:29,364] Trial 204 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.012350746853582907, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.1623880529909085, 'loop': 0, 'loss': 'CE', 'lr': 0.0020875483491736607, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.7996917530901136e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0020288535978960193
weight_decay:  6.2736540063589226e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9800420578103513
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9959389939904213
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0201421780511737
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.0377037525177
total time:  3.094924160046503
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.21
[I 2023-06-11 23:33:32,956] Trial 205 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.012332989570340574, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.176602840814957, 'loop': 0, 'loss': 'CE', 'lr': 0.0020288535978960193, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.2736540063589226e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.002035646697607373
weight_decay:  9.174607882440501e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.126774531090632
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1965744190383703
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.1106748369056731
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.474884033203125
total time:  3.530081775970757
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.47
[I 2023-06-11 23:33:36,997] Trial 206 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.011435867534094094, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.1488456225337815, 'loop': 1, 'loss': 'CE', 'lr': 0.002035646697607373, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.174607882440501e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0020799238072688477
weight_decay:  5.968661237275893e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9909868671093136
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0485196739900857
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0020738248713315
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.083002805709839
total time:  3.1333724439609796
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.46
[I 2023-06-11 23:33:40,624] Trial 207 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.014902669150927535, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.253286145690714, 'loop': 0, 'loss': 'CE', 'lr': 0.0020799238072688477, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.968661237275893e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0017384344534649558
weight_decay:  6.042740747081041e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 70.10%
Split: 01, Run: 01
None time:  1.7316626440733671
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.08150913589634
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 69.40%
Split: 01, Run: 03
None time:  1.7569824510719627
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 4.611348390579224
total time:  4.670498494058847
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.36
[I 2023-06-11 23:33:45,759] Trial 208 finished with value: 68.79999542236328 and parameters: {'Fwd': 0.014224571048704563, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.272951984331451, 'loop': 0, 'loss': 'MSE', 'lr': 0.0017384344534649558, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.042740747081041e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0020501843149605195
weight_decay:  7.1928233313012625e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9995394570287317
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0927553591318429
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.9682758380658925
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.1011929512023926
total time:  3.1544272331520915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.17
[I 2023-06-11 23:33:49,367] Trial 209 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.01989591327216669, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.497137387599551, 'loop': 0, 'loss': 'CE', 'lr': 0.0020501843149605195, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.1928233313012625e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.002031181010776228
weight_decay:  6.897959037543495e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9914645701646805
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.8876304260920733
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.9301397718954831
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 2.8606364727020264
total time:  2.934431695844978
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.90
[I 2023-06-11 23:33:52,898] Trial 210 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.01986604841644933, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 4.52648256770217, 'loop': 0, 'loss': 'CE', 'lr': 0.002031181010776228, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.897959037543495e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0018597780178172746
weight_decay:  3.946019977800224e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0966141228564084
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0411324079614133
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0407870919443667
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.229281425476074
total time:  3.2869245239999145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.06
[I 2023-06-11 23:33:56,754] Trial 211 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.013508213330237094, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.1052735292918, 'loop': 0, 'loss': 'CE', 'lr': 0.0018597780178172746, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.946019977800224e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.002131029474903065
weight_decay:  6.00312378143877e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0522613120265305
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.009964644908905
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.1329202209599316
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.236351728439331
total time:  3.2964626180473715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.38
[I 2023-06-11 23:34:00,526] Trial 212 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.01753344993379811, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.419871815895995, 'loop': 0, 'loss': 'CE', 'lr': 0.002131029474903065, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.00312378143877e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.002153001828265152
weight_decay:  7.759567036489282e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0969670901540667
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.1377558570820838
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1124288069549948
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.393817663192749
total time:  3.4397785859182477
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.42
[I 2023-06-11 23:34:04,433] Trial 213 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.018492881144830546, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.423116139470013, 'loop': 0, 'loss': 'CE', 'lr': 0.002153001828265152, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.759567036489282e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.002065888081386806
weight_decay:  7.92043305996891e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0253563560545444
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.1320158699527383
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.031587467994541
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.23028302192688
total time:  3.286934570176527
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.42
[I 2023-06-11 23:34:08,187] Trial 214 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.017571114837827723, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.423606095253722, 'loop': 0, 'loss': 'CE', 'lr': 0.002065888081386806, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.92043305996891e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.002132593786761777
weight_decay:  7.767758451318654e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0431552820373327
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0286600748077035
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0841190530918539
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.197927236557007
total time:  3.2664777389727533
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.25
[I 2023-06-11 23:34:11,903] Trial 215 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.024887469382414037, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.40337696604908, 'loop': 0, 'loss': 'CE', 'lr': 0.002132593786761777, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.767758451318654e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.002093304191282175
weight_decay:  9.78056839175554e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0616204380057752
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0255082650110126
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.070111169014126
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.197627305984497
total time:  3.242262294050306
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.42
[I 2023-06-11 23:34:15,611] Trial 216 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.022034772984311255, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.40366319890929, 'loop': 0, 'loss': 'CE', 'lr': 0.002093304191282175, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.78056839175554e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0021472179793292794
weight_decay:  8.111144626880768e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0460368460044265
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9925603410229087
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0878187951166183
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.167316198348999
total time:  3.2174036600627005
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.17
[I 2023-06-11 23:34:19,258] Trial 217 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.027606076632545357, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.439431566208498, 'loop': 0, 'loss': 'CE', 'lr': 0.0021472179793292794, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.111144626880768e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0019365450470663328
weight_decay:  1.0917820391798448e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0150274669285864
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0906175929121673
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.2627518919762224
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.4109463691711426
total time:  3.472537104971707
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.26
[I 2023-06-11 23:34:23,163] Trial 218 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.027896229372928627, 'K': 8, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.617845486312129, 'loop': 0, 'loss': 'CE', 'lr': 0.0019365450470663328, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0917820391798448e-05, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0017751772665489192
weight_decay:  8.619189970147233e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0420964208897203
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.021805264055729
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.9941811240278184
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.099616050720215
total time:  3.160962395137176
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.12
[I 2023-06-11 23:34:26,780] Trial 219 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.0372326691061642, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.288001401252315, 'loop': 0, 'loss': 'CE', 'lr': 0.0017751772665489192, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.619189970147233e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0020878034418999394
weight_decay:  5.988798259276569e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0495812899898738
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9760140981525183
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0635714989621192
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.1298811435699463
total time:  3.1849759379401803
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.25
[I 2023-06-11 23:34:30,423] Trial 220 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.01996618019422925, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.491844874291817, 'loop': 0, 'loss': 'CE', 'lr': 0.0020878034418999394, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.988798259276569e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0021018746551376543
weight_decay:  6.570094799718146e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0256138530094177
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0299983590375632
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0445370830129832
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.1389153003692627
total time:  3.2043259260244668
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.21
[I 2023-06-11 23:34:34,154] Trial 221 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.02078657966466978, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.5216906514981705, 'loop': 0, 'loss': 'CE', 'lr': 0.0021018746551376543, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.570094799718146e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0020974182781930647
weight_decay:  5.93118309484662e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0714012600947171
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.034609833965078
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9681958071887493
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.1141390800476074
total time:  3.167250126833096
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.17
[I 2023-06-11 23:34:37,777] Trial 222 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.022543522171815926, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.719714573926844, 'loop': 0, 'loss': 'CE', 'lr': 0.0020974182781930647, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.93118309484662e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0022168008635242652
weight_decay:  5.890852329744053e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1064760121516883
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9393258369527757
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0686800538096577
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.1551034450531006
total time:  3.2077171788550913
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.15
[I 2023-06-11 23:34:41,395] Trial 223 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.018831139835920288, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.185566633712215, 'loop': 0, 'loss': 'CE', 'lr': 0.0022168008635242652, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.890852329744053e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.001878125834359642
weight_decay:  1.023621905420774e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0270890260580927
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.044366535032168
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0784094519913197
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.1897590160369873
total time:  3.2426748699508607
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.17
[I 2023-06-11 23:34:45,102] Trial 224 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.020971478950010333, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.093603471148443, 'loop': 0, 'loss': 'CE', 'lr': 0.001878125834359642, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.023621905420774e-05, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.002220626972317283
weight_decay:  6.950980278185341e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0330919830594212
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1102643988560885
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.9751450100447983
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.1592602729797363
total time:  3.2106672779191285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.17
[I 2023-06-11 23:34:48,803] Trial 225 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.02684716903007308, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.607241242933532, 'loop': 0, 'loss': 'CE', 'lr': 0.002220626972317283, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.950980278185341e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0016260716652051115
weight_decay:  5.330524743264679e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0257828368339688
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.045373264933005
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.9918257959652692
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.1088244915008545
total time:  3.1678463839925826
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.32
[I 2023-06-11 23:34:52,489] Trial 226 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.027881710713231894, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.198536745554444, 'loop': 0, 'loss': 'CE', 'lr': 0.0016260716652051115, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.330524743264679e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.002262171395686408
weight_decay:  1.196953250385687e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7248539689462632
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.20
Split: 01, Run: 02
None time:  0.7329262150451541
None Run 02:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.20
Split: 01, Run: 03
None time:  0.8166563929989934
None Run 03:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 97.50
   Final Test: 53.00
run time now: 2.3198933601379395
total time:  2.3709013119805604
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.47 ± 4.62
  Final Train: 99.17 ± 1.44
   Final Test: 48.47 ± 3.93
[I 2023-06-11 23:34:55,311] Trial 227 finished with value: 49.4666633605957 and parameters: {'Fwd': 0.02979168425064446, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.008603244474148, 'loop': 0, 'loss': 'CE', 'lr': 0.002262171395686408, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.196953250385687e-05, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.002241754207054477
weight_decay:  4.661768138158827e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9896039911545813
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9854562550317496
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.9487031889148057
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 2.9638471603393555
total time:  3.0208012277726084
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.67
[I 2023-06-11 23:34:58,751] Trial 228 finished with value: 71.0 and parameters: {'Fwd': 0.04726666365856319, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 4.690464666948955, 'loop': 0, 'loss': 'CE', 'lr': 0.002241754207054477, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.661768138158827e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0018634298565353632
weight_decay:  6.878640872949921e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0476080479566008
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.032882175175473
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.0978987789712846
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.219468593597412
total time:  3.281140257138759
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.32
[I 2023-06-11 23:35:02,491] Trial 229 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.024609516596566867, 'K': 7, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.906958303770394, 'loop': 0, 'loss': 'CE', 'lr': 0.0018634298565353632, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.878640872949921e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0017180542516646534
weight_decay:  5.161237200912617e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.46552084712311625
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.5239202338270843
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.5470232670195401
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 1.5771362781524658
total time:  1.6283505780156702
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.45
[I 2023-06-11 23:35:04,641] Trial 230 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.037424386094422765, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 4.208554395574354, 'loop': 0, 'loss': 'CE', 'lr': 0.0017180542516646534, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.161237200912617e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0020028889520655904
weight_decay:  7.216058211999643e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0690886019729078
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0088611540850252
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0354084630962461
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.153547763824463
total time:  3.2188612199388444
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.20
[I 2023-06-11 23:35:08,344] Trial 231 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.01816188863127357, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.56788734349651, 'loop': 0, 'loss': 'CE', 'lr': 0.0020028889520655904, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.216058211999643e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0022099622997048206
weight_decay:  8.916490826956755e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1692183108534664
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1299093829002231
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.0711963130161166
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.80
run time now: 3.410435914993286
total time:  3.4586579180322587
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.80
[I 2023-06-11 23:35:12,335] Trial 232 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.018510920735588104, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.51297693622096, 'loop': 1, 'loss': 'CE', 'lr': 0.0022099622997048206, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.916490826956755e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0020117118494073737
weight_decay:  6.575664587294491e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1075497299898416
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.081061257980764
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0558003559708595
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.283853054046631
total time:  3.341400978155434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.35
[I 2023-06-11 23:35:16,108] Trial 233 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.023030108885633328, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.01140410510455, 'loop': 0, 'loss': 'CE', 'lr': 0.0020117118494073737, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.575664587294491e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0021693071157444835
weight_decay:  4.04473713052933e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9619493950158358
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0145711689256132
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0776308819185942
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.0935096740722656
total time:  3.142926601925865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.21
[I 2023-06-11 23:35:19,719] Trial 234 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.01246440862597888, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.299519972287819, 'loop': 0, 'loss': 'CE', 'lr': 0.0021693071157444835, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.04473713052933e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.55
lr:  0.0022977198041706022
weight_decay:  1.5047614949102865e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9890942091587931
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.1064698779955506
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.114569972967729
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.248772621154785
total time:  3.2995374309830368
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.45
[I 2023-06-11 23:35:23,503] Trial 235 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.030101928161149333, 'K': 6, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.427303789771776, 'loop': 0, 'loss': 'CE', 'lr': 0.0022977198041706022, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5047614949102865e-05, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0018282199875603099
weight_decay:  5.47039496861718e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0412865111138672
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1119752500671893
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.1088930608239025
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.301438093185425
total time:  3.3469615490175784
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.32
[I 2023-06-11 23:35:27,290] Trial 236 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.019475216049133565, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.786347889954672, 'loop': 0, 'loss': 'CE', 'lr': 0.0018282199875603099, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.47039496861718e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.001612401324401689
weight_decay:  1.0735744707391578e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.008587112184614
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9189230678603053
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0215219659730792
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 2.9936115741729736
total time:  3.0418319499585778
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.26
[I 2023-06-11 23:35:30,810] Trial 237 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.011915900857035023, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.0405952132474, 'loop': 0, 'loss': 'CE', 'lr': 0.001612401324401689, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0735744707391578e-05, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0015306416991342291
weight_decay:  8.935282419779803e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0692390468902886
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0167805200908333
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0278445901349187
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.153639793395996
total time:  3.211079073138535
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.12
[I 2023-06-11 23:35:34,445] Trial 238 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.011600994266577585, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.9726549013683834, 'loop': 0, 'loss': 'CE', 'lr': 0.0015306416991342291, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.935282419779803e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0017053502382959771
weight_decay:  1.0970818877964747e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9929233188740909
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.976905751042068
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.1595172891393304
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.1693527698516846
total time:  3.219045156845823
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.51
[I 2023-06-11 23:35:38,109] Trial 239 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.013489897673824778, 'K': 7, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.17774739388707, 'loop': 0, 'loss': 'CE', 'lr': 0.0017053502382959771, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0970818877964747e-05, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0019514787886217753
weight_decay:  1.952195304757583e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0066466659773141
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0235538790002465
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0797930059488863
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.1529319286346436
total time:  3.2175725309643894
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.23
[I 2023-06-11 23:35:41,877] Trial 240 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.010200312560862113, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.866343535100776, 'loop': 0, 'loss': 'CE', 'lr': 0.0019514787886217753, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.952195304757583e-05, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.002350103143576921
weight_decay:  7.76579914913644e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0619478889275342
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0307503691874444
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1212605449836701
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.262099027633667
total time:  3.3132420249748975
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.15
[I 2023-06-11 23:35:45,660] Trial 241 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.01641701118428761, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.569884045574568, 'loop': 0, 'loss': 'CE', 'lr': 0.002350103143576921, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.76579914913644e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0020853325576022682
weight_decay:  6.137791001897565e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0750918230041862
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9881322411820292
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9845243061427027
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.0883467197418213
total time:  3.1423219298012555
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.31
[I 2023-06-11 23:35:49,275] Trial 242 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.023122265673840982, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.297240943763632, 'loop': 0, 'loss': 'CE', 'lr': 0.0020853325576022682, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.137791001897565e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0022868530840217567
weight_decay:  5.1765668967154785e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9949917308986187
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0170979311224073
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0752483899705112
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.129338026046753
total time:  3.187289868015796
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.31
[I 2023-06-11 23:35:52,951] Trial 243 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.014480287045301597, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.060916270056328, 'loop': 0, 'loss': 'CE', 'lr': 0.0022868530840217567, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.1765668967154785e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.002389604625289743
weight_decay:  4.223120374074696e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9451603649649769
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.987700778990984
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0677762448322028
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.04014253616333
total time:  3.0866568910423666
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.42
[I 2023-06-11 23:35:56,482] Trial 244 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.011774407018220051, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.015049292158123, 'loop': 0, 'loss': 'CE', 'lr': 0.002389604625289743, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.223120374074696e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.002348783260861711
weight_decay:  4.147258868281483e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0052620919886976
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0984036279842257
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0849807900376618
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.228180170059204
total time:  3.27963246894069
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.30
[I 2023-06-11 23:36:00,180] Trial 245 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.009390912805047131, 'K': 7, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.033075972333668, 'loop': 0, 'loss': 'CE', 'lr': 0.002348783260861711, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.147258868281483e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0022232188655994752
weight_decay:  3.698915292095897e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.31247372715733945
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.29905518097802997
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  0.29592074011452496
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.40
run time now: 0.949343204498291
total time:  1.0183426840230823
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 68.43 ± 0.95
[I 2023-06-11 23:36:01,649] Trial 246 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.015427379986160327, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 20, 'lambda1': 0.8500000000000001, 'lambda2': 3.9345355354182656, 'loop': 0, 'loss': 'CE', 'lr': 0.0022232188655994752, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.698915292095897e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.0024385260109957936
weight_decay:  1.3311469712954043e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0313122430816293
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0125282369554043
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0844715090934187
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.16804838180542
total time:  3.230200686957687
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.62
[I 2023-06-11 23:36:05,415] Trial 247 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.011522549769423521, 'K': 7, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.3271525386526575, 'loop': 0, 'loss': 'CE', 'lr': 0.0024385260109957936, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3311469712954043e-05, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.55
lr:  0.0017914840100326952
weight_decay:  5.133231186141483e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 70.10%
Split: 01, Run: 01
None time:  1.436119717080146
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 69.40%
Split: 01, Run: 02
None time:  1.417474830057472
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.60% Test: 69.50%
Split: 01, Run: 03
None time:  1.3571164819877595
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 4.2421629428863525
total time:  4.2901060229633
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.55
[I 2023-06-11 23:36:10,188] Trial 248 finished with value: 68.9333267211914 and parameters: {'Fwd': 0.01466152527816638, 'K': 1, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.9748391900964193, 'loop': 0, 'loss': 'MSE', 'lr': 0.0017914840100326952, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.133231186141483e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.002314864511306547
weight_decay:  4.087056508144252e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1274551469832659
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0319682240951806
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9993020810652524
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.198958396911621
total time:  3.243615864077583
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.40
[I 2023-06-11 23:36:13,934] Trial 249 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.00859537069154388, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.8153012480712785, 'loop': 0, 'loss': 'CE', 'lr': 0.002314864511306547, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.087056508144252e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0023728037459111017
weight_decay:  4.335935025805523e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9862128058448434
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0496698501519859
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.103883157018572
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.179551601409912
total time:  3.2324191930238158
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.25
[I 2023-06-11 23:36:17,666] Trial 250 finished with value: 71.73333740234375 and parameters: {'Fwd': 1.5535037691764023e-06, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.738909848352481, 'loop': 0, 'loss': 'CE', 'lr': 0.0023728037459111017, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.335935025805523e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0023459774635670775
weight_decay:  4.072810082655546e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9527864339761436
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.0702028330415487
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.9593958489131182
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.02286958694458
total time:  3.0800295248627663
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.84
[I 2023-06-11 23:36:21,218] Trial 251 finished with value: 70.93334197998047 and parameters: {'Fwd': 0.051477167908603516, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 3.7506356635320506, 'loop': 0, 'loss': 'CE', 'lr': 0.0023459774635670775, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.072810082655546e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0024676552540834535
weight_decay:  4.573207654159793e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0818262549582869
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.027495990972966
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0245630210265517
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.173021078109741
total time:  3.2294703640509397
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.64
[I 2023-06-11 23:36:24,901] Trial 252 finished with value: 71.66666412353516 and parameters: {'Fwd': 1.9229732059057916e-05, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.8517557586152997, 'loop': 0, 'loss': 'CE', 'lr': 0.0024676552540834535, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.573207654159793e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.55
lr:  0.002183215841378363
weight_decay:  4.875582471344644e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.987299975939095
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0182122560217977
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0270629371516407
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.0711863040924072
total time:  3.118185125058517
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.23 ± 0.45
[I 2023-06-11 23:36:28,524] Trial 253 finished with value: 71.66666412353516 and parameters: {'Fwd': 1.5847959020262451e-06, 'K': 6, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.685887492678019, 'loop': 0, 'loss': 'CE', 'lr': 0.002183215841378363, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.875582471344644e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.002303327583535672
weight_decay:  3.396879194894232e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0708034508861601
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.1463110940530896
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.11542206001468
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 70.00
run time now: 3.3764939308166504
total time:  3.4270242219790816
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.53
  Final Train: 99.72 ± 0.48
   Final Test: 69.87 ± 0.23
[I 2023-06-11 23:36:32,487] Trial 254 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.0006568866588017064, 'K': 7, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.924436575419147, 'loop': 0, 'loss': 'CE', 'lr': 0.002303327583535672, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.396879194894232e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.001919460220615089
weight_decay:  6.108890803159929e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.2281210341025144
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 02
None time:  0.2376260939054191
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 03
None time:  0.3151553049683571
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.10
run time now: 0.8214969635009766
total time:  0.8857250139117241
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 65.80 ± 0.52
[I 2023-06-11 23:36:33,894] Trial 255 finished with value: 66.20000457763672 and parameters: {'Fwd': 9.347060683185072e-06, 'K': 7, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 10, 'lambda1': 0.8500000000000001, 'lambda2': 4.228016273625593, 'loop': 0, 'loss': 'CE', 'lr': 0.001919460220615089, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.108890803159929e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.002552718562968348
weight_decay:  1.0398629939159598e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0838332138955593
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.1891544838435948
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0336050880141556
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.3501622676849365
total time:  3.3950556328054518
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.55
[I 2023-06-11 23:36:37,718] Trial 256 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.001249118911248178, 'K': 7, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.8535989185387396, 'loop': 0, 'loss': 'CE', 'lr': 0.002552718562968348, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0398629939159598e-05, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.5
lr:  0.0015846224665558698
weight_decay:  5.286921159987652e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9336614389903843
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0410625680815428
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.8953167849685997
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.9150748252868652
total time:  2.972065446898341
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.82
[I 2023-06-11 23:36:41,163] Trial 257 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.002723954588858837, 'K': 6, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 4.411401191693313, 'loop': 0, 'loss': 'CE', 'lr': 0.0015846224665558698, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.286921159987652e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.002200934758787271
weight_decay:  8.344723607214155e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.724620508030057
None Run 01:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 98.33
   Final Test: 54.60
Split: 01, Run: 02
None time:  0.7861450300551951
None Run 02:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 98.33
   Final Test: 57.90
Split: 01, Run: 03
None time:  0.7760296510532498
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 98.33
   Final Test: 54.00
run time now: 2.3270318508148193
total time:  2.377724678022787
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.53 ± 4.94
  Final Train: 98.33 ± 0.00
   Final Test: 55.50 ± 2.10
[I 2023-06-11 23:36:44,117] Trial 258 finished with value: 55.5333366394043 and parameters: {'Fwd': 2.1860579735665113e-06, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.081130640381367, 'loop': 0, 'loss': 'CE', 'lr': 0.002200934758787271, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.344723607214155e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.0018584418907437378
weight_decay:  3.4387995450016326e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0321196720469743
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.1284774809610099
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0371268677990884
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.236530065536499
total time:  3.280774886952713
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.15
[I 2023-06-11 23:36:47,951] Trial 259 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.03132793986391977, 'K': 7, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.7279658298456724, 'loop': 0, 'loss': 'CE', 'lr': 0.0018584418907437378, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.4387995450016326e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.002500644949264951
weight_decay:  4.414093735553406e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9985637271311134
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.068900265963748
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0861148568801582
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.193467855453491
total time:  3.2527540680021048
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.35
[I 2023-06-11 23:36:51,725] Trial 260 finished with value: 71.60000610351562 and parameters: {'Fwd': 4.923646985188706e-06, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.2857462500306625, 'loop': 0, 'loss': 'CE', 'lr': 0.002500644949264951, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.414093735553406e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0019959953466395603
weight_decay:  6.547898773681213e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9338074850384146
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.9382758128922433
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.9351593188475817
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.848410129547119
total time:  2.911984165897593
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 1.14
[I 2023-06-11 23:36:55,139] Trial 261 finished with value: 70.73333740234375 and parameters: {'Fwd': 5.142198556586079e-05, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 4.599964664020206, 'loop': 0, 'loss': 'CE', 'lr': 0.0019959953466395603, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.547898773681213e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0021900390717441228
weight_decay:  5.457995781508085e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.027697263052687
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.006853116909042
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9848932770546526
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.00
run time now: 3.0629117488861084
total time:  3.1147536078933626
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.42
  Final Train: 99.72 ± 0.48
   Final Test: 70.00 ± 0.10
[I 2023-06-11 23:36:58,769] Trial 262 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0023719965742979043, 'K': 7, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.973992271854617, 'loop': 0, 'loss': 'CE', 'lr': 0.0021900390717441228, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.457995781508085e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0024087212519058325
weight_decay:  3.4040001935508883e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9970504930242896
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.1255926471203566
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0552853008266538
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.217625856399536
total time:  3.266404651803896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.62
[I 2023-06-11 23:37:02,580] Trial 263 finished with value: 71.66666412353516 and parameters: {'Fwd': 3.0265636848864877e-06, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.714517330694459, 'loop': 0, 'loss': 'CE', 'lr': 0.0024087212519058325, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.4040001935508883e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.001702110162576241
weight_decay:  7.867530136331146e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0546838829759508
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0978694721125066
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0532870080787688
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.24550461769104
total time:  3.3060288010165095
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.46
[I 2023-06-11 23:37:06,360] Trial 264 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.0808889144846147, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.415528647276606, 'loop': 0, 'loss': 'CE', 'lr': 0.001702110162576241, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.867530136331146e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.45
lr:  0.0008973103851280034
weight_decay:  6.778010595563845e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.015896124066785
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0234583369456232
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9928724300116301
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.0713117122650146
total time:  3.129134027985856
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.52
[I 2023-06-11 23:37:09,923] Trial 265 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.006581417674073133, 'K': 6, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.802209845003248, 'loop': 0, 'loss': 'CE', 'lr': 0.0008973103851280034, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.778010595563845e-05, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0014814719572635378
weight_decay:  4.555891925955799e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.006972226081416
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9710424260701984
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.109883195022121
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.130829095840454
total time:  3.1820031229872257
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.49
[I 2023-06-11 23:37:13,517] Trial 266 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.00204215675231139, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.1214012467884205, 'loop': 0, 'loss': 'CE', 'lr': 0.0014814719572635378, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.555891925955799e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.6000000000000001
lr:  0.0019775349684480964
weight_decay:  9.665322877707421e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9772601760923862
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 69.50%
Split: 01, Run: 02
None time:  1.5013770922087133
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 69.30%
Split: 01, Run: 03
None time:  1.4622178308200091
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.976639747619629
total time:  4.028094582958147
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.21
[I 2023-06-11 23:37:18,026] Trial 267 finished with value: 68.46666717529297 and parameters: {'Fwd': 0.0008444112476330315, 'K': 2, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.176412150704919, 'loop': 0, 'loss': 'MSE', 'lr': 0.0019775349684480964, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.665322877707421e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.002594530261090089
weight_decay:  0.000265888081250489
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.87803341797553
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9394323560409248
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  1.023374754935503
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 2.881502866744995
total time:  2.928599591134116
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 0.69
[I 2023-06-11 23:37:21,405] Trial 268 finished with value: 71.13333892822266 and parameters: {'Fwd': 1.0389434396747639e-06, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 4.237703669584041, 'loop': 0, 'loss': 'CE', 'lr': 0.002594530261090089, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000265888081250489, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.55
lr:  0.0021918773222392505
weight_decay:  1.2017022209291735e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0015812499914318
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.0674858330748975
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.092312433058396
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.00
run time now: 3.2108538150787354
total time:  3.2647001401055604
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 70.10 ± 0.17
[I 2023-06-11 23:37:25,158] Trial 269 finished with value: 71.66666412353516 and parameters: {'Fwd': 7.86922598223423e-06, 'K': 5, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.018756769833315, 'loop': 0, 'loss': 'CE', 'lr': 0.0021918773222392505, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2017022209291735e-05, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0018351432838519465
weight_decay:  4.016641164370495e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0049969218671322
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.9783388269133866
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0208876989781857
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.0458827018737793
total time:  3.110835059080273
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.06
[I 2023-06-11 23:37:28,841] Trial 270 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.017747569787170743, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.540793628643145, 'loop': 0, 'loss': 'CE', 'lr': 0.0018351432838519465, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.016641164370495e-06, 'weightedloss': True}. Best is trial 203 with value: 71.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0013256600757776348
weight_decay:  7.039111960761393e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.014189847977832
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.081122208153829
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0682076150551438
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.205029249191284
total time:  3.2593523929826915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.35
[I 2023-06-11 23:37:32,556] Trial 271 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.03956139864723021, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.8470632506024844, 'loop': 0, 'loss': 'CE', 'lr': 0.0013256600757776348, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.039111960761393e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0013220523918243672
weight_decay:  7.589590875599771e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2651436019223183
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.2195710139349103
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.276611922075972
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.8005640506744385
total time:  3.851862355833873
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.21
[I 2023-06-11 23:37:36,894] Trial 272 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.032763835990881174, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.869254710155618, 'loop': 2, 'loss': 'CE', 'lr': 0.0013220523918243672, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.589590875599771e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.00106627478481358
weight_decay:  3.289956240984308e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0544626470655203
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0353738381527364
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.0801159241236746
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.2105774879455566
total time:  3.2656499908771366
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.42
[I 2023-06-11 23:37:40,711] Trial 273 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0002383134962930077, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.6664744789615593, 'loop': 0, 'loss': 'CE', 'lr': 0.00106627478481358, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.289956240984308e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.001668095040292932
weight_decay:  5.113077877495568e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9989491009619087
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9623906649649143
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.9515816650819033
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.9566643238067627
total time:  3.012839791830629
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.98
[I 2023-06-11 23:37:44,218] Trial 274 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.06169739526351728, 'K': 7, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 4.116261846610596, 'loop': 0, 'loss': 'CE', 'lr': 0.001668095040292932, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.113077877495568e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0012071024094183177
weight_decay:  6.771202723198557e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0623279069550335
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0673381420783699
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.70%
Split: 01, Run: 03
None time:  1.773766481084749
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.9461257457733154
total time:  3.9998605269938707
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.60
[I 2023-06-11 23:37:48,703] Trial 275 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.04678627278621274, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.8746305929266414, 'loop': 0, 'loss': 'CE', 'lr': 0.0012071024094183177, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.771202723198557e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.001124019416816224
weight_decay:  7.194780975540711e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8437386739533395
None Run 01:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 50.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.60% Test: 57.10%
Split: 01, Run: 02
None time:  1.2958449441939592
None Run 02:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.40% Test: 56.60%
Split: 01, Run: 03
None time:  1.2852953870315105
None Run 03:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 56.30
run time now: 3.4655027389526367
total time:  3.5148443789221346
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.47 ± 3.52
  Final Train: 100.00 ± 0.00
   Final Test: 54.73 ± 3.34
[I 2023-06-11 23:37:52,666] Trial 276 finished with value: 51.4666633605957 and parameters: {'Fwd': 0.050355304842844645, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.8744961925875274, 'loop': 0, 'loss': 'CE', 'lr': 0.001124019416816224, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.194780975540711e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0015173354895499963
weight_decay:  1.064447907882855e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0537048219703138
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.9950815429911017
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.121516149956733
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.210592269897461
total time:  3.2593730760272592
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.25
[I 2023-06-11 23:37:56,394] Trial 277 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.0004360950443404468, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.376686060858944, 'loop': 0, 'loss': 'CE', 'lr': 0.0015173354895499963, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.064447907882855e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.6000000000000001
lr:  0.0015034098848844021
weight_decay:  1.0591470046319493e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9948015259578824
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0857737560290843
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0593244368210435
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.1796884536743164
total time:  3.2387108530383557
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.15
[I 2023-06-11 23:38:00,061] Trial 278 finished with value: 71.66667175292969 and parameters: {'Fwd': 9.664187289918539e-05, 'K': 6, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.41263360022681, 'loop': 0, 'loss': 'CE', 'lr': 0.0015034098848844021, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0591470046319493e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.0014136306044726823
weight_decay:  1.5944724651762968e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0355853370856494
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0917161549441516
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.12063406012021
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.288270950317383
total time:  3.343915635952726
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.29
[I 2023-06-11 23:38:03,911] Trial 279 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.03671763121036992, 'K': 7, 'alpha': 0.65, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.698936346440468, 'loop': 0, 'loss': 'CE', 'lr': 0.0014136306044726823, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5944724651762968e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0012465680483813146
weight_decay:  9.18900237627562e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8450312798377126
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.080322562949732
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  1.0126559529453516
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.9875802993774414
total time:  3.0552274668589234
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 1.50
[I 2023-06-11 23:38:07,499] Trial 280 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.001553686792957689, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 4.247123039403073, 'loop': 0, 'loss': 'CE', 'lr': 0.0012465680483813146, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.18900237627562e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0013904802925984688
weight_decay:  1.3369105947963404e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0348395679611713
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9968761201016605
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0432108792010695
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.114917039871216
total time:  3.164434793870896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.25
[I 2023-06-11 23:38:11,109] Trial 281 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.00021937887118363012, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.031362183842749, 'loop': 0, 'loss': 'CE', 'lr': 0.0013904802925984688, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3369105947963404e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0011960626519215878
weight_decay:  1.2990814238249114e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1166554999072105
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0089236630592495
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.70%
Split: 01, Run: 03
None time:  1.7407804219983518
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.908428907394409
total time:  3.955254490021616
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.56
[I 2023-06-11 23:38:15,525] Trial 282 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.04260460065225507, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.010159584881502, 'loop': 0, 'loss': 'CE', 'lr': 0.0011960626519215878, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2990814238249114e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0012339511802037535
weight_decay:  9.44039551299431e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.069372541969642
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9781893058679998
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.70%
Split: 01, Run: 03
None time:  1.836726794950664
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.925835371017456
total time:  3.9789832460228354
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.55
[I 2023-06-11 23:38:19,967] Trial 283 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.04268746318907993, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.9111806171938595, 'loop': 0, 'loss': 'CE', 'lr': 0.0012339511802037535, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.44039551299431e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012153799390272882
weight_decay:  1.3550641595948439e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9997734779026359
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.033458641031757
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.70%
Split: 01, Run: 03
None time:  1.800255309091881
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.8739864826202393
total time:  3.9288470579776913
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.57
[I 2023-06-11 23:38:24,362] Trial 284 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.04484251867166444, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.039850895357893, 'loop': 0, 'loss': 'CE', 'lr': 0.0012153799390272882, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3550641595948439e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0012718840242830684
weight_decay:  1.3191784284489962e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8510818530339748
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.8176214389968663
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  0.8248422269243747
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.545307159423828
total time:  2.617762964218855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 1.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.85
[I 2023-06-11 23:38:27,554] Trial 285 finished with value: 71.06665802001953 and parameters: {'Fwd': 0.04240226858540823, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.7000000000000001, 'lambda2': 4.971710842979973, 'loop': 0, 'loss': 'CE', 'lr': 0.0012718840242830684, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3191784284489962e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0013513506366173264
weight_decay:  2.0373612425550312e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0733841189648956
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9882514940109104
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1159929959103465
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.2295777797698975
total time:  3.2899310591164976
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.15
[I 2023-06-11 23:38:31,378] Trial 286 finished with value: 72.0 and parameters: {'Fwd': 0.04253496472871335, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.148464776047852, 'loop': 0, 'loss': 'CE', 'lr': 0.0013513506366173264, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.0373612425550312e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.001356510897300815
weight_decay:  2.1138258009542482e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5906495619565248
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.5484315948560834
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.5953843069728464
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.40
run time now: 1.7846617698669434
total time:  1.8418054580688477
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 68.87 ± 0.42
[I 2023-06-11 23:38:33,693] Trial 287 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.07230823154649045, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.036422817163483, 'loop': 0, 'loss': 'CE', 'lr': 0.001356510897300815, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.1138258009542482e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0011691781999719078
weight_decay:  1.762808163916632e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.112680742982775
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.60%
Split: 01, Run: 02
None time:  1.759266495006159
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.0562638170085847
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.9701411724090576
total time:  4.0168423731811345
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.06
[I 2023-06-11 23:38:38,210] Trial 288 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.06518221319717511, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.323107698550595, 'loop': 0, 'loss': 'MSE', 'lr': 0.0011691781999719078, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.762808163916632e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0011709110844463138
weight_decay:  1.4391676824400199e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9314806298352778
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0772376279346645
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  1.0043295638170093
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.0537047386169434
total time:  3.1094553659204394
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 1.04
[I 2023-06-11 23:38:41,765] Trial 289 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.044056250941298114, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 5.247763196231705, 'loop': 0, 'loss': 'CE', 'lr': 0.0011709110844463138, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4391676824400199e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0012798438491305776
weight_decay:  1.504558499815438e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0965214029420167
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0634412788785994
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.60%
Split: 01, Run: 03
None time:  1.8215068990830332
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 4.022636890411377
total time:  4.078455326845869
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.50
[I 2023-06-11 23:38:46,304] Trial 290 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.05609469127719617, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.847088194547329, 'loop': 0, 'loss': 'CE', 'lr': 0.0012798438491305776, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.504558499815438e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013570841215938486
weight_decay:  2.265039750342028e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.065811518812552
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0000699090305716
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0754396559204906
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.182631254196167
total time:  3.2324158009141684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.15
[I 2023-06-11 23:38:49,986] Trial 291 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.05333216043104666, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.191033252686995, 'loop': 0, 'loss': 'CE', 'lr': 0.0013570841215938486, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.265039750342028e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013960890122771874
weight_decay:  2.1459005439169916e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.195111932931468
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.039878159062937
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 71.10%
Split: 01, Run: 03
None time:  1.930853335885331
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 4.216625452041626
total time:  4.277933482080698
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.29
[I 2023-06-11 23:38:54,747] Trial 292 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.05202051089188635, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.162238668857424, 'loop': 0, 'loss': 'CE', 'lr': 0.0013960890122771874, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.1459005439169916e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012489568173836188
weight_decay:  1.4277299077140405e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0122614761348814
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0728018579538912
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.60%
Split: 01, Run: 03
None time:  1.7727728690952063
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.8998425006866455
total time:  3.949674286879599
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.45
[I 2023-06-11 23:38:59,174] Trial 293 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.05693813591665503, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.994601618711697, 'loop': 0, 'loss': 'CE', 'lr': 0.0012489568173836188, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4277299077140405e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013223993556093455
weight_decay:  1.5651746452483148e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9104150719940662
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.06093157408759
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.70%
Split: 01, Run: 03
None time:  1.851482273079455
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.863348960876465
total time:  3.9071193169802427
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.55
[I 2023-06-11 23:39:03,624] Trial 294 finished with value: 72.0 and parameters: {'Fwd': 0.06029371905612438, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.0596496385907095, 'loop': 0, 'loss': 'CE', 'lr': 0.0013223993556093455, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5651746452483148e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012450464800510424
weight_decay:  1.558038713270611e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9051273670047522
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 68.30%
Split: 01, Run: 02
None time:  1.727482640184462
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  0.9953168241772801
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.672288656234741
total time:  3.722747622989118
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 1.39
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 1.19
[I 2023-06-11 23:39:07,861] Trial 295 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.09113772222506178, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 5.539326906703234, 'loop': 0, 'loss': 'CE', 'lr': 0.0012450464800510424, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.558038713270611e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0010266754831817632
weight_decay:  1.75101504631494e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0912314211018384
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0540322170127183
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.1727876069489866
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.3612260818481445
total time:  3.4122164661530405
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.25
[I 2023-06-11 23:39:11,712] Trial 296 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.0637902302386136, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.101271691961916, 'loop': 0, 'loss': 'CE', 'lr': 0.0010266754831817632, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.75101504631494e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013100607039318163
weight_decay:  1.283993872034844e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7539934439118952
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.50
Split: 01, Run: 02
None time:  0.7619018999394029
None Run 02:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 58.00
Split: 01, Run: 03
None time:  0.7225312499795109
None Run 03:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 58.80
run time now: 2.2793526649475098
total time:  2.334089550888166
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.40 ± 7.56
  Final Train: 100.00 ± 0.00
   Final Test: 54.43 ± 6.88
[I 2023-06-11 23:39:14,490] Trial 297 finished with value: 55.39999771118164 and parameters: {'Fwd': 0.055323205378579016, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.971968904518096, 'loop': 0, 'loss': 'CE', 'lr': 0.0013100607039318163, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.283993872034844e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0011680411319513074
weight_decay:  2.559744192886665e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0016157489735633
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0171405340079218
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.80%
Split: 01, Run: 03
None time:  1.8957985339220613
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.9636337757110596
total time:  4.016991845099255
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.59
[I 2023-06-11 23:39:18,977] Trial 298 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.041653752762585095, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.275652699537577, 'loop': 0, 'loss': 'CE', 'lr': 0.0011680411319513074, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.559744192886665e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0014544580025301318
weight_decay:  1.965589909242836e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7694069431163371
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.7393386769108474
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.7433156159240752
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.2928624153137207
total time:  2.346554592018947
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.49
[I 2023-06-11 23:39:21,805] Trial 299 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.06997844831979229, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 4.882369747030098, 'loop': 0, 'loss': 'CE', 'lr': 0.0014544580025301318, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.965589909242836e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0011169117838671129
weight_decay:  1.2778346433740231e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0523221460171044
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1061922279186547
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 70.70%
Split: 01, Run: 03
None time:  1.9252596870064735
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 4.124493598937988
total time:  4.185926548903808
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.49
[I 2023-06-11 23:39:26,596] Trial 300 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.046856300491446366, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.440672078596732, 'loop': 0, 'loss': 'CE', 'lr': 0.0011169117838671129, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2778346433740231e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012940366708132725
weight_decay:  2.2816758856204115e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1537419809028506
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.086362644098699
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.1624321579001844
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.20
run time now: 3.4437546730041504
total time:  3.504639548016712
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 69.07 ± 0.81
[I 2023-06-11 23:39:30,543] Trial 301 finished with value: 70.13333892822266 and parameters: {'Fwd': 0.06019205809694364, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 4.92735430086217, 'loop': 1, 'loss': 'CE', 'lr': 0.0012940366708132725, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2816758856204115e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012379366181065753
weight_decay:  1.4179367817546887e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0426083258353174
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0375339360907674
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0322517009917647
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.1539764404296875
total time:  3.21407338604331
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.32
[I 2023-06-11 23:39:34,222] Trial 302 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.07637586665651204, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.098680309109717, 'loop': 0, 'loss': 'CE', 'lr': 0.0012379366181065753, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4179367817546887e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0010373629338863001
weight_decay:  1.0665365986244727e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.20% Test: 49.50%
Split: 01, Run: 01
None time:  0.8930323158856481
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 49.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 48.80% Test: 46.90%
Split: 01, Run: 02
None time:  0.9177865020465106
None Run 02:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 46.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.20% Test: 50.80%
Split: 01, Run: 03
None time:  0.9146551380399615
None Run 03:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 50.80
run time now: 2.7675514221191406
total time:  2.811512727988884
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.07 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 48.90 ± 2.07
[I 2023-06-11 23:39:37,509] Trial 303 finished with value: 50.06666564941406 and parameters: {'Fwd': 0.083985850140914, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 0, 'lambda1': 0.65, 'lambda2': 5.309548044009819, 'loop': 0, 'loss': 'CE', 'lr': 0.0010373629338863001, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0665365986244727e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0011968656344379844
weight_decay:  1.6332965445454788e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0974745298735797
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0344293708913028
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0821959269233048
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.255272388458252
total time:  3.301135851070285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.31
[I 2023-06-11 23:39:41,308] Trial 304 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.07330366170205363, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.770192447964542, 'loop': 0, 'loss': 'CE', 'lr': 0.0011968656344379844, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6332965445454788e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012558019862294446
weight_decay:  1.0650458457233946e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9178605210036039
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.0386906750500202
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.028216095175594
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.035552501678467
total time:  3.093240341870114
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.93
[I 2023-06-11 23:39:45,017] Trial 305 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.06043323690302958, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 5.633461609048081, 'loop': 0, 'loss': 'CE', 'lr': 0.0012558019862294446, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0650458457233946e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0014838790645985938
weight_decay:  2.8131294819095327e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0440296200104058
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.153150785015896
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.30%
Split: 01, Run: 03
None time:  1.8755139189306647
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 4.121220111846924
total time:  4.169369759969413
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.25
[I 2023-06-11 23:39:49,726] Trial 306 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.09943167586705119, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.814068988920463, 'loop': 0, 'loss': 'CE', 'lr': 0.0014838790645985938, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8131294819095327e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0010944064046573357
weight_decay:  1.2968985309894849e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.004634978948161
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9755335689987987
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.70%
Split: 01, Run: 03
None time:  1.8803524519316852
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.9033122062683105
total time:  3.9629914429970086
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.64
[I 2023-06-11 23:39:54,177] Trial 307 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.042734467184741234, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.136223360731863, 'loop': 0, 'loss': 'CE', 'lr': 0.0010944064046573357, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2968985309894849e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0009908291217554225
weight_decay:  1.823249626512357e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1606754809617996
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1444339570589364
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.00% Test: 70.20%
Split: 01, Run: 03
None time:  1.8678397049661726
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 4.217537879943848
total time:  4.273848362965509
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.32
[I 2023-06-11 23:39:59,020] Trial 308 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.05560605583218612, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.151144213187179, 'loop': 0, 'loss': 'CE', 'lr': 0.0009908291217554225, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.823249626512357e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.001387145927869671
weight_decay:  9.647786816220839e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.50%
Split: 01, Run: 01
None time:  1.8228628751821816
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.70%
Split: 01, Run: 02
None time:  1.9135423870757222
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 70.10%
Split: 01, Run: 03
None time:  1.8460406579542905
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 5.62554669380188
total time:  5.683157516876236
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.47 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.25
[I 2023-06-11 23:40:05,148] Trial 309 finished with value: 69.46666717529297 and parameters: {'Fwd': 0.03537363117236204, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.446720924331278, 'loop': 0, 'loss': 'MSE', 'lr': 0.001387145927869671, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.647786816220839e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0012025789164142175
weight_decay:  1.5441232386507383e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1181098481174558
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.2549133650027215
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.1859325419645756
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.605865716934204
total time:  3.6556060290895402
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.31
[I 2023-06-11 23:40:09,269] Trial 310 finished with value: 71.13333129882812 and parameters: {'Fwd': 0.04813482870486913, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.782896710604231, 'loop': 1, 'loss': 'CE', 'lr': 0.0012025789164142175, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5441232386507383e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0016223856567261343
weight_decay:  1.2705394988080273e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.032525076996535
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0370787028223276
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0914712131489068
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.2025578022003174
total time:  3.2484339089132845
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.36
[I 2023-06-11 23:40:12,989] Trial 311 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.03951021057529596, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.002159290749218, 'loop': 0, 'loss': 'CE', 'lr': 0.0016223856567261343, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2705394988080273e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.001563952690662615
weight_decay:  2.2965437022672023e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1083768708631396
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0281466150190681
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.07567775901407
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.255312442779541
total time:  3.301446845056489
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.21
[I 2023-06-11 23:40:16,855] Trial 312 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.057721794548403475, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.7192461896197795, 'loop': 0, 'loss': 'CE', 'lr': 0.001563952690662615, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2965437022672023e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013135279060912475
weight_decay:  3.148176286496951e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.978324435884133
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.082836288958788
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1836454970762134
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.2893247604370117
total time:  3.3536627390421927
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.17
[I 2023-06-11 23:40:20,742] Trial 313 finished with value: 72.0 and parameters: {'Fwd': 0.07292396253960529, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.796928916249811, 'loop': 0, 'loss': 'CE', 'lr': 0.0013135279060912475, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.148176286496951e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013403831219585924
weight_decay:  2.015609556743999e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9431033849250525
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.1270119729451835
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.9912183580454439
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.90
run time now: 3.1153805255889893
total time:  3.178588805021718
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 1.63
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 1.37
[I 2023-06-11 23:40:24,377] Trial 314 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.06788054492856713, 'K': 8, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 5.488923235889314, 'loop': 0, 'loss': 'CE', 'lr': 0.0013403831219585924, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.015609556743999e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0011210203070664943
weight_decay:  2.39876850880717e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.37246386683546007
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.4282430380117148
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.4096201369538903
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 1.2554967403411865
total time:  1.309446182101965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 69.33 ± 0.67
[I 2023-06-11 23:40:26,156] Trial 315 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.0527764344026254, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 30, 'lambda1': 0.6000000000000001, 'lambda2': 5.847464955949689, 'loop': 0, 'loss': 'CE', 'lr': 0.0011210203070664943, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.39876850880717e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013107850124111336
weight_decay:  2.8401132095568738e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0582757978700101
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.004948273068294
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1077753058634698
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.212580919265747
total time:  3.275415427982807
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.49
[I 2023-06-11 23:40:29,894] Trial 316 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.08507181625531017, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.550608187653018, 'loop': 0, 'loss': 'CE', 'lr': 0.0013107850124111336, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8401132095568738e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.001296413278476981
weight_decay:  3.388317761423785e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6618272229097784
None Run 01:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 54.60
Split: 01, Run: 02
None time:  0.7396633070893586
None Run 02:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 56.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.00% Test: 61.00%
Split: 01, Run: 03
None time:  1.3233775470871478
None Run 03:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 61.00
run time now: 2.7657270431518555
total time:  2.814625723985955
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.07 ± 4.00
  Final Train: 100.00 ± 0.00
   Final Test: 57.23 ± 3.35
[I 2023-06-11 23:40:33,171] Trial 317 finished with value: 56.06666564941406 and parameters: {'Fwd': 0.07905071141309453, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.735204168146368, 'loop': 0, 'loss': 'CE', 'lr': 0.001296413278476981, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.388317761423785e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012518119040723986
weight_decay:  2.2919941841091048e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9362846179865301
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.058743302943185
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 70.30%
Split: 01, Run: 03
None time:  1.7951685381121933
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.8388545513153076
total time:  3.910536329029128
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.17
[I 2023-06-11 23:40:37,568] Trial 318 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.0870454554215218, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.69818881709518, 'loop': 0, 'loss': 'CE', 'lr': 0.0012518119040723986, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2919941841091048e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0009442413505202519
weight_decay:  3.3156616208515135e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0483371100854129
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0289939939975739
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.0804504042025656
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.199673652648926
total time:  3.2581029520370066
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.12
[I 2023-06-11 23:40:41,314] Trial 319 finished with value: 71.13333129882812 and parameters: {'Fwd': 0.09533703466360417, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.138724198905818, 'loop': 0, 'loss': 'CE', 'lr': 0.0009442413505202519, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.3156616208515135e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0012622033116002792
weight_decay:  2.6935277334074727e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0732385569717735
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 68.50%
Split: 01, Run: 02
None time:  1.7522336789406836
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.9849920528940856
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.8597545623779297
total time:  3.923196658026427
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 1.39
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 1.14
[I 2023-06-11 23:40:45,789] Trial 320 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.07791699905395756, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 5.92549448556943, 'loop': 0, 'loss': 'CE', 'lr': 0.0012622033116002792, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.6935277334074727e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.75
lr:  0.0011107871837415537
weight_decay:  3.498274329222297e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0203788559883833
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0215400441084057
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.142678527859971
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.2211625576019287
total time:  3.2791333459317684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.10
[I 2023-06-11 23:40:49,533] Trial 321 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.06465395702572087, 'K': 3, 'alpha': 0.75, 'dropout': 0.1, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.74956846129572, 'loop': 0, 'loss': 'CE', 'lr': 0.0011107871837415537, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.498274329222297e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0014052513951782939
weight_decay:  2.1929744432682307e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0349416940007359
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.038848735857755
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.50%
Split: 01, Run: 03
None time:  1.8130944119766355
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.9334397315979004
total time:  3.993934019934386
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.21
[I 2023-06-11 23:40:53,995] Trial 322 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.09917064902091925, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.4519850601501085, 'loop': 0, 'loss': 'CE', 'lr': 0.0014052513951782939, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.1929744432682307e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0011852655375022786
weight_decay:  4.918261168502857e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.02490647113882
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.071516145952046
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 70.70%
Split: 01, Run: 03
None time:  1.8490007428918034
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.9976513385772705
total time:  4.058298502117395
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.35
[I 2023-06-11 23:40:58,518] Trial 323 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.07997100562200232, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.534274008605303, 'loop': 0, 'loss': 'CE', 'lr': 0.0011852655375022786, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.918261168502857e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0009772872516948833
weight_decay:  3.1158127138167075e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9326317987870425
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.60% Test: 68.10%
Split: 01, Run: 02
None time:  1.7320839930325747
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.9715581201016903
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.6781005859375
total time:  3.729296299163252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 1.23
[I 2023-06-11 23:41:02,683] Trial 324 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.05899878106867154, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 5.281469804125912, 'loop': 0, 'loss': 'CE', 'lr': 0.0009772872516948833, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.1158127138167075e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0012372146535087906
weight_decay:  2.5547840034942273e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1292921910062432
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0131066818721592
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.70%
Split: 01, Run: 03
None time:  1.8231027598958462
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 4.0074427127838135
total time:  4.064556234981865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.29
[I 2023-06-11 23:41:07,215] Trial 325 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.044790299162302, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.647543431395589, 'loop': 0, 'loss': 'CE', 'lr': 0.0012372146535087906, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.5547840034942273e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.001212732574611231
weight_decay:  2.5023443947988242e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9981401800177991
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0791776299010962
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.80%
Split: 01, Run: 03
None time:  1.8706702871713787
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.988140821456909
total time:  4.041293767979369
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.51
[I 2023-06-11 23:41:11,747] Trial 326 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.04921756921456165, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.683857524513022, 'loop': 0, 'loss': 'CE', 'lr': 0.001212732574611231, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.5023443947988242e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0010496989698686279
weight_decay:  4.546757726731483e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9950485459994525
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0941015949938446
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 70.20%
Split: 01, Run: 03
None time:  1.9056752130854875
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 4.037460088729858
total time:  4.095302754081786
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.49
[I 2023-06-11 23:41:16,330] Trial 327 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.03925943986902658, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.330080748692317, 'loop': 0, 'loss': 'CE', 'lr': 0.0010496989698686279, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.546757726731483e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0014381760519183249
weight_decay:  2.097166483025322e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.089597153943032
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.027119938051328
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0256426560226828
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.1837470531463623
total time:  3.2319067411590368
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.30
[I 2023-06-11 23:41:19,964] Trial 328 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.07406292123081062, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.651678329990437, 'loop': 0, 'loss': 'CE', 'lr': 0.0014381760519183249, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.097166483025322e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0012935243807594482
weight_decay:  3.844345924651837e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0818076599389315
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 69.80%
Split: 01, Run: 02
None time:  1.80685157305561
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.70%
Split: 01, Run: 03
None time:  1.7261694250628352
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 4.6564781665802
total time:  4.714433874934912
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.10
[I 2023-06-11 23:41:25,302] Trial 329 finished with value: 69.73333740234375 and parameters: {'Fwd': 0.056305446376451844, 'K': 8, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.995895435619228, 'loop': 0, 'loss': 'MSE', 'lr': 0.0012935243807594482, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.844345924651837e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0011512770919963674
weight_decay:  1.750212957491303e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0189653548877686
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1352578490041196
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.80%
Split: 01, Run: 03
None time:  1.8651070280466229
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 4.06693959236145
total time:  4.1148412430193275
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.70
[I 2023-06-11 23:41:29,886] Trial 330 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.04327126563615603, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.780788540896763, 'loop': 0, 'loss': 'CE', 'lr': 0.0011512770919963674, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.750212957491303e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0015323557689833004
weight_decay:  2.8652811725627316e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9497555589769036
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 68.40%
Split: 01, Run: 02
None time:  1.749538267031312
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.9332684930413961
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.6794931888580322
total time:  3.7315743148792535
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.89
[I 2023-06-11 23:41:34,146] Trial 331 finished with value: 70.60000610351562 and parameters: {'Fwd': 0.05761598737705203, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 6.266324912148876, 'loop': 0, 'loss': 'CE', 'lr': 0.0015323557689833004, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8652811725627316e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013610269060435113
weight_decay:  1.6112593963975925e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1683630819898099
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9771723470184952
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9915053478907794
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.1903812885284424
total time:  3.2636064349208027
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.30
[I 2023-06-11 23:41:37,905] Trial 332 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.034443775386751654, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.164700946439315, 'loop': 0, 'loss': 'CE', 'lr': 0.0013610269060435113, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6112593963975925e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013711786596683072
weight_decay:  1.5268440068270727e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.065088015049696
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0490900329314172
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0347469882108271
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.1908767223358154
total time:  3.247956532984972
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.35
[I 2023-06-11 23:41:41,575] Trial 333 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.034330022705240965, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.146370032002049, 'loop': 0, 'loss': 'CE', 'lr': 0.0013711786596683072, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5268440068270727e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001372343506247942
weight_decay:  1.5957261998786788e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0067217499017715
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0583767960779369
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0642152589280158
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.1734812259674072
total time:  3.2215219389181584
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.35
[I 2023-06-11 23:41:45,276] Trial 334 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.03511322266877522, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.166369267193215, 'loop': 0, 'loss': 'CE', 'lr': 0.001372343506247942, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5957261998786788e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0014404144234385896
weight_decay:  1.767510615238133e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9996270861010998
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.095498412149027
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0335207290481776
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.1699235439300537
total time:  3.22869387594983
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.47
[I 2023-06-11 23:41:48,994] Trial 335 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.03407705100468263, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.235131614062415, 'loop': 0, 'loss': 'CE', 'lr': 0.0014404144234385896, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.767510615238133e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013722554839991983
weight_decay:  1.6814415901307265e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.025962149957195
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0205283649265766
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0853629228658974
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.172893524169922
total time:  3.231287684990093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.35
[I 2023-06-11 23:41:52,701] Trial 336 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.03356111782944439, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.059124022181882, 'loop': 0, 'loss': 'CE', 'lr': 0.0013722554839991983, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6814415901307265e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0015628482973718087
weight_decay:  1.6361329213401143e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0324997731950134
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9201777661219239
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.0287448789458722
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.0420291423797607
total time:  3.100281100952998
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.67
[I 2023-06-11 23:41:56,364] Trial 337 finished with value: 70.66667175292969 and parameters: {'Fwd': 0.03298578474030195, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 4.901422759096783, 'loop': 0, 'loss': 'CE', 'lr': 0.0015628482973718087, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6361329213401143e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0013737816609442604
weight_decay:  1.955744108575962e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7317747490014881
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.40% Test: 49.90%
Split: 01, Run: 02
None time:  1.3882205011323094
None Run 02:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 50.10
Split: 01, Run: 03
None time:  0.7915508239530027
None Run 03:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 99.17
   Final Test: 58.30
run time now: 2.9542183876037598
total time:  3.016420852858573
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.27 ± 5.64
  Final Train: 99.72 ± 0.48
   Final Test: 51.60 ± 6.09
[I 2023-06-11 23:41:59,871] Trial 338 finished with value: 51.26666259765625 and parameters: {'Fwd': 0.034659894889199676, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.348512547698428, 'loop': 0, 'loss': 'CE', 'lr': 0.0013737816609442604, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.955744108575962e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.001614208326135429
weight_decay:  6.0466551601542397e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.06697679287754
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.0621771330479532
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 70.80%
Split: 01, Run: 03
None time:  1.8132198499515653
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.30
run time now: 3.985320806503296
total time:  4.048847934929654
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.47 ± 0.72
[I 2023-06-11 23:42:04,420] Trial 339 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.03708799025748176, 'K': 8, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.15000000000000002, 'lambda2': 5.170218815748791, 'loop': 0, 'loss': 'CE', 'lr': 0.001614208326135429, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.0466551601542397e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013883104529836083
weight_decay:  1.5707870082478722e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0755052310414612
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0285152888391167
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.070974148111418
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.227036714553833
total time:  3.284191929968074
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.46
[I 2023-06-11 23:42:08,181] Trial 340 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.028546805102560063, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.386383202273285, 'loop': 0, 'loss': 'CE', 'lr': 0.0013883104529836083, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5707870082478722e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0015097494113368243
weight_decay:  2.016125141247889e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0566931669600308
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0526957160327584
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1342833898961544
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.292109966278076
total time:  3.3467451399192214
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.35
[I 2023-06-11 23:42:12,008] Trial 341 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.031404087233858784, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.646326353410462, 'loop': 0, 'loss': 'CE', 'lr': 0.0015097494113368243, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.016125141247889e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013956207412986407
weight_decay:  1.499254537028843e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0806503198109567
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0332760089077055
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1535893520340323
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.308627128601074
total time:  3.366927476134151
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.25
[I 2023-06-11 23:42:15,876] Trial 342 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.04763216144027363, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.894383830007154, 'loop': 0, 'loss': 'CE', 'lr': 0.0013956207412986407, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.499254537028843e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013556016825476763
weight_decay:  1.5314023096896343e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0775829448830336
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1519429781474173
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0760592340957373
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.3525569438934326
total time:  3.4112641979008913
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.23
[I 2023-06-11 23:42:19,794] Trial 343 finished with value: 72.0 and parameters: {'Fwd': 0.05226760111923603, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.163095391028969, 'loop': 0, 'loss': 'CE', 'lr': 0.0013556016825476763, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.5314023096896343e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013916016869366886
weight_decay:  0.005177229014333365
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9705172530375421
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 68.00%
Split: 01, Run: 02
None time:  1.8020278681069613
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.9058467079885304
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.721809148788452
total time:  3.7750049370806664
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.98
[I 2023-06-11 23:42:24,039] Trial 344 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.05297427496850215, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 4.754207401330465, 'loop': 0, 'loss': 'CE', 'lr': 0.0013916016869366886, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.005177229014333365, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.001631075814910079
weight_decay:  1.6828390469401667e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.064463583054021
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0572757190093398
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.10123704187572
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.2647597789764404
total time:  3.320755163906142
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.38
[I 2023-06-11 23:42:27,871] Trial 345 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.06251255891044927, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 5.1740036994338, 'loop': 0, 'loss': 'CE', 'lr': 0.001631075814910079, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.6828390469401667e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0015339201575092728
weight_decay:  9.469058413836771e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9871037739794701
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9346882819663733
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.9302369880024344
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.894335985183716
total time:  2.9488356271758676
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.74
[I 2023-06-11 23:42:31,272] Trial 346 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.029044403294250603, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 5.490745547223877, 'loop': 0, 'loss': 'CE', 'lr': 0.0015339201575092728, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.469058413836771e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013370802282008092
weight_decay:  2.411444506184484e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0111683760769665
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.1057539349421859
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9899600511416793
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.155954360961914
total time:  3.2179450190160424
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.17
[I 2023-06-11 23:42:34,946] Trial 347 finished with value: 72.0 and parameters: {'Fwd': 0.0518501460317296, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 9.275257425140177, 'loop': 0, 'loss': 'CE', 'lr': 0.0013370802282008092, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.411444506184484e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0017372545159569572
weight_decay:  2.6712513674219816e-05
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9937912770546973
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 68.30%
Split: 01, Run: 02
None time:  1.8064201939851046
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.9855342339724302
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.70
run time now: 3.833798408508301
total time:  3.892699504038319
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 68.97 ± 0.55
[I 2023-06-11 23:42:39,319] Trial 348 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.06049471128521683, 'K': 8, 'alpha': 0.8, 'dropout': 0.0, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 9.27341302774478, 'loop': 0, 'loss': 'CE', 'lr': 0.0017372545159569572, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.6712513674219816e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0013712199911255988
weight_decay:  3.5481487776249894e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 69.60%
Split: 01, Run: 01
None time:  1.8354608309455216
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.60%
Split: 01, Run: 02
None time:  1.7996708110440522
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.70%
Split: 01, Run: 03
None time:  1.8444812919478863
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 5.520092487335205
total time:  5.573339071124792
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.12
[I 2023-06-11 23:42:45,375] Trial 349 finished with value: 69.33333587646484 and parameters: {'Fwd': 0.03917643032510262, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 9.750123651935992, 'loop': 0, 'loss': 'MSE', 'lr': 0.0013712199911255988, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.5481487776249894e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.00018842219344636845
weight_decay:  2.2823739325136165e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4284811548423022
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 02
None time:  1.3425661630462855
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.3363268771208823
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.50
run time now: 4.149115085601807
total time:  4.198893940076232
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.87 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 67.87 ± 0.32
[I 2023-06-11 23:42:50,023] Trial 350 finished with value: 67.86666870117188 and parameters: {'Fwd': 0.02754503655158512, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.272896830798615, 'loop': 2, 'loss': 'CE', 'lr': 0.00018842219344636845, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.2823739325136165e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.8
lr:  0.0015395260121468383
weight_decay:  2.08938762540006e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.938626779941842
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9799885051324964
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0590510480105877
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.014997720718384
total time:  3.077671998878941
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.21
[I 2023-06-11 23:42:53,594] Trial 351 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.07166536874274568, 'K': 4, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 8.51999154309325, 'loop': 0, 'loss': 'CE', 'lr': 0.0015395260121468383, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.08938762540006e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0014288998165397052
weight_decay:  2.947129199674955e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0098883360624313
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0558281289413571
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.207273146836087
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 98.33
   Final Test: 70.50
run time now: 3.314100980758667
total time:  3.3573594740591943
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.35
  Final Train: 98.89 ± 0.48
   Final Test: 69.90 ± 0.60
[I 2023-06-11 23:42:57,435] Trial 352 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.0498400059396247, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 0.8248381096625641, 'loop': 0, 'loss': 'CE', 'lr': 0.0014288998165397052, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.947129199674955e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0017666987010892398
weight_decay:  1.552595425907055e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.07330248109065
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0910605639219284
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0977519690059125
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.30344295501709
total time:  3.3556944190058857
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.21
[I 2023-06-11 23:43:01,261] Trial 353 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.03345159319719552, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.285432862770115, 'loop': 0, 'loss': 'CE', 'lr': 0.0017666987010892398, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.552595425907055e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0008423245800047967
weight_decay:  0.00016355231907560496
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0189976720139384
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0005225359927863
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.8790317748207599
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.943887710571289
total time:  3.0053287169430405
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 1.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 1.23
[I 2023-06-11 23:43:04,740] Trial 354 finished with value: 70.0 and parameters: {'Fwd': 0.05518051366251122, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 7.7367514686045515, 'loop': 0, 'loss': 'CE', 'lr': 0.0008423245800047967, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016355231907560496, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013551383938584529
weight_decay:  3.8384009478342485e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.046103946166113
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1204915819689631
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.025898989988491
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.235987663269043
total time:  3.3023498149123043
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.17
[I 2023-06-11 23:43:08,637] Trial 355 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.026045254759201796, 'K': 8, 'alpha': 0.8, 'dropout': 0.5, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.409671859376213, 'loop': 0, 'loss': 'CE', 'lr': 0.0013551383938584529, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.8384009478342485e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0016839519032381587
weight_decay:  0.07407559382179656
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0686429729685187
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0867274070624262
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.0514037769753486
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.2545902729034424
total time:  3.312341261887923
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.46
[I 2023-06-11 23:43:12,440] Trial 356 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.038512505707402056, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.948708935534652, 'loop': 0, 'loss': 'CE', 'lr': 0.0016839519032381587, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07407559382179656, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0006194434424481339
weight_decay:  1.9817595482709095e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 58.20% Test: 61.30%
Split: 01, Run: 01
None time:  1.3443414960056543
None Run 01:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 61.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.80% Test: 63.10%
Split: 01, Run: 02
None time:  1.2645805990323424
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 63.20
Split: 01, Run: 03
None time:  0.8006806210614741
None Run 03:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.10
run time now: 3.4512271881103516
total time:  3.5031138740014285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.73 ± 2.20
  Final Train: 100.00 ± 0.00
   Final Test: 62.17 ± 1.00
[I 2023-06-11 23:43:16,375] Trial 357 finished with value: 60.733333587646484 and parameters: {'Fwd': 0.07098324455581806, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.0562456959316435, 'loop': 0, 'loss': 'CE', 'lr': 0.0006194434424481339, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.9817595482709095e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0014581720429995635
weight_decay:  1.396862520149299e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0724179139360785
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0238406739663333
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.011565756984055
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.148772716522217
total time:  3.2139977149199694
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.35
[I 2023-06-11 23:43:20,041] Trial 358 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.05306341552038366, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.780169329794543, 'loop': 0, 'loss': 'CE', 'lr': 0.0014581720429995635, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.396862520149299e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0015964215032598602
weight_decay:  2.961965233272565e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.60% Test: 50.10%
Split: 01, Run: 01
None time:  1.8177502939943224
None Run 01:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.60% Test: 50.10%
Split: 01, Run: 02
None time:  1.7989482870325446
None Run 02:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.60% Test: 50.10%
Split: 01, Run: 03
None time:  1.8320071699563414
None Run 03:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.80
run time now: 5.499634742736816
total time:  5.563943411922082
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 49.80 ± 0.00
[I 2023-06-11 23:43:26,068] Trial 359 finished with value: 50.59999465942383 and parameters: {'Fwd': 0.03710544030325772, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.0, 'lambda2': 4.686508371201374, 'loop': 0, 'loss': 'CE', 'lr': 0.0015964215032598602, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.961965233272565e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0010420278764302125
weight_decay:  1.8257309098071687e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7044750698842108
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.828094715019688
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.7073591430671513
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.2814366817474365
total time:  2.3315943889319897
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.38
[I 2023-06-11 23:43:28,853] Trial 360 finished with value: 71.0 and parameters: {'Fwd': 0.09756245267978582, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 4.8904519408436595, 'loop': 0, 'loss': 'CE', 'lr': 0.0010420278764302125, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.8257309098071687e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013237694769646082
weight_decay:  2.3787223552277196e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0706121020484716
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.057282533030957
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.09189767902717
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.260307788848877
total time:  3.3167305670212954
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 0.31
[I 2023-06-11 23:43:32,638] Trial 361 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.06914519519085931, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.516011206611665, 'loop': 0, 'loss': 'CE', 'lr': 0.0013237694769646082, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3787223552277196e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0017687882119953027
weight_decay:  1.1450103372899239e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0831496550235897
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.10148686892353
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.1050738198682666
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.3355112075805664
total time:  3.39411512715742
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.35
[I 2023-06-11 23:43:36,579] Trial 362 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.02796324749585765, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.490336152299118, 'loop': 0, 'loss': 'CE', 'lr': 0.0017687882119953027, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.1450103372899239e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.0013266095736393006
weight_decay:  1.5280530224109196e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1169191428925842
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 93.33
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.1224834700115025
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 93.33
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.062565433094278
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 90.83
   Final Test: 70.20
run time now: 3.3438472747802734
total time:  3.391917717177421
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 92.50 ± 1.44
   Final Test: 69.67 ± 0.61
[I 2023-06-11 23:43:40,492] Trial 363 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.04785129146274146, 'K': 9, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 0.022829691335434, 'loop': 0, 'loss': 'CE', 'lr': 0.0013266095736393006, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5280530224109196e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.00011713711315915693
weight_decay:  4.504939207610779e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.20% Test: 66.60%
Split: 01, Run: 01
None time:  1.9214870480354875
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.50
Split: 01, Run: 02
None time:  1.0978943780064583
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.00% Test: 69.00%
Split: 01, Run: 03
None time:  1.8729016981087625
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 69.10
run time now: 4.933003902435303
total time:  4.981060005025938
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 67.87 ± 1.31
[I 2023-06-11 23:43:45,961] Trial 364 finished with value: 66.66666412353516 and parameters: {'Fwd': 0.026363388315959354, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 6.068230250921143, 'loop': 0, 'loss': 'CE', 'lr': 0.00011713711315915693, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.504939207610779e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0010962329796640265
weight_decay:  1.257365020272562e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9406531529966742
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.115659911185503
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 70.60%
Split: 01, Run: 03
None time:  1.9039981469977647
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.005177974700928
total time:  4.061327855102718
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.20
[I 2023-06-11 23:43:50,508] Trial 365 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.06365729607337994, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.328716895049642, 'loop': 0, 'loss': 'CE', 'lr': 0.0010962329796640265, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.257365020272562e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0015163918979456618
weight_decay:  0.0007213984327642676
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0024311009328812
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.60% Test: 68.40%
Split: 01, Run: 02
None time:  1.8121333660092205
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.9996442408300936
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.8552849292755127
total time:  3.9114943330641836
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 1.59
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.75
[I 2023-06-11 23:43:54,866] Trial 366 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.04547573107976609, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 5.108018179929133, 'loop': 0, 'loss': 'CE', 'lr': 0.0015163918979456618, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007213984327642676, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.001465696288319268
weight_decay:  1.7611614192194284e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5027139810845256
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.50640774006024
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.46824336308054626
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 1.5283396244049072
total time:  1.5805022870190442
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.40
[I 2023-06-11 23:43:56,929] Trial 367 finished with value: 71.0 and parameters: {'Fwd': 0.03390303781841875, 'K': 8, 'alpha': 0.8, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 1.5428589241835242, 'loop': 0, 'loss': 'CE', 'lr': 0.001465696288319268, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.7611614192194284e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.007139402970833544
weight_decay:  2.2672555490333875e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 70.20%
Split: 01, Run: 01
None time:  1.718558836961165
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 69.10%
Split: 01, Run: 02
None time:  1.7855039190035313
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.1652508249972016
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 4.716763496398926
total time:  4.775444564176723
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.50
[I 2023-06-11 23:44:02,264] Trial 368 finished with value: 70.0 and parameters: {'Fwd': 0.05873724657508388, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.804320710814927, 'loop': 0, 'loss': 'CE', 'lr': 0.007139402970833544, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2672555490333875e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0008016395291134988
weight_decay:  1.168128585597455e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.20%
Split: 01, Run: 01
None time:  1.7133052500430495
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 69.60%
Split: 01, Run: 02
None time:  1.763584452914074
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 69.10%
Split: 01, Run: 03
None time:  1.7234520940110087
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.10
run time now: 5.242353200912476
total time:  5.3014722489751875
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 0.26
[I 2023-06-11 23:44:08,018] Trial 369 finished with value: 69.73333740234375 and parameters: {'Fwd': 0.003368064075387274, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.712805204067093, 'loop': 0, 'loss': 'MSE', 'lr': 0.0008016395291134988, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.168128585597455e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0016567261652478881
weight_decay:  2.8337028909201903e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0518970568664372
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0223471361678094
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.03733826498501
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.1531591415405273
total time:  3.2024321388453245
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.42
[I 2023-06-11 23:44:11,742] Trial 370 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.08600391727388805, 'K': 8, 'alpha': 0.65, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.886614921647378, 'loop': 0, 'loss': 'CE', 'lr': 0.0016567261652478881, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8337028909201903e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013084849956738233
weight_decay:  1.5380383818343453e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0873504399787635
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0455197091214359
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1829310739412904
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.358003854751587
total time:  3.414850757922977
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.40
[I 2023-06-11 23:44:15,683] Trial 371 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.03897917238752253, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.929742747565201, 'loop': 0, 'loss': 'CE', 'lr': 0.0013084849956738233, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5380383818343453e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.000377368967112897
weight_decay:  9.621933853396455e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.003869113046676
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.9718364379368722
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.1590318500529975
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.177117347717285
total time:  3.228881728835404
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.30
[I 2023-06-11 23:44:19,414] Trial 372 finished with value: 69.93334197998047 and parameters: {'Fwd': 0.0018571795001680223, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.192967159948586, 'loop': 0, 'loss': 'CE', 'lr': 0.000377368967112897, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.621933853396455e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.0018590299228304552
weight_decay:  1.936478930558234e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.915014241123572
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0039226131048054
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.9388939030468464
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 2.897829294204712
total time:  2.9532952138688415
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.83
[I 2023-06-11 23:44:22,924] Trial 373 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.05022234072930756, 'K': 8, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 8.118700983743647, 'loop': 0, 'loss': 'CE', 'lr': 0.0018590299228304552, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.936478930558234e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0013966992455236157
weight_decay:  3.4716034719194524e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8410149388946593
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.7982770919334143
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.8514705838169903
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.70
run time now: 2.531350612640381
total time:  2.5773993330076337
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.80
[I 2023-06-11 23:44:25,972] Trial 374 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.02290370866936825, 'K': 8, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 8.891505757493565, 'loop': 0, 'loss': 'CE', 'lr': 0.0013966992455236157, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.4716034719194524e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0011313412321933487
weight_decay:  2.362623928384289e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9322483381256461
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0480908120516688
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 70.40%
Split: 01, Run: 03
None time:  1.8073477509897202
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.828099250793457
total time:  3.886478781932965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.70
[I 2023-06-11 23:44:30,313] Trial 375 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.031245473139877727, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.562905796941515, 'loop': 0, 'loss': 'CE', 'lr': 0.0011313412321933487, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.362623928384289e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0016183727884928265
weight_decay:  8.830654665310662e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7489642610307783
None Run 01:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 46.50
Split: 01, Run: 02
None time:  0.7158743489999324
None Run 02:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 53.90
Split: 01, Run: 03
None time:  0.7780975000932813
None Run 03:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 59.80
run time now: 2.2839486598968506
total time:  2.333777564112097
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.07 ± 7.90
  Final Train: 100.00 ± 0.00
   Final Test: 53.40 ± 6.66
[I 2023-06-11 23:44:33,095] Trial 376 finished with value: 54.06666946411133 and parameters: {'Fwd': 0.07987764090500203, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.595908470628104, 'loop': 0, 'loss': 'CE', 'lr': 0.0016183727884928265, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.830654665310662e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0012916982752841776
weight_decay:  1.3719460286384427e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6274560121819377
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.7083435819949955
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.6216299880761653
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 1.9975769519805908
total time:  2.0553585330490023
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.32
[I 2023-06-11 23:44:35,646] Trial 377 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.04059048680759234, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 7.6704032989131505, 'loop': 0, 'loss': 'CE', 'lr': 0.0012916982752841776, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3719460286384427e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.0014534434678381935
weight_decay:  5.021269496365702e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9977276579011232
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0833941840101033
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0693430558312684
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.192713499069214
total time:  3.2448911948595196
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.80
[I 2023-06-11 23:44:39,326] Trial 378 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.0007988471876829856, 'K': 9, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.271445609652801, 'loop': 0, 'loss': 'CE', 'lr': 0.0014534434678381935, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.021269496365702e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0018414501154006898
weight_decay:  6.97374473062832e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0221539109479636
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0780708719976246
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0328330278862268
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.1753623485565186
total time:  3.2298767371103168
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.12
[I 2023-06-11 23:44:43,021] Trial 379 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.02426632834242289, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.009230429999303, 'loop': 0, 'loss': 'CE', 'lr': 0.0018414501154006898, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.97374473062832e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0015722538074523836
weight_decay:  1.7291971874472397e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9266481939703226
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9065734141040593
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.8886403399519622
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
run time now: 2.77923846244812
total time:  2.8378235639538616
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.33 ± 0.58
[I 2023-06-11 23:44:46,313] Trial 380 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.058396044449929366, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 5.390779170300587, 'loop': 0, 'loss': 'CE', 'lr': 0.0015722538074523836, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.7291971874472397e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.00108841231065896
weight_decay:  1.1138846344242995e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9579385810066015
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9991521039046347
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.0143764191307127
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.011962890625
total time:  3.065592327155173
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 1.44
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 1.04
[I 2023-06-11 23:44:49,882] Trial 381 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.06871074004224596, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 9.233280139155495, 'loop': 0, 'loss': 'CE', 'lr': 0.00108841231065896, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.1138846344242995e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0017289640766808931
weight_decay:  0.00016451611852572075
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1033498898614198
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9496134270448238
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.0857971699442714
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.1789941787719727
total time:  3.2467382398899645
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.35
[I 2023-06-11 23:44:53,596] Trial 382 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.033771524041877596, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.720843941850541, 'loop': 0, 'loss': 'CE', 'lr': 0.0017289640766808931, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00016451611852572075, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.00130126684190252
weight_decay:  2.8161084548167492e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0183770249132067
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0033539989963174
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 71.00%
Split: 01, Run: 03
None time:  1.733864082954824
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.79899525642395
total time:  3.8551184879615903
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.36
[I 2023-06-11 23:44:58,020] Trial 383 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.046406793631393696, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.2564168129964335, 'loop': 0, 'loss': 'CE', 'lr': 0.00130126684190252, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.8161084548167492e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001485267317613974
weight_decay:  4.1178817957964406e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1277502228040248
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1366616368759423
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1474019240122288
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.4570255279541016
total time:  3.5189492800273
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.53
[I 2023-06-11 23:45:02,079] Trial 384 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.09801701109264195, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.346508799066679, 'loop': 1, 'loss': 'CE', 'lr': 0.001485267317613974, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.1178817957964406e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013314306105007944
weight_decay:  2.955059381561859e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0640886290930212
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0878287749364972
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.00% Test: 71.00%
Split: 01, Run: 03
None time:  1.8523572569247335
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 4.046940088272095
total time:  4.102224236121401
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.26
[I 2023-06-11 23:45:06,699] Trial 385 finished with value: 72.0 and parameters: {'Fwd': 0.055062410314797014, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.094681218123228, 'loop': 0, 'loss': 'CE', 'lr': 0.0013314306105007944, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.955059381561859e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0011555552832174896
weight_decay:  2.924543780486063e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0844262100290507
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.059178841067478
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 70.70%
Split: 01, Run: 03
None time:  1.8949434880632907
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 4.085988759994507
total time:  4.1437653379980475
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.56
[I 2023-06-11 23:45:11,315] Trial 386 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.054515673299707995, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.856388309124623, 'loop': 0, 'loss': 'CE', 'lr': 0.0011555552832174896, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.924543780486063e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013121312641276323
weight_decay:  2.7414853666048425e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.111443897942081
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0848588389344513
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.120332483900711
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.3570644855499268
total time:  3.414045033045113
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.26
[I 2023-06-11 23:45:15,241] Trial 387 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.06914338456745858, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 5.541761642669086, 'loop': 0, 'loss': 'CE', 'lr': 0.0013121312641276323, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.7414853666048425e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0009447548080843225
weight_decay:  3.240662663952496e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0813985401764512
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0823268829844892
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 70.30%
Split: 01, Run: 03
None time:  1.8553017110098153
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 4.0603063106536865
total time:  4.121647954918444
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.25
[I 2023-06-11 23:45:19,846] Trial 388 finished with value: 71.06665802001953 and parameters: {'Fwd': 0.07801708674897911, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 5.967466607291526, 'loop': 0, 'loss': 'CE', 'lr': 0.0009447548080843225, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.240662663952496e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0014088563636190073
weight_decay:  0.00010722561563825551
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 69.50%
Split: 01, Run: 01
None time:  1.7195732230320573
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 69.30%
Split: 01, Run: 02
None time:  1.693582777865231
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 69.90%
Split: 01, Run: 03
None time:  1.6904107078444213
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 5.149658441543579
total time:  5.20945169008337
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.38
[I 2023-06-11 23:45:25,618] Trial 389 finished with value: 69.93333435058594 and parameters: {'Fwd': 0.0013874623378092078, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 6.366897083122955, 'loop': 0, 'loss': 'MSE', 'lr': 0.0014088563636190073, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00010722561563825551, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.0004812679440952283
weight_decay:  1.9709122535654462e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2399114170111716
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.2010234468616545
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.1459724069572985
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.6292386054992676
total time:  3.7002492588944733
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.81
[I 2023-06-11 23:45:29,789] Trial 390 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.048983310267936994, 'K': 9, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.060550321169906, 'loop': 1, 'loss': 'CE', 'lr': 0.0004812679440952283, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.9709122535654462e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012368531401310242
weight_decay:  1.4979826948384108e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0337813110090792
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.044189905980602
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0530985470395535
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.1895833015441895
total time:  3.2675065190996975
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.53
[I 2023-06-11 23:45:33,559] Trial 391 finished with value: 71.86666107177734 and parameters: {'Fwd': 0.0027167251950572244, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 7.768171162713104, 'loop': 0, 'loss': 'CE', 'lr': 0.0012368531401310242, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4979826948384108e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0010100281867298272
weight_decay:  0.0014788175259586565
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.085407939972356
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1017350431066006
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 70.30%
Split: 01, Run: 03
None time:  1.7419001839589328
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.971179485321045
total time:  4.019686366198584
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.42
[I 2023-06-11 23:45:38,077] Trial 392 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.04181748012254827, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.081395397005641, 'loop': 0, 'loss': 'CE', 'lr': 0.0010100281867298272, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0014788175259586565, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.009587950076328141
weight_decay:  2.5552904501372196e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.20%
Split: 01, Run: 01
None time:  1.8106393348425627
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.070888867136091
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 69.20%
Split: 01, Run: 03
None time:  1.8914146970491856
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 4.827816009521484
total time:  4.874481202103198
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 68.90 ± 0.52
[I 2023-06-11 23:45:43,439] Trial 393 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.061630717374933204, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 9.683239787942924, 'loop': 0, 'loss': 'CE', 'lr': 0.009587950076328141, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.5552904501372196e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0015541816862614283
weight_decay:  2.2034152184395558e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8612079741433263
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.077490716939792
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.9780383869074285
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.9581995010375977
total time:  3.027349716052413
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.72
[I 2023-06-11 23:45:47,006] Trial 394 finished with value: 70.53333282470703 and parameters: {'Fwd': 4.007089337707338e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 5.340422384013777, 'loop': 0, 'loss': 'CE', 'lr': 0.0015541816862614283, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2034152184395558e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001139724399116849
weight_decay:  3.0209963064043547e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.07870076992549
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0754789020866156
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.1306801040191203
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.325575828552246
total time:  3.389049038058147
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.53
[I 2023-06-11 23:45:50,881] Trial 395 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.00029606773526057027, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.857957682296804, 'loop': 0, 'loss': 'CE', 'lr': 0.001139724399116849, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.0209963064043547e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.001367698534742611
weight_decay:  1.6232917336792766e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0318137330468744
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0219196390826255
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0729813850484788
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.1696248054504395
total time:  3.225849774898961
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.38
[I 2023-06-11 23:45:54,588] Trial 396 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.035606777087151674, 'K': 9, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.738919376178216, 'loop': 0, 'loss': 'CE', 'lr': 0.001367698534742611, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6232917336792766e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.001250717746062819
weight_decay:  1.1855022060731526e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9994163420051336
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9838049339596182
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.9845840609632432
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.0192861557006836
total time:  3.0876808939501643
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.98
[I 2023-06-11 23:45:58,225] Trial 397 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.05738603241665851, 'K': 8, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 8.106699833636759, 'loop': 0, 'loss': 'CE', 'lr': 0.001250717746062819, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.1855022060731526e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0017283906876384837
weight_decay:  3.635746993071478e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.268792127026245
None Run 01:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 47.10
Split: 01, Run: 02
None time:  0.3015666070859879
None Run 02:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 51.80
Split: 01, Run: 03
None time:  0.28284898214042187
None Run 03:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 46.40
run time now: 0.9000842571258545
total time:  0.9502755508292466
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 49.13 ± 3.03
  Final Train: 100.00 ± 0.00
   Final Test: 48.43 ± 2.94
[I 2023-06-11 23:45:59,665] Trial 398 finished with value: 49.133331298828125 and parameters: {'Fwd': 0.08393131088411057, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 0.7000000000000001, 'lambda2': 7.980959041044375, 'loop': 0, 'loss': 'CE', 'lr': 0.0017283906876384837, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.635746993071478e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0014943594871202862
weight_decay:  1.8693806840269745e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0858396750409156
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 98.33
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.104093600064516
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 97.50
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.1345291258767247
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.00
   Final Test: 70.30
run time now: 3.3892574310302734
total time:  3.446258637821302
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 96.94 ± 1.73
   Final Test: 70.03 ± 0.38
[I 2023-06-11 23:46:03,592] Trial 399 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.09971969225031727, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 0.37738737283205204, 'loop': 0, 'loss': 'CE', 'lr': 0.0014943594871202862, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8693806840269745e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0019051988396595499
weight_decay:  1.3755988989552138e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0798133970238268
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0526232949923724
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  1.1045103250071406
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 68.70
run time now: 3.2784371376037598
total time:  3.3277109120972455
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.40
  Final Train: 99.72 ± 0.48
   Final Test: 69.07 ± 0.64
[I 2023-06-11 23:46:07,490] Trial 400 finished with value: 70.60000610351562 and parameters: {'Fwd': 0.0038609532194203828, 'K': 8, 'alpha': 0.65, 'dropout': 0.1, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.485140479392496, 'loop': 0, 'loss': 'CE', 'lr': 0.0019051988396595499, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3755988989552138e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013644372304502897
weight_decay:  3.512154862358641e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0141406289767474
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0421145120635629
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.018964909017086
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.1249167919158936
total time:  3.183676842134446
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.31
[I 2023-06-11 23:46:11,246] Trial 401 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.04139692167763046, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.577008203951456, 'loop': 0, 'loss': 'CE', 'lr': 0.0013644372304502897, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.512154862358641e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001326111370685828
weight_decay:  2.8747220489939567e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0520146831404418
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9929430289193988
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0026931669563055
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.090575695037842
total time:  3.1582066619303077
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.31
[I 2023-06-11 23:46:14,981] Trial 402 finished with value: 72.0 and parameters: {'Fwd': 0.042181019179803166, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.605223995547034, 'loop': 0, 'loss': 'CE', 'lr': 0.001326111370685828, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8747220489939567e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0013402437687696253
weight_decay:  3.3032470417205554e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0574048380367458
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0298212170600891
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0146462148986757
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.142052173614502
total time:  3.2042240740265697
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.29
[I 2023-06-11 23:46:18,662] Trial 403 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.042765217995787565, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.961319040652944, 'loop': 0, 'loss': 'CE', 'lr': 0.0013402437687696253, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.3032470417205554e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0013411492447225688
weight_decay:  4.308283685293379e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0003038209397346
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.071731291944161
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1594373690895736
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.2774031162261963
total time:  3.3374092099256814
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.35
[I 2023-06-11 23:46:22,492] Trial 404 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.0421453554572976, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.6425034784306956, 'loop': 0, 'loss': 'CE', 'lr': 0.0013411492447225688, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.308283685293379e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0013298026469982323
weight_decay:  4.278644266239227e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0531536529306322
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0564360301941633
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.1153700170107186
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.2736995220184326
total time:  3.3312056951690465
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.32
[I 2023-06-11 23:46:26,319] Trial 405 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.042995323552058526, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.532964199539016, 'loop': 0, 'loss': 'CE', 'lr': 0.0013298026469982323, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.278644266239227e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0011846414259482367
weight_decay:  5.540495711990731e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1761332140304148
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9390207810793072
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.90%
Split: 01, Run: 03
None time:  1.8332186678890139
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.90
run time now: 3.989475727081299
total time:  4.040763930883259
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.72
[I 2023-06-11 23:46:30,867] Trial 406 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.04225446688772838, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 6.7192953072604675, 'loop': 0, 'loss': 'CE', 'lr': 0.0011846414259482367, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.540495711990731e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0013341434931032359
weight_decay:  3.800173832256497e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0127415428869426
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0813511500600725
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.9918399460148066
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.127387285232544
total time:  3.174247493967414
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.25
[I 2023-06-11 23:46:34,529] Trial 407 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.04838600978483517, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.517887341929736, 'loop': 0, 'loss': 'CE', 'lr': 0.0013341434931032359, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.800173832256497e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0010905939297966877
weight_decay:  3.981505569455298e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8888949321117252
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9620011451188475
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.9248627899214625
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.818366050720215
total time:  2.8687231331132352
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.44
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 1.08
[I 2023-06-11 23:46:37,819] Trial 408 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.048490830583968636, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 6.835642639601573, 'loop': 0, 'loss': 'CE', 'lr': 0.0010905939297966877, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.981505569455298e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9500000000000001
lr:  0.0013049746971292428
weight_decay:  3.756028008094428e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0814121791627258
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.07764454302378
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0697545169387013
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.263629198074341
total time:  3.319510354893282
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.45
[I 2023-06-11 23:46:41,617] Trial 409 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.035167180230304095, 'K': 2, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 6.184215798258695, 'loop': 0, 'loss': 'CE', 'lr': 0.0013049746971292428, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.756028008094428e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0012008172209589793
weight_decay:  5.1435672882070116e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.60%
Split: 01, Run: 01
None time:  1.7180077477823943
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.40%
Split: 01, Run: 02
None time:  1.733121694996953
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.80%
Split: 01, Run: 03
None time:  1.793704055948183
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.60
run time now: 5.297703504562378
total time:  5.354348134016618
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.12
[I 2023-06-11 23:46:47,492] Trial 410 finished with value: 70.0666732788086 and parameters: {'Fwd': 0.051566157205389845, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.9039403163125215, 'loop': 0, 'loss': 'MSE', 'lr': 0.0012008172209589793, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.1435672882070116e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0014278783236566241
weight_decay:  4.744296118940932e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.067455373937264
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.070502249058336
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0880463030189276
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.2689785957336426
total time:  3.3236271070782095
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.50
[I 2023-06-11 23:46:51,274] Trial 411 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.06483831434131578, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.98905586879379, 'loop': 0, 'loss': 'CE', 'lr': 0.0014278783236566241, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.744296118940932e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0013466093218458626
weight_decay:  3.3614388436734885e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9895419918466359
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0256823140662163
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  1.0108790039084852
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
run time now: 3.069552421569824
total time:  3.1271595270372927
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 1.56
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 1.41
[I 2023-06-11 23:46:54,948] Trial 412 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.03263704280541071, 'K': 8, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 6.5681020329860385, 'loop': 0, 'loss': 'CE', 'lr': 0.0013466093218458626, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.3614388436734885e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0012617003860815896
weight_decay:  7.118438044567227e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0849264201242477
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0438034010585397
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.80%
Split: 01, Run: 03
None time:  1.8470675009302795
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 4.016360521316528
total time:  4.074047615984455
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.49
[I 2023-06-11 23:46:59,627] Trial 413 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.04912868403849669, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.515371968249602, 'loop': 0, 'loss': 'CE', 'lr': 0.0012617003860815896, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.118438044567227e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0010525157185807608
weight_decay:  4.2019023066978075e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9846381959505379
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0600927311461419
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 70.30%
Split: 01, Run: 03
None time:  1.7806920770090073
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.866407632827759
total time:  3.923487232066691
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.42
[I 2023-06-11 23:47:04,094] Trial 414 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.040026536345712044, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.721409835100443, 'loop': 0, 'loss': 'CE', 'lr': 0.0010525157185807608, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.2019023066978075e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0014467432349885797
weight_decay:  2.7847386072710472e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9537487120833248
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0159073339309543
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1065660337917507
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.116041421890259
total time:  3.166313141118735
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.31
[I 2023-06-11 23:47:07,853] Trial 415 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.06398974501678274, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.121763409072376, 'loop': 0, 'loss': 'CE', 'lr': 0.0014467432349885797, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.7847386072710472e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0012194103001524398
weight_decay:  6.0472298479655684e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.008718254044652
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9442664450034499
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.1082864811178297
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.1131885051727295
total time:  3.169221359072253
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.72
[I 2023-06-11 23:47:11,534] Trial 416 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.03175220764109647, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.935064553863781, 'loop': 0, 'loss': 'CE', 'lr': 0.0012194103001524398, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.0472298479655684e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0015614887666151663
weight_decay:  3.426989510969776e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 55.00% Test: 55.10%
Split: 01, Run: 01
None time:  1.246015323093161
None Run 01:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.10
Split: 01, Run: 02
None time:  0.6866941677872092
None Run 02:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 54.20
Split: 01, Run: 03
None time:  0.71970453299582
None Run 03:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 56.70
run time now: 2.6929407119750977
total time:  2.740238277008757
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.80 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 55.33 ± 1.27
[I 2023-06-11 23:47:14,738] Trial 417 finished with value: 54.79999923706055 and parameters: {'Fwd': 0.05302598728241969, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.370355703098347, 'loop': 0, 'loss': 'CE', 'lr': 0.0015614887666151663, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.426989510969776e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0011164526859015105
weight_decay:  2.7700834907041878e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.250201195012778
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.3539128440897912
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  2.0137346189003438
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 5.659300088882446
total time:  5.723513609962538
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.51
[I 2023-06-11 23:47:20,976] Trial 418 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.043994738794148266, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.55218508509701, 'loop': 2, 'loss': 'CE', 'lr': 0.0011164526859015105, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.7700834907041878e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0013418072641946173
weight_decay:  4.3313742555371355e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1778613009955734
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.2111060081515461
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.1215134251397103
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.5519402027130127
total time:  3.6093556149862707
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.21
[I 2023-06-11 23:47:25,103] Trial 419 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.07173915416081911, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 6.21963301609874, 'loop': 1, 'loss': 'CE', 'lr': 0.0013418072641946173, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.3313742555371355e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0014885163175181852
weight_decay:  2.4732995773988737e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1104693219531327
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0415681418962777
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0890078980010003
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.2848246097564697
total time:  3.340031886007637
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.56
[I 2023-06-11 23:47:28,984] Trial 420 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.036864231538572684, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 7.08996184615231, 'loop': 0, 'loss': 'CE', 'lr': 0.0014885163175181852, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.4732995773988737e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0013072543633073262
weight_decay:  3.285063691923803e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.09112315508537
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9960183540824801
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0344168059527874
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.1640210151672363
total time:  3.2124700411222875
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.45
[I 2023-06-11 23:47:32,684] Trial 421 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.053941747192417004, 'K': 8, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.806586307141903, 'loop': 0, 'loss': 'CE', 'lr': 0.0013072543633073262, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.285063691923803e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.001177997685614123
weight_decay:  2.1143673901905952e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9865733180195093
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0859420509077609
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.040400587953627
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.155322551727295
total time:  3.2125349638517946
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.17
[I 2023-06-11 23:47:36,372] Trial 422 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.07567705637382517, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.185957536167217, 'loop': 0, 'loss': 'CE', 'lr': 0.001177997685614123, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.1143673901905952e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0009520328187813068
weight_decay:  2.4452051495690516e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0091493560466915
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0199884460307658
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.9121741091366857
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.983668804168701
total time:  3.0464988499879837
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.92
[I 2023-06-11 23:47:39,983] Trial 423 finished with value: 69.86666870117188 and parameters: {'Fwd': 0.0009920862885891613, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 6.523381110673422, 'loop': 0, 'loss': 'CE', 'lr': 0.0009520328187813068, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.4452051495690516e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001426387565682158
weight_decay:  5.466877210721792e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5718459191266447
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.6251358960289508
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.6101706349290907
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.70
run time now: 1.864440679550171
total time:  1.9071117818821222
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.20 ± 0.44
[I 2023-06-11 23:47:42,373] Trial 424 finished with value: 70.0666732788086 and parameters: {'Fwd': 0.02838327922706619, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.152837343215059, 'loop': 0, 'loss': 'CE', 'lr': 0.001426387565682158, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.466877210721792e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0015615523923013506
weight_decay:  3.0931345484431136e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.103307815035805
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0410501740407199
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0333262730855495
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.21876859664917
total time:  3.2737249829806387
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.65
[I 2023-06-11 23:47:46,137] Trial 425 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.0005459530654608029, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.219297960353415, 'loop': 0, 'loss': 'CE', 'lr': 0.0015615523923013506, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.0931345484431136e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0012893729279979146
weight_decay:  7.86458698820865e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0449363570660353
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0591494580730796
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.1459167839493603
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.29313325881958
total time:  3.350027841050178
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.51
[I 2023-06-11 23:47:50,058] Trial 426 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.0003925420944646346, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.392755657068429, 'loop': 0, 'loss': 'CE', 'lr': 0.0012893729279979146, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.86458698820865e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0010390336680401785
weight_decay:  2.0125756403056267e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0041958938818425
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.097317713079974
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.00% Test: 70.50%
Split: 01, Run: 03
None time:  1.822261530905962
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.965158462524414
total time:  4.018093101913109
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.51
[I 2023-06-11 23:47:54,666] Trial 427 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.04174987825540827, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 6.912206332357985, 'loop': 0, 'loss': 'CE', 'lr': 0.0010390336680401785, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.0125756403056267e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0011516237022419602
weight_decay:  0.00030289021897111066
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.104282946093008
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1293440870940685
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.9742450478952378
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.2498769760131836
total time:  3.310523235006258
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.10
[I 2023-06-11 23:47:58,489] Trial 428 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.05859922961409751, 'K': 8, 'alpha': 0.8, 'dropout': 0.2, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.460445014227638, 'loop': 0, 'loss': 'CE', 'lr': 0.0011516237022419602, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00030289021897111066, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013985399872369858
weight_decay:  0.0005006179190816339
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 69.50%
Split: 01, Run: 01
None time:  1.8779829901177436
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.80%
Split: 01, Run: 02
None time:  1.7479575469624251
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 69.50%
Split: 01, Run: 03
None time:  1.7582258540205657
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.50
run time now: 5.4251320362091064
total time:  5.48451399593614
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.12
[I 2023-06-11 23:48:04,559] Trial 429 finished with value: 69.5999984741211 and parameters: {'Fwd': 0.03083053035981992, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.8893168866274985, 'loop': 0, 'loss': 'MSE', 'lr': 0.0013985399872369858, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005006179190816339, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001612958133725709
weight_decay:  5.609870826340359e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0222247368656099
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0715183531865478
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1103792609646916
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.245720386505127
total time:  3.3034133489709347
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.29
[I 2023-06-11 23:48:08,399] Trial 430 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.04430027700879352, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.000941320912161, 'loop': 0, 'loss': 'CE', 'lr': 0.001612958133725709, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.609870826340359e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0012726267536729452
weight_decay:  4.408817154990559e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9810125748626888
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.976961072999984
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.9972121468745172
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.9976117610931396
total time:  3.044511548941955
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 1.63
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 1.10
[I 2023-06-11 23:48:11,942] Trial 431 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.07903552157628481, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 6.685837726278284, 'loop': 0, 'loss': 'CE', 'lr': 0.0012726267536729452, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.408817154990559e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0014504713358709678
weight_decay:  2.40816684719256e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.031148012029007
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0367623020429164
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0000299620442092
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.1174535751342773
total time:  3.163592080818489
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 0.25
[I 2023-06-11 23:48:15,590] Trial 432 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.05547990442780336, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 5.619520349635519, 'loop': 0, 'loss': 'CE', 'lr': 0.0014504713358709678, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.40816684719256e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.9
lr:  0.0011361150992932052
weight_decay:  0.0002462425743104784
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0106175208929926
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9691654711496085
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.50%
Split: 01, Run: 03
None time:  1.5774110879283398
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.593252182006836
total time:  3.648745682090521
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.49
[I 2023-06-11 23:48:19,749] Trial 433 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.026060855886820857, 'K': 4, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.357855500395948, 'loop': 0, 'loss': 'CE', 'lr': 0.0011361150992932052, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002462425743104784, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0013230658298490656
weight_decay:  1.7152324708816897e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9902639291249216
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.9595370669849217
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.930586309870705
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.935824155807495
total time:  2.9937464979011565
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 1.34
[I 2023-06-11 23:48:23,248] Trial 434 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.001979559720428234, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 8.313698964745326, 'loop': 0, 'loss': 'CE', 'lr': 0.0013230658298490656, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.7152324708816897e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0016026092985793393
weight_decay:  0.00011673180239019802
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9560401781927794
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.0241826409474015
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0417050989344716
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.063005208969116
total time:  3.126318772090599
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.68
[I 2023-06-11 23:48:26,913] Trial 435 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.037112554535955744, 'K': 8, 'alpha': 0.8, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.5, 'lambda2': 8.688270998370598, 'loop': 0, 'loss': 'CE', 'lr': 0.0016026092985793393, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00011673180239019802, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001214903394344322
weight_decay:  3.294919975773892e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1132383819203824
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0421650970820338
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0993190750014037
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.297511100769043
total time:  3.366672867909074
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.64
[I 2023-06-11 23:48:30,772] Trial 436 finished with value: 71.86666107177734 and parameters: {'Fwd': 0.00012619880518783923, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 5.229758858296202, 'loop': 0, 'loss': 'CE', 'lr': 0.001214903394344322, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.294919975773892e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0014412538390294232
weight_decay:  2.0870353407727384e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7736209570430219
None Run 01:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 45.30
Split: 01, Run: 02
None time:  0.8994364168029279
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 99.17
   Final Test: 58.00
Split: 01, Run: 03
None time:  0.8760118058416992
None Run 03:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 99.17
   Final Test: 63.60
run time now: 2.5906713008880615
total time:  2.6488528680056334
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.40 ± 7.99
  Final Train: 99.44 ± 0.48
   Final Test: 55.63 ± 9.38
[I 2023-06-11 23:48:33,941] Trial 437 finished with value: 57.40000534057617 and parameters: {'Fwd': 0.0005602853964289164, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.981777246620407, 'loop': 0, 'loss': 'CE', 'lr': 0.0014412538390294232, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.0870353407727384e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.00029104667764309023
weight_decay:  7.495599648638225e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3133513971697539
None Run 01:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.00% Test: 59.40%
Split: 01, Run: 02
None time:  1.1274572680704296
None Run 02:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.30
Split: 01, Run: 03
None time:  0.311304050963372
None Run 03:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 57.70
run time now: 1.794170618057251
total time:  1.8445036690682173
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.80 ± 1.44
  Final Train: 100.00 ± 0.00
   Final Test: 58.37 ± 0.83
[I 2023-06-11 23:48:36,345] Trial 438 finished with value: 59.79999923706055 and parameters: {'Fwd': 0.06026822943482706, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 20, 'lambda1': 0.7000000000000001, 'lambda2': 6.710715118806645, 'loop': 0, 'loss': 'CE', 'lr': 0.00029104667764309023, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.495599648638225e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0010493843174678298
weight_decay:  1.4467456342133493e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1192102239001542
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0781802970450372
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.00% Test: 70.40%
Split: 01, Run: 03
None time:  1.7913231500424445
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 4.030736923217773
total time:  4.084027368109673
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.42
[I 2023-06-11 23:48:40,892] Trial 439 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.04584029451172253, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.439918594955094, 'loop': 0, 'loss': 'CE', 'lr': 0.0010493843174678298, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4467456342133493e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013346204849168037
weight_decay:  4.3159647187008274e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9577589640393853
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0554687390103936
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.1296002480667084
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.10
run time now: 3.1874828338623047
total time:  3.236632619984448
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.40 ± 0.62
[I 2023-06-11 23:48:44,614] Trial 440 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0017599785170002334, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 5.7674910883200745, 'loop': 0, 'loss': 'CE', 'lr': 0.0013346204849168037, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.3159647187008274e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  1.0
lr:  0.001207821680931852
weight_decay:  2.9359392290067334e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0368023649789393
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0304984180256724
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0600088010542095
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.1688308715820312
total time:  3.2166414309758693
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.62
[I 2023-06-11 23:48:48,355] Trial 441 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.035964269158303766, 'K': 8, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.992951327073204, 'loop': 0, 'loss': 'CE', 'lr': 0.001207821680931852, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.9359392290067334e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.0015253532671387728
weight_decay:  1.7575696014739892e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.07100562681444
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.0601170139852911
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.067603708943352
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.247720956802368
total time:  3.3115956301335245
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.82
[I 2023-06-11 23:48:52,176] Trial 442 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.07503015036712081, 'K': 10, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.066847496674103, 'loop': 0, 'loss': 'CE', 'lr': 0.0015253532671387728, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.7575696014739892e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.0016519640739464353
weight_decay:  1.1732542681922558e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9135623848997056
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.032987066078931
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.9918670579791069
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.981212854385376
total time:  3.0351619648281485
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 1.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.91
[I 2023-06-11 23:48:55,770] Trial 443 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.02786689023002821, 'K': 9, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 6.033723394313106, 'loop': 0, 'loss': 'CE', 'lr': 0.0016519640739464353, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.1732542681922558e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.000951659459808188
weight_decay:  2.3607091201283443e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.055572282988578
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0874198090750724
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 70.20%
Split: 01, Run: 03
None time:  1.8380811370443553
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 4.021554946899414
total time:  4.085065961116925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.50
[I 2023-06-11 23:49:00,327] Trial 444 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.051435280935286605, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 8.466522211920639, 'loop': 0, 'loss': 'CE', 'lr': 0.000951659459808188, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3607091201283443e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0013814951765570619
weight_decay:  3.732120263287142e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0547215430997312
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0722472621127963
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1272510171402246
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.2944843769073486
total time:  3.346686305012554
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.25
[I 2023-06-11 23:49:04,140] Trial 445 finished with value: 72.0 and parameters: {'Fwd': 0.06646501659458323, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.190178395364366, 'loop': 0, 'loss': 'CE', 'lr': 0.0013814951765570619, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.732120263287142e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0011541594655762038
weight_decay:  3.674625299818525e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0512057640589774
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.015716893132776
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.0692878761328757
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.176927089691162
total time:  3.2249277168884873
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.17
[I 2023-06-11 23:49:07,832] Trial 446 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.09668708267375864, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.143507525268873, 'loop': 0, 'loss': 'CE', 'lr': 0.0011541594655762038, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.674625299818525e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001284543828778687
weight_decay:  5.021935803740393e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0129380631260574
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.036101567093283
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0496204239316285
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.138915538787842
total time:  3.186517577851191
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.51
[I 2023-06-11 23:49:11,501] Trial 447 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.001200044474826116, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.460582231733341, 'loop': 0, 'loss': 'CE', 'lr': 0.001284543828778687, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.021935803740393e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0012473653656342037
weight_decay:  5.0543151230083815e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 69.60%
Split: 01, Run: 01
None time:  1.7203001859597862
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.30%
Split: 01, Run: 02
None time:  1.673838715068996
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.70%
Split: 01, Run: 03
None time:  1.7457083240151405
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 5.189197778701782
total time:  5.2425247938372195
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.25
[I 2023-06-11 23:49:17,287] Trial 448 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.0016866473201447053, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 7.275743093701569, 'loop': 0, 'loss': 'MSE', 'lr': 0.0012473653656342037, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.0543151230083815e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.000890605618645247
weight_decay:  6.028673254982913e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0261699729599059
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0674562030471861
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.093259806977585
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.227571964263916
total time:  3.284492520848289
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.53
[I 2023-06-11 23:49:21,036] Trial 449 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.0013720521135143053, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.391081658656127, 'loop': 0, 'loss': 'CE', 'lr': 0.000890605618645247, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.028673254982913e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0007554354221530428
weight_decay:  4.123365314555098e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1623916730750352
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.241221794160083
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.1453956679906696
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.5907530784606934
total time:  3.646198572125286
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.75
[I 2023-06-11 23:49:25,148] Trial 450 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.0037308888450011896, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.131020633884956, 'loop': 1, 'loss': 'CE', 'lr': 0.0007554354221530428, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.123365314555098e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0010564883334749282
weight_decay:  8.085823975981282e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.087043380131945
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0459107588976622
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.1256173960864544
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.2996482849121094
total time:  3.358164665987715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.42
[I 2023-06-11 23:49:29,035] Trial 451 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0003344067187971164, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.5645870869377205, 'loop': 0, 'loss': 'CE', 'lr': 0.0010564883334749282, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.085823975981282e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0012760856911461442
weight_decay:  3.62305788321028e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0303012700751424
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9783120700158179
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0776029299013317
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.1280252933502197
total time:  3.184607467846945
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.46
[I 2023-06-11 23:49:32,722] Trial 452 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.0006498010435779391, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.549558081931517, 'loop': 0, 'loss': 'CE', 'lr': 0.0012760856911461442, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.62305788321028e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0010987335208595588
weight_decay:  4.9934998387069876e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6800302839837968
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.6449200580827892
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.6988868080079556
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
run time now: 2.066000461578369
total time:  2.1267589579802006
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.42
[I 2023-06-11 23:49:35,367] Trial 453 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.06879022919755018, 'K': 8, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 6.722920886630933, 'loop': 0, 'loss': 'CE', 'lr': 0.0010987335208595588, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.9934998387069876e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0015189132511917059
weight_decay:  2.9022707191970952e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.30%
Split: 01, Run: 01
None time:  1.7938496398273855
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 71.10%
Split: 01, Run: 02
None time:  1.8690516371279955
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0769774809014052
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 71.40
run time now: 4.783018350601196
total time:  4.837837169878185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 70.33 ± 1.01
[I 2023-06-11 23:49:40,688] Trial 454 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.06624461493378074, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.05, 'lambda2': 6.534790794954294, 'loop': 0, 'loss': 'CE', 'lr': 0.0015189132511917059, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.9022707191970952e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0013794816366113803
weight_decay:  3.89115944362641e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0609405438881367
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.0231407689861953
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  0.8618939418811351
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.9936158657073975
total time:  3.0505316650960594
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 1.27
[I 2023-06-11 23:49:44,245] Trial 455 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.00525239105174428, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 6.912381418328064, 'loop': 0, 'loss': 'CE', 'lr': 0.0013794816366113803, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.89115944362641e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0011755588177922145
weight_decay:  6.255108073972359e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1075975559651852
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.086084911134094
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.042569138109684
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.277050018310547
total time:  3.3246167390607297
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.50
[I 2023-06-11 23:49:48,092] Trial 456 finished with value: 71.13333892822266 and parameters: {'Fwd': 0.0028503112798073217, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.368936686280904, 'loop': 0, 'loss': 'CE', 'lr': 0.0011755588177922145, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.255108073972359e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.001716585245448177
weight_decay:  2.9842850542336963e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7308810129761696
None Run 01:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 46.70
Split: 01, Run: 02
None time:  0.7717767769936472
None Run 02:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 46.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.00% Test: 60.00%
Split: 01, Run: 03
None time:  1.3395117518957704
None Run 03:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 59.70
run time now: 2.886998414993286
total time:  2.9426820350345224
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.87 ± 7.07
  Final Train: 100.00 ± 0.00
   Final Test: 50.97 ± 7.56
[I 2023-06-11 23:49:51,558] Trial 457 finished with value: 51.866668701171875 and parameters: {'Fwd': 0.07875001105146083, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.186129070428344, 'loop': 0, 'loss': 'CE', 'lr': 0.001716585245448177, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.9842850542336963e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0013103530525003311
weight_decay:  2.4611079545415355e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9870054700877517
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0390845669899136
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0502132079564035
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
run time now: 3.1165969371795654
total time:  3.15901037491858
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 70.30 ± 0.66
[I 2023-06-11 23:49:55,348] Trial 458 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.05594500410277922, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 8.690635623677764, 'loop': 0, 'loss': 'CE', 'lr': 0.0013103530525003311, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.4611079545415355e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.001467118710867173
weight_decay:  4.454854753039213e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0673070619814098
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1106066200882196
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1166863557882607
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.10
run time now: 3.335040330886841
total time:  3.3971380048897117
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.20 ± 0.82
[I 2023-06-11 23:49:59,209] Trial 459 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.003848425716979047, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.903397633239164, 'loop': 0, 'loss': 'CE', 'lr': 0.001467118710867173, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.454854753039213e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0009950873047510217
weight_decay:  3.226039418499758e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9693361900281161
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.9236955179367214
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  1.0373096570838243
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.90
run time now: 2.972639799118042
total time:  3.0375278629362583
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 1.37
[I 2023-06-11 23:50:02,719] Trial 460 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.04179494609665948, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 9.957049562909054, 'loop': 0, 'loss': 'CE', 'lr': 0.0009950873047510217, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.226039418499758e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001619105509740958
weight_decay:  8.620694032856175e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.165226235985756
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.9830552509520203
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.0036903431173414
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.2098796367645264
total time:  3.2732054609805346
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.46
[I 2023-06-11 23:50:06,566] Trial 461 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0004688054906569339, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.812883558245898, 'loop': 0, 'loss': 'CE', 'lr': 0.001619105509740958, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.620694032856175e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012549381890495704
weight_decay:  0.0003671631853344612
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.109065973898396
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0498346858657897
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 70.60%
Split: 01, Run: 03
None time:  1.826905441004783
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 4.032057523727417
total time:  4.078142320970073
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.31
[I 2023-06-11 23:50:11,152] Trial 462 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.06216644357254106, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.561481470777001, 'loop': 0, 'loss': 'CE', 'lr': 0.0012549381890495704, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0003671631853344612, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.001444792511428725
weight_decay:  0.0048893982019320515
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0394960171543062
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.046941943001002
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.40%
Split: 01, Run: 03
None time:  1.8812347410712391
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 4.011186122894287
total time:  4.0687640339601785
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.51
[I 2023-06-11 23:50:15,698] Trial 463 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.02356345622904585, 'K': 9, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 6.35936175261067, 'loop': 0, 'loss': 'CE', 'lr': 0.001444792511428725, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0048893982019320515, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0011593253936270907
weight_decay:  5.783983919932811e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.052407891023904
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.079254019074142
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1567195910029113
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.10
run time now: 3.339028835296631
total time:  3.3966022699605674
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.23 ± 0.78
[I 2023-06-11 23:50:19,588] Trial 464 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0047261019230101405, 'K': 8, 'alpha': 0.65, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 8.356740388865646, 'loop': 0, 'loss': 'CE', 'lr': 0.0011593253936270907, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.783983919932811e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013397680232316602
weight_decay:  2.451558764393385e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9667656549718231
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0451870530378073
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.020848484011367
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.075711727142334
total time:  3.1333047640509903
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 1.30
[I 2023-06-11 23:50:23,179] Trial 465 finished with value: 70.13333129882812 and parameters: {'Fwd': 1.3099790110454738e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 9.122990248081674, 'loop': 0, 'loss': 'CE', 'lr': 0.0013397680232316602, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.451558764393385e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.9
lr:  0.0015226333628853709
weight_decay:  3.692705839277491e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0063406641129404
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9841717528179288
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.1326576529536396
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.160738706588745
total time:  3.205930717056617
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.26
[I 2023-06-11 23:50:26,910] Trial 466 finished with value: 71.73333740234375 and parameters: {'Fwd': 5.0742563780920816e-05, 'K': 5, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.04414009280545, 'loop': 0, 'loss': 'CE', 'lr': 0.0015226333628853709, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.692705839277491e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0010661509633183356
weight_decay:  0.0001621460880298039
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 69.20%
Split: 01, Run: 01
None time:  1.684064564993605
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 69.90%
Split: 01, Run: 02
None time:  1.8223137638997287
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.092436607927084
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 4.640432119369507
total time:  4.705757790012285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.40
[I 2023-06-11 23:50:32,094] Trial 467 finished with value: 70.19999694824219 and parameters: {'Fwd': 0.084180879720028, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.217389795986839, 'loop': 0, 'loss': 'MSE', 'lr': 0.0010661509633183356, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001621460880298039, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.00010484026800612553
weight_decay:  2.0481939578612554e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.40% Test: 66.10%
Split: 01, Run: 01
None time:  1.8164236010052264
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.60% Test: 67.00%
Split: 01, Run: 02
None time:  1.7752177228685468
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.60% Test: 68.70%
Split: 01, Run: 03
None time:  1.7946440861560404
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 68.70
run time now: 5.430755615234375
total time:  5.483072876930237
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 67.17 ± 1.46
[I 2023-06-11 23:50:38,063] Trial 468 finished with value: 65.86666870117188 and parameters: {'Fwd': 0.04811872866255595, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.391020043614321, 'loop': 0, 'loss': 'CE', 'lr': 0.00010484026800612553, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.0481939578612554e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001217888854992023
weight_decay:  2.8202209395085454e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.12368761212565
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0442071279976517
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.143857718911022
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.20
run time now: 3.365461587905884
total time:  3.4380946080200374
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.30 ± 0.82
[I 2023-06-11 23:50:42,020] Trial 469 finished with value: 71.53333282470703 and parameters: {'Fwd': 5.148398863017563e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.828334401318473, 'loop': 0, 'loss': 'CE', 'lr': 0.001217888854992023, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8202209395085454e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0016670991168797986
weight_decay:  4.766997710714041e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0842554550617933
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0395594099536538
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.9842053221073002
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.1502904891967773
total time:  3.206011219881475
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.42
[I 2023-06-11 23:50:45,825] Trial 470 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.000822062979778621, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.713592483548528, 'loop': 0, 'loss': 'CE', 'lr': 0.0016670991168797986, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.766997710714041e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9
lr:  0.0009023438513676993
weight_decay:  0.00010999463553860074
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9268589809071273
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9777771441731602
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  1.0685071439947933
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.0110669136047363
total time:  3.0542189269326627
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 1.11
[I 2023-06-11 23:50:49,425] Trial 471 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.03661241874221954, 'K': 1, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 5.64858095255677, 'loop': 0, 'loss': 'CE', 'lr': 0.0009023438513676993, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00010999463553860074, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.001376693635931286
weight_decay:  0.00013592280146728115
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9884238049853593
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0861464620102197
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1476663628127426
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.2637622356414795
total time:  3.315727058099583
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.50
[I 2023-06-11 23:50:53,243] Trial 472 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.000980774169025204, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.72441588380298, 'loop': 0, 'loss': 'CE', 'lr': 0.001376693635931286, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00013592280146728115, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0012563444007684138
weight_decay:  9.929760848756747e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.993782059988007
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0828528460115194
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 70.30%
Split: 01, Run: 03
None time:  1.8839531431440264
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 4.00252366065979
total time:  4.060770857846364
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.20
[I 2023-06-11 23:50:57,982] Trial 473 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.09884388737539329, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.557733546228, 'loop': 0, 'loss': 'CE', 'lr': 0.0012563444007684138, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.929760848756747e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001537722270753687
weight_decay:  0.0018160214580081112
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0967701659537852
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0563851450569928
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0778538468293846
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.273813247680664
total time:  3.325216182973236
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.21
[I 2023-06-11 23:51:01,783] Trial 474 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.062408058203725865, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.582595340419202, 'loop': 0, 'loss': 'CE', 'lr': 0.001537722270753687, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0018160214580081112, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.005992188167876205
weight_decay:  1.8839378546577125e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.206173888174817
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.1414669768419117
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 98.33
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.0971037580166012
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.487955331802368
total time:  3.54350790893659
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.12
  Final Train: 99.17 ± 0.83
   Final Test: 69.60 ± 0.36
[I 2023-06-11 23:51:05,959] Trial 475 finished with value: 70.73332977294922 and parameters: {'Fwd': 3.2575830450293266e-06, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.099011786209605, 'loop': 0, 'loss': 'CE', 'lr': 0.005992188167876205, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.8839378546577125e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0011135287955580824
weight_decay:  6.690344709818506e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0404661879874766
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.049897882854566
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.045555355027318
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.1772522926330566
total time:  3.235759997041896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.59
[I 2023-06-11 23:51:09,657] Trial 476 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.0004247760831477733, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 5.403810504791831, 'loop': 0, 'loss': 'CE', 'lr': 0.0011135287955580824, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.690344709818506e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.004704889271916326
weight_decay:  0.012607557247163694
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1328285369090736
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.1808953671716154
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.063988264882937
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.50
run time now: 3.4238779544830322
total time:  3.4931832829024643
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.12
  Final Train: 98.89 ± 0.48
   Final Test: 69.90 ± 0.36
[I 2023-06-11 23:51:13,653] Trial 477 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.0002691378348100551, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.9111037685769645, 'loop': 0, 'loss': 'CE', 'lr': 0.004704889271916326, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.012607557247163694, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.00016122798941781816
weight_decay:  3.083803804040929e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 65.40%
Split: 01, Run: 01
None time:  1.2622589729726315
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 65.10
Split: 01, Run: 02
None time:  0.6955321750137955
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.40% Test: 64.80%
Split: 01, Run: 03
None time:  1.225903965998441
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.50
run time now: 3.2252695560455322
total time:  3.2730869711376727
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.07 ± 1.81
  Final Train: 100.00 ± 0.00
   Final Test: 65.20 ± 0.75
[I 2023-06-11 23:51:17,449] Trial 478 finished with value: 67.06665802001953 and parameters: {'Fwd': 0.028668933986562516, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 7.693567192822431, 'loop': 0, 'loss': 'CE', 'lr': 0.00016122798941781816, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.083803804040929e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.001409180671492594
weight_decay:  1.3021106379400554e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0044777328148484
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0818538200110197
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1000717689748853
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.90
run time now: 3.2278783321380615
total time:  3.280875438125804
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.68
[I 2023-06-11 23:51:21,298] Trial 479 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.00021114621526651813, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.152960769623151, 'loop': 0, 'loss': 'CE', 'lr': 0.001409180671492594, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3021106379400554e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.8500000000000001
lr:  0.0009909079017122408
weight_decay:  0.0005312805974097579
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1373199662193656
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.120290705934167
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.1281201429665089
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.4235596656799316
total time:  3.478491249959916
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.55
[I 2023-06-11 23:51:25,267] Trial 480 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.0003329245980271837, 'K': 3, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.321852552457351, 'loop': 0, 'loss': 'CE', 'lr': 0.0009909079017122408, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005312805974097579, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.001693621834175902
weight_decay:  2.2941937479620706e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.194933838211
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0699127360712737
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.1184616598766297
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.60
run time now: 3.4353702068328857
total time:  3.4854167220182717
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.23 ± 0.57
[I 2023-06-11 23:51:29,264] Trial 481 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.0011783152391168878, 'K': 8, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.629905599530112, 'loop': 1, 'loss': 'CE', 'lr': 0.001693621834175902, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2941937479620706e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.0013052528784571558
weight_decay:  3.869238254476619e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0517824080307037
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0641868589445949
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1152694139163941
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.90
run time now: 3.2800793647766113
total time:  3.3380652819760144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.68
[I 2023-06-11 23:51:33,079] Trial 482 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.0012152031229955146, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.508715409464486, 'loop': 0, 'loss': 'CE', 'lr': 0.0013052528784571558, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.869238254476619e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0011698620120098755
weight_decay:  1.911036303221985e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8932038659695536
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0427396630402654
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.9348660849500448
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.90
run time now: 2.911529541015625
total time:  2.9703134959563613
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 1.18
[I 2023-06-11 23:51:36,530] Trial 483 finished with value: 70.13333892822266 and parameters: {'Fwd': 0.0006709789214230453, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 6.777407674354866, 'loop': 0, 'loss': 'CE', 'lr': 0.0011698620120098755, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.911036303221985e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0014900814608420077
weight_decay:  2.581388402863731e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.120790959103033
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0966423840727657
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.1581576010212302
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.4184563159942627
total time:  3.4788265470415354
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.55
[I 2023-06-11 23:51:40,503] Trial 484 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.00015051467500667586, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 8.877539025045067, 'loop': 0, 'loss': 'CE', 'lr': 0.0014900814608420077, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.581388402863731e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013451006464758855
weight_decay:  0.0007782530917397301
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9675334289204329
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0498947238083929
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0632422920316458
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.121183156967163
total time:  3.1720605338923633
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.36
[I 2023-06-11 23:51:44,211] Trial 485 finished with value: 72.0 and parameters: {'Fwd': 0.043646905613037267, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.460281493330312, 'loop': 0, 'loss': 'CE', 'lr': 0.0013451006464758855, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007782530917397301, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0012383805982482165
weight_decay:  0.0012513613868438624
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9644867000170052
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0020881791133434
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0811439352110028
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.0883569717407227
total time:  3.145279407966882
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.49
[I 2023-06-11 23:51:47,861] Trial 486 finished with value: 71.93333435058594 and parameters: {'Fwd': 2.246109857124923e-06, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.041016913234772, 'loop': 0, 'loss': 'CE', 'lr': 0.0012383805982482165, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0012513613868438624, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0011173951426382536
weight_decay:  0.0018927782704230053
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.50%
Split: 01, Run: 01
None time:  1.756024147151038
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.70%
Split: 01, Run: 02
None time:  1.8088016400579363
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 69.60%
Split: 01, Run: 03
None time:  1.8041247089859098
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.60
run time now: 5.410748243331909
total time:  5.467655434040353
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.10
[I 2023-06-11 23:51:53,899] Trial 487 finished with value: 70.0 and parameters: {'Fwd': 0.0022970038212877697, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.853873797783335, 'loop': 0, 'loss': 'MSE', 'lr': 0.0011173951426382536, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0018927782704230053, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.0007344421114978206
weight_decay:  0.001086523348533165
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0744624328799546
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.1110427628736943
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.0563709689304233
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.2833621501922607
total time:  3.3381520081311464
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.38
[I 2023-06-11 23:51:57,737] Trial 488 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.07532278738090374, 'K': 9, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.32540526648334, 'loop': 0, 'loss': 'CE', 'lr': 0.0007344421114978206, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001086523348533165, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0011893853212902718
weight_decay:  0.0007512710633237333
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9468494059983641
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.0684973350726068
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  0.9251433329191059
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.9815659523010254
total time:  3.0343261379748583
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 1.47
[I 2023-06-11 23:52:01,382] Trial 489 finished with value: 70.13333892822266 and parameters: {'Fwd': 3.627013003822317e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 9.216931834500524, 'loop': 0, 'loss': 'CE', 'lr': 0.0011893853212902718, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007512710633237333, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0008521224445141481
weight_decay:  0.001230099098805373
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9781573379877955
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.061934102093801
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.131840460933745
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.212228775024414
total time:  3.2596204958390445
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.60
[I 2023-06-11 23:52:05,142] Trial 490 finished with value: 71.0 and parameters: {'Fwd': 2.5252414762572525e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.27714450823189, 'loop': 0, 'loss': 'CE', 'lr': 0.0008521224445141481, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001230099098805373, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001271211850490216
weight_decay:  0.0009361095976897816
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9915744059253484
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.065562724135816
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.1084726720582694
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.2071189880371094
total time:  3.2687504270579666
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.59
[I 2023-06-11 23:52:08,857] Trial 491 finished with value: 71.93333435058594 and parameters: {'Fwd': 1.3681752486083252e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.736886962442684, 'loop': 0, 'loss': 'CE', 'lr': 0.001271211850490216, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009361095976897816, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0010111383324602936
weight_decay:  0.0007994123005645153
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.033502658130601
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0437135100364685
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.1105563470628113
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.2317516803741455
total time:  3.285470373928547
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.53
[I 2023-06-11 23:52:12,571] Trial 492 finished with value: 71.46666717529297 and parameters: {'Fwd': 1.9908657045838128e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.413262772696502, 'loop': 0, 'loss': 'CE', 'lr': 0.0010111383324602936, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0007994123005645153, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0012413832020848727
weight_decay:  0.0010686767816297424
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4511376798618585
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.4863583769183606
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 03
None time:  0.45523587707430124
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.80
run time now: 1.4336719512939453
total time:  1.480844764970243
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 1.91
  Final Train: 100.00 ± 0.00
   Final Test: 68.20 ± 2.12
[I 2023-06-11 23:52:14,599] Trial 493 finished with value: 69.20000457763672 and parameters: {'Fwd': 1.032554346824167e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 40, 'lambda1': 0.55, 'lambda2': 9.866734100419094, 'loop': 0, 'loss': 'CE', 'lr': 0.0012413832020848727, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0010686767816297424, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.001058413311091664
weight_decay:  0.0007430896763539266
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0972391569521278
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0347092770971358
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0299794061575085
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.2046563625335693
total time:  3.264897827990353
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.40
[I 2023-06-11 23:52:18,333] Trial 494 finished with value: 71.20000457763672 and parameters: {'Fwd': 1.8303149503205788e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.75694861852551, 'loop': 0, 'loss': 'CE', 'lr': 0.001058413311091664, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007430896763539266, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0012721707624720692
weight_decay:  0.000669457562083755
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9228700581006706
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9922337019816041
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  0.8726411070674658
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.8318495750427246
total time:  2.8786696549504995
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 1.59
[I 2023-06-11 23:52:21,792] Trial 495 finished with value: 70.13333129882812 and parameters: {'Fwd': 1.291648770246693e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 9.705327566130514, 'loop': 0, 'loss': 'CE', 'lr': 0.0012721707624720692, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000669457562083755, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0056787086803857315
weight_decay:  0.0009123983231916805
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 70.30%
Split: 01, Run: 01
None time:  1.795812435913831
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.40%
Split: 01, Run: 02
None time:  1.8863575460854918
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.0943832991179079
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 4.816721677780151
total time:  4.878626463934779
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.46
[I 2023-06-11 23:52:27,141] Trial 496 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.05405725076145523, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 9.664569975577471, 'loop': 0, 'loss': 'CE', 'lr': 0.0056787086803857315, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009123983231916805, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001838092394685177
weight_decay:  0.00142277769392129
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0704528749920428
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.087226043920964
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0957680421415716
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.29561448097229
total time:  3.346267496002838
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.15
[I 2023-06-11 23:52:30,994] Trial 497 finished with value: 71.53333282470703 and parameters: {'Fwd': 1.60999972778209e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.894679306392804, 'loop': 0, 'loss': 'CE', 'lr': 0.001838092394685177, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00142277769392129, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0011239191620500738
weight_decay:  0.0010352231577794868
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9195535168983042
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.9773180279880762
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.9748268350958824
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.917692184448242
total time:  2.9715997797902673
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 1.45
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.98
[I 2023-06-11 23:52:34,470] Trial 498 finished with value: 70.06666564941406 and parameters: {'Fwd': 1.311548333158847e-06, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 9.425622543243662, 'loop': 0, 'loss': 'CE', 'lr': 0.0011239191620500738, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0010352231577794868, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0006412627469276547
weight_decay:  0.0005578597005252557
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7525869298260659
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.00
Split: 01, Run: 02
None time:  0.8089742781594396
None Run 02:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 99.17
   Final Test: 62.60
Split: 01, Run: 03
None time:  0.7903074200730771
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.70
run time now: 2.3967761993408203
total time:  2.4571381870191544
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.20 ± 0.60
  Final Train: 99.72 ± 0.48
   Final Test: 61.77 ± 0.97
[I 2023-06-11 23:52:37,373] Trial 499 finished with value: 62.20000076293945 and parameters: {'Fwd': 4.126513184258949e-06, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.539930392670264, 'loop': 0, 'loss': 'CE', 'lr': 0.0006412627469276547, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0005578597005252557, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0015248722066404565
weight_decay:  0.0020775542771233595
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0242245581466705
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9683453869074583
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.1529852449893951
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.187350273132324
total time:  3.2462652681861073
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.56
[I 2023-06-11 23:52:41,159] Trial 500 finished with value: 71.66666412353516 and parameters: {'Fwd': 2.459995395922561e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 6.965856644780486, 'loop': 0, 'loss': 'CE', 'lr': 0.0015248722066404565, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0020775542771233595, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.00124919295297575
weight_decay:  0.001335056369364972
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8524976880289614
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9613557250704616
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.934114808915183
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.7887840270996094
total time:  2.8346307040192187
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.47
[I 2023-06-11 23:52:44,629] Trial 501 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.0022928645691567976, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 7.153487519664156, 'loop': 0, 'loss': 'CE', 'lr': 0.00124919295297575, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001335056369364972, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0014092938980538546
weight_decay:  0.00046602529145832537
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8680549471173435
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.896019778912887
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  0.8450927007943392
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.6497700214385986
total time:  2.70189452287741
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.75
[I 2023-06-11 23:52:47,907] Trial 502 finished with value: 71.26666259765625 and parameters: {'Fwd': 3.4007282449732212e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.8, 'lambda2': 6.449128374219573, 'loop': 0, 'loss': 'CE', 'lr': 0.0014092938980538546, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00046602529145832537, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0009636203837900827
weight_decay:  5.3878766489642544e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.039920340059325
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0629896139726043
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0974441750440747
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.2430825233459473
total time:  3.3102884620893747
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.50
[I 2023-06-11 23:52:51,743] Trial 503 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.00010398920419244039, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.53825122965391, 'loop': 0, 'loss': 'CE', 'lr': 0.0009636203837900827, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.3878766489642544e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0016425027798036053
weight_decay:  0.0002882847237737446
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3291545289102942
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.246730657061562
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.235397612908855
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.854462146759033
total time:  3.898418519180268
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.37 ± 0.32
[I 2023-06-11 23:52:56,138] Trial 504 finished with value: 71.20000457763672 and parameters: {'Fwd': 7.693095944978286e-05, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.93211524679442, 'loop': 2, 'loss': 'CE', 'lr': 0.0016425027798036053, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002882847237737446, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001208412109574082
weight_decay:  0.00020138915122994115
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0838649100624025
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.004393155919388
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.132228516973555
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.2607717514038086
total time:  3.3146609070245177
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.62
[I 2023-06-11 23:52:59,961] Trial 505 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.001046902796398467, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.199931770081315, 'loop': 0, 'loss': 'CE', 'lr': 0.001208412109574082, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00020138915122994115, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.00043488818526183785
weight_decay:  0.0005720194302835673
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.229906793916598
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.017761378083378
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.2362390561029315
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 3.526639461517334
total time:  3.5730573188047856
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.10
[I 2023-06-11 23:53:04,012] Trial 506 finished with value: 70.26667022705078 and parameters: {'Fwd': 2.504288812035301e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.28499204011403, 'loop': 0, 'loss': 'CE', 'lr': 0.00043488818526183785, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005720194302835673, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.00035551065200948467
weight_decay:  0.0009023926893331
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.80% Test: 65.00%
Split: 01, Run: 01
None time:  1.7158157709054649
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.80% Test: 65.10%
Split: 01, Run: 02
None time:  1.8481419389136136
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 65.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.60% Test: 65.90%
Split: 01, Run: 03
None time:  1.8572830420453101
None Run 03:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.00
run time now: 5.465686082839966
total time:  5.5253021460957825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.73 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 65.37 ± 0.55
[I 2023-06-11 23:53:10,064] Trial 507 finished with value: 65.73333740234375 and parameters: {'Fwd': 2.797130823611161e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 8.9789719003732, 'loop': 0, 'loss': 'MSE', 'lr': 0.00035551065200948467, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009023926893331, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.00024457852931512517
weight_decay:  0.00040217589412039725
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0707853778731078
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0031549190171063
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1280683958902955
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.2437057495117188
total time:  3.2961010409053415
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.38
[I 2023-06-11 23:53:13,914] Trial 508 finished with value: 69.46666717529297 and parameters: {'Fwd': 1.8617567927506273e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.541201048624728, 'loop': 0, 'loss': 'CE', 'lr': 0.00024457852931512517, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00040217589412039725, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.001151979815147948
weight_decay:  0.0009483194522503333
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0347103218082339
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0658128049690276
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.0162389210890979
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.158396005630493
total time:  3.2122374491300434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.55
[I 2023-06-11 23:53:17,572] Trial 509 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.00018173310873674666, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.17902932520465, 'loop': 0, 'loss': 'CE', 'lr': 0.001151979815147948, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0009483194522503333, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0010571422824492143
weight_decay:  0.0012785085504878316
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9920431377831846
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.9738881390076131
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  1.040833543986082
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.048832893371582
total time:  3.099413188872859
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 1.27
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 1.59
[I 2023-06-11 23:53:21,131] Trial 510 finished with value: 70.06666564941406 and parameters: {'Fwd': 1.3080735094468145e-06, 'K': 8, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 6.94640469119765, 'loop': 0, 'loss': 'CE', 'lr': 0.0010571422824492143, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0012785085504878316, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0008337151496509772
weight_decay:  0.0006307095815848435
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1053358800709248
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.1053728619590402
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.106705549173057
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.369946241378784
total time:  3.417266375850886
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.50
[I 2023-06-11 23:53:25,038] Trial 511 finished with value: 70.93333435058594 and parameters: {'Fwd': 0.00016806082201737226, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.607674378826028, 'loop': 0, 'loss': 'CE', 'lr': 0.0008337151496509772, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006307095815848435, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0012358442243855124
weight_decay:  0.001259406313108079
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.086445044958964
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0321379019878805
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.157295798882842
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.3197290897369385
total time:  3.3804665310308337
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.46
[I 2023-06-11 23:53:28,920] Trial 512 finished with value: 71.93333435058594 and parameters: {'Fwd': 8.285550280462803e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.381876176546399, 'loop': 0, 'loss': 'CE', 'lr': 0.0012358442243855124, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001259406313108079, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0011283760389646448
weight_decay:  0.00017402034293185234
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0628121320623904
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1164673380553722
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.1076893729623407
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.3292877674102783
total time:  3.3867610450834036
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.55
[I 2023-06-11 23:53:32,898] Trial 513 finished with value: 71.73332977294922 and parameters: {'Fwd': 4.097263267162206e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.400535995844342, 'loop': 0, 'loss': 'CE', 'lr': 0.0011283760389646448, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00017402034293185234, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001215034207413959
weight_decay:  0.0012056132096886468
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9426561850123107
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0232159639708698
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.9620272070169449
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.988410234451294
total time:  3.04310584301129
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 1.51
[I 2023-06-11 23:53:36,499] Trial 514 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.006065803055006426, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 9.170098884079001, 'loop': 0, 'loss': 'CE', 'lr': 0.001215034207413959, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0012056132096886468, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.0009101854571785449
weight_decay:  0.000256519374875565
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7721003510523587
None Run 01:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 99.17
   Final Test: 52.00
Split: 01, Run: 02
None time:  0.8527239209506661
None Run 02:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 99.17
   Final Test: 57.10
Split: 01, Run: 03
None time:  0.8029396599158645
None Run 03:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 98.33
   Final Test: 59.10
run time now: 2.470979928970337
total time:  2.524084674892947
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.80 ± 1.59
  Final Train: 98.89 ± 0.48
   Final Test: 56.07 ± 3.66
[I 2023-06-11 23:53:39,537] Trial 515 finished with value: 56.79999923706055 and parameters: {'Fwd': 7.542101562987907e-06, 'K': 9, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.702775345997646, 'loop': 0, 'loss': 'CE', 'lr': 0.0009101854571785449, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.000256519374875565, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0012415926637172412
weight_decay:  0.0015564001679881595
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.035716295009479
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.069661189103499
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1167312529869378
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.2660915851593018
total time:  3.3224074200261384
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.66
[I 2023-06-11 23:53:43,344] Trial 516 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.00010740382586999312, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.672769308234441, 'loop': 0, 'loss': 'CE', 'lr': 0.0012415926637172412, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0015564001679881595, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0014644686511206362
weight_decay:  0.0009223986507842928
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0216716930735856
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0138900568708777
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1191127500496805
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.1964216232299805
total time:  3.2473905328661203
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.65
[I 2023-06-11 23:53:47,079] Trial 517 finished with value: 71.66667175292969 and parameters: {'Fwd': 1.394527571728733e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.134529839385847, 'loop': 0, 'loss': 'CE', 'lr': 0.0014644686511206362, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009223986507842928, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0009870555728759163
weight_decay:  0.002327945361146137
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1588289740029722
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1409846059978008
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.1542581079993397
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.70
run time now: 3.4959824085235596
total time:  3.547377329086885
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 0.52
[I 2023-06-11 23:53:51,127] Trial 518 finished with value: 70.5999984741211 and parameters: {'Fwd': 6.280322438530493e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 8.905861611254384, 'loop': 1, 'loss': 'CE', 'lr': 0.0009870555728759163, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.002327945361146137, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0005025595773040485
weight_decay:  0.0015700945690543325
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9872616631910205
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.055011214921251
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  1.073347776895389
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.1568500995635986
total time:  3.2041115039028227
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.07 ± 1.42
  Final Train: 100.00 ± 0.00
   Final Test: 68.80 ± 1.05
[I 2023-06-11 23:53:54,809] Trial 519 finished with value: 69.06666564941406 and parameters: {'Fwd': 0.00030448150891517145, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 6.234374319552599, 'loop': 0, 'loss': 'CE', 'lr': 0.0005025595773040485, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0015700945690543325, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013150322846362521
weight_decay:  0.0007426425738665673
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0530451908707619
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0744223510846496
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1197737550828606
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.30
run time now: 3.289402723312378
total time:  3.3370645658578724
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.27 ± 0.93
[I 2023-06-11 23:53:58,710] Trial 520 finished with value: 71.5999984741211 and parameters: {'Fwd': 1.0422160609560346e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.420366001283314, 'loop': 0, 'loss': 'CE', 'lr': 0.0013150322846362521, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007426425738665673, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.00178293898402484
weight_decay:  0.0010357132361354488
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0636310430709273
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0988933071494102
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0848243290092796
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.2889556884765625
total time:  3.3502460159361362
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.31
[I 2023-06-11 23:54:02,580] Trial 521 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.0001882090027884734, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 8.92348967890748, 'loop': 0, 'loss': 'CE', 'lr': 0.00178293898402484, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0010357132361354488, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.007717916034071523
weight_decay:  0.0015570068329180413
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1508196638897061
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.114543406991288
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.13385144690983
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.4417030811309814
total time:  3.507004987914115
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.53
  Final Train: 99.44 ± 0.48
   Final Test: 69.43 ± 0.31
[I 2023-06-11 23:54:06,553] Trial 522 finished with value: 70.4000015258789 and parameters: {'Fwd': 6.188250985012617e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 7.420881655860248, 'loop': 0, 'loss': 'CE', 'lr': 0.007717916034071523, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0015570068329180413, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0010887930291305858
weight_decay:  0.0005469532216910098
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0716063601430506
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1136183349881321
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.109756438061595
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.3361895084381104
total time:  3.391749707981944
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.59
[I 2023-06-11 23:54:10,439] Trial 523 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.00024300345291809435, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 8.442371853562914, 'loop': 0, 'loss': 'CE', 'lr': 0.0010887930291305858, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005469532216910098, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001193075108145321
weight_decay:  0.002406321299249358
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.764709061011672
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.7188471409026533
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.7352681399788707
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 2.259361743927002
total time:  2.3360018129460514
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.21
[I 2023-06-11 23:54:13,389] Trial 524 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.0010707856780117228, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.75, 'lambda2': 8.626572537542971, 'loop': 0, 'loss': 'CE', 'lr': 0.001193075108145321, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002406321299249358, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0015392505993735903
weight_decay:  0.00018337071399345285
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.101455138064921
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.020958575187251
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1673749508336186
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.3306045532226562
total time:  3.385955971898511
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.60
[I 2023-06-11 23:54:17,273] Trial 525 finished with value: 71.5999984741211 and parameters: {'Fwd': 2.4872828534364233e-05, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.059799187654691, 'loop': 0, 'loss': 'CE', 'lr': 0.0015392505993735903, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00018337071399345285, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0013387253503309774
weight_decay:  0.0003744125218999858
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.40% Test: 68.50%
Split: 01, Run: 01
None time:  1.7815463219303638
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.00% Test: 68.40%
Split: 01, Run: 02
None time:  1.7495648139156401
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.80% Test: 68.90%
Split: 01, Run: 03
None time:  1.6403683768585324
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.80
run time now: 5.213390350341797
total time:  5.2561298061627895
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 68.53 ± 0.25
[I 2023-06-11 23:54:23,044] Trial 526 finished with value: 67.73332977294922 and parameters: {'Fwd': 0.003127538068673888, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.1, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 9.027475136599186, 'loop': 0, 'loss': 'MSE', 'lr': 0.0013387253503309774, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003744125218999858, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0014072567764296798
weight_decay:  0.0006925405543389158
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1033063579816371
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9919799577910453
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1181857432238758
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.254865884780884
total time:  3.311674459138885
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.36
[I 2023-06-11 23:54:26,791] Trial 527 finished with value: 71.66666412353516 and parameters: {'Fwd': 8.093788204952939e-05, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.180462860449074, 'loop': 0, 'loss': 'CE', 'lr': 0.0014072567764296798, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006925405543389158, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.0011623826002217395
weight_decay:  0.001199748483507304
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9860852370038629
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0089628850109875
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  1.0151323238387704
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.051818609237671
total time:  3.101128197973594
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 1.10
[I 2023-06-11 23:54:30,428] Trial 528 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.0006170300443957973, 'K': 9, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 9.96683988391308, 'loop': 0, 'loss': 'CE', 'lr': 0.0011623826002217395, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001199748483507304, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0015966552461342438
weight_decay:  0.0002124705431422281
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4724197220057249
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.511745996074751
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.5191688660997897
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.90
run time now: 1.5535533428192139
total time:  1.6075355762150139
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 70.20 ± 0.82
[I 2023-06-11 23:54:32,525] Trial 529 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0005112448182807022, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 6.457374003279814, 'loop': 0, 'loss': 'CE', 'lr': 0.0015966552461342438, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002124705431422281, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0012650362421669664
weight_decay:  0.0008264895695251227
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0175138630438596
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0857255898881704
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.067021206021309
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.233846664428711
total time:  3.2966906169895083
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.49
[I 2023-06-11 23:54:36,339] Trial 530 finished with value: 71.79999542236328 and parameters: {'Fwd': 5.984081814466943e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.690754880389673, 'loop': 0, 'loss': 'CE', 'lr': 0.0012650362421669664, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0008264895695251227, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.00108634468522786
weight_decay:  0.00040508146873588144
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.033535816008225
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.032643378013745
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.9617931707762182
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.0798487663269043
total time:  3.126458145910874
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 1.23
[I 2023-06-11 23:54:40,001] Trial 531 finished with value: 70.13333892822266 and parameters: {'Fwd': 3.7461575504505014e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 8.145247038709744, 'loop': 0, 'loss': 'CE', 'lr': 0.00108634468522786, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00040508146873588144, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0017998094960585496
weight_decay:  0.0001248582169355318
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1375208541285247
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0546198941301554
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0833820779807866
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.317509412765503
total time:  3.3688259050250053
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.31
[I 2023-06-11 23:54:43,889] Trial 532 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0004210684060323907, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.457639321169651, 'loop': 0, 'loss': 'CE', 'lr': 0.0017998094960585496, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0001248582169355318, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.001456441528362173
weight_decay:  6.752830355951836e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0514305990654975
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0560860000550747
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.122367839096114
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.10
run time now: 3.2707788944244385
total time:  3.321362149901688
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.23 ± 0.81
[I 2023-06-11 23:54:47,717] Trial 533 finished with value: 71.66667175292969 and parameters: {'Fwd': 4.4712257194538795e-06, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 7.919507440288493, 'loop': 0, 'loss': 'CE', 'lr': 0.001456441528362173, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.752830355951836e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0002075544503494174
weight_decay:  0.0003663502018973567
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6583468818571419
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 65.40
Split: 01, Run: 02
None time:  0.7751243899110705
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 03
None time:  1.1490565710701048
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.20
run time now: 2.624955177307129
total time:  2.6801195750012994
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.80 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 65.67 ± 0.64
[I 2023-06-11 23:54:50,884] Trial 534 finished with value: 67.79999542236328 and parameters: {'Fwd': 0.0016054155832837334, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 8.73894639947503, 'loop': 0, 'loss': 'CE', 'lr': 0.0002075544503494174, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003663502018973567, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.0006763921405923653
weight_decay:  0.00014249807991543583
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0286936222109944
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.1064194971695542
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  1.1143149218987674
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.291820764541626
total time:  3.35377678507939
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.75
[I 2023-06-11 23:54:54,734] Trial 535 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.0002791312011348958, 'K': 9, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.2, 'lambda2': 7.560404600874378, 'loop': 0, 'loss': 'CE', 'lr': 0.0006763921405923653, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00014249807991543583, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0012941603317239195
weight_decay:  0.00020372660048524407
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.083411263069138
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0068025728687644
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1854669461026788
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.90
run time now: 3.3255581855773926
total time:  3.382913365960121
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.68
[I 2023-06-11 23:54:58,645] Trial 536 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.0008333438392575402, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.01807803810228, 'loop': 0, 'loss': 'CE', 'lr': 0.0012941603317239195, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00020372660048524407, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0010203016401519743
weight_decay:  8.874035315103483e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0124086160212755
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.055579591076821
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.153111161896959
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.262564182281494
total time:  3.3161118449643254
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.45
[I 2023-06-11 23:55:02,447] Trial 537 finished with value: 71.39999389648438 and parameters: {'Fwd': 7.518027126085252e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.270086167365183, 'loop': 0, 'loss': 'CE', 'lr': 0.0010203016401519743, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.874035315103483e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013953544195344097
weight_decay:  0.00010081772869589289
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9798485550563782
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.9776368751190603
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.9678660039789975
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.966525077819824
total time:  3.0162762668915093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 1.23
[I 2023-06-11 23:55:05,922] Trial 538 finished with value: 70.13333129882812 and parameters: {'Fwd': 1.6914284634056733e-05, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 9.293164052851242, 'loop': 0, 'loss': 'CE', 'lr': 0.0013953544195344097, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00010081772869589289, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0094307528146877
weight_decay:  0.00191052865684567
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.31279260804876685
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 68.70
Split: 01, Run: 02
None time:  0.32552622887305915
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 98.33
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.3498459728434682
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 69.50
run time now: 1.0292694568634033
total time:  1.0800905330106616
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.64
  Final Train: 98.61 ± 0.48
   Final Test: 69.37 ± 0.61
[I 2023-06-11 23:55:07,617] Trial 539 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0001399569630740129, 'K': 8, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 30, 'lambda1': 0.8, 'lambda2': 1.2152879209934153, 'loop': 0, 'loss': 'CE', 'lr': 0.0094307528146877, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00191052865684567, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0016409888640055118
weight_decay:  7.471750557632142e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.27487151604145765
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.20
Split: 01, Run: 02
None time:  0.25082239089533687
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.50
Split: 01, Run: 03
None time:  0.2818363809492439
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.30
run time now: 0.8493959903717041
total time:  0.9092592489905655
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 65.67 ± 1.27
[I 2023-06-11 23:55:09,042] Trial 540 finished with value: 66.5333251953125 and parameters: {'Fwd': 0.0019180597397613014, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 10, 'lambda1': 0.7000000000000001, 'lambda2': 5.984202889735417, 'loop': 0, 'loss': 'CE', 'lr': 0.0016409888640055118, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.471750557632142e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0012127291109614378
weight_decay:  0.0031284538506692106
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0314202799927443
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0473265601322055
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0734722211491317
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.1939797401428223
total time:  3.262190959881991
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.59
[I 2023-06-11 23:55:12,840] Trial 541 finished with value: 71.86666107177734 and parameters: {'Fwd': 0.0008445115791245253, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.762114545179436, 'loop': 0, 'loss': 'CE', 'lr': 0.0012127291109614378, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0031284538506692106, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0014797449474271943
weight_decay:  0.0012418232662127578
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0992612100671977
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1007081270217896
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0421742380131036
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.283066511154175
total time:  3.3389596161432564
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.56
[I 2023-06-11 23:55:16,653] Trial 542 finished with value: 71.53333282470703 and parameters: {'Fwd': 7.807058525307413e-06, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.613047709865089, 'loop': 0, 'loss': 'CE', 'lr': 0.0014797449474271943, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0012418232662127578, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001328664887432638
weight_decay:  0.0002995090116300181
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6250566870439798
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.6285624839365482
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.7065252240281552
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.000715732574463
total time:  2.0546999021898955
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.53
[I 2023-06-11 23:55:19,198] Trial 543 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.0012714221030485982, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 6.862325474167918, 'loop': 0, 'loss': 'CE', 'lr': 0.001328664887432638, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002995090116300181, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0011474817893542693
weight_decay:  0.00021174629369600465
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9801656780764461
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0027589749079198
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.0746589240152389
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.100311517715454
total time:  3.1569227369036525
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.38
[I 2023-06-11 23:55:22,857] Trial 544 finished with value: 71.20000457763672 and parameters: {'Fwd': 2.2610801270553375e-05, 'K': 9, 'alpha': 0.9, 'dropout': 0.2, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 9.013998248550596, 'loop': 0, 'loss': 'CE', 'lr': 0.0011474817893542693, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00021174629369600465, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.0019101927959954085
weight_decay:  0.00011302853108354853
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 69.90%
Split: 01, Run: 01
None time:  1.8562787158880383
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 69.60%
Split: 01, Run: 02
None time:  1.8277560230344534
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.80% Test: 70.20%
Split: 01, Run: 03
None time:  1.867312747053802
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 5.596195936203003
total time:  5.6512190769426525
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.67 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.30
[I 2023-06-11 23:55:29,035] Trial 545 finished with value: 68.66666412353516 and parameters: {'Fwd': 0.0007126542852131313, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 8.325805208293454, 'loop': 0, 'loss': 'MSE', 'lr': 0.0019101927959954085, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00011302853108354853, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0005775292517072832
weight_decay:  0.0008097077067505461
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0297113959677517
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.1335114520043135
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.2561300739180297
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.460548162460327
total time:  3.506078553153202
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.31
[I 2023-06-11 23:55:33,047] Trial 546 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.0009834747660406036, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 9.509621730237345, 'loop': 0, 'loss': 'CE', 'lr': 0.0005775292517072832, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0008097077067505461, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0009421397236400476
weight_decay:  5.354841495700304e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9841035162098706
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.1096167899668217
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.0602305240463465
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.1950020790100098
total time:  3.2543148938566446
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.46
[I 2023-06-11 23:55:36,758] Trial 547 finished with value: 71.26667022705078 and parameters: {'Fwd': 2.4995457271654487e-06, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.362872566996483, 'loop': 0, 'loss': 'CE', 'lr': 0.0009421397236400476, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.354841495700304e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001710309605417095
weight_decay:  0.0005982083666737368
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.037622984033078
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0930521821137518
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.0933463498950005
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.264216184616089
total time:  3.309455149108544
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.40
[I 2023-06-11 23:55:40,521] Trial 548 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.0003627066272687776, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.472161784631791, 'loop': 0, 'loss': 'CE', 'lr': 0.001710309605417095, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005982083666737368, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.00125156566763898
weight_decay:  0.000301859506858709
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0429793670773506
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0406007640995085
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0615477850660682
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.90
run time now: 3.1848721504211426
total time:  3.2441395721398294
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 70.27 ± 0.55
[I 2023-06-11 23:55:44,280] Trial 549 finished with value: 71.53333282470703 and parameters: {'Fwd': 1.10210434801195e-06, 'K': 8, 'alpha': 0.8, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.7034018393718275, 'loop': 0, 'loss': 'CE', 'lr': 0.00125156566763898, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000301859506858709, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001535880993106578
weight_decay:  4.201625227545599e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4437892069108784
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.46352137601934373
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 03
None time:  0.423963749082759
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 1.3821463584899902
total time:  1.4462857861071825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 1.68
  Final Train: 100.00 ± 0.00
   Final Test: 68.17 ± 2.06
[I 2023-06-11 23:55:46,327] Trial 550 finished with value: 69.13333129882812 and parameters: {'Fwd': 0.0020371436069853165, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 40, 'lambda1': 0.8, 'lambda2': 7.108184204686645, 'loop': 0, 'loss': 'CE', 'lr': 0.001535880993106578, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.201625227545599e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.001369440758415269
weight_decay:  7.826021501648183e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9650829201564193
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.17847596318461
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  1.018742245156318
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.206394910812378
total time:  3.2574620319064707
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 1.39
[I 2023-06-11 23:55:50,077] Trial 551 finished with value: 70.13333129882812 and parameters: {'Fwd': 5.747238070353417e-06, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 8.556606329375446, 'loop': 0, 'loss': 'CE', 'lr': 0.001369440758415269, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.826021501648183e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0010341934526196743
weight_decay:  0.00022073625342658928
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0543778450228274
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1671574339270592
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 03
None time:  1.1134240659885108
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.3930842876434326
total time:  3.455851879902184
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.60
[I 2023-06-11 23:55:54,072] Trial 552 finished with value: 70.86666870117188 and parameters: {'Fwd': 2.0769457319885744e-05, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.153017912114042, 'loop': 1, 'loss': 'CE', 'lr': 0.0010341934526196743, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00022073625342658928, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0011764517873001047
weight_decay:  0.0005079830787681691
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7540242408867925
None Run 01:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 54.30
Split: 01, Run: 02
None time:  1.2122894099447876
None Run 02:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 97.50
   Final Test: 62.60
Split: 01, Run: 03
None time:  0.7591935768723488
None Run 03:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 98.33
   Final Test: 59.50
run time now: 2.768232583999634
total time:  2.819653309881687
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.13 ± 5.33
  Final Train: 98.61 ± 1.27
   Final Test: 58.80 ± 4.19
[I 2023-06-11 23:55:57,407] Trial 553 finished with value: 59.133331298828125 and parameters: {'Fwd': 0.0001222990367106017, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.15283984954997, 'loop': 0, 'loss': 'CE', 'lr': 0.0011764517873001047, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0005079830787681691, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.0014914658367334124
weight_decay:  0.0010224326493302237
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.19695602310821414
None Run 01:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 51.60
Split: 01, Run: 02
None time:  0.17898256797343493
None Run 02:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 50.20
Split: 01, Run: 03
None time:  0.20271257194690406
None Run 03:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 55.20
run time now: 0.6212637424468994
total time:  0.6684331619180739
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.73 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 52.33 ± 2.58
[I 2023-06-11 23:55:58,585] Trial 554 finished with value: 52.733333587646484 and parameters: {'Fwd': 4.958648926226127e-06, 'K': 9, 'alpha': 0.8, 'dropout': 0.30000000000000004, 'gnnepoch': 0, 'lambda1': 0.75, 'lambda2': 6.789140453762332, 'loop': 0, 'loss': 'CE', 'lr': 0.0014914658367334124, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0010224326493302237, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  1.0
lr:  0.004675557268782474
weight_decay:  0.0013373326215202746
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0393163140397519
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.0929126711562276
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.2595827570185065
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.432873487472534
total time:  3.4856130259577185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.23
  Final Train: 99.17 ± 0.83
   Final Test: 69.77 ± 0.42
[I 2023-06-11 23:56:02,589] Trial 555 finished with value: 70.53333282470703 and parameters: {'Fwd': 1.8438444618950627e-05, 'K': 8, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.838365900166574, 'loop': 0, 'loss': 'CE', 'lr': 0.004675557268782474, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0013373326215202746, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0007741308127905914
weight_decay:  9.098339969135283e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0220626888331026
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0390015309676528
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 91.67
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.1147242840379477
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 91.67
   Final Test: 70.30
run time now: 3.2155799865722656
total time:  3.270749493036419
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.42
  Final Train: 93.89 ± 3.85
   Final Test: 69.97 ± 0.76
[I 2023-06-11 23:56:06,463] Trial 556 finished with value: 70.73333740234375 and parameters: {'Fwd': 1.9686981170364764e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 0.2158878923782428, 'loop': 0, 'loss': 'CE', 'lr': 0.0007741308127905914, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.098339969135283e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013097141167546314
weight_decay:  0.0017540690145069592
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0472355540841818
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0375342301558703
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.066453997977078
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 3.1912295818328857
total time:  3.241126430919394
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.20 ± 0.72
[I 2023-06-11 23:56:10,340] Trial 557 finished with value: 71.86666870117188 and parameters: {'Fwd': 3.841998013431006e-05, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.4139728681765185, 'loop': 0, 'loss': 'CE', 'lr': 0.0013097141167546314, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0017540690145069592, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0011063163106851991
weight_decay:  0.00014644292154123914
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.018403708934784
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0193777568638325
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.091755700064823
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 95.83
   Final Test: 70.80
run time now: 3.1686320304870605
total time:  3.2190068159252405
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 98.61 ± 2.41
   Final Test: 69.97 ± 0.74
[I 2023-06-11 23:56:14,057] Trial 558 finished with value: 71.66666412353516 and parameters: {'Fwd': 1.214957653869865e-05, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 0.8842669942777253, 'loop': 0, 'loss': 'CE', 'lr': 0.0011063163106851991, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014644292154123914, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0016094397792865665
weight_decay:  3.715815701815996e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9372388320043683
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0218615180347115
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.9363876699935645
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 2.9371073246002197
total time:  2.9916452860925347
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 1.29
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.75
[I 2023-06-11 23:56:17,564] Trial 559 finished with value: 70.66666412353516 and parameters: {'Fwd': 6.295442370857207e-06, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 9.713393456778183, 'loop': 0, 'loss': 'CE', 'lr': 0.0016094397792865665, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.715815701815996e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0012403442425855224
weight_decay:  0.0027416300253014073
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0563215038273484
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1032139260787517
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1001936700195074
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.304276704788208
total time:  3.369492572033778
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.56
[I 2023-06-11 23:56:21,440] Trial 560 finished with value: 71.93333435058594 and parameters: {'Fwd': 2.748807618488355e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.329812083560613, 'loop': 0, 'loss': 'CE', 'lr': 0.0012403442425855224, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0027416300253014073, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.0014081050797730822
weight_decay:  4.7899597474557625e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0340059709269553
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0523427869193256
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1273497720248997
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.254749298095703
total time:  3.317922307178378
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.65
[I 2023-06-11 23:56:25,222] Trial 561 finished with value: 71.5999984741211 and parameters: {'Fwd': 2.671504857983708e-05, 'K': 9, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 8.773136519113553, 'loop': 0, 'loss': 'CE', 'lr': 0.0014081050797730822, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.7899597474557625e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0070558475705401
weight_decay:  6.361539132725671e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1319209998473525
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 97.50
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0788866269867867
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 97.50
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.1774932439438999
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 69.70
run time now: 3.429969310760498
total time:  3.492724529001862
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.20
  Final Train: 98.06 ± 0.96
   Final Test: 69.37 ± 0.31
[I 2023-06-11 23:56:29,175] Trial 562 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.00022883022888259472, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 4.598236144200937, 'loop': 0, 'loss': 'CE', 'lr': 0.0070558475705401, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.361539132725671e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8
lr:  0.0017335554382149905
weight_decay:  0.00042664909529658304
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0410685909446329
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0124352970160544
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0917927550617605
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.183330535888672
total time:  3.239606701070443
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.38
[I 2023-06-11 23:56:32,942] Trial 563 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.000173593157150188, 'K': 5, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 6.275365437917812, 'loop': 0, 'loss': 'CE', 'lr': 0.0017335554382149905, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00042664909529658304, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0008662997207140637
weight_decay:  0.0001290702341118065
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0925656030885875
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0917116140481085
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.156511610839516
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.40
run time now: 3.383639097213745
total time:  3.439068408915773
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.50
  Final Train: 99.72 ± 0.48
   Final Test: 69.87 ± 0.50
[I 2023-06-11 23:56:36,862] Trial 564 finished with value: 71.06666564941406 and parameters: {'Fwd': 0.0005108451388422661, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 1.7572386006368523, 'loop': 0, 'loss': 'CE', 'lr': 0.0008662997207140637, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0001290702341118065, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013210892387200443
weight_decay:  8.045937003243746e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.60%
Split: 01, Run: 01
None time:  1.7374340819660574
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 70.10%
Split: 01, Run: 02
None time:  1.858978986972943
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 69.40%
Split: 01, Run: 03
None time:  1.8361367578618228
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 5.473269939422607
total time:  5.520464457105845
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.35
[I 2023-06-11 23:56:42,887] Trial 565 finished with value: 69.80000305175781 and parameters: {'Fwd': 2.9608630235056283e-05, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 8.265947300685376, 'loop': 0, 'loss': 'MSE', 'lr': 0.0013210892387200443, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.045937003243746e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0011639007050312565
weight_decay:  0.0008716663234912223
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9612806248478591
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0416894289664924
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  1.0042863129638135
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.047398567199707
total time:  3.1015018310863525
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 1.14
[I 2023-06-11 23:56:46,549] Trial 566 finished with value: 70.13333892822266 and parameters: {'Fwd': 1.7101251447242554e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 9.561998586858115, 'loop': 0, 'loss': 'CE', 'lr': 0.0011639007050312565, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0008716663234912223, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0001324371157590343
weight_decay:  4.043762976481175e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1452626020181924
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.013121377909556
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  1.160357696004212
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.70
run time now: 3.3735616207122803
total time:  3.4189141248352826
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 68.37 ± 1.23
[I 2023-06-11 23:56:50,466] Trial 567 finished with value: 67.66666412353516 and parameters: {'Fwd': 0.00020751376851934158, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.257581820821212, 'loop': 0, 'loss': 'CE', 'lr': 0.0001324371157590343, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.043762976481175e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.0007139403895461461
weight_decay:  0.0011535947179184892
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0188091648742557
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9662412058096379
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.1880187208298594
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.2087464332580566
total time:  3.2610714808106422
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.40
[I 2023-06-11 23:56:54,276] Trial 568 finished with value: 71.00000762939453 and parameters: {'Fwd': 9.332333984929529e-06, 'K': 4, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.586840118925561, 'loop': 0, 'loss': 'CE', 'lr': 0.0007139403895461461, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0011535947179184892, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0015181797301226543
weight_decay:  0.00025604715596054013
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9541590269654989
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0891480310820043
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 68.20
Split: 01, Run: 03
None time:  1.0290720649063587
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.1142187118530273
total time:  3.1722617400810122
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 0.61
  Final Train: 99.44 ± 0.96
   Final Test: 69.10 ± 0.78
[I 2023-06-11 23:56:58,029] Trial 569 finished with value: 70.9333267211914 and parameters: {'Fwd': 0.0027207799257641316, 'K': 8, 'alpha': 0.75, 'dropout': 0.0, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 2.1529314901613117, 'loop': 0, 'loss': 'CE', 'lr': 0.0015181797301226543, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00025604715596054013, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0018548607292446975
weight_decay:  0.0003577095092934668
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.060876013012603
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0454523819498718
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0363742881454527
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.183168411254883
total time:  3.2328636369202286
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.10
[I 2023-06-11 23:57:01,965] Trial 570 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.00039833486770899425, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 5.951544036023618, 'loop': 0, 'loss': 'CE', 'lr': 0.0018548607292446975, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0003577095092934668, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.001024716094897523
weight_decay:  3.37158582402727e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.014964526053518
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9874680319335312
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.0229634509887546
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.0700488090515137
total time:  3.1266329078935087
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.81
[I 2023-06-11 23:57:05,646] Trial 571 finished with value: 69.73333740234375 and parameters: {'Fwd': 3.567228045128457e-06, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.15000000000000002, 'lambda2': 9.969150398019119, 'loop': 0, 'loss': 'CE', 'lr': 0.001024716094897523, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.37158582402727e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.000287760418141338
weight_decay:  0.0017940431804760013
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7326373721007258
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 02
None time:  0.7733657611533999
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 99.17
   Final Test: 65.30
Split: 01, Run: 03
None time:  0.8903212810400873
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 99.17
   Final Test: 64.70
run time now: 2.4378068447113037
total time:  2.4844107280950993
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.40 ± 0.87
  Final Train: 99.44 ± 0.48
   Final Test: 65.60 ± 1.08
[I 2023-06-11 23:57:08,700] Trial 572 finished with value: 66.39999389648438 and parameters: {'Fwd': 1.3849779204808577e-06, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.040804504605481, 'loop': 0, 'loss': 'CE', 'lr': 0.000287760418141338, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0017940431804760013, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0012372519569342378
weight_decay:  0.0006377737014958842
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0842728950083256
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9967038419563323
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1557087050750852
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.20
run time now: 3.282675266265869
total time:  3.342740088934079
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 70.30 ± 0.82
[I 2023-06-11 23:57:12,535] Trial 573 finished with value: 71.66666412353516 and parameters: {'Fwd': 1.6656501720076557e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.579594850938674, 'loop': 0, 'loss': 'CE', 'lr': 0.0012372519569342378, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006377737014958842, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0014261494697738
weight_decay:  5.1922563459632714e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8346400738228112
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.8989761020056903
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.9335520849563181
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 98.33
   Final Test: 69.20
run time now: 2.7106130123138428
total time:  2.7611992079764605
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.93 ± 1.10
  Final Train: 98.89 ± 0.48
   Final Test: 69.33 ± 0.51
[I 2023-06-11 23:57:15,801] Trial 574 finished with value: 70.93333435058594 and parameters: {'Fwd': 1.5010921122240025e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 0.5987690177640967, 'loop': 0, 'loss': 'CE', 'lr': 0.0014261494697738, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.1922563459632714e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.000243190623164604
weight_decay:  0.012512632778403128
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2866247799247503
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 02
None time:  1.3110055229626596
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.2361120390705764
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.70
run time now: 3.875439167022705
total time:  3.927285694051534
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 68.87 ± 0.29
[I 2023-06-11 23:57:20,267] Trial 575 finished with value: 69.13333129882812 and parameters: {'Fwd': 1.9171726745848756e-06, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 9.274222376504616, 'loop': 2, 'loss': 'CE', 'lr': 0.000243190623164604, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.012512632778403128, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.0013433133179330118
weight_decay:  0.0004337162421183379
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0605281570460647
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1085835059639066
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0684263780713081
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.280411958694458
total time:  3.336814999114722
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.60
[I 2023-06-11 23:57:24,089] Trial 576 finished with value: 71.80000305175781 and parameters: {'Fwd': 9.831502458954505e-06, 'K': 9, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.834337745953494, 'loop': 0, 'loss': 'CE', 'lr': 0.0013433133179330118, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0004337162421183379, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0010816821504001865
weight_decay:  9.484559154323457e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9795656511560082
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0094574661925435
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.1579268020577729
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.195974111557007
total time:  3.257440601941198
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.70
[I 2023-06-11 23:57:27,843] Trial 577 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.004617162629056572, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.7236981833984615, 'loop': 0, 'loss': 'CE', 'lr': 0.0010816821504001865, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.484559154323457e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001602480918130253
weight_decay:  0.001507637151232315
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2306646360084414
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0639958051033318
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0918571869842708
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.4264373779296875
total time:  3.477322840830311
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.29
[I 2023-06-11 23:57:31,881] Trial 578 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0007513248905085486, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.213335422788789, 'loop': 0, 'loss': 'CE', 'lr': 0.001602480918130253, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001507637151232315, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0007993941131981258
weight_decay:  0.05812570624994175
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9892563340254128
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9940802881028503
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.0132761888671666
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.038180112838745
total time:  3.0986626560334116
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 1.20
  Final Train: 100.00 ± 0.00
   Final Test: 68.90 ± 0.85
[I 2023-06-11 23:57:35,534] Trial 579 finished with value: 69.80000305175781 and parameters: {'Fwd': 0.0005538866177953935, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 6.068086960948448, 'loop': 0, 'loss': 'CE', 'lr': 0.0007993941131981258, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.05812570624994175, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.005617949551053007
weight_decay:  0.0001920751919145516
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2394490239676088
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.2026159879751503
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.1886670731473714
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.675309658050537
total time:  3.734524662140757
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.64
[I 2023-06-11 23:57:39,797] Trial 580 finished with value: 70.80000305175781 and parameters: {'Fwd': 8.304652575338868e-05, 'K': 8, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.054521466380695, 'loop': 0, 'loss': 'CE', 'lr': 0.005617949551053007, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0001920751919145516, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.0012110052000188277
weight_decay:  3.084513131424925e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0492325711529702
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9985388738568872
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1669531029183418
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.257312774658203
total time:  3.310416460968554
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.44
[I 2023-06-11 23:57:43,645] Trial 581 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0003027453212780905, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.735764355195035, 'loop': 0, 'loss': 'CE', 'lr': 0.0012110052000188277, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.084513131424925e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.00035093441950146597
weight_decay:  4.038253260534236e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.075211383169517
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1219673419836909
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  1.3511209939606488
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.5883984565734863
total time:  3.656361266039312
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.10
[I 2023-06-11 23:57:47,837] Trial 582 finished with value: 69.80000305175781 and parameters: {'Fwd': 0.00011408234328714141, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.686463772144301, 'loop': 0, 'loss': 'CE', 'lr': 0.00035093441950146597, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.038253260534236e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0019547106447436358
weight_decay:  8.925249372136562e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.60% Test: 69.80%
Split: 01, Run: 01
None time:  1.797435011016205
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 69.50%
Split: 01, Run: 02
None time:  1.7894305209629238
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.60% Test: 69.20%
Split: 01, Run: 03
None time:  1.737580293789506
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 5.373879432678223
total time:  5.424277194077149
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.30
[I 2023-06-11 23:57:53,753] Trial 583 finished with value: 68.53333282470703 and parameters: {'Fwd': 0.0001010401560366745, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 6.395820500659175, 'loop': 0, 'loss': 'MSE', 'lr': 0.0019547106447436358, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.925249372136562e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0014572420281712501
weight_decay:  3.082152123652566e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9550519268959761
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.017743853153661
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  1.0196108159143478
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.039116144180298
total time:  3.0986903740558773
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 1.26
[I 2023-06-11 23:57:57,385] Trial 584 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.006093828619560967, 'K': 8, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 8.880954993123508, 'loop': 0, 'loss': 'CE', 'lr': 0.0014572420281712501, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.082152123652566e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.008863225538605524
weight_decay:  1.0463793483874919e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.149492688011378
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 98.33
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.1100153259467334
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 98.33
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.1246374291367829
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.20
run time now: 3.4241394996643066
total time:  3.4799580960534513
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 0.23
  Final Train: 98.61 ± 0.48
   Final Test: 69.27 ± 0.12
[I 2023-06-11 23:58:01,380] Trial 585 finished with value: 70.33333587646484 and parameters: {'Fwd': 2.2193563493440295e-06, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.474339189260624, 'loop': 0, 'loss': 'CE', 'lr': 0.008863225538605524, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0463793483874919e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0009369067663596736
weight_decay:  0.00033581837941652954
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0530140630435199
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0348864919506013
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.1692283230368048
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.2967605590820312
total time:  3.341101008001715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.40
[I 2023-06-11 23:58:05,305] Trial 586 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.0013945637313291534, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 8.498587354030844, 'loop': 0, 'loss': 'CE', 'lr': 0.0009369067663596736, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00033581837941652954, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0012973757214625652
weight_decay:  6.07089938981544e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9637202359735966
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.0550733897835016
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  1.030405628029257
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.088632345199585
total time:  3.145668121986091
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.37 ± 1.55
[I 2023-06-11 23:58:09,028] Trial 587 finished with value: 70.13333129882812 and parameters: {'Fwd': 4.446646452038094e-05, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 7.903642060060405, 'loop': 0, 'loss': 'CE', 'lr': 0.0012973757214625652, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.07089938981544e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001169086053472351
weight_decay:  0.0010067043389475438
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.37762911594472826
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.42550150002352893
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.3330268419813365
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 1.177140474319458
total time:  1.231097023934126
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.64
[I 2023-06-11 23:58:10,798] Trial 588 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.004706038917382734, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 30, 'lambda1': 0.65, 'lambda2': 4.4207909797790865, 'loop': 0, 'loss': 'CE', 'lr': 0.001169086053472351, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0010067043389475438, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0017176414882684754
weight_decay:  3.029520154195936e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0870080271270126
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9961354250553995
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.1231265109963715
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.2563910484313965
total time:  3.3149003779981285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.36
[I 2023-06-11 23:58:14,607] Trial 589 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.0025200410591389604, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 8.064870855119409, 'loop': 0, 'loss': 'CE', 'lr': 0.0017176414882684754, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.029520154195936e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001392147659127772
weight_decay:  4.620970920771135e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0694389420095831
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.0778792519122362
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.028001139871776
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.2145822048187256
total time:  3.262925532879308
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.81
[I 2023-06-11 23:58:18,345] Trial 590 finished with value: 71.13333892822266 and parameters: {'Fwd': 0.0001572615238157521, 'K': 8, 'alpha': 0.75, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.839238737041264, 'loop': 0, 'loss': 'CE', 'lr': 0.001392147659127772, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.620970920771135e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.001090793700915752
weight_decay:  2.4730493922784158e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8096256400458515
None Run 01:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 98.33
   Final Test: 61.40
Split: 01, Run: 02
None time:  0.8051039460115135
None Run 02:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 98.33
   Final Test: 61.90
Split: 01, Run: 03
None time:  0.8205835619010031
None Run 03:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 98.33
   Final Test: 60.80
run time now: 2.4766194820404053
total time:  2.5234983649570495
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.93 ± 1.14
  Final Train: 98.33 ± 0.00
   Final Test: 61.37 ± 0.55
[I 2023-06-11 23:58:21,356] Trial 591 finished with value: 60.93333435058594 and parameters: {'Fwd': 0.0010971807754315923, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 7.097602722672148, 'loop': 0, 'loss': 'CE', 'lr': 0.001090793700915752, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.4730493922784158e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.00013855739210700624
weight_decay:  0.00012979884884708635
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0507085339631885
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02
None time:  1.12023815093562
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  1.186907900031656
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.399005174636841
total time:  3.4539945560973138
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 68.80 ± 0.72
[I 2023-06-11 23:58:25,400] Trial 592 finished with value: 67.86666870117188 and parameters: {'Fwd': 1.1944055462153017e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 9.683541277151306, 'loop': 0, 'loss': 'CE', 'lr': 0.00013855739210700624, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00012979884884708635, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.00032579085517704925
weight_decay:  2.578179872105038e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0793370069004595
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.1921944958157837
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.1461252779699862
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.4626216888427734
total time:  3.532462951960042
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.23
[I 2023-06-11 23:58:29,524] Trial 593 finished with value: 69.73333740234375 and parameters: {'Fwd': 0.0005401916683456133, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.598423812243292, 'loop': 0, 'loss': 'CE', 'lr': 0.00032579085517704925, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.578179872105038e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0015471269077316878
weight_decay:  1.232865607186205e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0628058209549636
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0936241950839758
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0919682020321488
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.2902333736419678
total time:  3.345095886848867
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.53
[I 2023-06-11 23:58:33,377] Trial 594 finished with value: 71.5999984741211 and parameters: {'Fwd': 3.4611573640520188e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.410270734719675, 'loop': 0, 'loss': 'CE', 'lr': 0.0015471269077316878, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.232865607186205e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0001053807465026676
weight_decay:  3.381482203640988e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0070181470364332
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 02
None time:  1.0240385651122779
None Run 02:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 64.20
Split: 01, Run: 03
None time:  1.0122747560963035
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.40
run time now: 3.0828163623809814
total time:  3.1495585159864277
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.53 ± 1.81
  Final Train: 100.00 ± 0.00
   Final Test: 65.67 ± 1.27
[I 2023-06-11 23:58:37,025] Trial 595 finished with value: 65.53333282470703 and parameters: {'Fwd': 1.904335811789963e-05, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 4.820534237137972, 'loop': 0, 'loss': 'CE', 'lr': 0.0001053807465026676, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.381482203640988e-05, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.001321828784027252
weight_decay:  0.0007871923346349114
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0685400830116123
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0849849099759012
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.2096312548965216
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.403790235519409
total time:  3.450235364958644
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.62
[I 2023-06-11 23:58:41,093] Trial 596 finished with value: 71.86666870117188 and parameters: {'Fwd': 3.419187990900453e-05, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.886162851757556, 'loop': 0, 'loss': 'CE', 'lr': 0.001321828784027252, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007871923346349114, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.003919761616096457
weight_decay:  7.528069904086462e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0931107348296791
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.1803885539993644
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.162933938903734
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.4766199588775635
total time:  3.538553839083761
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.31
  Final Train: 99.17 ± 0.83
   Final Test: 69.80 ± 0.30
[I 2023-06-11 23:58:45,176] Trial 597 finished with value: 70.66666412353516 and parameters: {'Fwd': 1.4769776268474945e-06, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.458696255410523, 'loop': 0, 'loss': 'CE', 'lr': 0.003919761616096457, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.528069904086462e-06, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0012163198841493893
weight_decay:  0.002243557141427872
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.018109675962478
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1010100420098752
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.10919758095406
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.2699995040893555
total time:  3.3264485858380795
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.55
[I 2023-06-11 23:58:49,086] Trial 598 finished with value: 71.86666107177734 and parameters: {'Fwd': 0.00011481506214333966, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 1.9767179440625107, 'loop': 0, 'loss': 'CE', 'lr': 0.0012163198841493893, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.002243557141427872, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0014534815986612887
weight_decay:  0.000609242577998474
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9436189930420369
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.9796609859913588
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  0.9910573267843574
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 2.9541454315185547
total time:  3.003955617081374
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 1.14
[I 2023-06-11 23:58:52,632] Trial 599 finished with value: 70.26666259765625 and parameters: {'Fwd': 2.8062025671493255e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 9.804110223219205, 'loop': 0, 'loss': 'CE', 'lr': 0.0014534815986612887, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000609242577998474, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0011172763285924212
weight_decay:  0.00016167685459412707
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.094764610985294
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0547967159654945
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1519881109707057
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.3481781482696533
total time:  3.402439579134807
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.50
[I 2023-06-11 23:58:56,552] Trial 600 finished with value: 71.20000457763672 and parameters: {'Fwd': 1.0020709588928778e-06, 'K': 8, 'alpha': 0.5, 'dropout': 0.5, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.82219273864761, 'loop': 0, 'loss': 'CE', 'lr': 0.0011172763285924212, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00016167685459412707, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0010196781235747925
weight_decay:  0.0004752260830097754
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0432433870155364
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0343083480838686
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1322313549462706
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.90
run time now: 3.2493062019348145
total time:  3.296720603015274
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.71
[I 2023-06-11 23:59:00,372] Trial 601 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.0014929798815820842, 'K': 8, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 6.176687031989842, 'loop': 0, 'loss': 'CE', 'lr': 0.0010196781235747925, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0004752260830097754, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0016595307328911672
weight_decay:  0.0032072869925788483
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.80%
Split: 01, Run: 01
None time:  1.7890050869900733
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.90%
Split: 01, Run: 02
None time:  1.7516392969992012
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 69.20%
Split: 01, Run: 03
None time:  1.8825698178261518
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 5.464768409729004
total time:  5.525666478089988
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.38
[I 2023-06-11 23:59:06,419] Trial 602 finished with value: 69.93334197998047 and parameters: {'Fwd': 6.564683199116549e-06, 'K': 8, 'alpha': 0.75, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 8.621487861174726, 'loop': 0, 'loss': 'MSE', 'lr': 0.0016595307328911672, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0032072869925788483, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.00023061932444766496
weight_decay:  0.03309171829024916
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0794752980582416
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.0254327340517193
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0821245890110731
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.2269558906555176
total time:  3.292432541027665
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.64
[I 2023-06-11 23:59:10,212] Trial 603 finished with value: 69.4000015258789 and parameters: {'Fwd': 5.557303740467928e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.030426323216522, 'loop': 0, 'loss': 'CE', 'lr': 0.00023061932444766496, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.03309171829024916, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.004229021955069631
weight_decay:  0.0013340989473281813
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.108603622065857
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.1440083249472082
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0760493129491806
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.370513677597046
total time:  3.4299888368695974
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.12
  Final Train: 99.44 ± 0.48
   Final Test: 69.83 ± 0.38
[I 2023-06-11 23:59:14,157] Trial 604 finished with value: 70.46666717529297 and parameters: {'Fwd': 7.542810563029134e-05, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 4.638117855215894, 'loop': 0, 'loss': 'CE', 'lr': 0.004229021955069631, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0013340989473281813, 'weightedloss': True}. Best is trial 271 with value: 72.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0013129418762610966
weight_decay:  0.00023625401205731118
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0614593380596489
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.9913652730174363
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.024250972084701
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.117004871368408
total time:  3.177084838040173
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.10
[I 2023-06-11 23:59:17,844] Trial 605 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.0002616024244297153, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.140215043825703, 'loop': 0, 'loss': 'CE', 'lr': 0.0013129418762610966, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00023625401205731118, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0005525748117291273
weight_decay:  0.00017143088063897505
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9828625700902194
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9657346280291677
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  1.0331648318096995
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.0197646617889404
total time:  3.0704122548922896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.03 ± 1.16
[I 2023-06-11 23:59:21,389] Trial 606 finished with value: 69.13333129882812 and parameters: {'Fwd': 0.007808247172708013, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 1.4626883419778403, 'loop': 0, 'loss': 'CE', 'lr': 0.0005525748117291273, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017143088063897505, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0014519255373292214
weight_decay:  2.2498921697180787e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9598378781229258
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0575945430900902
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0933000859804451
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.1540000438690186
total time:  3.212747426936403
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 0.55
[I 2023-06-11 23:59:25,078] Trial 607 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.003668450110531316, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.357659435890247, 'loop': 0, 'loss': 'CE', 'lr': 0.0014519255373292214, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2498921697180787e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.0019090678392591931
weight_decay:  7.156507826848608e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.091533645056188
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.09680091496557
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0491016681771725
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.277992010116577
total time:  3.3292191529180855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.25
[I 2023-06-11 23:59:28,946] Trial 608 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.0014379443630213996, 'K': 9, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.120611795249001, 'loop': 0, 'loss': 'CE', 'lr': 0.0019090678392591931, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.156507826848608e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0013015356044736184
weight_decay:  0.00031945742437545664
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.212629565037787
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.3583045990671962
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.2466557070147246
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.865387201309204
total time:  3.920136063825339
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.32
[I 2023-06-11 23:59:33,357] Trial 609 finished with value: 71.26666259765625 and parameters: {'Fwd': 0.00021022658066904287, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.587324756545719, 'loop': 2, 'loss': 'CE', 'lr': 0.0013015356044736184, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00031945742437545664, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.00016518033373157266
weight_decay:  0.0002762767158529926
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7927088472060859
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.90
Split: 01, Run: 02
None time:  0.8048045269679278
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 99.17
   Final Test: 65.70
Split: 01, Run: 03
None time:  0.7849075808189809
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.80
run time now: 2.4240622520446777
total time:  2.481645296094939
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.80 ± 0.40
  Final Train: 99.72 ± 0.48
   Final Test: 64.80 ± 0.95
[I 2023-06-11 23:59:36,337] Trial 610 finished with value: 66.79999542236328 and parameters: {'Fwd': 0.0010442129972864135, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.206371552388029, 'loop': 0, 'loss': 'CE', 'lr': 0.00016518033373157266, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0002762767158529926, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.004974610310488197
weight_decay:  0.00021769700305306248
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1719467169605196
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.0941704190336168
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.089873410994187
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 69.00
run time now: 3.403684139251709
total time:  3.4615086489357054
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.35
  Final Train: 98.89 ± 0.48
   Final Test: 69.70 ± 0.62
[I 2023-06-11 23:59:40,392] Trial 611 finished with value: 70.5999984741211 and parameters: {'Fwd': 5.663652677032405e-05, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.94022994702744, 'loop': 0, 'loss': 'CE', 'lr': 0.004974610310488197, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00021769700305306248, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.55
lr:  0.0013821834125392419
weight_decay:  0.09773795469919007
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0507010200526565
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0300851901993155
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0492984699085355
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.166250705718994
total time:  3.2281877188943326
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.75
[I 2023-06-11 23:59:44,182] Trial 612 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.0018112277171256808, 'K': 6, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.780915642266818, 'loop': 0, 'loss': 'CE', 'lr': 0.0013821834125392419, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.09773795469919007, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.001581480698305046
weight_decay:  0.0001402367211365699
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9366911679971963
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9349351348355412
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  0.9978943599853665
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 2.9076590538024902
total time:  2.9682657970115542
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.80
[I 2023-06-11 23:59:47,674] Trial 613 finished with value: 70.73332977294922 and parameters: {'Fwd': 1.0803239434389145e-05, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 4.436988668615395, 'loop': 0, 'loss': 'CE', 'lr': 0.001581480698305046, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0001402367211365699, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0005971306150170174
weight_decay:  4.979899057623191e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0415773598942906
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0696352859959006
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.1860008649528027
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.3477330207824707
total time:  3.404712578980252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.45
[I 2023-06-11 23:59:51,557] Trial 614 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.0060677259592671765, 'K': 8, 'alpha': 0.65, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.381144361090543, 'loop': 0, 'loss': 'CE', 'lr': 0.0005971306150170174, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.979899057623191e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.5
lr:  0.0017314292777583678
weight_decay:  1.959291055449643e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9711327641271055
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.018979714019224
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.0328475420828909
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.0611019134521484
total time:  3.1152166191022843
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.29
[I 2023-06-11 23:59:55,276] Trial 615 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0008839340506912688, 'K': 6, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.6295324713062507, 'loop': 0, 'loss': 'CE', 'lr': 0.0017314292777583678, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.959291055449643e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0012791110842592553
weight_decay:  0.00027128467157209004
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.093938963022083
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1818752868566662
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.1139758799690753
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.431145429611206
total time:  3.477508248994127
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 0.36
[I 2023-06-11 23:59:59,378] Trial 616 finished with value: 71.26666259765625 and parameters: {'Fwd': 0.00420211022564639, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.933118666180638, 'loop': 1, 'loss': 'CE', 'lr': 0.0012791110842592553, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00027128467157209004, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.0026495648109943833
weight_decay:  0.00010326446901924699
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1051545820664614
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0757215868216008
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0061282578390092
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.227888584136963
total time:  3.2760925740003586
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.15
[I 2023-06-12 00:00:03,143] Trial 617 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0001552842357484146, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.5, 'lambda2': 5.598594762657173, 'loop': 0, 'loss': 'CE', 'lr': 0.0026495648109943833, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00010326446901924699, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0015359075572289787
weight_decay:  2.5930694307404343e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.056085156975314
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0450233749579638
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1862557439599186
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.3267743587493896
total time:  3.374143701978028
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.26
[I 2023-06-12 00:00:07,012] Trial 618 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.023407067665711215, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.7676506759346005, 'loop': 0, 'loss': 'CE', 'lr': 0.0015359075572289787, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.5930694307404343e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.005090623202136052
weight_decay:  0.0002464363843350309
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1376241319812834
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0748546030372381
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.200250978814438
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 69.70
run time now: 3.4537339210510254
total time:  3.512330213095993
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.42
  Final Train: 98.89 ± 0.48
   Final Test: 69.73 ± 0.15
[I 2023-06-12 00:00:11,018] Trial 619 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.0002819835692950185, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.244107684474674, 'loop': 0, 'loss': 'CE', 'lr': 0.005090623202136052, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002464363843350309, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.0011925922769308065
weight_decay:  8.735848767381182e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.02087288396433
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  1.023025759961456
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  0.9628772740252316
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.0535013675689697
total time:  3.1197381909005344
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 1.27
[I 2023-06-12 00:00:14,648] Trial 620 finished with value: 70.20000457763672 and parameters: {'Fwd': 1.3551969391476741e-05, 'K': 7, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 6.526871602822931, 'loop': 0, 'loss': 'CE', 'lr': 0.0011925922769308065, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.735848767381182e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.0006482894022726185
weight_decay:  1.3070987337649308e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 68.20%
Split: 01, Run: 01
None time:  1.8474327879957855
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 69.50%
Split: 01, Run: 02
None time:  1.7836986801121384
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 68.40%
Split: 01, Run: 03
None time:  1.9142313899938017
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.50
run time now: 5.59049916267395
total time:  5.646505828946829
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 68.73 ± 0.68
[I 2023-06-12 00:00:20,889] Trial 621 finished with value: 69.5999984741211 and parameters: {'Fwd': 1.6572876654014998e-06, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.544139836066914, 'loop': 0, 'loss': 'MSE', 'lr': 0.0006482894022726185, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3070987337649308e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013796080845734208
weight_decay:  0.00021845394542104794
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1529293551575392
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0311077958904207
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0755972790066153
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.3015925884246826
total time:  3.3538677499163896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 0.50
[I 2023-06-12 00:00:24,751] Trial 622 finished with value: 71.66666412353516 and parameters: {'Fwd': 2.8005653024550013e-05, 'K': 8, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 8.21660637684129, 'loop': 0, 'loss': 'CE', 'lr': 0.0013796080845734208, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021845394542104794, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0007048691543719568
weight_decay:  0.004291786120701108
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9404415530152619
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9919054468628019
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 99.17
   Final Test: 68.40
Split: 01, Run: 03
None time:  1.1143897180445492
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.0871567726135254
total time:  3.1417831999715418
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.47 ± 1.10
  Final Train: 99.72 ± 0.48
   Final Test: 69.43 ± 1.00
[I 2023-06-12 00:00:28,390] Trial 623 finished with value: 69.46666717529297 and parameters: {'Fwd': 0.0006178918182082555, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 0.4674499367943463, 'loop': 0, 'loss': 'CE', 'lr': 0.0007048691543719568, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004291786120701108, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0011267948269646697
weight_decay:  0.00572198772549773
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8946989078540355
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  0.8824513079598546
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.8153060260228813
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.80
run time now: 2.6360409259796143
total time:  2.6908287049736828
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 1.00
[I 2023-06-12 00:00:31,612] Trial 624 finished with value: 71.06666564941406 and parameters: {'Fwd': 0.0004633454637747534, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 7.637863819011943, 'loop': 0, 'loss': 'CE', 'lr': 0.0011267948269646697, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00572198772549773, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0008786765464335438
weight_decay:  3.746799170848992e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0662510741967708
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.037943912902847
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0620381790213287
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.2074687480926514
total time:  3.259691999061033
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.59
[I 2023-06-12 00:00:35,383] Trial 625 finished with value: 71.0666732788086 and parameters: {'Fwd': 5.3370612040468456e-06, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 5.342488486900101, 'loop': 0, 'loss': 'CE', 'lr': 0.0008786765464335438, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.746799170848992e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.007375447789879852
weight_decay:  3.269214365631076e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2209812151268125
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 91.67
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1374617519322783
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 93.33
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.0596544470172375
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 96.67
   Final Test: 69.50
run time now: 3.4662129878997803
total time:  3.5188795139547437
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.20
  Final Train: 93.89 ± 2.55
   Final Test: 69.60 ± 0.10
[I 2023-06-12 00:00:39,558] Trial 626 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.00026215079148695297, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 0.7565161493493857, 'loop': 0, 'loss': 'CE', 'lr': 0.007375447789879852, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.269214365631076e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.005710703816197725
weight_decay:  0.00040632575204502903
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0795968640595675
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.1443697588983923
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 98.33
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.093492287909612
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.20
run time now: 3.3646020889282227
total time:  3.431048210011795
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.12
  Final Train: 99.17 ± 0.83
   Final Test: 69.57 ± 0.35
[I 2023-06-12 00:00:43,465] Trial 627 finished with value: 70.73332977294922 and parameters: {'Fwd': 0.0007706051264828907, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.95088184914281, 'loop': 0, 'loss': 'CE', 'lr': 0.005710703816197725, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00040632575204502903, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0014677250603017122
weight_decay:  0.02729081629444386
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0482310941442847
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0578447689767927
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1061328591313213
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.10
run time now: 3.253170967102051
total time:  3.2983830240555108
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.37 ± 0.64
[I 2023-06-12 00:00:47,320] Trial 628 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.00042824894016568944, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 4.831048841285098, 'loop': 0, 'loss': 'CE', 'lr': 0.0014677250603017122, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.02729081629444386, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0004790293409628604
weight_decay:  5.8223472698446976e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7359304910060018
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 99.17
   Final Test: 65.30
Split: 01, Run: 02
None time:  0.9633238532114774
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 98.33
   Final Test: 63.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 97.50%, Valid: 61.60% Test: 61.40%
Split: 01, Run: 03
None time:  1.3075990870129317
None Run 03:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 97.50
   Final Test: 61.40
run time now: 3.048802375793457
total time:  3.1085340450517833
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.13 ± 3.41
  Final Train: 98.33 ± 0.83
   Final Test: 63.27 ± 1.96
[I 2023-06-12 00:00:50,940] Trial 629 finished with value: 65.13333129882812 and parameters: {'Fwd': 4.283688061692639e-06, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 7.394307079172036, 'loop': 0, 'loss': 'CE', 'lr': 0.0004790293409628604, 'softmaxF': False, 'useGCN': False, 'weight_decay': 5.8223472698446976e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0018745690038969474
weight_decay:  1.6949606540316558e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0291336150839925
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0104475531261414
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.1245449660345912
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.20575213432312
total time:  3.263311413116753
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.10
[I 2023-06-12 00:00:54,766] Trial 630 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0023227517776558174, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.90327648092448, 'loop': 0, 'loss': 'CE', 'lr': 0.0018745690038969474, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.6949606540316558e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.00019811786170735728
weight_decay:  1.0972055861024881e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 68.80%
Split: 01, Run: 01
None time:  1.8144939970225096
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.0086308179888874
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 70.10%
Split: 01, Run: 03
None time:  1.8661666791886091
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 4.7279908657073975
total time:  4.786089330213144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.79
[I 2023-06-12 00:01:00,121] Trial 631 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.04444940056035255, 'K': 8, 'alpha': 0.75, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.738213939777745, 'loop': 0, 'loss': 'CE', 'lr': 0.00019811786170735728, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0972055861024881e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.00040624447371725617
weight_decay:  3.4406566240852066e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2164265851024538
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.172812373843044
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.1790830169338733
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.30
run time now: 3.6096608638763428
total time:  3.6659183509182185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 1.07
[I 2023-06-12 00:01:04,356] Trial 632 finished with value: 70.13333892822266 and parameters: {'Fwd': 0.0029282190154587937, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 8.724892749547656, 'loop': 1, 'loss': 'CE', 'lr': 0.00040624447371725617, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.4406566240852066e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.00027436925670770577
weight_decay:  2.6068422270479673e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1330979499034584
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.0970684778876603
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.0457693040370941
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.3277993202209473
total time:  3.3863293901085854
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 0.36
[I 2023-06-12 00:01:08,243] Trial 633 finished with value: 69.79999542236328 and parameters: {'Fwd': 7.4683428016275285e-06, 'K': 8, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.053835853101939, 'loop': 0, 'loss': 'CE', 'lr': 0.00027436925670770577, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.6068422270479673e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0012810257071387229
weight_decay:  4.972684823008978e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0184576290193945
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0566409800667316
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0648954771459103
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.182626962661743
total time:  3.2344755548983812
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.51
[I 2023-06-12 00:01:11,963] Trial 634 finished with value: 71.26667022705078 and parameters: {'Fwd': 5.2156122539718986e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.715792682388083, 'loop': 0, 'loss': 'CE', 'lr': 0.0012810257071387229, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.972684823008978e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0009651838067679389
weight_decay:  4.172779716418132e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.060424542054534
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0070872819051147
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0939168308395892
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.1998629570007324
total time:  3.2569051571190357
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.40
[I 2023-06-12 00:01:15,682] Trial 635 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.007468424357056567, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.182105353839803, 'loop': 0, 'loss': 'CE', 'lr': 0.0009651838067679389, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.172779716418132e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0016102405021997965
weight_decay:  2.6491263327622013e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6594055569730699
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.5672167069278657
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.5671381000429392
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.90
run time now: 1.8335840702056885
total time:  1.888706783996895
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 68.73 ± 0.80
[I 2023-06-12 00:01:18,093] Trial 636 finished with value: 69.4000015258789 and parameters: {'Fwd': 4.4464813812360355e-05, 'K': 8, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 8.013986190685698, 'loop': 0, 'loss': 'CE', 'lr': 0.0016102405021997965, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.6491263327622013e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013562958781832325
weight_decay:  1.530543027572132e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0692602419294417
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0673709011171013
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0936131451744586
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.2702229022979736
total time:  3.3296300577931106
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.42
[I 2023-06-12 00:01:21,925] Trial 637 finished with value: 71.86666870117188 and parameters: {'Fwd': 3.132963129979884e-05, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.31731638694037, 'loop': 0, 'loss': 'CE', 'lr': 0.0013562958781832325, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.530543027572132e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.0011749720823417528
weight_decay:  2.107140207386328e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9804115609731525
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  0.9940104139968753
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  1.013675716938451
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.031850576400757
total time:  3.082641715183854
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 1.10
[I 2023-06-12 00:01:25,547] Trial 638 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.00014198897442694515, 'K': 9, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 6.541054895459819, 'loop': 0, 'loss': 'CE', 'lr': 0.0011749720823417528, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.107140207386328e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001050514972675111
weight_decay:  2.9275992789598073e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1086266308557242
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.063323845854029
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.1284580379724503
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.3409743309020996
total time:  3.3954085051082075
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.53
[I 2023-06-12 00:01:29,444] Trial 639 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0034452270144264786, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.9131429207504382, 'loop': 0, 'loss': 'CE', 'lr': 0.001050514972675111, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.9275992789598073e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0014662403861758272
weight_decay:  8.348530568598903e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 98.33%, Valid: 70.00% Test: 69.80%
Split: 01, Run: 01
None time:  1.799149053869769
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 98.33
   Final Test: 69.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 98.33%, Valid: 70.20% Test: 69.70%
Split: 01, Run: 02
None time:  1.7655683720950037
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 98.33
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 98.33%, Valid: 69.60% Test: 69.90%
Split: 01, Run: 03
None time:  1.7716796579770744
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 98.33
   Final Test: 69.80
run time now: 5.376318454742432
total time:  5.4442508039064705
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.31
  Final Train: 98.33 ± 0.00
   Final Test: 69.77 ± 0.06
[I 2023-06-12 00:01:35,420] Trial 640 finished with value: 69.93334197998047 and parameters: {'Fwd': 0.001056808213291086, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 0.11652633716005312, 'loop': 0, 'loss': 'MSE', 'lr': 0.0014662403861758272, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.348530568598903e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0012403325183762254
weight_decay:  0.0004900057839731231
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0396472429856658
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0004211510531604
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1316327350214124
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.2106919288635254
total time:  3.2677198969759047
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.46
[I 2023-06-12 00:01:39,164] Trial 641 finished with value: 71.93333435058594 and parameters: {'Fwd': 1.63032349691472e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.083322471578327, 'loop': 0, 'loss': 'CE', 'lr': 0.0012403325183762254, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0004900057839731231, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.00038875968648038065
weight_decay:  0.0001676464707379403
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9456449979916215
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0359070498961955
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.70
Split: 01, Run: 03
None time:  0.9672357710078359
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.20
run time now: 2.989210367202759
total time:  3.042450370034203
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 1.70
  Final Train: 100.00 ± 0.00
   Final Test: 68.23 ± 2.21
[I 2023-06-12 00:01:42,738] Trial 642 finished with value: 68.46666717529297 and parameters: {'Fwd': 2.330756803890562e-06, 'K': 8, 'alpha': 0.9, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 7.473648567242295, 'loop': 0, 'loss': 'CE', 'lr': 0.00038875968648038065, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0001676464707379403, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.00011409512265135154
weight_decay:  7.349129765706767e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.00% Test: 66.30%
Split: 01, Run: 01
None time:  1.7596421260386705
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.90
Split: 01, Run: 02
None time:  1.187579344958067
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.20% Test: 69.10%
Split: 01, Run: 03
None time:  1.8600714078638703
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 69.10
run time now: 4.847825765609741
total time:  4.906374684069306
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 67.30 ± 1.64
[I 2023-06-12 00:01:48,172] Trial 643 finished with value: 66.53333282470703 and parameters: {'Fwd': 0.06371202598325557, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.572294556715578, 'loop': 0, 'loss': 'CE', 'lr': 0.00011409512265135154, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.349129765706767e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0017753223057742327
weight_decay:  1.232362332696769e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0378699069842696
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.155197286978364
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.035350866150111
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.30
run time now: 3.271655559539795
total time:  3.3275786859449
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 70.67 ± 0.78
[I 2023-06-12 00:01:52,007] Trial 644 finished with value: 71.0 and parameters: {'Fwd': 0.0006587726156746257, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.1, 'lambda2': 5.865161693075929, 'loop': 0, 'loss': 'CE', 'lr': 0.0017753223057742327, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.232362332696769e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013768997673059295
weight_decay:  4.871073388186928e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0003153709694743
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0257039130665362
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.1512241610325873
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.2175071239471436
total time:  3.274782483931631
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.31
[I 2023-06-12 00:01:55,808] Trial 645 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.04778131642088943, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.990536293255364, 'loop': 0, 'loss': 'CE', 'lr': 0.0013768997673059295, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.871073388186928e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.0011242232188930755
weight_decay:  0.00010674826062514966
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0412398709449917
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0564418861176819
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.180446685058996
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.319190740585327
total time:  3.37284879013896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.59
[I 2023-06-12 00:01:59,629] Trial 646 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.023113816510910913, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 4.281612009983706, 'loop': 0, 'loss': 'CE', 'lr': 0.0011242232188930755, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010674826062514966, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.75
lr:  0.001575488670483464
weight_decay:  6.631734399239105e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0224724910221994
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.9672450590878725
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.9791234189178795
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.007298231124878
total time:  3.0645530379842967
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.71
[I 2023-06-12 00:02:03,254] Trial 647 finished with value: 70.66667175292969 and parameters: {'Fwd': 3.4820628348320446e-05, 'K': 7, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 4.616511277776958, 'loop': 0, 'loss': 'CE', 'lr': 0.001575488670483464, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.631734399239105e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.0019563148098402116
weight_decay:  1.9433135147469206e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6445921009872109
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.40
Split: 01, Run: 02
None time:  0.7205338049679995
None Run 02:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 59.40
Split: 01, Run: 03
None time:  0.7678552058059722
None Run 03:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 98.33
   Final Test: 63.10
run time now: 2.1716201305389404
total time:  2.2188616571947932
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.20 ± 7.87
  Final Train: 99.44 ± 0.96
   Final Test: 56.30 ± 8.77
[I 2023-06-12 00:02:06,105] Trial 648 finished with value: 55.20000076293945 and parameters: {'Fwd': 0.002097090379606805, 'K': 8, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.293718703126865, 'loop': 0, 'loss': 'CE', 'lr': 0.0019563148098402116, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.9433135147469206e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0002632892871679312
weight_decay:  0.000199860947916384
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0752797280438244
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.90%
Split: 01, Run: 02
None time:  1.736269178101793
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0548360201064497
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.90983247756958
total time:  3.9682780168950558
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.80
[I 2023-06-12 00:02:10,586] Trial 649 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.041746218318249304, 'K': 8, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.593097995933796, 'loop': 0, 'loss': 'CE', 'lr': 0.0002632892871679312, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000199860947916384, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.003557158835064328
weight_decay:  3.6726514652742556e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.110220008995384
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 70.20%
Split: 01, Run: 02
None time:  1.8516513349022716
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.127617449965328
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.13105320930481
total time:  4.188937004189938
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.10
[I 2023-06-12 00:02:15,344] Trial 650 finished with value: 70.73332977294922 and parameters: {'Fwd': 0.06775243926209319, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.25, 'lambda2': 8.86220826944456, 'loop': 0, 'loss': 'CE', 'lr': 0.003557158835064328, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.6726514652742556e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0012895875021279115
weight_decay:  0.00032940445971650926
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0368235770147294
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9955072009470314
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0639446540735662
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.136047840118408
total time:  3.1930318539962173
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.62
[I 2023-06-12 00:02:19,111] Trial 651 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.001755449115186333, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.089006474736955, 'loop': 0, 'loss': 'CE', 'lr': 0.0012895875021279115, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00032940445971650926, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0014419504281191673
weight_decay:  0.0007332562765910337
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.002199118025601
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.9669981668703258
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.9273298848420382
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.9363884925842285
total time:  2.988213036907837
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 1.21
[I 2023-06-12 00:02:22,597] Trial 652 finished with value: 70.26666259765625 and parameters: {'Fwd': 1.2219904045059781e-06, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 6.40604189106754, 'loop': 0, 'loss': 'CE', 'lr': 0.0014419504281191673, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007332562765910337, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.001195744062554794
weight_decay:  2.8740700397772138e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7494982739444822
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.8223184880334884
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.7873104210011661
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.3995041847229004
total time:  2.4501801000442356
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.53
[I 2023-06-12 00:02:25,532] Trial 653 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.0013101205247911724, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 9.203984362283071, 'loop': 0, 'loss': 'CE', 'lr': 0.001195744062554794, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8740700397772138e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.003941585630962798
weight_decay:  0.0036722558749089098
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.172043995000422
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.2285257999319583
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.1088957430329174
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.5521247386932373
total time:  3.608105869963765
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.35
  Final Train: 99.44 ± 0.48
   Final Test: 69.90 ± 0.56
[I 2023-06-12 00:02:29,690] Trial 654 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.005330648727257796, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.602236653262714, 'loop': 0, 'loss': 'CE', 'lr': 0.003941585630962798, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0036722558749089098, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.00018330496847478373
weight_decay:  4.084833505675314e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0973136669490486
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02
None time:  1.1117557201068848
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0840790309011936
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.332761287689209
total time:  3.381546420045197
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 1.04
[I 2023-06-12 00:02:33,561] Trial 655 finished with value: 68.86666107177734 and parameters: {'Fwd': 4.483331812393555e-06, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 2.166102650728975, 'loop': 0, 'loss': 'CE', 'lr': 0.00018330496847478373, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.084833505675314e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0009958865304307478
weight_decay:  0.0024517205685978174
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0544597341213375
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.9963009010534734
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1378719818312675
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.2331924438476562
total time:  3.280800050124526
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.55
[I 2023-06-12 00:02:37,386] Trial 656 finished with value: 70.86666870117188 and parameters: {'Fwd': 9.560225988284164e-06, 'K': 8, 'alpha': 0.8, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.925602673834784, 'loop': 0, 'loss': 'CE', 'lr': 0.0009958865304307478, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0024517205685978174, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.0017063273329936172
weight_decay:  0.009219633673165275
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.055996340001002
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1529466309584677
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.1693846939597279
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.421298027038574
total time:  3.48226423189044
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.44
[I 2023-06-12 00:02:41,455] Trial 657 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.0533110602834627, 'K': 7, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 4.781304165264851, 'loop': 0, 'loss': 'CE', 'lr': 0.0017063273329936172, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.009219633673165275, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0013125757062600603
weight_decay:  1.4549284090072951e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0673641259782016
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0383252939209342
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0217543658800423
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.1676888465881348
total time:  3.2177082321140915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.12
[I 2023-06-12 00:02:45,163] Trial 658 finished with value: 72.0 and parameters: {'Fwd': 0.028788308585860598, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 3.692769150658383, 'loop': 0, 'loss': 'CE', 'lr': 0.0013125757062600603, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4549284090072951e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.0015663077754942154
weight_decay:  1.5559605915897854e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 70.20%
Split: 01, Run: 01
None time:  1.802353928098455
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 69.40%
Split: 01, Run: 02
None time:  1.8543300819583237
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.60% Test: 69.70%
Split: 01, Run: 03
None time:  1.8351580130401999
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 5.542258262634277
total time:  5.599360317923129
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.27 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.40
[I 2023-06-12 00:02:51,276] Trial 659 finished with value: 69.26666259765625 and parameters: {'Fwd': 0.0300256575492789, 'K': 9, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 3.5777545075992188, 'loop': 0, 'loss': 'MSE', 'lr': 0.0015663077754942154, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5559605915897854e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.00021850222321462552
weight_decay:  1.0945221060957316e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 68.60%
Split: 01, Run: 01
None time:  1.7780628940090537
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.0212069328408688
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.50
Split: 01, Run: 03
None time:  0.9902223229873925
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.80
run time now: 3.8292953968048096
total time:  3.8851235299371183
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.93 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 67.70 ± 1.15
[I 2023-06-12 00:02:55,661] Trial 660 finished with value: 67.9333267211914 and parameters: {'Fwd': 0.021730365171357513, 'K': 8, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 4.053107665452306, 'loop': 0, 'loss': 'CE', 'lr': 0.00021850222321462552, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0945221060957316e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.001349499634774854
weight_decay:  1.2806681182613382e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.158278264803812
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0157825930509716
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.119688777020201
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.3357279300689697
total time:  3.3929050150327384
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.40
[I 2023-06-12 00:02:59,566] Trial 661 finished with value: 71.86666870117188 and parameters: {'Fwd': 3.2504901018275245e-06, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 3.649920457697615, 'loop': 0, 'loss': 'CE', 'lr': 0.001349499634774854, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2806681182613382e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.0014385040822873767
weight_decay:  1.8691242094560278e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0252224451396614
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0277560639660805
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.0950952130369842
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.1961066722869873
total time:  3.2491448731161654
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.36
[I 2023-06-12 00:03:03,278] Trial 662 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.037873883926721696, 'K': 7, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.987603741204238, 'loop': 0, 'loss': 'CE', 'lr': 0.0014385040822873767, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.8691242094560278e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.001976948540963434
weight_decay:  0.002006023206977212
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9252646900713444
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0470468259882182
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.1606207008007914
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.184231758117676
total time:  3.2354117720387876
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.23
[I 2023-06-12 00:03:06,991] Trial 663 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.02912335370230348, 'K': 9, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 2.4313554631669754, 'loop': 0, 'loss': 'CE', 'lr': 0.001976948540963434, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.002006023206977212, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0016435897001285183
weight_decay:  2.437368750584786e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0936272251419723
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0617113390471786
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0470234660897404
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.2418885231018066
total time:  3.311553815146908
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.42
[I 2023-06-12 00:03:10,902] Trial 664 finished with value: 71.73332977294922 and parameters: {'Fwd': 7.830421071450125e-06, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 3.9485696795775125, 'loop': 0, 'loss': 'CE', 'lr': 0.0016435897001285183, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.437368750584786e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0012959385407085953
weight_decay:  9.031226657314002e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 68.70%
Split: 01, Run: 01
None time:  1.007783604087308
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 67.20%
Split: 01, Run: 02
None time:  1.0395190720446408
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 03
None time:  0.3103142259642482
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.60
run time now: 2.3991055488586426
total time:  2.454247595043853
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.60 ± 1.71
  Final Train: 100.00 ± 0.00
   Final Test: 67.53 ± 1.14
[I 2023-06-12 00:03:13,955] Trial 665 finished with value: 68.5999984741211 and parameters: {'Fwd': 0.046348206871389123, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 20, 'lambda1': 0.65, 'lambda2': 3.8163457604329256, 'loop': 0, 'loss': 'CE', 'lr': 0.0012959385407085953, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.031226657314002e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0025911313774092514
weight_decay:  1.4507412740569036e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.086287401849404
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.298550870968029
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.038866584887728
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.4642415046691895
total time:  3.5122434550430626
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 70.27 ± 0.42
[I 2023-06-12 00:03:18,090] Trial 666 finished with value: 71.0 and parameters: {'Fwd': 6.330172217577777e-05, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 6.632690282230139, 'loop': 1, 'loss': 'CE', 'lr': 0.0025911313774092514, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4507412740569036e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.00042967547505104285
weight_decay:  2.0639541944245506e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7175226700492203
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.60% Test: 66.40%
Split: 01, Run: 02
None time:  1.2616761000826955
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.00% Test: 64.20%
Split: 01, Run: 03
None time:  1.2720091410446912
None Run 03:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.20
run time now: 3.2927744388580322
total time:  3.35024063102901
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.13 ± 1.94
  Final Train: 100.00 ± 0.00
   Final Test: 65.57 ± 1.19
[I 2023-06-12 00:03:21,991] Trial 667 finished with value: 66.13333129882812 and parameters: {'Fwd': 0.07506943315817562, 'K': 8, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.389210877352065, 'loop': 0, 'loss': 'CE', 'lr': 0.00042967547505104285, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.0639541944245506e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0015201431314666304
weight_decay:  2.3509572602421256e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0091030660551041
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0166942779906094
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0958065409213305
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.1691529750823975
total time:  3.223959338152781
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.50
[I 2023-06-12 00:03:25,862] Trial 668 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.0003470544322429074, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 3.488120076682027, 'loop': 0, 'loss': 'CE', 'lr': 0.0015201431314666304, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3509572602421256e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.5
lr:  0.0005588539596745569
weight_decay:  0.0032351969776820227
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0842493230011314
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0825366210192442
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 70.00%
Split: 01, Run: 03
None time:  1.610633125063032
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.8134725093841553
total time:  3.868702568113804
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.31
[I 2023-06-12 00:03:30,274] Trial 669 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.03810984185218916, 'K': 5, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 3.764530476235173, 'loop': 0, 'loss': 'CE', 'lr': 0.0005588539596745569, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0032351969776820227, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0011038332318467257
weight_decay:  4.297836785716556e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0101731589529663
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0512218088842928
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 70.60%
Split: 01, Run: 03
None time:  1.7787908311001956
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.8819150924682617
total time:  3.9345928421244025
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.59
[I 2023-06-12 00:03:34,824] Trial 670 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.05599264868040731, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.067040813197033, 'loop': 0, 'loss': 'CE', 'lr': 0.0011038332318467257, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.297836785716556e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.55
lr:  0.0013772131458333853
weight_decay:  7.3696000248685194e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9642016820143908
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.067364010028541
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.054965274175629
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 3.120469093322754
total time:  3.17724610096775
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 1.68
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 1.51
[I 2023-06-12 00:03:38,524] Trial 671 finished with value: 70.73333740234375 and parameters: {'Fwd': 4.249600343478139e-05, 'K': 1, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 7.104745702111424, 'loop': 0, 'loss': 'CE', 'lr': 0.0013772131458333853, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.3696000248685194e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.006153858953722342
weight_decay:  0.0009430948913828822
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1907725278288126
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 97.50
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1000481150113046
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 98.33
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.1321315299719572
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 69.30
run time now: 3.4642324447631836
total time:  3.531149386893958
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.42
  Final Train: 98.33 ± 0.83
   Final Test: 69.33 ± 0.25
[I 2023-06-12 00:03:42,566] Trial 672 finished with value: 70.66666412353516 and parameters: {'Fwd': 2.2583947575700248e-05, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.478794697104983, 'loop': 0, 'loss': 'CE', 'lr': 0.006153858953722342, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009430948913828822, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.0017701709864866636
weight_decay:  0.000635182597556957
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0114048800896853
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0762317450717092
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.1136537150014192
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.2450342178344727
total time:  3.288983382983133
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.40
[I 2023-06-12 00:03:46,340] Trial 673 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.019819670238267875, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.423718140766724, 'loop': 0, 'loss': 'CE', 'lr': 0.0017701709864866636, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000635182597556957, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  1.0
lr:  0.0012635544269305205
weight_decay:  0.0017658694329982891
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0515259120147675
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0710480050183833
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1436855860520154
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.311594009399414
total time:  3.358192300889641
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.70
[I 2023-06-12 00:03:50,299] Trial 674 finished with value: 71.06666564941406 and parameters: {'Fwd': 1.5429169003803565e-06, 'K': 8, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.23697529159212, 'loop': 0, 'loss': 'CE', 'lr': 0.0012635544269305205, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0017658694329982891, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0014854367504174466
weight_decay:  1.0359074954890665e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9980299491435289
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0569831868633628
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.0854909368790686
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.1803436279296875
total time:  3.233910867013037
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.44
[I 2023-06-12 00:03:54,113] Trial 675 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.00890002741272827, 'K': 8, 'alpha': 0.5, 'dropout': 0.2, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.3037284931176085, 'loop': 0, 'loss': 'CE', 'lr': 0.0014854367504174466, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0359074954890665e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0011623416120221956
weight_decay:  0.007218407080505873
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9835708709433675
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.036456428002566
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.9719496651086956
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.0333714485168457
total time:  3.0881890011951327
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 1.00
[I 2023-06-12 00:03:57,780] Trial 676 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.02845585944476023, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 7.498000165020506, 'loop': 0, 'loss': 'CE', 'lr': 0.0011623416120221956, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007218407080505873, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0007699653841870579
weight_decay:  0.0027880558119419644
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0532595871482044
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.12156921508722
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 70.40%
Split: 01, Run: 03
None time:  1.7360035448800772
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.954291820526123
total time:  4.005316518014297
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.70
[I 2023-06-12 00:04:02,391] Trial 677 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.060068200477750085, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 1.7018689687474051, 'loop': 0, 'loss': 'CE', 'lr': 0.0007699653841870579, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0027880558119419644, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.004792297767023533
weight_decay:  5.748700761434469e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0482756891287863
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 95.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.2215070030651987
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 95.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0565874688327312
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 97.50
   Final Test: 69.20
run time now: 3.3653268814086914
total time:  3.409552204888314
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.12
  Final Train: 95.83 ± 1.44
   Final Test: 69.73 ± 0.47
[I 2023-06-12 00:04:06,275] Trial 678 finished with value: 70.53333282470703 and parameters: {'Fwd': 1.0212374801379538e-06, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 1.2531889395446805, 'loop': 0, 'loss': 'CE', 'lr': 0.004792297767023533, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.748700761434469e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.002070830611112073
weight_decay:  1.628700897927896e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.00% Test: 69.60%
Split: 01, Run: 01
None time:  1.7511046768631786
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.00% Test: 69.60%
Split: 01, Run: 02
None time:  1.724318017018959
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.20% Test: 69.60%
Split: 01, Run: 03
None time:  1.8080680160783231
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.60
run time now: 5.324053049087524
total time:  5.37952123908326
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.00
[I 2023-06-12 00:04:12,294] Trial 679 finished with value: 68.06666564941406 and parameters: {'Fwd': 0.08171849598977957, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.741757891767875, 'loop': 0, 'loss': 'MSE', 'lr': 0.002070830611112073, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.628700897927896e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.00134419484181376
weight_decay:  5.088604940662051e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1531776480842382
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0524877309799194
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1725113969296217
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.4214959144592285
total time:  3.4709438469726592
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.30
[I 2023-06-12 00:04:16,243] Trial 680 finished with value: 71.46666717529297 and parameters: {'Fwd': 2.8442723373307384e-06, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 6.754808760067175, 'loop': 0, 'loss': 'CE', 'lr': 0.00134419484181376, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.088604940662051e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0010826997167112226
weight_decay:  0.003837937927097986
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.011370537104085
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0793464810121804
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.1886069420725107
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.3200502395629883
total time:  3.3728018370456994
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.61
[I 2023-06-12 00:04:20,128] Trial 681 finished with value: 71.66666412353516 and parameters: {'Fwd': 1.4288862748020156e-05, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.265637690565052, 'loop': 0, 'loss': 'CE', 'lr': 0.0010826997167112226, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003837937927097986, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.002308208995345066
weight_decay:  3.382011615348268e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0711045768111944
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.1373846651986241
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0686523250769824
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 3.316161870956421
total time:  3.3754193880595267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.44
[I 2023-06-12 00:04:24,034] Trial 682 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.041455345464783515, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.3435484177914, 'loop': 0, 'loss': 'CE', 'lr': 0.002308208995345066, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.382011615348268e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.001652250228641387
weight_decay:  1.337200087837858e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.036610326031223
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0446239679586142
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0552561290096492
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.1762502193450928
total time:  3.224837995832786
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.36
[I 2023-06-12 00:04:27,807] Trial 683 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.0002247517305463259, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.178472615089727, 'loop': 0, 'loss': 'CE', 'lr': 0.001652250228641387, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.337200087837858e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.55
lr:  0.0012345330129223083
weight_decay:  2.3981223132987947e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9373094930779189
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0295109539292753
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  0.9955653040669858
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 2.9983890056610107
total time:  3.055882061831653
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.45
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 1.46
[I 2023-06-12 00:04:31,424] Trial 684 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.0001231231860887054, 'K': 2, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 5.003370634753812, 'loop': 0, 'loss': 'CE', 'lr': 0.0012345330129223083, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3981223132987947e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.001453917421352773
weight_decay:  0.004568654415388179
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0683019470889121
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0921178550925106
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0731989110354334
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.10
run time now: 3.274939775466919
total time:  3.3293138328008354
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.30 ± 0.72
[I 2023-06-12 00:04:35,277] Trial 685 finished with value: 71.66667175292969 and parameters: {'Fwd': 6.231054729289139e-06, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.97182507317721, 'loop': 0, 'loss': 'CE', 'lr': 0.001453917421352773, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004568654415388179, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.007929238978954357
weight_decay:  3.194020454610639e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6990637958515435
None Run 01:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 97.50
   Final Test: 56.60
Split: 01, Run: 02
None time:  0.7088945750147104
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 99.17
   Final Test: 63.30
Split: 01, Run: 03
None time:  0.7650120449252427
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.00
run time now: 2.215693712234497
total time:  2.2632032961118966
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.13 ± 2.73
  Final Train: 98.89 ± 1.27
   Final Test: 61.63 ± 4.44
[I 2023-06-12 00:04:38,117] Trial 686 finished with value: 65.13333129882812 and parameters: {'Fwd': 0.00711095723681928, 'K': 9, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.815755901036075, 'loop': 0, 'loss': 'CE', 'lr': 0.007929238978954357, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.194020454610639e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0018436350382816647
weight_decay:  2.888404452242414e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0247305480297655
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.9868813070934266
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0707748930435628
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.122882604598999
total time:  3.17566443211399
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.10
[I 2023-06-12 00:04:41,780] Trial 687 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.026388443069104858, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.216517037513755, 'loop': 0, 'loss': 'CE', 'lr': 0.0018436350382816647, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.888404452242414e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.009344042728415098
weight_decay:  1.905386123071196e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0357246238272637
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.40% Test: 68.70%
Split: 01, Run: 02
None time:  1.6817460858728737
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 69.40% Test: 69.20%
Split: 01, Run: 03
None time:  1.7472589409444481
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 99.17
   Final Test: 69.30
run time now: 4.506129264831543
total time:  4.567382239038125
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.40 ± 1.00
  Final Train: 99.44 ± 0.48
   Final Test: 68.83 ± 0.50
[I 2023-06-12 00:04:46,882] Trial 688 finished with value: 68.4000015258789 and parameters: {'Fwd': 0.0493546081733916, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.55, 'lambda2': 4.0724585047808795, 'loop': 0, 'loss': 'CE', 'lr': 0.009344042728415098, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.905386123071196e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.000895752849692045
weight_decay:  0.005477438572613086
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0285408769268543
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0758749649394304
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.2903593610972166
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.4447479248046875
total time:  3.495817705988884
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.38
[I 2023-06-12 00:04:50,888] Trial 689 finished with value: 71.13333129882812 and parameters: {'Fwd': 1.032654517375257e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.551449690565116, 'loop': 0, 'loss': 'CE', 'lr': 0.000895752849692045, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005477438572613086, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.5
lr:  0.0013308810183369616
weight_decay:  6.561862954916147e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9921574841719121
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.9584514768794179
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.0487411259673536
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.036015033721924
total time:  3.090853980043903
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.70
[I 2023-06-12 00:04:54,558] Trial 690 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.03275339796519272, 'K': 3, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.9890632307596725, 'loop': 0, 'loss': 'CE', 'lr': 0.0013308810183369616, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.561862954916147e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0015674549596655693
weight_decay:  4.476377060923098e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.014376405859366
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0450509611982852
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.2096057289745659
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.3111319541931152
total time:  3.3629595930688083
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.49
[I 2023-06-12 00:04:58,416] Trial 691 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.0003385008432496907, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.817081731538986, 'loop': 0, 'loss': 'CE', 'lr': 0.0015674549596655693, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.476377060923098e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.00042320030553936956
weight_decay:  1.029536076716043e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2631987950298935
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.280833733966574
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.2718907191883773
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.857224941253662
total time:  3.907828707015142
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.67 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.12
[I 2023-06-12 00:05:02,858] Trial 692 finished with value: 69.66666412353516 and parameters: {'Fwd': 2.206203725518819e-06, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.6497366139842375, 'loop': 2, 'loss': 'CE', 'lr': 0.00042320030553936956, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.029536076716043e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.001172074228290502
weight_decay:  6.34342572743613e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0620495760813355
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1165603110566735
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.0734077680390328
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.3028736114501953
total time:  3.358210003003478
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.35
[I 2023-06-12 00:05:06,794] Trial 693 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.0609759676361849, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.894506719240701, 'loop': 0, 'loss': 'CE', 'lr': 0.001172074228290502, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.34342572743613e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0013918028892342554
weight_decay:  2.012727349511782e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0491224562283605
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0356220970861614
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1488658969756216
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.272648811340332
total time:  3.318949769018218
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.36
[I 2023-06-12 00:05:10,617] Trial 694 finished with value: 71.66666412353516 and parameters: {'Fwd': 9.725961610317752e-05, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.307282369053867, 'loop': 0, 'loss': 'CE', 'lr': 0.0013918028892342554, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.012727349511782e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.001013009278501246
weight_decay:  0.0014998762861314296
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0135014429688454
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.947589326184243
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  1.0710665159858763
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 3.0749666690826416
total time:  3.123904898064211
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 69.00 ± 0.95
[I 2023-06-12 00:05:14,285] Trial 695 finished with value: 70.13333892822266 and parameters: {'Fwd': 0.03930710256893937, 'K': 8, 'alpha': 0.8, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 4.823153351498831, 'loop': 0, 'loss': 'CE', 'lr': 0.001013009278501246, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0014998762861314296, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012721903893753116
weight_decay:  8.916961751234649e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0474452679045498
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0852494009304792
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.40%
Split: 01, Run: 03
None time:  1.7938018417917192
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.9730594158172607
total time:  4.031570551218465
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.42
[I 2023-06-12 00:05:18,852] Trial 696 finished with value: 71.86666107177734 and parameters: {'Fwd': 0.018585048370758514, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 7.344082864396366, 'loop': 0, 'loss': 'CE', 'lr': 0.0012721903893753116, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.916961751234649e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.007763882150254866
weight_decay:  3.426773839523297e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.60% Test: 66.10%
Split: 01, Run: 01
None time:  1.8760473120491952
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.80% Test: 66.40%
Split: 01, Run: 02
None time:  1.7781695760786533
None Run 02:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.40% Test: 65.90%
Split: 01, Run: 03
None time:  1.7801484090741724
None Run 03:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.80
run time now: 5.474715709686279
total time:  5.522741609020159
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 66.10 ± 0.30
[I 2023-06-12 00:05:24,932] Trial 697 finished with value: 64.60000610351562 and parameters: {'Fwd': 2.318502617601766e-05, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.640936043668539, 'loop': 0, 'loss': 'MSE', 'lr': 0.007763882150254866, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.426773839523297e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.00015108206661795066
weight_decay:  0.044846418543099384
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0415678380522877
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 02
None time:  1.061083032982424
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  1.0713774599134922
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.2193894386291504
total time:  3.2679238580167294
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 67.80 ± 1.45
[I 2023-06-12 00:05:28,712] Trial 698 finished with value: 67.06666564941406 and parameters: {'Fwd': 0.07470287857133097, 'K': 7, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.207251520131422, 'loop': 0, 'loss': 'CE', 'lr': 0.00015108206661795066, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.044846418543099384, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0006575585471393524
weight_decay:  0.012042165145442563
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9905180800706148
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.9295334410853684
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  1.006765634054318
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.96633243560791
total time:  3.018973212921992
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 68.87 ± 1.02
[I 2023-06-12 00:05:32,253] Trial 699 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.0034029095715998785, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 3.622740790503164, 'loop': 0, 'loss': 'CE', 'lr': 0.0006575585471393524, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.012042165145442563, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0001359472704498763
weight_decay:  0.0004882761152615293
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0213765988592058
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.00% Test: 68.00%
Split: 01, Run: 02
None time:  1.88831437099725
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.120886008022353
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 69.30
run time now: 4.072064161300659
total time:  4.125752395950258
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.73 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 68.13 ± 1.11
[I 2023-06-12 00:05:36,927] Trial 700 finished with value: 67.73333740234375 and parameters: {'Fwd': 0.09601185971905853, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.6780453513197315, 'loop': 0, 'loss': 'CE', 'lr': 0.0001359472704498763, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0004882761152615293, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0015186728607967073
weight_decay:  1.5015005800559288e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.023052919888869
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.033087142976001
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0713003720156848
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 3.175727605819702
total time:  3.2242132101673633
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.17
[I 2023-06-12 00:05:40,668] Trial 701 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.049829560796930586, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 3.872836880342353, 'loop': 0, 'loss': 'CE', 'lr': 0.0015186728607967073, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5015005800559288e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.00281188159637678
weight_decay:  3.90213754228075e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0544742031488568
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.034907041117549
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.108701451914385
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.2428767681121826
total time:  3.2982189811300486
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.55
[I 2023-06-12 00:05:44,547] Trial 702 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.03363515250888381, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.4693282386690045, 'loop': 0, 'loss': 'CE', 'lr': 0.00281188159637678, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.90213754228075e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0010891716569418847
weight_decay:  2.223695798425838e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2043713331222534
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.2087336729746312
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.118842639029026
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.5746915340423584
total time:  3.636870717164129
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.47
[I 2023-06-12 00:05:48,738] Trial 703 finished with value: 71.0 and parameters: {'Fwd': 9.778176931794982e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.386992323559787, 'loop': 1, 'loss': 'CE', 'lr': 0.0010891716569418847, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.223695798425838e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0002068915683368082
weight_decay:  0.0009396352784278576
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9931332319974899
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.0978058180771768
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 03
None time:  1.028642073040828
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.80
run time now: 3.159252643585205
total time:  3.21100240200758
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 68.00 ± 0.82
[I 2023-06-12 00:05:52,441] Trial 704 finished with value: 67.79999542236328 and parameters: {'Fwd': 0.023396831175524484, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 5.133011671403709, 'loop': 0, 'loss': 'CE', 'lr': 0.0002068915683368082, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009396352784278576, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.001711786967187056
weight_decay:  0.03470038686608449
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7299528149887919
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.20
Split: 01, Run: 02
None time:  0.7157812730874866
None Run 02:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 55.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 56.80% Test: 55.00%
Split: 01, Run: 03
None time:  1.2630527629517019
None Run 03:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 55.00
run time now: 2.7462968826293945
total time:  2.7985377500299364
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.40 ± 5.11
  Final Train: 100.00 ± 0.00
   Final Test: 52.23 ± 5.23
[I 2023-06-12 00:05:55,806] Trial 705 finished with value: 52.40000534057617 and parameters: {'Fwd': 0.06388519334812717, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 8.193583943123345, 'loop': 0, 'loss': 'CE', 'lr': 0.001711786967187056, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.03470038686608449, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0024568473277108544
weight_decay:  0.00011480761065736925
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0708512880373746
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0531165970023721
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.129640518920496
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
run time now: 3.29425311088562
total time:  3.344602297991514
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.47
[I 2023-06-12 00:05:59,689] Trial 706 finished with value: 71.66666412353516 and parameters: {'Fwd': 7.820649038783653e-05, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 7.03052311344363, 'loop': 0, 'loss': 'CE', 'lr': 0.0024568473277108544, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00011480761065736925, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0012317897721235802
weight_decay:  2.671668276227861e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.846781644038856
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9328911118209362
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  0.825071529019624
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.30
run time now: 2.646588087081909
total time:  2.702426344854757
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.51
[I 2023-06-12 00:06:02,992] Trial 707 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.04396849255404202, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 8.449128993955373, 'loop': 0, 'loss': 'CE', 'lr': 0.0012317897721235802, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.671668276227861e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.0020157606776961333
weight_decay:  4.8648349957983097e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.036709126085043
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0822985540144145
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.0026979881804436
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.1716179847717285
total time:  3.227637992007658
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.23
[I 2023-06-12 00:06:06,705] Trial 708 finished with value: 71.79999542236328 and parameters: {'Fwd': 1.7430720375426917e-05, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.426805717472807, 'loop': 0, 'loss': 'CE', 'lr': 0.0020157606776961333, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.8648349957983097e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.001397562393320963
weight_decay:  8.31688950436897e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0055984111968428
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.1584406609181315
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0704631060361862
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 95.83
   Final Test: 70.60
run time now: 3.2746639251708984
total time:  3.326847149990499
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.80
  Final Train: 97.78 ± 1.73
   Final Test: 69.87 ± 0.87
[I 2023-06-12 00:06:10,574] Trial 709 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.0039002619541873168, 'K': 8, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 0.6090077931383533, 'loop': 0, 'loss': 'CE', 'lr': 0.001397562393320963, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.31688950436897e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.006144451231923726
weight_decay:  1.234884659433469e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.168327647028491
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1226490479893982
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.115482916124165
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 3.4473366737365723
total time:  3.4983128218445927
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.12
  Final Train: 99.44 ± 0.48
   Final Test: 69.40 ± 0.26
[I 2023-06-12 00:06:14,674] Trial 710 finished with value: 70.73332977294922 and parameters: {'Fwd': 1.6074076094933923e-06, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.990536999038406, 'loop': 0, 'loss': 'CE', 'lr': 0.006144451231923726, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.234884659433469e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013048753318517419
weight_decay:  1.7254597508457786e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6019242021720856
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.696129716001451
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  0.6511177020147443
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 1.9956562519073486
total time:  2.041989393066615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.32
[I 2023-06-12 00:06:17,223] Trial 711 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.00020513576796694915, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 2.0977401848356414, 'loop': 0, 'loss': 'CE', 'lr': 0.0013048753318517419, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.7254597508457786e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0009531126466493622
weight_decay:  3.563732118086828e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0208540309686214
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.9605001918971539
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  1.0411415409762412
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.064021587371826
total time:  3.1080105919390917
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.98
[I 2023-06-12 00:06:20,870] Trial 712 finished with value: 70.0 and parameters: {'Fwd': 0.002729532353971354, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 7.581492337098252, 'loop': 0, 'loss': 'CE', 'lr': 0.0009531126466493622, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.563732118086828e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0011365856422924355
weight_decay:  2.83224436769696e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.034482709132135
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0954016190953553
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 71.10%
Split: 01, Run: 03
None time:  1.8259815268684179
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 4.000287055969238
total time:  4.048195451963693
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.57
[I 2023-06-12 00:06:25,416] Trial 713 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.055048838610851816, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.037552245864863, 'loop': 0, 'loss': 'CE', 'lr': 0.0011365856422924355, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.83224436769696e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0015238692829426695
weight_decay:  0.0011040159509088621
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9620624191593379
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.05924649303779
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0523457878734916
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.1128790378570557
total time:  3.157681494951248
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.50
[I 2023-06-12 00:06:29,112] Trial 714 finished with value: 71.66666412353516 and parameters: {'Fwd': 4.6753386018308585e-06, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 4.947518213828207, 'loop': 0, 'loss': 'CE', 'lr': 0.0015238692829426695, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0011040159509088621, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0005937986252773199
weight_decay:  0.015209851510885561
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0076678520999849
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0409714449197054
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  1.224106972105801
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.3140010833740234
total time:  3.380891869077459
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.56
[I 2023-06-12 00:06:32,987] Trial 715 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.030090949826255042, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 5.815685051470198, 'loop': 0, 'loss': 'CE', 'lr': 0.0005937986252773199, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.015209851510885561, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.4
lr:  0.000798006634086432
weight_decay:  2.2396064662002177e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 69.10%
Split: 01, Run: 01
None time:  1.6034460531082004
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0529782781377435
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 69.70%
Split: 01, Run: 03
None time:  1.6805004349444062
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 4.3759095668792725
total time:  4.429963040864095
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.37 ± 0.29
[I 2023-06-12 00:06:37,960] Trial 716 finished with value: 70.13333129882812 and parameters: {'Fwd': 1.396410191745917e-05, 'K': 7, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 7.851556989184036, 'loop': 0, 'loss': 'MSE', 'lr': 0.000798006634086432, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2396064662002177e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.001786197677339232
weight_decay:  0.061062851968385706
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0118648489005864
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.14011914213188
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0744313062168658
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.266484498977661
total time:  3.3108680869918317
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.62
[I 2023-06-12 00:06:41,759] Trial 717 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.004902086032915101, 'K': 8, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.306356908762689, 'loop': 0, 'loss': 'CE', 'lr': 0.001786197677339232, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.061062851968385706, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.001420387372861736
weight_decay:  4.6290102363705315e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0324124367907643
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.0630309621337801
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.140440730145201
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.10
run time now: 3.2794594764709473
total time:  3.3275082861073315
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.27 ± 0.74
[I 2023-06-12 00:06:45,593] Trial 718 finished with value: 71.73332977294922 and parameters: {'Fwd': 3.299178687583768e-05, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.754764156859904, 'loop': 0, 'loss': 'CE', 'lr': 0.001420387372861736, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.6290102363705315e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012681716714040287
weight_decay:  5.746263825157681e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.012800124939531
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 98.33
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.0578647861257195
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 98.33
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.149430274963379
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 93.33
   Final Test: 70.70
run time now: 3.259601593017578
total time:  3.322740025119856
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 96.67 ± 2.89
   Final Test: 69.97 ± 0.70
[I 2023-06-12 00:06:49,433] Trial 719 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.0004530716671089493, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 0.40686137964991786, 'loop': 0, 'loss': 'CE', 'lr': 0.0012681716714040287, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.746263825157681e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0022273827467409525
weight_decay:  2.9727829675179374e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0635811330284923
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.9813104348722845
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0182959551457316
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.1049399375915527
total time:  3.1526929130777717
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.29
[I 2023-06-12 00:06:53,104] Trial 720 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.03893815190930779, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.015886812337037, 'loop': 0, 'loss': 'CE', 'lr': 0.0022273827467409525, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.9727829675179374e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0016525368663594113
weight_decay:  3.992518711891142e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0303850988857448
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0868998470250517
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.024115694919601
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.181220293045044
total time:  3.229075464885682
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.31
[I 2023-06-12 00:06:56,882] Trial 721 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.008555401803509164, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 3.4815805126892143, 'loop': 0, 'loss': 'CE', 'lr': 0.0016525368663594113, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.992518711891142e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.00022217538661024007
weight_decay:  0.0007289901602800807
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0495264159981161
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0804979098029435
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.60% Test: 70.30%
Split: 01, Run: 03
None time:  1.7927086791023612
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.9644691944122314
total time:  4.019015718018636
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.57
[I 2023-06-12 00:07:01,488] Trial 722 finished with value: 69.0666732788086 and parameters: {'Fwd': 0.07404055505719681, 'K': 8, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.713118912708586, 'loop': 0, 'loss': 'CE', 'lr': 0.00022217538661024007, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007289901602800807, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0011775205104474446
weight_decay:  0.09245925604896912
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0229650118853897
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.9670987839344889
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.148589475080371
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.1865057945251465
total time:  3.23913372005336
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.49
[I 2023-06-12 00:07:05,384] Trial 723 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.018088041832053984, 'K': 8, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 2.3516588726860554, 'loop': 0, 'loss': 'CE', 'lr': 0.0011775205104474446, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.09245925604896912, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.00034536992685300585
weight_decay:  0.0024899067222349377
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8441501918714494
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  0.8421879869420081
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 98.33
   Final Test: 63.70
Split: 01, Run: 03
None time:  0.8260980481281877
None Run 03:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 98.33
   Final Test: 61.60
run time now: 2.5556397438049316
total time:  2.6078723079990596
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.87 ± 2.53
  Final Train: 98.89 ± 0.96
   Final Test: 64.10 ± 2.72
[I 2023-06-12 00:07:08,556] Trial 724 finished with value: 65.86666870117188 and parameters: {'Fwd': 0.009797146955903164, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 6.5697164575270275, 'loop': 0, 'loss': 'CE', 'lr': 0.00034536992685300585, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0024899067222349377, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013392713395879042
weight_decay:  0.025253305918766396
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9314056418370456
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.973518606973812
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.0392077639698982
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 2.9844703674316406
total time:  3.05398394796066
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.98
[I 2023-06-12 00:07:12,170] Trial 725 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.04847363470136932, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 4.093519698293294, 'loop': 0, 'loss': 'CE', 'lr': 0.0013392713395879042, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.025253305918766396, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0014984073980197337
weight_decay:  8.677371557253462e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0095737441442907
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0062995709013194
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.9678545899223536
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.0311949253082275
total time:  3.0898082880303264
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.80
[I 2023-06-12 00:07:15,824] Trial 726 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.02432908178896705, 'K': 10, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 7.26197935160048, 'loop': 0, 'loss': 'CE', 'lr': 0.0014984073980197337, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.677371557253462e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0010386437424994546
weight_decay:  1.7871107352005597e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0105445270892233
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0573563082143664
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.166777155129239
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.273956775665283
total time:  3.330287842079997
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.40
[I 2023-06-12 00:07:19,709] Trial 727 finished with value: 71.46666717529297 and parameters: {'Fwd': 8.615922332532069e-06, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.666775636259884, 'loop': 0, 'loss': 'CE', 'lr': 0.0010386437424994546, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.7871107352005597e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0012016507244498598
weight_decay:  1.0257423686450983e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0478015751577914
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.069958879146725
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0738501029554754
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.236785411834717
total time:  3.286521404981613
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.56
[I 2023-06-12 00:07:23,514] Trial 728 finished with value: 71.86666107177734 and parameters: {'Fwd': 1.2716213257856193e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 9.00845386198777, 'loop': 0, 'loss': 'CE', 'lr': 0.0012016507244498598, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0257423686450983e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0019274199742978684
weight_decay:  0.0005661906566561955
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0509065170772374
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0298735580872744
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.026365782134235
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.155254602432251
total time:  3.2126367001328617
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.15
[I 2023-06-12 00:07:27,224] Trial 729 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.0001369263653492031, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.73456347370504, 'loop': 0, 'loss': 'CE', 'lr': 0.0019274199742978684, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005661906566561955, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013979964084471813
weight_decay:  1.3976082557045772e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0891279568895698
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0941240689717233
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.1098303869366646
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.3334567546844482
total time:  3.3890854141209275
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 0.47
[I 2023-06-12 00:07:31,123] Trial 730 finished with value: 71.79999542236328 and parameters: {'Fwd': 2.0637593186169173e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 3.7690922391644723, 'loop': 0, 'loss': 'CE', 'lr': 0.0013979964084471813, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3976082557045772e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.00011371285443201533
weight_decay:  6.0465208182808714e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0957122498657554
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.068459894042462
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.80% Test: 68.40%
Split: 01, Run: 03
None time:  1.8104401580058038
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.30
run time now: 4.016180753707886
total time:  4.072815016144887
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.07 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 67.83 ± 0.72
[I 2023-06-12 00:07:35,734] Trial 731 finished with value: 67.06665802001953 and parameters: {'Fwd': 1.326810012608097e-06, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 9.541200455044832, 'loop': 0, 'loss': 'CE', 'lr': 0.00011371285443201533, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.0465208182808714e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0015748026178619863
weight_decay:  2.5353344683548823e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0690525190439075
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0337033888790756
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0575917069800198
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.1991562843322754
total time:  3.2459691299591213
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.56
[I 2023-06-12 00:07:39,585] Trial 732 finished with value: 71.46666717529297 and parameters: {'Fwd': 4.808377240631677e-05, 'K': 8, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.248839658027424, 'loop': 0, 'loss': 'CE', 'lr': 0.0015748026178619863, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.5353344683548823e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.0010723504567133472
weight_decay:  0.0015486023920816127
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0229428969323635
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.0705622618552297
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0924794930033386
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 3.228804111480713
total time:  3.2867084939498454
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.61
[I 2023-06-12 00:07:43,482] Trial 733 finished with value: 70.73333740234375 and parameters: {'Fwd': 6.0791683638994055e-05, 'K': 9, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.83787367771636, 'loop': 0, 'loss': 'CE', 'lr': 0.0010723504567133472, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0015486023920816127, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0035112803651384966
weight_decay:  3.4596468721754676e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9570588099304587
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.9884025971405208
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  1.032325325999409
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.01835036277771
total time:  3.0666392010170966
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 0.70
[I 2023-06-12 00:07:47,169] Trial 734 finished with value: 70.73332977294922 and parameters: {'Fwd': 6.78547759269919e-05, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 6.469523550746115, 'loop': 0, 'loss': 'CE', 'lr': 0.0035112803651384966, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.4596468721754676e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013098206521529217
weight_decay:  0.0020495633986108075
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.60%
Split: 01, Run: 01
None time:  1.726997439051047
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.70%
Split: 01, Run: 02
None time:  1.8452510559000075
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.30%
Split: 01, Run: 03
None time:  1.7969932609703392
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 5.420924186706543
total time:  5.472396444994956
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.15
[I 2023-06-12 00:07:53,255] Trial 735 finished with value: 70.0 and parameters: {'Fwd': 0.006539225788325994, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 1.6743569478103892, 'loop': 0, 'loss': 'MSE', 'lr': 0.0013098206521529217, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0020495633986108075, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.65
lr:  0.005048212515603974
weight_decay:  0.00013392136944496505
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0526812069583684
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 69.90%
Split: 01, Run: 02
None time:  1.6576936340425164
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 69.00%
Split: 01, Run: 03
None time:  1.694060550071299
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.00
run time now: 4.440487384796143
total time:  4.483477517031133
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.70
[I 2023-06-12 00:07:58,324] Trial 736 finished with value: 70.60000610351562 and parameters: {'Fwd': 0.09739561193617959, 'K': 5, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.9603411737821546, 'loop': 0, 'loss': 'CE', 'lr': 0.005048212515603974, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00013392136944496505, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.001170914377286405
weight_decay:  0.005975379445904351
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0378475410398096
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1023218280170113
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.109645745018497
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.290264844894409
total time:  3.335010793991387
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.64
[I 2023-06-12 00:08:02,182] Trial 737 finished with value: 71.80000305175781 and parameters: {'Fwd': 1.939159382071929e-06, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.5822757313401326, 'loop': 0, 'loss': 'CE', 'lr': 0.001170914377286405, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.005975379445904351, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0002650793370696107
weight_decay:  0.00893415718093286
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1030497190076858
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.3283544438891113
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.2487215721048415
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.40
run time now: 3.7211318016052246
total time:  3.7743593719787896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 2.52
  Final Train: 100.00 ± 0.00
   Final Test: 68.97 ± 1.43
[I 2023-06-12 00:08:06,473] Trial 738 finished with value: 69.9333267211914 and parameters: {'Fwd': 3.084203014171455e-06, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 8.088462709706274, 'loop': 1, 'loss': 'CE', 'lr': 0.0002650793370696107, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00893415718093286, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0014404511271155069
weight_decay:  8.343012820638563e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7832463709637523
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.7889841138385236
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.80
Split: 01, Run: 03
None time:  0.8448480400256813
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
run time now: 2.461724042892456
total time:  2.513884849846363
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 1.27
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.68
[I 2023-06-12 00:08:09,516] Trial 739 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.06353310351365946, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.55, 'lambda2': 4.228571303390666, 'loop': 0, 'loss': 'CE', 'lr': 0.0014404511271155069, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.343012820638563e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0008801199893362169
weight_decay:  4.236082552895122e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0143915149383247
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.118425098946318
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.83
   Final Test: 70.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 92.50%, Valid: 71.20% Test: 70.60%
Split: 01, Run: 03
None time:  1.8471882930025458
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 92.50
   Final Test: 70.40
run time now: 4.026906251907349
total time:  4.075385453877971
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.50
  Final Train: 95.56 ± 2.93
   Final Test: 69.93 ± 0.72
[I 2023-06-12 00:08:14,120] Trial 740 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.039210830890630696, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 0.27087565711814676, 'loop': 0, 'loss': 'CE', 'lr': 0.0008801199893362169, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.236082552895122e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0016239916266481793
weight_decay:  1.915381931333541e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0186011230107397
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9706611151341349
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  0.9931801999919116
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 3.0241787433624268
total time:  3.0874187061563134
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.35
[I 2023-06-12 00:08:17,702] Trial 741 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.03227547821904479, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.492483890806354, 'loop': 0, 'loss': 'CE', 'lr': 0.0016239916266481793, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.915381931333541e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0004008405170453367
weight_decay:  0.023966283671193845
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5384212308563292
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  0.5788486530072987
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.6351559970062226
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.00
run time now: 1.7981488704681396
total time:  1.856395544949919
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.67 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 0.87
[I 2023-06-12 00:08:20,141] Trial 742 finished with value: 69.66666412353516 and parameters: {'Fwd': 4.0482634807276914e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 7.419186692173027, 'loop': 0, 'loss': 'CE', 'lr': 0.0004008405170453367, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.023966283671193845, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.75
lr:  0.0021133967584466055
weight_decay:  0.000828335625206619
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7110350928269327
None Run 01:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 99.17
   Final Test: 59.30
Split: 01, Run: 02
None time:  0.7262845579534769
None Run 02:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 98.33
   Final Test: 57.30
Split: 01, Run: 03
None time:  0.8061330469790846
None Run 03:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 96.67
   Final Test: 61.10
run time now: 2.282719373703003
total time:  2.3312006241176277
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.33 ± 0.70
  Final Train: 98.06 ± 1.27
   Final Test: 59.23 ± 1.90
[I 2023-06-12 00:08:23,121] Trial 743 finished with value: 60.33333206176758 and parameters: {'Fwd': 7.0179928740356564e-06, 'K': 7, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 5.184925085598443, 'loop': 0, 'loss': 'CE', 'lr': 0.0021133967584466055, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000828335625206619, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.00024105096063466996
weight_decay:  6.817297597998042e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.10%
Split: 01, Run: 01
None time:  1.8230783499311656
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.04873262392357
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 70.40%
Split: 01, Run: 03
None time:  1.82852773508057
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 4.741140365600586
total time:  4.786359410965815
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.13 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.55
[I 2023-06-12 00:08:28,466] Trial 744 finished with value: 69.13333129882812 and parameters: {'Fwd': 0.052020430550812326, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.652829203508821, 'loop': 0, 'loss': 'CE', 'lr': 0.00024105096063466996, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.817297597998042e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0012627366583396566
weight_decay:  1.2010875485320153e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0436834739521146
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.0331616702023894
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.086274234810844
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.202547073364258
total time:  3.2469042020384222
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 0.55
[I 2023-06-12 00:08:32,228] Trial 745 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.00035654445082712073, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 9.35246882565177, 'loop': 0, 'loss': 'CE', 'lr': 0.0012627366583396566, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2010875485320153e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.00012824063990761434
weight_decay:  2.474707559291954e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1174376730341464
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 02
None time:  1.0550996591337025
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.1042348248884082
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 69.20
run time now: 3.3206539154052734
total time:  3.3666524419095367
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 68.53 ± 0.65
[I 2023-06-12 00:08:36,142] Trial 746 finished with value: 67.5999984741211 and parameters: {'Fwd': 0.0030470208073792, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 8.514672471474137, 'loop': 0, 'loss': 'CE', 'lr': 0.00012824063990761434, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.474707559291954e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0007207058557669923
weight_decay:  3.492138064822603e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0453130030073225
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0395085630007088
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1156861910130829
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.240590810775757
total time:  3.2946028551086783
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.35
[I 2023-06-12 00:08:39,987] Trial 747 finished with value: 70.73333740234375 and parameters: {'Fwd': 1.1087094692711685e-05, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.146762546868713, 'loop': 0, 'loss': 'CE', 'lr': 0.0007207058557669923, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.492138064822603e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0009846992573579263
weight_decay:  0.00044882422500809686
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0498305931687355
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0672830641269684
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.0337890998926014
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.1899242401123047
total time:  3.234155177138746
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.51
[I 2023-06-12 00:08:43,782] Trial 748 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.001427779948250363, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.772633721947323, 'loop': 0, 'loss': 'CE', 'lr': 0.0009846992573579263, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00044882422500809686, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.00036644488296480295
weight_decay:  5.094570521898522e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9582267929799855
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.9530430769082159
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  1.0639841679949313
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.30
run time now: 3.0195281505584717
total time:  3.080825777957216
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.73 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 68.27 ± 0.65
[I 2023-06-12 00:08:47,350] Trial 749 finished with value: 68.73332977294922 and parameters: {'Fwd': 0.0005873488207378873, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 3.9761687969256125, 'loop': 0, 'loss': 'CE', 'lr': 0.00036644488296480295, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.094570521898522e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0023832171042012617
weight_decay:  0.0037052814690576863
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.40% Test: 51.90%
Split: 01, Run: 01
None time:  1.8296202151104808
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.40% Test: 51.90%
Split: 01, Run: 02
None time:  1.8126971970777959
None Run 02:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.40% Test: 51.90%
Split: 01, Run: 03
None time:  1.7813280678819865
None Run 03:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.50
run time now: 5.464050054550171
total time:  5.5090895891189575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 51.50 ± 0.00
[I 2023-06-12 00:08:53,441] Trial 750 finished with value: 51.40000534057617 and parameters: {'Fwd': 0.00028296275495469223, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.0, 'lambda2': 5.380567780575826, 'loop': 0, 'loss': 'CE', 'lr': 0.0023832171042012617, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0037052814690576863, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.001375975200523791
weight_decay:  2.9160407260601764e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2650593968573958
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.377192263957113
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.324468492064625
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.50
run time now: 4.02152156829834
total time:  4.07618401106447
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.61
[I 2023-06-12 00:08:58,067] Trial 751 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.00017811728540713251, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 5.717028597131408, 'loop': 2, 'loss': 'CE', 'lr': 0.001375975200523791, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.9160407260601764e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0027403711438266135
weight_decay:  0.0011039035938353087
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1466485580895096
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.073604241013527
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.0309352879412472
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.2903523445129395
total time:  3.3403546151239425
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.68
[I 2023-06-12 00:09:02,035] Trial 752 finished with value: 70.86666870117188 and parameters: {'Fwd': 3.323653153872316e-05, 'K': 8, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.282568254986576, 'loop': 0, 'loss': 'CE', 'lr': 0.0027403711438266135, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0011039035938353087, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0017454044868726738
weight_decay:  0.00034830572785583233
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.068485074909404
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9851223120931536
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.1365406909026206
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.2333505153656006
total time:  3.2870070319622755
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.50
[I 2023-06-12 00:09:05,930] Trial 753 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.0024286410208197986, 'K': 8, 'alpha': 0.75, 'dropout': 0.1, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.921159915834436, 'loop': 0, 'loss': 'CE', 'lr': 0.0017454044868726738, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00034830572785583233, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0011160981799105004
weight_decay:  2.2404586114086685e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 69.60%
Split: 01, Run: 01
None time:  1.8108489329461008
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 69.70%
Split: 01, Run: 02
None time:  1.796197972027585
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 69.60%
Split: 01, Run: 03
None time:  1.724134923890233
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 5.378519773483276
total time:  5.429017504910007
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.06
[I 2023-06-12 00:09:11,993] Trial 754 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.000807591554818508, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.3993902370906524, 'loop': 0, 'loss': 'MSE', 'lr': 0.0011160981799105004, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2404586114086685e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.0046057252328973244
weight_decay:  4.764606247063216e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0408222479745746
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.035429532872513
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.1085212170146406
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
run time now: 3.2262306213378906
total time:  3.273288605036214
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.20
  Final Train: 99.44 ± 0.48
   Final Test: 69.93 ± 0.47
[I 2023-06-12 00:09:15,896] Trial 755 finished with value: 70.5999984741211 and parameters: {'Fwd': 2.6703294146087828e-06, 'K': 8, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.469389605498561, 'loop': 0, 'loss': 'CE', 'lr': 0.0046057252328973244, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.764606247063216e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0015364056365869444
weight_decay:  1.4667730127010153e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0794331599026918
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0955459719989449
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1261185379698873
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.3417677879333496
total time:  3.3997112940996885
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.55
[I 2023-06-12 00:09:19,846] Trial 756 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.014928144714810118, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.9670479351718475, 'loop': 0, 'loss': 'CE', 'lr': 0.0015364056365869444, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4667730127010153e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0012407713936928842
weight_decay:  1.991078460476571e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.20% Test: 49.60%
Split: 01, Run: 01
None time:  0.8448515040799975
None Run 01:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 49.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 48.80% Test: 47.30%
Split: 01, Run: 02
None time:  0.8174194940365851
None Run 02:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 47.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.60% Test: 51.30%
Split: 01, Run: 03
None time:  0.8527756889816374
None Run 03:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 51.10
run time now: 2.561328649520874
total time:  2.611879443982616
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 50.20 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 49.13 ± 2.00
[I 2023-06-12 00:09:23,036] Trial 757 finished with value: 50.20000076293945 and parameters: {'Fwd': 0.07902712170063807, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 0, 'lambda1': 0.65, 'lambda2': 8.831945676892094, 'loop': 0, 'loss': 'CE', 'lr': 0.0012407713936928842, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.991078460476571e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0013524557473506066
weight_decay:  9.54420693416356e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1153288308996707
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.0195242518093437
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0926130239386111
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.300788640975952
total time:  3.3576183142140508
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.60
[I 2023-06-12 00:09:26,885] Trial 758 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.04410843925892296, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.664522546004467, 'loop': 0, 'loss': 'CE', 'lr': 0.0013524557473506066, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.54420693416356e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0018514140419363466
weight_decay:  7.377128457017583e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8942282299976796
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.1011597469914705
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  0.965375353815034
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.000835418701172
total time:  3.0453232950530946
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.92
[I 2023-06-12 00:09:30,418] Trial 759 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.004569769205870795, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 6.096506939227283, 'loop': 0, 'loss': 'CE', 'lr': 0.0018514140419363466, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.377128457017583e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.00146150587280441
weight_decay:  0.02195547728044944
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.60% Test: 62.30%
Split: 01, Run: 01
None time:  0.9485896178521216
None Run 01:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.30
Split: 01, Run: 02
None time:  0.24545264290645719
None Run 02:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.40% Test: 65.90%
Split: 01, Run: 03
None time:  1.020030922954902
None Run 03:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.60
run time now: 2.259369373321533
total time:  2.308740740874782
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 64.37 ± 1.80
[I 2023-06-12 00:09:33,264] Trial 760 finished with value: 64.79999542236328 and parameters: {'Fwd': 0.06271543142365628, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 10, 'lambda1': 0.7000000000000001, 'lambda2': 4.258858218505155, 'loop': 0, 'loss': 'CE', 'lr': 0.00146150587280441, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.02195547728044944, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0001508103092030731
weight_decay:  1.764214972420471e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.20% Test: 68.00%
Split: 01, Run: 01
None time:  1.8346871170215309
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.80% Test: 69.30%
Split: 01, Run: 02
None time:  1.8875352679751813
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  1.1651071840897202
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 4.930202007293701
total time:  4.9932992837857455
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.00 ± 0.80
[I 2023-06-12 00:09:38,809] Trial 761 finished with value: 67.4000015258789 and parameters: {'Fwd': 0.032359036961257026, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.5, 'lambda2': 9.809708159577811, 'loop': 0, 'loss': 'CE', 'lr': 0.0001508103092030731, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.764214972420471e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0011555772497683966
weight_decay:  2.983172998414988e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7823393491562456
None Run 01:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 48.70
Split: 01, Run: 02
None time:  0.7139019181486219
None Run 02:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 61.30
Split: 01, Run: 03
None time:  0.8253709629643708
None Run 03:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 53.80
run time now: 2.365119457244873
total time:  2.420609842054546
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.80 ± 6.88
  Final Train: 100.00 ± 0.00
   Final Test: 54.60 ± 6.34
[I 2023-06-12 00:09:41,845] Trial 762 finished with value: 54.79999923706055 and parameters: {'Fwd': 0.022170454556320857, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.484368393297547, 'loop': 0, 'loss': 'CE', 'lr': 0.0011555772497683966, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.983172998414988e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0012862445871904742
weight_decay:  0.0006259002164458689
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5909427618607879
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.6089798221364617
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  0.6342466347850859
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.60
run time now: 1.8859550952911377
total time:  1.934725906001404
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.10 ± 0.50
[I 2023-06-12 00:09:44,514] Trial 763 finished with value: 69.86666870117188 and parameters: {'Fwd': 2.6903916088154594e-05, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 3.8329714131252075, 'loop': 0, 'loss': 'CE', 'lr': 0.0012862445871904742, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006259002164458689, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001637063759472283
weight_decay:  4.142738176462727e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0843612658791244
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.083708070917055
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1416514799930155
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.30
run time now: 3.3492937088012695
total time:  3.4002767060883343
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 1.21
[I 2023-06-12 00:09:48,440] Trial 764 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.051127240809106085, 'K': 8, 'alpha': 0.75, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 7.811446302957687, 'loop': 0, 'loss': 'CE', 'lr': 0.001637063759472283, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.142738176462727e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0010754456428638498
weight_decay:  5.8887224732184e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0634030159562826
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0232147290371358
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.2253423910588026
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.358456611633301
total time:  3.4035537419840693
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.64
[I 2023-06-12 00:09:52,381] Trial 765 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.010107331669856646, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.860644021126899, 'loop': 0, 'loss': 'CE', 'lr': 0.0010754456428638498, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.8887224732184e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0014323895602228053
weight_decay:  8.630781665360837e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0856210349593312
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0899270561058074
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.0765396999195218
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 3.2955288887023926
total time:  3.3487667380832136
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 0.76
[I 2023-06-12 00:09:56,288] Trial 766 finished with value: 71.66666412353516 and parameters: {'Fwd': 4.6455060598564756e-05, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.671344809685965, 'loop': 0, 'loss': 'CE', 'lr': 0.0014323895602228053, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.630781665360837e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0012546179051095658
weight_decay:  0.0013419589707529115
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9759268069174141
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.0464892371091992
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1742803601082414
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.236400604248047
total time:  3.2873106310144067
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.56
[I 2023-06-12 00:10:00,136] Trial 767 finished with value: 71.66666412353516 and parameters: {'Fwd': 5.864690428018276e-06, 'K': 7, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.075094048170147, 'loop': 0, 'loss': 'CE', 'lr': 0.0012546179051095658, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0013419589707529115, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.7000000000000001
lr:  0.001960794325795903
weight_decay:  1.1678506761240981e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9513784318696707
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  0.9573619170114398
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  1.0843696179799736
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.0318973064422607
total time:  3.083074948983267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 1.04
[I 2023-06-12 00:10:03,756] Trial 768 finished with value: 71.0 and parameters: {'Fwd': 0.001916520394616476, 'K': 6, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 8.261871255557846, 'loop': 0, 'loss': 'CE', 'lr': 0.001960794325795903, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.1678506761240981e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0015632967906048204
weight_decay:  0.046466405264169945
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0589454870205373
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 97.50
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.1108631039969623
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 97.50
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.001797845121473
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 92.50
   Final Test: 70.40
run time now: 3.2106826305389404
total time:  3.270284297177568
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.12
  Final Train: 95.83 ± 2.89
   Final Test: 69.83 ± 0.60
[I 2023-06-12 00:10:07,523] Trial 769 finished with value: 71.53333282470703 and parameters: {'Fwd': 1.3461183239226406e-06, 'K': 8, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 0.6132789121346827, 'loop': 0, 'loss': 'CE', 'lr': 0.0015632967906048204, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.046466405264169945, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0025986871169936406
weight_decay:  2.0773997632286402e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0563899909611791
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.0643624840304255
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.0616663109976798
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 3.2239620685577393
total time:  3.281645423034206
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.65
[I 2023-06-12 00:10:11,314] Trial 770 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.038231641650193535, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.35000000000000003, 'lambda2': 5.529405014291552, 'loop': 0, 'loss': 'CE', 'lr': 0.0025986871169936406, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.0773997632286402e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.00031236755928325466
weight_decay:  3.181919352320067e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0483612089883536
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.1013115490786731
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.2732042260468006
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.46478009223938
total time:  3.5181752699427307
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.44
[I 2023-06-12 00:10:15,363] Trial 771 finished with value: 69.73333740234375 and parameters: {'Fwd': 0.0001702220795027496, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.507585549304498, 'loop': 0, 'loss': 'CE', 'lr': 0.00031236755928325466, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.181919352320067e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0001233804578832158
weight_decay:  3.492558235202765e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.022334311157465
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.0794119990896434
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.1423514909110963
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.288039445877075
total time:  3.335336129879579
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 68.53 ± 0.55
[I 2023-06-12 00:10:19,240] Trial 772 finished with value: 67.73332977294922 and parameters: {'Fwd': 9.880801549354152e-05, 'K': 8, 'alpha': 0.9, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.892919288209371, 'loop': 0, 'loss': 'CE', 'lr': 0.0001233804578832158, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.492558235202765e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.0013500699690003587
weight_decay:  6.059314074852282e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 69.50%
Split: 01, Run: 01
None time:  1.7270344099961221
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.40%
Split: 01, Run: 02
None time:  1.7805810240097344
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 70.30%
Split: 01, Run: 03
None time:  1.6966538589913398
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 5.248716592788696
total time:  5.299295864999294
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.49
[I 2023-06-12 00:10:25,112] Trial 773 finished with value: 70.06666564941406 and parameters: {'Fwd': 0.005892520504417432, 'K': 9, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 1.9212319584953486, 'loop': 0, 'loss': 'MSE', 'lr': 0.0013500699690003587, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.059314074852282e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0011674848942964426
weight_decay:  0.00027260899306663254
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1147168891038746
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0918294270522892
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.30%
Split: 01, Run: 03
None time:  1.8427993119694293
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 4.090163707733154
total time:  4.138170738937333
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.44
[I 2023-06-12 00:10:29,819] Trial 774 finished with value: 71.86666107177734 and parameters: {'Fwd': 0.02634744809343982, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.026401489989926, 'loop': 0, 'loss': 'CE', 'lr': 0.0011674848942964426, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00027260899306663254, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.0022613349030436458
weight_decay:  3.9982948507322634e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0841884179972112
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9984232680872083
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.0061096257995814
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.1288745403289795
total time:  3.1737808738835156
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.46
[I 2023-06-12 00:10:33,533] Trial 775 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.06951183253174122, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.03868699347482, 'loop': 0, 'loss': 'CE', 'lr': 0.0022613349030436458, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.9982948507322634e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001009488108949069
weight_decay:  2.568776859383464e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9895862948615104
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.053891516989097
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.1338001829572022
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.227599620819092
total time:  3.2864165778737515
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.60
[I 2023-06-12 00:10:37,321] Trial 776 finished with value: 71.13333129882812 and parameters: {'Fwd': 0.0010055417864562465, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 7.114029323067053, 'loop': 0, 'loss': 'CE', 'lr': 0.001009488108949069, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.568776859383464e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0014624803566035585
weight_decay:  0.0025280409056443443
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.979467358905822
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0152928379829973
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  0.9212154729757458
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 2.9549918174743652
total time:  2.9996373478788882
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 1.44
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.83
[I 2023-06-12 00:10:40,888] Trial 777 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.046262977373029014, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 3.672482892534954, 'loop': 0, 'loss': 'CE', 'lr': 0.0014624803566035585, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0025280409056443443, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.00010700036587403974
weight_decay:  1.5106996642216883e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0427451368886977
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 02
None time:  1.1383991530165076
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.80% Test: 69.00%
Split: 01, Run: 03
None time:  1.8794919790234417
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 68.90
run time now: 4.101267099380493
total time:  4.152852942002937
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 67.03 ± 1.69
[I 2023-06-12 00:10:45,576] Trial 778 finished with value: 66.06666564941406 and parameters: {'Fwd': 0.05908663509408768, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.29176407545434, 'loop': 0, 'loss': 'CE', 'lr': 0.00010700036587403974, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5106996642216883e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.000541531344475949
weight_decay:  7.455455637372272e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.079312832094729
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.1153254478704184
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.1802130700089037
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.419224500656128
total time:  3.485716731986031
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.21
[I 2023-06-12 00:10:49,606] Trial 779 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.0016317015968001021, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.855579986408415, 'loop': 0, 'loss': 'CE', 'lr': 0.000541531344475949, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.455455637372272e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.00010163503442812678
weight_decay:  4.9308131491580654e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.00% Test: 65.40%
Split: 01, Run: 01
None time:  1.7965265330858529
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 02
None time:  1.1987109179608524
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  1.2471719719469547
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 68.70
run time now: 4.297072172164917
total time:  4.34708668012172
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.40 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 67.43 ± 1.30
[I 2023-06-12 00:10:54,525] Trial 780 finished with value: 66.4000015258789 and parameters: {'Fwd': 0.017370145148792787, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 7.436064360814946, 'loop': 0, 'loss': 'CE', 'lr': 0.00010163503442812678, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.9308131491580654e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.004430921186000666
weight_decay:  0.07469321785415935
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6698082620278001
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.40
Split: 01, Run: 02
None time:  0.7949792970903218
None Run 02:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 98.33
   Final Test: 63.60
Split: 01, Run: 03
None time:  0.7780585400760174
None Run 03:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 98.33
   Final Test: 61.10
run time now: 2.2823755741119385
total time:  2.332204299978912
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.00 ± 9.70
  Final Train: 98.89 ± 0.96
   Final Test: 57.03 ± 9.29
[I 2023-06-12 00:10:57,361] Trial 781 finished with value: 58.0 and parameters: {'Fwd': 0.01199821420515162, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.60058668591698, 'loop': 0, 'loss': 'CE', 'lr': 0.004430921186000666, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.07469321785415935, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0012311743817297884
weight_decay:  0.003217629199679882
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.114993352908641
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1608061660081148
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.2210997820366174
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.00
run time now: 3.5384671688079834
total time:  3.5969864779617637
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 0.35
[I 2023-06-12 00:11:01,552] Trial 782 finished with value: 71.20000457763672 and parameters: {'Fwd': 1.0598853989013472e-06, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.464613882511617, 'loop': 1, 'loss': 'CE', 'lr': 0.0012311743817297884, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003217629199679882, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0017523612109580458
weight_decay:  0.0008632950083634748
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9287474590819329
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.9812871539033949
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  1.0421695939730853
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 2.9921681880950928
total time:  3.0498017619829625
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.95
[I 2023-06-12 00:11:05,132] Trial 783 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.0007331124020471974, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 4.13445191375111, 'loop': 0, 'loss': 'CE', 'lr': 0.0017523612109580458, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0008632950083634748, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0013256457421059015
weight_decay:  0.0017913283958077245
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.049460849026218
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0414218418300152
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0290602690074593
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 3.1624741554260254
total time:  3.2114715499337763
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.56
[I 2023-06-12 00:11:08,868] Trial 784 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.08744170994653232, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.2749574330313145, 'loop': 0, 'loss': 'CE', 'lr': 0.0013256457421059015, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0017913283958077245, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.0010702209608550843
weight_decay:  1.9650334864327073e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.071783646941185
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.1304331729188561
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.17618339904584
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 3.4174296855926514
total time:  3.4782321639358997
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.76
[I 2023-06-12 00:11:12,923] Trial 785 finished with value: 71.66666412353516 and parameters: {'Fwd': 7.003644908293369e-05, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 2.34253197071146, 'loop': 0, 'loss': 'CE', 'lr': 0.0010702209608550843, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.9650334864327073e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.00014609978310440628
weight_decay:  2.5505428634786977e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.081278702011332
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 02
None time:  1.0557255311869085
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.1316266357898712
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.3083274364471436
total time:  3.353706941008568
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 68.83 ± 0.83
[I 2023-06-12 00:11:16,879] Trial 786 finished with value: 68.20000457763672 and parameters: {'Fwd': 1.9172619396940573e-05, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 2.6448844293770053, 'loop': 0, 'loss': 'CE', 'lr': 0.00014609978310440628, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.5505428634786977e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.003625017368427632
weight_decay:  0.00038479622043090966
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.156601700000465
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.1361244299914688
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 98.33
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.1235953238792717
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.20
run time now: 3.4574384689331055
total time:  3.5204954058863223
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.23
  Final Train: 99.44 ± 0.96
   Final Test: 69.67 ± 0.42
[I 2023-06-12 00:11:20,914] Trial 787 finished with value: 70.66667175292969 and parameters: {'Fwd': 8.746223710694972e-06, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.285068548380255, 'loop': 0, 'loss': 'CE', 'lr': 0.003625017368427632, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00038479622043090966, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0015190709064074471
weight_decay:  0.008528667765917802
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0248361581470817
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  1.0945458579808474
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1311132630798966
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.2903308868408203
total time:  3.3465596861205995
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.90
[I 2023-06-12 00:11:24,849] Trial 788 finished with value: 71.06666564941406 and parameters: {'Fwd': 0.000131898585852328, 'K': 8, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 6.060083344639155, 'loop': 0, 'loss': 'CE', 'lr': 0.0015190709064074471, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.008528667765917802, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0009252325333849207
weight_decay:  1.3271565990586795e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9534482699818909
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.0043208869174123
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  0.9452514071017504
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 2.9444973468780518
total time:  2.9922271301038563
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.82
[I 2023-06-12 00:11:28,384] Trial 789 finished with value: 69.86666870117188 and parameters: {'Fwd': 0.0002696666536759224, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 9.622463515743597, 'loop': 0, 'loss': 'CE', 'lr': 0.0009252325333849207, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3271565990586795e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0001843934076299686
weight_decay:  9.973998289242381e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1060343438293785
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  1.1369051090441644
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.1232882051263005
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.4079575538635254
total time:  3.4706412530504167
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.93
[I 2023-06-12 00:11:32,352] Trial 790 finished with value: 69.06666564941406 and parameters: {'Fwd': 0.007341177008601816, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.27410236389176, 'loop': 0, 'loss': 'CE', 'lr': 0.0001843934076299686, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.973998289242381e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.0011905534701754478
weight_decay:  1.600360062629269e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0992337840143591
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0863405070267618
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 70.40%
Split: 01, Run: 03
None time:  1.9405347250867635
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.80
run time now: 4.168607711791992
total time:  4.221234041033313
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.61
[I 2023-06-12 00:11:37,106] Trial 791 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.027060795210627892, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.626250778298752, 'loop': 0, 'loss': 'CE', 'lr': 0.0011905534701754478, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.600360062629269e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0013604761362787923
weight_decay:  9.327885072133842e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 69.50%
Split: 01, Run: 01
None time:  1.7223591189831495
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.60%
Split: 01, Run: 02
None time:  1.699897225946188
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 70.30%
Split: 01, Run: 03
None time:  1.7006170919630677
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 5.162990093231201
total time:  5.207771964138374
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.49
[I 2023-06-12 00:11:42,950] Trial 792 finished with value: 70.0 and parameters: {'Fwd': 3.958529052088719e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 7.295225383722682, 'loop': 0, 'loss': 'MSE', 'lr': 0.0013604761362787923, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.327885072133842e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0016472835446238948
weight_decay:  3.56603872279624e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.118543580174446
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.1141203539445996
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  0.9688243260607123
None Run 03:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.241147041320801
total time:  3.2897817292250693
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.35
[I 2023-06-12 00:11:46,851] Trial 793 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.03578478157009081, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.990874994756634, 'loop': 0, 'loss': 'CE', 'lr': 0.0016472835446238948, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.56603872279624e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0011150716060165078
weight_decay:  5.340152719209463e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0463213429320604
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0628903261385858
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.00% Test: 70.50%
Split: 01, Run: 03
None time:  1.8329851960297674
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 3.9818294048309326
total time:  4.031139206839725
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.47
[I 2023-06-12 00:11:51,400] Trial 794 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.054154861799401884, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 7.674315930789146, 'loop': 0, 'loss': 'CE', 'lr': 0.0011150716060165078, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.340152719209463e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0008344767331618402
weight_decay:  1.6552996535272057e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0167470190208405
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.0492891080211848
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 70.20%
Split: 01, Run: 03
None time:  1.8538496070541441
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 3.9647881984710693
total time:  4.009993152925745
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.30
[I 2023-06-12 00:11:55,954] Trial 795 finished with value: 71.06666564941406 and parameters: {'Fwd': 0.0449769934037319, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 1.575097127569518, 'loop': 0, 'loss': 'CE', 'lr': 0.0008344767331618402, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6552996535272057e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0021565756562752004
weight_decay:  0.004544871084439909
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0686643079388887
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1315182701218873
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.0323508391156793
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 3.2725515365600586
total time:  3.3218973400071263
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 0.50
[I 2023-06-12 00:11:59,964] Trial 796 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.07092273024316836, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.362482151189275, 'loop': 0, 'loss': 'CE', 'lr': 0.0021565756562752004, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004544871084439909, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.001437957979684926
weight_decay:  2.263131725937762e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0721018710173666
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.0360689950175583
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.1122622769325972
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.2668070793151855
total time:  3.328262175200507
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.30
[I 2023-06-12 00:12:03,856] Trial 797 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.032233775020622205, 'K': 8, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.9796180192831176, 'loop': 0, 'loss': 'CE', 'lr': 0.001437957979684926, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.263131725937762e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0012908183519271118
weight_decay:  0.00012975015157069651
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9972267569974065
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.114232501015067
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.057624036911875
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.50
run time now: 3.218629837036133
total time:  3.2662728340364993
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.87
[I 2023-06-12 00:12:07,677] Trial 798 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.020624118631853792, 'K': 8, 'alpha': 0.8, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.726769331230651, 'loop': 0, 'loss': 'CE', 'lr': 0.0012908183519271118, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00012975015157069651, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.00028137291882623163
weight_decay:  2.486552562730114e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0638171820901334
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.80%
Split: 01, Run: 02
None time:  1.8099974100477993
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 70.60%
Split: 01, Run: 03
None time:  1.8564565570559353
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 4.772696495056152
total time:  4.833169192075729
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.71
[I 2023-06-12 00:12:13,060] Trial 799 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.08260034187732902, 'K': 8, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 5.071044425858533, 'loop': 0, 'loss': 'CE', 'lr': 0.00028137291882623163, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.486552562730114e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.005378554846241798
weight_decay:  0.0005961527099976652
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.925784305203706
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 68.50%
Split: 01, Run: 02
None time:  1.684466300997883
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.20% Test: 69.20%
Split: 01, Run: 03
None time:  2.0225614809896797
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.10
run time now: 4.679058790206909
total time:  4.724446409149095
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.07 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 69.17 ± 0.70
[I 2023-06-12 00:12:18,311] Trial 800 finished with value: 69.06666564941406 and parameters: {'Fwd': 0.09975865230805263, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 4.728725920076007, 'loop': 0, 'loss': 'CE', 'lr': 0.005378554846241798, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005961527099976652, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.00769015356498175
weight_decay:  7.634745256586705e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8576701511628926
None Run 01:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 97.50
   Final Test: 53.70
Split: 01, Run: 02
None time:  0.7442936229053885
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 98.33
   Final Test: 64.90
Split: 01, Run: 03
None time:  0.8364074439741671
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 97.50
   Final Test: 63.80
run time now: 2.481194257736206
total time:  2.534740950912237
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.07 ± 5.99
  Final Train: 97.78 ± 0.48
   Final Test: 60.80 ± 6.17
[I 2023-06-12 00:12:21,445] Trial 801 finished with value: 62.06666564941406 and parameters: {'Fwd': 0.00036952046421354437, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 6.8914030307601255, 'loop': 0, 'loss': 'CE', 'lr': 0.00769015356498175, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.634745256586705e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.8500000000000001
lr:  0.0018414010883771436
weight_decay:  0.00023311701678269294
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9453224360477179
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  0.8966938029043376
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.397626494988799
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.80
run time now: 3.2848832607269287
total time:  3.3433951411861926
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.61
[I 2023-06-12 00:12:25,414] Trial 802 finished with value: 70.66667175292969 and parameters: {'Fwd': 5.076437396837155e-05, 'K': 4, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.980482873290407, 'loop': 0, 'loss': 'CE', 'lr': 0.0018414010883771436, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00023311701678269294, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.006017790107749691
weight_decay:  0.0011950922737650272
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 70.60% Test: 70.50%
Split: 01, Run: 01
None time:  4.524032366927713
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 70.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 70.00% Test: 69.50%
Split: 01, Run: 02
None time:  3.940907553071156
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.20
Split: 01, Run: 03
None time:  2.026830559130758
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
run time now: 10.545663595199585
total time:  10.59308902407065
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.50
  Final Train: 99.44 ± 0.48
   Final Test: 69.63 ± 0.59
[I 2023-06-12 00:12:36,627] Trial 803 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.04061756962295251, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.471363877469346, 'loop': 0, 'loss': 'CE', 'lr': 0.006017790107749691, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0011950922737650272, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.0012079624025041415
weight_decay:  4.488417765144161e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3620731569826603
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.1328841131180525
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.4216275638900697
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.968227386474609
total time:  7.022760634077713
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.51
[I 2023-06-12 00:12:44,421] Trial 804 finished with value: 71.5999984741211 and parameters: {'Fwd': 1.9173453507065252e-06, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.718318935389538, 'loop': 0, 'loss': 'CE', 'lr': 0.0012079624025041415, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.488417765144161e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.00011723905480007155
weight_decay:  2.9696335928489536e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1926541039720178
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 02
None time:  2.4229844000656158
None Run 02:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 59.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.60% Test: 67.00%
Split: 01, Run: 03
None time:  4.226615516003221
None Run 03:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.00
run time now: 8.890345573425293
total time:  8.938744890037924
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.13 ± 3.26
  Final Train: 100.00 ± 0.00
   Final Test: 64.63 ± 4.63
[I 2023-06-12 00:12:53,925] Trial 805 finished with value: 65.13333129882812 and parameters: {'Fwd': 0.014131140584390823, 'K': 8, 'alpha': 0.75, 'dropout': 0.2, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 3.5946124547423985, 'loop': 0, 'loss': 'CE', 'lr': 0.00011723905480007155, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.9696335928489536e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0002215903657368421
weight_decay:  1.1187318903191006e-05
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9442644708324224
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  2.0566375439520925
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.9870803409721702
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.10
run time now: 6.038293123245239
total time:  6.092891121050343
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 1.20
  Final Train: 100.00 ± 0.00
   Final Test: 68.77 ± 0.67
[I 2023-06-12 00:13:00,648] Trial 806 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.0031936020156828615, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.0, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 0.7134895148931388, 'loop': 0, 'loss': 'CE', 'lr': 0.0002215903657368421, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.1187318903191006e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  1.0
lr:  0.004006024772639522
weight_decay:  0.0008663622930906377
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.377883870154619
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  2.1916125710122287
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.3861504439264536
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
run time now: 7.003816604614258
total time:  7.060189831070602
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.12
  Final Train: 99.44 ± 0.48
   Final Test: 69.83 ± 0.31
[I 2023-06-12 00:13:08,328] Trial 807 finished with value: 70.73332977294922 and parameters: {'Fwd': 2.2995317518552596e-06, 'K': 8, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.9462687970416575, 'loop': 0, 'loss': 'CE', 'lr': 0.004006024772639522, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0008663622930906377, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001545454505219528
weight_decay:  5.9842665344247864e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1387633439153433
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.0885508470237255
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.1476468229666352
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.431173086166382
total time:  6.476446329150349
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.26
[I 2023-06-12 00:13:15,331] Trial 808 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.060311963672593415, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 6.457438238716602, 'loop': 0, 'loss': 'CE', 'lr': 0.001545454505219528, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.9842665344247864e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0013794733924626333
weight_decay:  4.299668977851729e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0569900579284877
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.339753763983026
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.191598810022697
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.50
run time now: 6.637041807174683
total time:  6.688455210067332
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.36
[I 2023-06-12 00:13:22,596] Trial 809 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.0006171431606742841, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 6.68292401645801, 'loop': 0, 'loss': 'CE', 'lr': 0.0013794733924626333, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.299668977851729e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0005398985444166393
weight_decay:  1.6047138676561395e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 68.10%
Split: 01, Run: 01
None time:  4.182475023902953
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.10%
Split: 01, Run: 02
None time:  4.143404029076919
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 68.70%
Split: 01, Run: 03
None time:  4.023689890047535
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.70
run time now: 12.41192102432251
total time:  12.478999982122332
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 68.60 ± 0.46
[I 2023-06-12 00:13:35,666] Trial 810 finished with value: 69.33333587646484 and parameters: {'Fwd': 0.0012628551637243273, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.243827380457358, 'loop': 0, 'loss': 'MSE', 'lr': 0.0005398985444166393, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6047138676561395e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.000253124988898913
weight_decay:  0.0015291355772307056
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3663132588844746
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  2.1749452580697834
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.3744229190051556
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.966001272201538
total time:  7.0268099301029
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.93 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 1.07
[I 2023-06-12 00:13:43,349] Trial 811 finished with value: 68.93333435058594 and parameters: {'Fwd': 0.00023576751578168557, 'K': 8, 'alpha': 0.65, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 8.825989337324785, 'loop': 0, 'loss': 'CE', 'lr': 0.000253124988898913, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0015291355772307056, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.002419039551518875
weight_decay:  0.00017989454993636941
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5954327029176056
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.09408384305425
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  2.085055593168363
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.30
run time now: 5.825638771057129
total time:  5.871918354183435
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.47
[I 2023-06-12 00:13:49,802] Trial 812 finished with value: 71.20000457763672 and parameters: {'Fwd': 2.3866869474243944e-05, 'K': 9, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 4.552435009792431, 'loop': 0, 'loss': 'CE', 'lr': 0.002419039551518875, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00017989454993636941, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.004267593903938139
weight_decay:  0.014909220891609527
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.210968645988032
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.5175219872035086
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.4374780820216984
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 7.215775728225708
total time:  7.2652188879437745
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.00
  Final Train: 99.44 ± 0.48
   Final Test: 69.80 ± 0.40
[I 2023-06-12 00:13:57,604] Trial 813 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.025421649387017308, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.234185967190289, 'loop': 0, 'loss': 'CE', 'lr': 0.004267593903938139, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.014909220891609527, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0016633599081311904
weight_decay:  3.34406307646305e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.061834883876145
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.1611890259664506
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.297329126158729
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.5914130210876465
total time:  6.651800584979355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.35
[I 2023-06-12 00:14:04,914] Trial 814 finished with value: 71.66667175292969 and parameters: {'Fwd': 3.580724829033671e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 8.369717636007055, 'loop': 0, 'loss': 'CE', 'lr': 0.0016633599081311904, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.34406307646305e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0020377487956593707
weight_decay:  2.1227749067970292e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8501231351401657
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.3990942649543285
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  2.0932148760184646
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.30
run time now: 6.393092393875122
total time:  6.44587887218222
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.20
[I 2023-06-12 00:14:11,972] Trial 815 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.049487432496607184, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 9.372516133817285, 'loop': 1, 'loss': 'CE', 'lr': 0.0020377487956593707, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.1227749067970292e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0012386391907817616
weight_decay:  3.0026620972048796e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3214862148743123
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.30088007892482
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.350014148047194
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 96.67
   Final Test: 70.60
run time now: 7.035335540771484
total time:  7.088694748934358
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 98.33 ± 1.44
   Final Test: 69.97 ± 0.65
[I 2023-06-12 00:14:19,770] Trial 816 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.003845390708691262, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 0.9318989441452894, 'loop': 0, 'loss': 'CE', 'lr': 0.0012386391907817616, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.0026620972048796e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0010803915118311443
weight_decay:  4.143499899487125e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9266632569488138
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.322597234044224
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.3131334399804473
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.70
run time now: 6.640657663345337
total time:  6.694400175940245
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.70
[I 2023-06-12 00:14:26,984] Trial 817 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0009114295574533119, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.188541573063652, 'loop': 0, 'loss': 'CE', 'lr': 0.0010803915118311443, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.143499899487125e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.0014434443171014654
weight_decay:  1.1318020329542544e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2583590019494295
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.40% Test: 59.30%
Split: 01, Run: 02
None time:  3.011816269950941
None Run 02:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.40
Split: 01, Run: 03
None time:  1.511592268012464
None Run 03:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 99.17
   Final Test: 49.90
run time now: 5.828422546386719
total time:  5.87811409891583
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.33 ± 7.15
  Final Train: 99.72 ± 0.48
   Final Test: 51.50 ± 6.26
[I 2023-06-12 00:14:33,506] Trial 818 finished with value: 52.33333206176758 and parameters: {'Fwd': 0.03596595501380312, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 4.86114578580858, 'loop': 0, 'loss': 'CE', 'lr': 0.0014434443171014654, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.1318020329542544e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0004586448504382956
weight_decay:  0.00015952480533332365
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2368157838936895
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.8638278651051223
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  2.2651827370282263
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.60
run time now: 6.4163782596588135
total time:  6.467070781858638
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.00 ± 1.31
  Final Train: 100.00 ± 0.00
   Final Test: 68.67 ± 0.80
[I 2023-06-12 00:14:40,618] Trial 819 finished with value: 69.0 and parameters: {'Fwd': 0.0005112539086645431, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 9.108231729435726, 'loop': 0, 'loss': 'CE', 'lr': 0.0004586448504382956, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00015952480533332365, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.00132019258039816
weight_decay:  0.0004230911267430433
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.46785752591677
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.2601823781151325
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.274152349913493
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 7.074037075042725
total time:  7.140068640932441
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.59
[I 2023-06-12 00:14:48,388] Trial 820 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.0003985011227409829, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.681428514431445, 'loop': 0, 'loss': 'CE', 'lr': 0.00132019258039816, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0004230911267430433, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0009982110755390615
weight_decay:  1.4456443104028084e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3863597081508487
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.911451966036111
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  2.684596013976261
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 8.032121896743774
total time:  8.08188410406001
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.37 ± 0.60
[I 2023-06-12 00:14:57,065] Trial 821 finished with value: 70.00000762939453 and parameters: {'Fwd': 0.005007075513515902, 'K': 8, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.252053562938119, 'loop': 2, 'loss': 'CE', 'lr': 0.0009982110755390615, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4456443104028084e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.001208605697121859
weight_decay:  6.677804670732458e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.976864186115563
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.2910022831056267
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.5471192519180477
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
run time now: 6.865471124649048
total time:  6.926614820957184
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.57
[I 2023-06-12 00:15:04,589] Trial 822 finished with value: 71.93333435058594 and parameters: {'Fwd': 1.4095084617875891e-06, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.846760405344936, 'loop': 0, 'loss': 'CE', 'lr': 0.001208605697121859, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.677804670732458e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.001542789103042173
weight_decay:  0.0007190473681728452
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7144634469877928
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 68.80
Split: 01, Run: 02
None time:  2.127886716974899
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.7558507518842816
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 5.64897894859314
total time:  5.703125830972567
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.31
  Final Train: 99.72 ± 0.48
   Final Test: 69.57 ± 0.71
[I 2023-06-12 00:15:10,852] Trial 823 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.00947667942523033, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.8500000000000001, 'lambda2': 0.888433875126208, 'loop': 0, 'loss': 'CE', 'lr': 0.001542789103042173, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0007190473681728452, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0017546556830913853
weight_decay:  7.114239571219854e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3611072739586234
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.968907400034368
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.3098352409433573
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.689239740371704
total time:  6.742910451954231
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.23
[I 2023-06-12 00:15:18,207] Trial 824 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0664165693195204, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 7.043289942607547, 'loop': 0, 'loss': 'CE', 'lr': 0.0017546556830913853, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.114239571219854e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0030647649102224536
weight_decay:  0.00031127895334288175
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9681238699704409
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 97.50
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.1331100210081786
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.83
   Final Test: 68.80
Split: 01, Run: 03
None time:  2.067519912030548
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 97.50
   Final Test: 69.90
run time now: 6.223686456680298
total time:  6.27347166207619
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.53
  Final Train: 96.94 ± 0.96
   Final Test: 69.57 ± 0.67
[I 2023-06-12 00:15:25,064] Trial 825 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.04282212583165354, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 0.44608827450880106, 'loop': 0, 'loss': 'CE', 'lr': 0.0030647649102224536, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00031127895334288175, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.00032647158607748147
weight_decay:  2.5627973063105532e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3573087570257485
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.3474410050548613
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 70.00%
Split: 01, Run: 03
None time:  4.748778730863705
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 9.503579378128052
total time:  9.563728195847943
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.26
[I 2023-06-12 00:15:35,147] Trial 826 finished with value: 69.86666870117188 and parameters: {'Fwd': 0.02993400984347584, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.813327353615025, 'loop': 0, 'loss': 'CE', 'lr': 0.00032647158607748147, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.5627973063105532e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.001128830188695293
weight_decay:  0.001049980532766909
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7674200260080397
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.2576754661276937
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.2832800848409534
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 97.50
   Final Test: 70.70
run time now: 6.363166332244873
total time:  6.414327898994088
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.70
  Final Train: 99.17 ± 1.44
   Final Test: 70.00 ± 0.61
[I 2023-06-12 00:15:42,199] Trial 827 finished with value: 71.73332977294922 and parameters: {'Fwd': 1.0143529411916262e-06, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 1.3559730257598224, 'loop': 0, 'loss': 'CE', 'lr': 0.001128830188695293, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001049980532766909, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.00030516073554719044
weight_decay:  0.0005173326686305121
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.325323861092329
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.372423468856141
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.3636330268345773
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.70
run time now: 7.121841192245483
total time:  7.174897633027285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.20
[I 2023-06-12 00:15:50,107] Trial 828 finished with value: 69.73333740234375 and parameters: {'Fwd': 8.252214157487785e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.032142140504957, 'loop': 0, 'loss': 'CE', 'lr': 0.00030516073554719044, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005173326686305121, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0055723566219276835
weight_decay:  5.514197237451841e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.80% Test: 67.10%
Split: 01, Run: 01
None time:  4.3298507269937545
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.00% Test: 67.00%
Split: 01, Run: 02
None time:  3.8823514371179044
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 66.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.80% Test: 66.30%
Split: 01, Run: 03
None time:  4.305866091977805
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 66.30
run time now: 12.578235864639282
total time:  12.629481522832066
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 66.73 ± 0.40
[I 2023-06-12 00:16:03,256] Trial 829 finished with value: 64.86666870117188 and parameters: {'Fwd': 0.05425581228059347, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 8.607353857262483, 'loop': 0, 'loss': 'MSE', 'lr': 0.0055723566219276835, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.514197237451841e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0013589018322549857
weight_decay:  0.01878355960785216
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.03685114486143
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.0979095101356506
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  2.023907440016046
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 6.206132888793945
total time:  6.251712715951726
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 1.17
[I 2023-06-12 00:16:10,240] Trial 830 finished with value: 70.13333129882812 and parameters: {'Fwd': 4.731067869572362e-06, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 5.365567969079995, 'loop': 0, 'loss': 'CE', 'lr': 0.0013589018322549857, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.01878355960785216, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.00024497637052629323
weight_decay:  1.8849781196407647e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1512906888965517
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 02
None time:  1.8362150029279292
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  2.1045126270037144
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.165748834609985
total time:  6.245402215979993
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 1.04
[I 2023-06-12 00:16:17,186] Trial 831 finished with value: 69.33333587646484 and parameters: {'Fwd': 0.002155591023779797, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.6000000000000001, 'lambda2': 1.9668316574845104, 'loop': 0, 'loss': 'CE', 'lr': 0.00024497637052629323, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8849781196407647e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0014731351484254728
weight_decay:  2.0676160954546555e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.114281593123451
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.277828613994643
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.8621186579111964
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.10
run time now: 6.307231664657593
total time:  6.352961230091751
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.23 ± 0.81
[I 2023-06-12 00:16:24,062] Trial 832 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0014968776802830339, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.938257709636531, 'loop': 0, 'loss': 'CE', 'lr': 0.0014731351484254728, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.0676160954546555e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0019446332206412861
weight_decay:  2.9544250465638752e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.49348785309121
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.405122925993055
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  2.1330407618079334
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 7.081900596618652
total time:  7.145796928089112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.53
[I 2023-06-12 00:16:31,771] Trial 833 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.019574036882176963, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 6.488382267646965, 'loop': 0, 'loss': 'CE', 'lr': 0.0019446332206412861, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.9544250465638752e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.007086938579324285
weight_decay:  0.002742830277359332
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 69.40% Test: 69.30%
Split: 01, Run: 01
None time:  4.540190411033109
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.37185493693687
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.80% Test: 68.60%
Split: 01, Run: 03
None time:  4.1184772229753435
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.20
run time now: 11.080238342285156
total time:  11.136933909030631
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.87 ± 0.92
  Final Train: 99.44 ± 0.48
   Final Test: 68.93 ± 0.64
[I 2023-06-12 00:16:43,551] Trial 834 finished with value: 68.86666870117188 and parameters: {'Fwd': 0.07700801769974228, 'K': 8, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.085742092797359, 'loop': 0, 'loss': 'CE', 'lr': 0.007086938579324285, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002742830277359332, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.5
lr:  0.00029232890115880796
weight_decay:  9.832880064789281e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.186491817003116
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  2.011373896850273
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  2.167216036003083
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.20
run time now: 6.4136457443237305
total time:  6.466254765866324
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.60 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 68.50 ± 0.61
[I 2023-06-12 00:16:50,595] Trial 835 finished with value: 68.5999984741211 and parameters: {'Fwd': 6.854195306394655e-06, 'K': 6, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 6.171277572902375, 'loop': 0, 'loss': 'CE', 'lr': 0.00029232890115880796, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.832880064789281e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.00018561531006447437
weight_decay:  0.0020486024234130946
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.067099146079272
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 02
None time:  2.382855898933485
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.1924002789892256
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 6.691936731338501
total time:  6.73728335602209
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.27 ± 0.84
[I 2023-06-12 00:16:57,880] Trial 836 finished with value: 68.73333740234375 and parameters: {'Fwd': 0.0001308525139748968, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.582260266421269, 'loop': 0, 'loss': 'CE', 'lr': 0.00018561531006447437, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0020486024234130946, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.0001442057597205056
weight_decay:  3.566553572089515e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5099801910109818
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 02
None time:  1.493381954031065
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 03
None time:  1.191888083005324
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.50
run time now: 4.250293731689453
total time:  4.297140323091298
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.13 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 65.43 ± 0.21
[I 2023-06-12 00:17:02,715] Trial 837 finished with value: 67.13333129882812 and parameters: {'Fwd': 0.0023972781627477143, 'K': 9, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.831573966050708, 'loop': 0, 'loss': 'CE', 'lr': 0.0001442057597205056, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.566553572089515e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.00020154090316448333
weight_decay:  0.030359884596994357
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.20% Test: 68.80%
Split: 01, Run: 01
None time:  4.244750667130575
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02
None time:  2.2846732810139656
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.20% Test: 70.10%
Split: 01, Run: 03
None time:  4.194990825140849
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 10.76961374282837
total time:  10.81534450291656
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.93
[I 2023-06-12 00:17:14,119] Trial 838 finished with value: 68.46666717529297 and parameters: {'Fwd': 0.03975300660790754, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.487138661555841, 'loop': 0, 'loss': 'CE', 'lr': 0.00020154090316448333, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.030359884596994357, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.007991934191449893
weight_decay:  5.640790625885477e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 97.50%, Valid: 70.40% Test: 69.10%
Split: 01, Run: 01
None time:  5.078942002961412
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 97.50
   Final Test: 69.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 97.50%, Valid: 70.20% Test: 69.30%
Split: 01, Run: 02
None time:  4.30180450482294
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 98.33
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.2981543869245797
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 97.50
   Final Test: 69.50
run time now: 11.736303091049194
total time:  11.810089187929407
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.53
  Final Train: 97.78 ± 0.48
   Final Test: 69.43 ± 0.31
[I 2023-06-12 00:17:26,631] Trial 839 finished with value: 70.60000610351562 and parameters: {'Fwd': 0.013373582806467136, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.702806778444023, 'loop': 0, 'loss': 'CE', 'lr': 0.007991934191449893, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.640790625885477e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0001371911843469491
weight_decay:  4.6581921533378435e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.605773143004626
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.70
Split: 01, Run: 02
None time:  1.6185333831235766
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  1.7966979891061783
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 68.20
run time now: 5.067180871963501
total time:  5.11235758010298
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 66.93 ± 1.94
[I 2023-06-12 00:17:32,357] Trial 840 finished with value: 67.19999694824219 and parameters: {'Fwd': 0.00017221329348904288, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 1.5877909478099506, 'loop': 0, 'loss': 'CE', 'lr': 0.0001371911843469491, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.6581921533378435e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0012626102646873492
weight_decay:  1.300087842981926e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9112077590543777
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  2.3408026800025254
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.3202454408165067
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.628106594085693
total time:  6.672735859174281
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.70
[I 2023-06-12 00:17:39,571] Trial 841 finished with value: 71.06666564941406 and parameters: {'Fwd': 1.7671291126897665e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 8.18985435975524, 'loop': 0, 'loss': 'CE', 'lr': 0.0012626102646873492, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.300087842981926e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.00037583695551991785
weight_decay:  3.463081755605848e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.30187467392534
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.70%
Split: 01, Run: 02
None time:  4.2583907139487565
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.313797543058172
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.20
run time now: 8.922437191009521
total time:  8.975785203976557
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.25
[I 2023-06-12 00:17:49,155] Trial 842 finished with value: 69.86666870117188 and parameters: {'Fwd': 0.055638655615974336, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.428342917763447, 'loop': 0, 'loss': 'CE', 'lr': 0.00037583695551991785, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.463081755605848e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0025057832401528903
weight_decay:  2.3693524667856912e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.896318816114217
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.086025740019977
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.7764966890681535
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
run time now: 5.84032416343689
total time:  5.905972981126979
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 0.60
[I 2023-06-12 00:17:55,635] Trial 843 finished with value: 71.13333129882812 and parameters: {'Fwd': 2.8519940048203644e-06, 'K': 7, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 7.420204951792121, 'loop': 0, 'loss': 'CE', 'lr': 0.0025057832401528903, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3693524667856912e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.0009325829263154964
weight_decay:  0.00010427161716893329
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0936297429725528
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.9487151780631393
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.5034372080117464
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.596142292022705
total time:  6.6467542690224946
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.40
[I 2023-06-12 00:18:03,047] Trial 844 finished with value: 71.20000457763672 and parameters: {'Fwd': 5.615493824641807e-06, 'K': 8, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.33308925038896, 'loop': 0, 'loss': 'CE', 'lr': 0.0009325829263154964, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00010427161716893329, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.0016087520395973503
weight_decay:  8.799791359300585e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1882766790222377
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.9778011578600854
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.9449037490412593
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.80
run time now: 6.167766809463501
total time:  6.215150820091367
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.17 ± 0.35
[I 2023-06-12 00:18:09,795] Trial 845 finished with value: 71.0666732788086 and parameters: {'Fwd': 1.7596525864080454e-06, 'K': 9, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.856610828815519, 'loop': 0, 'loss': 'CE', 'lr': 0.0016087520395973503, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.799791359300585e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.003273340775460463
weight_decay:  0.007055938951165542
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.261025703046471
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.2333284011110663
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.3929520410019904
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.80
run time now: 6.942142963409424
total time:  6.990871206857264
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.59
[I 2023-06-12 00:18:17,333] Trial 846 finished with value: 71.13333892822266 and parameters: {'Fwd': 0.007902320856614098, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.3969229263244047, 'loop': 0, 'loss': 'CE', 'lr': 0.003273340775460463, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007055938951165542, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.001113387717582902
weight_decay:  1.9026465965205145e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.26829028991051
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.1061078631319106
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.46781796310097
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 6.914748668670654
total time:  6.976787518011406
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.64
[I 2023-06-12 00:18:24,991] Trial 847 finished with value: 71.73333740234375 and parameters: {'Fwd': 1.0293145709810651e-05, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.563759696785203, 'loop': 0, 'loss': 'CE', 'lr': 0.001113387717582902, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.9026465965205145e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.001317052946319303
weight_decay:  3.119168104202383e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  4.226527435006574
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  5.29726843489334
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  3.6252549418713897
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 13.195963382720947
total time:  13.252208825899288
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 70.33 ± 0.95
[I 2023-06-12 00:18:38,864] Trial 848 finished with value: 71.13333129882812 and parameters: {'Fwd': 1.3518044428068273e-05, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 3.711646600674109, 'loop': 1, 'loss': 'MSE', 'lr': 0.001317052946319303, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.119168104202383e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.002756106433211442
weight_decay:  0.003735088983435575
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9786171989981085
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.367709461832419
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 69.30%
Split: 01, Run: 03
None time:  3.8685425738804042
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.90
run time now: 8.263097763061523
total time:  8.31916795601137
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.59
[I 2023-06-12 00:18:47,843] Trial 849 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.025230646164319, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.701085865812372, 'loop': 0, 'loss': 'CE', 'lr': 0.002756106433211442, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.003735088983435575, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0006798586938508637
weight_decay:  1.6435473316242672e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.206338353920728
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.0282900049351156
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 03
None time:  1.93571450188756
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.221850395202637
total time:  6.266983680892736
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 1.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 0.93
[I 2023-06-12 00:18:54,673] Trial 850 finished with value: 69.19999694824219 and parameters: {'Fwd': 0.0011091397272943563, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 7.03959707638164, 'loop': 0, 'loss': 'CE', 'lr': 0.0006798586938508637, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6435473316242672e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0007377986657795094
weight_decay:  4.259619960052555e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.160905933007598
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.5680334689095616
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 70.30%
Split: 01, Run: 03
None time:  4.335761936148629
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 9.11475133895874
total time:  9.173961643129587
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.40
[I 2023-06-12 00:19:04,453] Trial 851 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.033264421597056344, 'K': 8, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 5.2260668479785375, 'loop': 0, 'loss': 'CE', 'lr': 0.0007377986657795094, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.259619960052555e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.001434301240266345
weight_decay:  3.899076166432567e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3277614240068942
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.1769424688536674
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  2.4334454589989036
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 6.98517370223999
total time:  7.031024280935526
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 70.40 ± 0.72
[I 2023-06-12 00:19:12,184] Trial 852 finished with value: 71.13333129882812 and parameters: {'Fwd': 0.0063749877100749, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.1, 'lambda2': 5.802382253997694, 'loop': 0, 'loss': 'CE', 'lr': 0.001434301240266345, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.899076166432567e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0005945347569940661
weight_decay:  1.8037523725961267e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.787367856130004
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.211484726984054
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 70.20%
Split: 01, Run: 03
None time:  4.3296613281127065
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 8.375555753707886
total time:  8.432269481010735
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.49
[I 2023-06-12 00:19:21,211] Trial 853 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.04649193109950572, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 2.542603921204793, 'loop': 0, 'loss': 'CE', 'lr': 0.0005945347569940661, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.8037523725961267e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0011765981033259399
weight_decay:  8.474241153859927e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.915009430842474
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  2.1485443650744855
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  1.9119625980965793
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.90
run time now: 6.027199983596802
total time:  6.077751548029482
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 1.23
[I 2023-06-12 00:19:27,860] Trial 854 finished with value: 70.13333892822266 and parameters: {'Fwd': 2.772777616680384e-05, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 9.68260342896581, 'loop': 0, 'loss': 'CE', 'lr': 0.0011765981033259399, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.474241153859927e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.0010184305791597042
weight_decay:  0.0007198886022366392
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3593014921061695
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  2.1630485269706696
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.4255975261330605
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 7.0077314376831055
total time:  7.059080186998472
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.51
[I 2023-06-12 00:19:35,562] Trial 855 finished with value: 71.26666259765625 and parameters: {'Fwd': 0.01641921983777952, 'K': 9, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.1885463486282224, 'loop': 0, 'loss': 'CE', 'lr': 0.0010184305791597042, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007198886022366392, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0013118180207990118
weight_decay:  0.0013836649416061422
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0884209270589054
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.60% Test: 66.90%
Split: 01, Run: 02
None time:  3.187000337988138
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  1.1577976599801332
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 5.485532522201538
total time:  5.5334857809357345
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 2.27
  Final Train: 100.00 ± 0.00
   Final Test: 68.53 ± 1.42
[I 2023-06-12 00:19:41,718] Trial 856 finished with value: 69.20000457763672 and parameters: {'Fwd': 0.0691507600587915, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 0.7000000000000001, 'lambda2': 6.582663122013687, 'loop': 0, 'loss': 'CE', 'lr': 0.0013118180207990118, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0013836649416061422, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.00043276109872454426
weight_decay:  1.4538496961873993e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0562790650874376
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.50
Split: 01, Run: 02
None time:  1.1539304391480982
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.0730020620394498
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.90
run time now: 3.3312273025512695
total time:  3.3817886230535805
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.47 ± 1.17
  Final Train: 100.00 ± 0.00
   Final Test: 67.97 ± 2.16
[I 2023-06-12 00:19:45,765] Trial 857 finished with value: 67.46666717529297 and parameters: {'Fwd': 5.387031323860696e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 30, 'lambda1': 0.8, 'lambda2': 9.170171634621012, 'loop': 0, 'loss': 'CE', 'lr': 0.00043276109872454426, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4538496961873993e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.0017796913039728334
weight_decay:  2.512068998483536e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.285048226127401
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.165268673095852
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  2.2370115709491074
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.740354776382446
total time:  6.807001254986972
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.40
[I 2023-06-12 00:19:53,205] Trial 858 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0005653067944358565, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.823107044393586, 'loop': 0, 'loss': 'CE', 'lr': 0.0017796913039728334, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.512068998483536e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.001555396229100568
weight_decay:  0.0469656175671487
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.31674272287637
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.0030696738976985
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.438208183972165
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.8185648918151855
total time:  6.872330441139638
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.36
[I 2023-06-12 00:20:00,736] Trial 859 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.00022237920016528, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 3.9039740954741666, 'loop': 0, 'loss': 'CE', 'lr': 0.001555396229100568, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0469656175671487, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.009782979380760967
weight_decay:  4.818426488504081e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7146373640280217
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.7670172059442848
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  0.5224663109984249
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.50
run time now: 2.057922601699829
total time:  2.111629302846268
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.64
  Final Train: 100.00 ± 0.00
   Final Test: 67.73 ± 1.31
[I 2023-06-12 00:20:03,496] Trial 860 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.004155322096225064, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 20, 'lambda1': 0.7000000000000001, 'lambda2': 6.860546184343294, 'loop': 0, 'loss': 'CE', 'lr': 0.009782979380760967, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.818426488504081e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.006583340072334942
weight_decay:  7.642011738295217e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4223504629917443
None Run 01:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 97.50
   Final Test: 51.50
Split: 01, Run: 02
None time:  1.4166227660607547
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 97.50
   Final Test: 63.90
Split: 01, Run: 03
None time:  1.4565562340430915
None Run 03:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 95.83
   Final Test: 54.00
run time now: 4.389997243881226
total time:  4.5022742378059775
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.07 ± 5.61
  Final Train: 96.94 ± 0.96
   Final Test: 56.47 ± 6.56
[I 2023-06-12 00:20:08,757] Trial 861 finished with value: 59.06666564941406 and parameters: {'Fwd': 3.5283907215927592e-06, 'K': 7, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.046103980508359, 'loop': 0, 'loss': 'CE', 'lr': 0.006583340072334942, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.642011738295217e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.002144437757804993
weight_decay:  6.503720116620447e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9603259151335806
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.366497178794816
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.6304810401052237
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 5.99843955039978
total time:  6.050381288165227
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.15
[I 2023-06-12 00:20:15,433] Trial 862 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.05760295606219347, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 8.383337891351161, 'loop': 0, 'loss': 'CE', 'lr': 0.002144437757804993, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.503720116620447e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0004636632353707869
weight_decay:  0.00014489699703543071
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1653392338193953
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 98.33
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.221363355172798
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 96.67
   Final Test: 68.20
Split: 01, Run: 03
None time:  1.864552672021091
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 93.33
   Final Test: 68.60
run time now: 6.301183223724365
total time:  6.381563990842551
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.47 ± 1.55
  Final Train: 96.11 ± 2.55
   Final Test: 68.80 ± 0.72
[I 2023-06-12 00:20:22,409] Trial 863 finished with value: 69.46666717529297 and parameters: {'Fwd': 0.04046257574142504, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 0.10167238130076584, 'loop': 0, 'loss': 'CE', 'lr': 0.0004636632353707869, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00014489699703543071, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0014036248621090365
weight_decay:  2.6236290100152828e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.106749637052417
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.28339768294245
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.40%
Split: 01, Run: 03
None time:  4.500567349139601
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 8.942517042160034
total time:  8.990965221077204
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.36
[I 2023-06-12 00:20:32,003] Trial 864 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.0218876691613738, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.137125791861398, 'loop': 0, 'loss': 'CE', 'lr': 0.0014036248621090365, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.6236290100152828e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.001184244357267968
weight_decay:  0.0005572101709418786
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2366708209738135
None Run 01:
Highest Train: 99.17
Highest Valid: 69.40
  Final Train: 92.50
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.1435382850468159
None Run 02:
Highest Train: 99.17
Highest Valid: 73.60
  Final Train: 93.33
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.13509004493244
None Run 03:
Highest Train: 99.17
Highest Valid: 71.20
  Final Train: 95.83
   Final Test: 70.80
run time now: 3.563681125640869
total time:  3.608670582063496
None All runs:
Highest Train: 99.17 ± 0.00
Highest Valid: 71.40 ± 2.11
  Final Train: 93.89 ± 1.73
   Final Test: 70.17 ± 0.57
[I 2023-06-12 00:20:36,190] Trial 865 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.0007059415502168288, 'K': 9, 'alpha': 0.75, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 0.013828915979450684, 'loop': 0, 'loss': 'CE', 'lr': 0.001184244357267968, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005572101709418786, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0016665817339894748
weight_decay:  0.010760321510420348
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1352044988889247
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.1825396241620183
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  2.1511822070460767
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.519999265670776
total time:  6.566610773093998
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.42
[I 2023-06-12 00:20:43,286] Trial 866 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.010616654483259921, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 7.301932329750164, 'loop': 0, 'loss': 'CE', 'lr': 0.0016665817339894748, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.010760321510420348, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0006441651551943018
weight_decay:  0.0011096755574594964
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8540430010762066
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02
None time:  3.216265678172931
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  4.80551411700435
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.20
run time now: 10.92781925201416
total time:  10.987700145924464
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 68.20 ± 0.00
[I 2023-06-12 00:20:54,896] Trial 867 finished with value: 69.53333282470703 and parameters: {'Fwd': 3.924300019931737e-05, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.617985977430464, 'loop': 2, 'loss': 'MSE', 'lr': 0.0006441651551943018, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0011096755574594964, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.001258616299652694
weight_decay:  1.0954134577809306e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.320868041133508
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.137312632985413
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.588460959959775
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 7.1140594482421875
total time:  7.165646344888955
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.46
[I 2023-06-12 00:21:02,637] Trial 868 finished with value: 71.86666107177734 and parameters: {'Fwd': 0.00011446176308962652, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.272270107735424, 'loop': 0, 'loss': 'CE', 'lr': 0.001258616299652694, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0954134577809306e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.55
lr:  0.00432754007204416
weight_decay:  2.918936590356627e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1518538440577686
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.216871903045103
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.063074041856453
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
run time now: 6.480993032455444
total time:  6.529694990022108
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.20
  Final Train: 99.44 ± 0.48
   Final Test: 69.57 ± 0.15
[I 2023-06-12 00:21:09,736] Trial 869 finished with value: 70.79999542236328 and parameters: {'Fwd': 2.1670822320021255e-06, 'K': 5, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.34311833714185, 'loop': 0, 'loss': 'CE', 'lr': 0.00432754007204416, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.918936590356627e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.00017639065383879518
weight_decay:  0.00759657250040607
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9689792799763381
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  2.1406440038699657
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03
None time:  2.0712582911364734
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.50
run time now: 6.228403568267822
total time:  6.275558156892657
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.67 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 67.73 ± 0.97
[I 2023-06-12 00:21:16,541] Trial 870 finished with value: 67.66666412353516 and parameters: {'Fwd': 0.0030022065975853756, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 8.720459528940852, 'loop': 0, 'loss': 'CE', 'lr': 0.00017639065383879518, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00759657250040607, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0014546826903451583
weight_decay:  2.112995842149854e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2228363959584385
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.339737670030445
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.0804941030219197
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.685592889785767
total time:  6.748303135856986
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.32
[I 2023-06-12 00:21:23,884] Trial 871 finished with value: 71.73332977294922 and parameters: {'Fwd': 8.98452878668975e-05, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.877095316844975, 'loop': 0, 'loss': 'CE', 'lr': 0.0014546826903451583, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.112995842149854e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.00020117654600519257
weight_decay:  4.923151155668407e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9327299841679633
None Run 01:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 55.10
Split: 01, Run: 02
None time:  1.2536375559866428
None Run 02:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 57.40
Split: 01, Run: 03
None time:  0.9463075171224773
None Run 03:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 54.70
run time now: 3.185415029525757
total time:  3.239057517144829
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.13 ± 1.45
  Final Train: 100.00 ± 0.00
   Final Test: 55.73 ± 1.46
[I 2023-06-12 00:21:27,695] Trial 872 finished with value: 56.133331298828125 and parameters: {'Fwd': 0.0003269977539865522, 'K': 8, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 10, 'lambda1': 0.7000000000000001, 'lambda2': 8.939801059637245, 'loop': 0, 'loss': 'CE', 'lr': 0.00020117654600519257, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.923151155668407e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.00015712327666537478
weight_decay:  0.006991173144374015
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.60% Test: 68.30%
Split: 01, Run: 01
None time:  4.684180069947615
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.60% Test: 69.20%
Split: 01, Run: 02
None time:  4.254641046049073
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.739798352122307
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 11.730939149856567
total time:  11.784508572891355
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.93 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 0.89
[I 2023-06-12 00:21:40,137] Trial 873 finished with value: 67.9333267211914 and parameters: {'Fwd': 0.030179219761043753, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 5.505748035788035, 'loop': 0, 'loss': 'CE', 'lr': 0.00015712327666537478, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006991173144374015, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0010719992404443319
weight_decay:  0.01280826153504466
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0067532770335674
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.33310030400753
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.091303848894313
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.479834794998169
total time:  6.5356013448908925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.46
[I 2023-06-12 00:21:47,291] Trial 874 finished with value: 70.86666870117188 and parameters: {'Fwd': 6.736139018175127e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.00034232653996, 'loop': 0, 'loss': 'CE', 'lr': 0.0010719992404443319, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.01280826153504466, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.005262425956558214
weight_decay:  0.00019102076963006256
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4630820620805025
None Run 01:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 99.17
   Final Test: 55.00
Split: 01, Run: 02
None time:  1.5017021540552378
None Run 02:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 99.17
   Final Test: 57.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 98.33%, Valid: 57.40% Test: 54.70%
Split: 01, Run: 03
None time:  3.098085653036833
None Run 03:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 98.33
   Final Test: 54.70
run time now: 6.114123582839966
total time:  6.166636310052127
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.73 ± 1.92
  Final Train: 98.89 ± 0.48
   Final Test: 55.83 ± 1.71
[I 2023-06-12 00:21:54,041] Trial 875 finished with value: 57.73333740234375 and parameters: {'Fwd': 0.07934697295350404, 'K': 9, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.4208847247177365, 'loop': 0, 'loss': 'CE', 'lr': 0.005262425956558214, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00019102076963006256, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0008696367618956248
weight_decay:  0.0002559134735415553
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1577535830438137
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.5741018790286034
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.00% Test: 70.70%
Split: 01, Run: 03
None time:  4.423176097916439
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.90
run time now: 9.206053495407104
total time:  9.258919344982132
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.74
[I 2023-06-12 00:22:03,915] Trial 876 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.04856431023966032, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.767235614705578, 'loop': 0, 'loss': 'CE', 'lr': 0.0008696367618956248, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002559134735415553, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.001338628461087986
weight_decay:  0.004638653265123502
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.204797419020906
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.2087779289577156
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.3797259309794754
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 6.875938415527344
total time:  6.929558416130021
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.45
[I 2023-06-12 00:22:11,560] Trial 877 finished with value: 71.86666870117188 and parameters: {'Fwd': 7.510806500505959e-06, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 2.842722260053586, 'loop': 0, 'loss': 'CE', 'lr': 0.001338628461087986, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004638653265123502, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.00033479831231019656
weight_decay:  0.0057245454652920386
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1621364259626716
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.8272704801056534
None Run 02:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  2.3062898060306907
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.20
run time now: 6.354435205459595
total time:  6.407454404979944
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.73 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 68.43 ± 0.97
[I 2023-06-12 00:22:18,542] Trial 878 finished with value: 68.73332977294922 and parameters: {'Fwd': 1.3212207412764562e-06, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 4.076303631142372, 'loop': 0, 'loss': 'CE', 'lr': 0.00033479831231019656, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0057245454652920386, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0018509886228664464
weight_decay:  0.0009233719835599438
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0059651830233634
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  2.308469790033996
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.9885276048444211
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.35494327545166
total time:  6.4036308189388365
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.15
[I 2023-06-12 00:22:25,566] Trial 879 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0008960134872542715, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.074759684803246, 'loop': 0, 'loss': 'CE', 'lr': 0.0018509886228664464, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009233719835599438, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0011794487068967866
weight_decay:  1.4668903587165317e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.429622882977128
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.786847093142569
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  4.6140924310311675
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 9.883918523788452
total time:  9.9433381089475
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.31
[I 2023-06-12 00:22:36,149] Trial 880 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.06542958882208456, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 5.315063151855538, 'loop': 1, 'loss': 'CE', 'lr': 0.0011794487068967866, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4668903587165317e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0038663876982396777
weight_decay:  0.0016404681590630364
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 71.00% Test: 70.10%
Split: 01, Run: 01
None time:  4.566177623812109
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 99.17
   Final Test: 70.50
Split: 01, Run: 02
None time:  2.5573439239524305
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 70.40
Split: 01, Run: 03
None time:  2.1307914899662137
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.20
run time now: 9.311166763305664
total time:  9.366194574860856
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.50
  Final Train: 99.44 ± 0.48
   Final Test: 70.03 ± 0.72
[I 2023-06-12 00:22:46,174] Trial 881 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.035527892602805866, 'K': 8, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.960266334071749, 'loop': 0, 'loss': 'CE', 'lr': 0.0038663876982396777, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0016404681590630364, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.00227770784107817
weight_decay:  3.755274365630955e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1918040511664003
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  2.1615124528761953
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  2.297159856883809
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 6.7032434940338135
total time:  6.760352059034631
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.75
[I 2023-06-12 00:22:53,641] Trial 882 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.005433358440898667, 'K': 9, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.393094933498811, 'loop': 0, 'loss': 'CE', 'lr': 0.00227770784107817, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.755274365630955e-05, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0015116926081437548
weight_decay:  0.014965738887757443
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9987723738886416
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 68.30%
Split: 01, Run: 02
None time:  4.121724390890449
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  2.048311799997464
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 8.220787286758423
total time:  8.270647326018661
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 1.06
[I 2023-06-12 00:23:02,581] Trial 883 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.04967197544824076, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 3.49755366147245, 'loop': 0, 'loss': 'CE', 'lr': 0.0015116926081437548, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.014965738887757443, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0008075818531670565
weight_decay:  5.2945598469158964e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.166256718803197
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.6337707990314811
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 70.00%
Split: 01, Run: 03
None time:  4.105799301993102
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 7.955026388168335
total time:  8.003438645973802
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.32
[I 2023-06-12 00:23:11,162] Trial 884 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.08614082782740676, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.747371117822467, 'loop': 0, 'loss': 'CE', 'lr': 0.0008075818531670565, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.2945598469158964e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.002051761969014296
weight_decay:  0.00038510262525861947
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.396666466956958
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.1208233470097184
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.1233634317759424
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 6.691783666610718
total time:  6.7414204040542245
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.17
[I 2023-06-12 00:23:18,784] Trial 885 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.025647279868035246, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 7.54492403182925, 'loop': 0, 'loss': 'CE', 'lr': 0.002051761969014296, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00038510262525861947, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0001283280407189864
weight_decay:  3.6838341120263235e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 54.40% Test: 54.80%
Split: 01, Run: 01
None time:  4.406008613994345
None Run 01:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 54.80
Split: 01, Run: 02
None time:  2.2171025241259485
None Run 02:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 46.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.00% Test: 52.40%
Split: 01, Run: 03
None time:  4.351410957984626
None Run 03:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 52.40
run time now: 11.026355028152466
total time:  11.07736773090437
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.33 ± 4.16
  Final Train: 100.00 ± 0.00
   Final Test: 51.10 ± 4.49
[I 2023-06-12 00:23:30,589] Trial 886 finished with value: 51.33333206176758 and parameters: {'Fwd': 0.001839498593974108, 'K': 8, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.193108885789499, 'loop': 0, 'loss': 'MSE', 'lr': 0.0001283280407189864, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.6838341120263235e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0005507514336257147
weight_decay:  0.009090171002542547
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.208436292828992
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.3039393560029566
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  1.7957201530225575
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.20
run time now: 6.358872413635254
total time:  6.406954396050423
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.07 ± 1.42
  Final Train: 100.00 ± 0.00
   Final Test: 68.87 ± 1.14
[I 2023-06-12 00:23:37,656] Trial 887 finished with value: 69.06666564941406 and parameters: {'Fwd': 0.0001429829138749397, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 5.668743046521929, 'loop': 0, 'loss': 'CE', 'lr': 0.0005507514336257147, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.009090171002542547, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013305281269028347
weight_decay:  6.107181607823009e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3514136970043182
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.2260298528708518
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.302877912996337
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.9333655834198
total time:  6.982420806074515
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.30
[I 2023-06-12 00:23:45,328] Trial 888 finished with value: 71.93333435058594 and parameters: {'Fwd': 1.6431719161719443e-05, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 8.538133208442293, 'loop': 0, 'loss': 'CE', 'lr': 0.0013305281269028347, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.107181607823009e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0016274794040361305
weight_decay:  0.0023088924880423686
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.343104361090809
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.3668167828582227
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.9339608550071716
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.690844774246216
total time:  6.750023445114493
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.42
[I 2023-06-12 00:23:52,749] Trial 889 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.01670998739222298, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 5.159092803553403, 'loop': 0, 'loss': 'CE', 'lr': 0.0016274794040361305, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0023088924880423686, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0010144690330480776
weight_decay:  1.7920818987356158e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4135447998996824
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.3525907199364156
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.856762396870181
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.676007986068726
total time:  6.724932614946738
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.47
[I 2023-06-12 00:24:00,094] Trial 890 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.00018479386542319618, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.635916811035962, 'loop': 0, 'loss': 'CE', 'lr': 0.0010144690330480776, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.7920818987356158e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0012400692073065188
weight_decay:  2.5781875007250232e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3268352050799876
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.9329656811896712
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.643206481123343
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.955812931060791
total time:  7.007909124018624
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.25
[I 2023-06-12 00:24:07,851] Trial 891 finished with value: 71.13333892822266 and parameters: {'Fwd': 0.04040201413880181, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 2.1823840964271257, 'loop': 0, 'loss': 'CE', 'lr': 0.0012400692073065188, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.5781875007250232e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0004991549741653258
weight_decay:  0.00011250652432106519
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7202037698589265
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.0806810359936208
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  2.2481426319573075
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.00
run time now: 6.098615884780884
total time:  6.159858967876062
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.07 ± 1.42
  Final Train: 100.00 ± 0.00
   Final Test: 68.83 ± 1.06
[I 2023-06-12 00:24:14,588] Trial 892 finished with value: 69.06666564941406 and parameters: {'Fwd': 0.0015813801012498272, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 6.518501879396059, 'loop': 0, 'loss': 'CE', 'lr': 0.0004991549741653258, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00011250652432106519, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0014304146982721303
weight_decay:  1.0099978950551296e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1036048920359462
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.2745907760690898
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  2.30749471206218
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.20
run time now: 6.734012603759766
total time:  6.787831885972992
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 70.40 ± 0.75
[I 2023-06-12 00:24:22,000] Trial 893 finished with value: 71.4000015258789 and parameters: {'Fwd': 4.287245849584426e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.25, 'lambda2': 1.2839790237304838, 'loop': 0, 'loss': 'CE', 'lr': 0.0014304146982721303, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0099978950551296e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.006955532112585151
weight_decay:  1.3387861062468428e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.414740805979818
None Run 01:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 56.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 58.40% Test: 60.00%
Split: 01, Run: 02
None time:  3.363413637969643
None Run 02:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 60.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.40% Test: 64.50%
Split: 01, Run: 03
None time:  3.418384829070419
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.50
run time now: 8.250430345535278
total time:  8.301132563035935
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.07 ± 4.73
  Final Train: 100.00 ± 0.00
   Final Test: 60.30 ± 4.15
[I 2023-06-12 00:24:30,935] Trial 894 finished with value: 60.06666946411133 and parameters: {'Fwd': 0.09836687059937278, 'K': 9, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 9.811132211534057, 'loop': 0, 'loss': 'CE', 'lr': 0.006955532112585151, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.3387861062468428e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0011343436649995044
weight_decay:  3.4317673441160364e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2530979041475803
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.227838078979403
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.18794840015471
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.40
run time now: 6.785341501235962
total time:  6.839756123023108
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.31
[I 2023-06-12 00:24:38,522] Trial 895 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0002854623758988411, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.30000000000000004, 'lambda2': 6.920566672354431, 'loop': 0, 'loss': 'CE', 'lr': 0.0011343436649995044, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.4317673441160364e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.4
lr:  0.0012746376638124394
weight_decay:  0.0003048720847367077
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3380713930819184
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.3167321369983256
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 70.50%
Split: 01, Run: 03
None time:  4.36087427707389
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 9.066650867462158
total time:  9.121344274142757
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.59
[I 2023-06-12 00:24:48,298] Trial 896 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.06280124633987069, 'K': 7, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 8.173843390931468, 'loop': 0, 'loss': 'CE', 'lr': 0.0012746376638124394, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003048720847367077, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.0015220093821957305
weight_decay:  8.049258104412662e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.043548010988161
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  2.3135561430826783
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.46031882497482
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 6.867274761199951
total time:  6.924753721104935
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.23 ± 0.67
[I 2023-06-12 00:24:55,800] Trial 897 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.008280635725069272, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 5.964915517991835, 'loop': 0, 'loss': 'CE', 'lr': 0.0015220093821957305, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.049258104412662e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.55
lr:  0.000500219818502708
weight_decay:  4.340188042725572e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9287208828609437
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 02
None time:  2.3776279180310667
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  2.1780172989238054
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 6.524879455566406
total time:  6.580814335029572
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 1.19
[I 2023-06-12 00:25:02,984] Trial 898 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.034352539769344596, 'K': 2, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 3.768280357368718, 'loop': 0, 'loss': 'CE', 'lr': 0.000500219818502708, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.340188042725572e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0013864411574518577
weight_decay:  2.2191024050700777e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2091872168239206
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  2.0396232339553535
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.990903761005029
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 6.291180610656738
total time:  6.348653462016955
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 1.37
[I 2023-06-12 00:25:09,983] Trial 899 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.00040472896828434255, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 9.114957473944589, 'loop': 0, 'loss': 'CE', 'lr': 0.0013864411574518577, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2191024050700777e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0017431706050518676
weight_decay:  7.45475332210831e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3393082779366523
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.3347075690981
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  1.8231088160537183
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.550235271453857
total time:  6.59739830205217
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.35
[I 2023-06-12 00:25:17,151] Trial 900 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.0012783701907533788, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.341887274711422, 'loop': 0, 'loss': 'CE', 'lr': 0.0017431706050518676, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.45475332210831e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0011233703015791413
weight_decay:  2.3125531282436294e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0659113579895347
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  2.0875488638412207
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  2.200065289158374
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.90
run time now: 6.4079506397247314
total time:  6.459055891027674
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 1.45
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 1.07
[I 2023-06-12 00:25:24,160] Trial 901 finished with value: 70.06666564941406 and parameters: {'Fwd': 6.214238985519183e-05, 'K': 8, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 4.571609326594335, 'loop': 0, 'loss': 'CE', 'lr': 0.0011233703015791413, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3125531282436294e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.00037913093186093915
weight_decay:  1.7055013941358432e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.998110966058448
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.420848160982132
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  2.479481956921518
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.946305274963379
total time:  6.996951547916979
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.29
[I 2023-06-12 00:25:31,719] Trial 902 finished with value: 69.93333435058594 and parameters: {'Fwd': 0.012098788395012269, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 7.204209958887919, 'loop': 0, 'loss': 'CE', 'lr': 0.00037913093186093915, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.7055013941358432e-05, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0012420277082075902
weight_decay:  0.0006976332220172878
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.290131490910426
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.3791442159563303
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.0747393101919442
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.7963221073150635
total time:  6.84716556686908
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.50
[I 2023-06-12 00:25:39,285] Trial 903 finished with value: 71.86666107177734 and parameters: {'Fwd': 9.738501806221182e-05, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 9.465197141536542, 'loop': 0, 'loss': 'CE', 'lr': 0.0012420277082075902, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006976332220172878, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0009386761961751429
weight_decay:  2.7002469861501987e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.32856549997814
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.1341177250724286
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.00% Test: 70.00%
Split: 01, Run: 03
None time:  4.989134151954204
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 9.50359559059143
total time:  9.554412971949205
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.25
[I 2023-06-12 00:25:49,479] Trial 904 finished with value: 71.26666259765625 and parameters: {'Fwd': 0.05133534460992118, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.110499849105156, 'loop': 0, 'loss': 'CE', 'lr': 0.0009386761961751429, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.7002469861501987e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.001402344921760002
weight_decay:  0.06961262459030688
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 69.60%
Split: 01, Run: 01
None time:  4.475195473060012
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.50%
Split: 01, Run: 02
None time:  4.121388913830742
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.50%
Split: 01, Run: 03
None time:  4.358622148167342
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 13.003844499588013
total time:  13.062066341983154
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.06
[I 2023-06-12 00:26:03,223] Trial 905 finished with value: 69.73333740234375 and parameters: {'Fwd': 5.11045973085166e-06, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 8.787934290801418, 'loop': 0, 'loss': 'MSE', 'lr': 0.001402344921760002, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.06961262459030688, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0025814025403621764
weight_decay:  3.0463180490954162e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.205310566117987
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.0867611691355705
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.393988194875419
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
run time now: 6.734536409378052
total time:  6.786896232049912
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.40
[I 2023-06-12 00:26:10,594] Trial 906 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.004324113777956687, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 5.489927483935408, 'loop': 0, 'loss': 'CE', 'lr': 0.0025814025403621764, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.0463180490954162e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0019182641725628122
weight_decay:  1.2203678988338497e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1088183152023703
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.329094649059698
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.361729711992666
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 6.859042167663574
total time:  6.910244170110673
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.31
[I 2023-06-12 00:26:18,194] Trial 907 finished with value: 71.4666748046875 and parameters: {'Fwd': 2.5611565051080355e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.741801474395349, 'loop': 0, 'loss': 'CE', 'lr': 0.0019182641725628122, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2203678988338497e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.0016003082869198758
weight_decay:  0.00048047157542407075
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3018735621590167
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.9341454620007426
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.1507986790966243
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.435672283172607
total time:  6.481537675019354
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.64
[I 2023-06-12 00:26:25,312] Trial 908 finished with value: 71.66666412353516 and parameters: {'Fwd': 2.4440634200820078e-05, 'K': 9, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 2.4649860766193186, 'loop': 0, 'loss': 'CE', 'lr': 0.0016003082869198758, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00048047157542407075, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.5
lr:  0.009598938942750176
weight_decay:  1.2638652757971436e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.522701817099005
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 99.17
   Final Test: 68.30
Split: 01, Run: 02
None time:  2.581151732010767
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.3845855840481818
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 97.50
   Final Test: 69.70
run time now: 7.539902687072754
total time:  7.5989277069456875
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 0.95
  Final Train: 98.33 ± 0.83
   Final Test: 69.33 ± 0.91
[I 2023-06-12 00:26:33,483] Trial 909 finished with value: 70.06666564941406 and parameters: {'Fwd': 8.474706435702156e-06, 'K': 6, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 7.439990599697869, 'loop': 0, 'loss': 'CE', 'lr': 0.009598938942750176, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2638652757971436e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0010906765998716745
weight_decay:  0.0008950129135100823
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.348272775998339
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.252568985102698
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.323029907885939
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 95.83
   Final Test: 70.80
run time now: 6.976053714752197
total time:  7.029263074975461
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.70
  Final Train: 98.61 ± 2.41
   Final Test: 69.97 ± 0.74
[I 2023-06-12 00:26:41,212] Trial 910 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.0026254060356227776, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 1.008915118473046, 'loop': 0, 'loss': 'CE', 'lr': 0.0010906765998716745, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0008950129135100823, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0002565114342356641
weight_decay:  0.0012767882977554235
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 68.70%
Split: 01, Run: 01
None time:  3.4502430569846183
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.210793775971979
None Run 02:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03
None time:  2.1736881288234144
None Run 03:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.80
run time now: 7.883531808853149
total time:  7.942279040114954
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.27 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 68.27 ± 0.99
[I 2023-06-12 00:26:49,830] Trial 911 finished with value: 68.26666259765625 and parameters: {'Fwd': 0.022368747118345238, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 3.93966139911471, 'loop': 0, 'loss': 'CE', 'lr': 0.0002565114342356641, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0012767882977554235, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0013243046144441953
weight_decay:  5.721749267645945e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.306229084962979
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 96.67
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.2540845391340554
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 97.50
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.0458519549574703
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 92.50
   Final Test: 70.70
run time now: 6.6519670486450195
total time:  6.709500978002325
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 95.56 ± 2.68
   Final Test: 70.00 ± 0.70
[I 2023-06-12 00:26:57,191] Trial 912 finished with value: 71.93333435058594 and parameters: {'Fwd': 1.7814310602667906e-06, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 0.3062170375184712, 'loop': 0, 'loss': 'CE', 'lr': 0.0013243046144441953, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.721749267645945e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001467615902111093
weight_decay:  0.0018696373039918286
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.365948675898835
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.40
Split: 01, Run: 02
None time:  1.1854433289263397
None Run 02:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 98.33%, Valid: 62.00% Test: 61.60%
Split: 01, Run: 03
None time:  3.1724897020030767
None Run 03:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 98.33
   Final Test: 61.50
run time now: 5.775259256362915
total time:  5.8202591300942
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.87 ± 8.78
  Final Train: 99.44 ± 0.96
   Final Test: 51.43 ± 8.72
[I 2023-06-12 00:27:03,606] Trial 913 finished with value: 51.866668701171875 and parameters: {'Fwd': 0.03017080299896602, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.702127148585128, 'loop': 0, 'loss': 'CE', 'lr': 0.001467615902111093, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0018696373039918286, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0011921381024546955
weight_decay:  3.094648910277798e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0645302881021053
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.1913416280876845
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.2076410341542214
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 6.521583318710327
total time:  6.570833649020642
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.45
[I 2023-06-12 00:27:10,798] Trial 914 finished with value: 71.53333282470703 and parameters: {'Fwd': 1.1146247903162118e-05, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.992394652521181, 'loop': 0, 'loss': 'CE', 'lr': 0.0011921381024546955, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.094648910277798e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.00239814005819893
weight_decay:  3.985687428600665e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0954260039143264
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  2.1419100838247687
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.072229322977364
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
run time now: 6.3609185218811035
total time:  6.420759524218738
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.47
[I 2023-06-12 00:27:17,766] Trial 915 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0697146837116519, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.8613978612474975, 'loop': 0, 'loss': 'CE', 'lr': 0.00239814005819893, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.985687428600665e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0016453134932109888
weight_decay:  0.032400099377547384
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.053519828012213
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.014861478935927
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  1.9673107541166246
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 6.089967250823975
total time:  6.1562562740873545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.76
[I 2023-06-12 00:27:24,577] Trial 916 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.044448633702458315, 'K': 7, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.7000000000000001, 'lambda2': 2.755336186352066, 'loop': 0, 'loss': 'CE', 'lr': 0.0016453134932109888, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.032400099377547384, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.003496919610633375
weight_decay:  0.016627563199372284
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2703039669431746
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 99.17
   Final Test: 69.90
Split: 01, Run: 02
None time:  2.3150191558524966
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.681401487905532
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 97.50
   Final Test: 68.90
run time now: 7.31623387336731
total time:  7.369890064932406
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.42
  Final Train: 98.61 ± 0.96
   Final Test: 69.53 ± 0.55
[I 2023-06-12 00:27:32,553] Trial 917 finished with value: 70.46666717529297 and parameters: {'Fwd': 2.182237178042857e-05, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.584812296939283, 'loop': 0, 'loss': 'CE', 'lr': 0.003496919610633375, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.016627563199372284, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0021252844298022934
weight_decay:  2.1881795827430905e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.503049216931686
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  2.8859563989099115
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  2.4387193038128316
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 7.895752668380737
total time:  7.9566107171121985
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.74
[I 2023-06-12 00:27:41,109] Trial 918 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.05787732101608863, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.032136368158499, 'loop': 1, 'loss': 'CE', 'lr': 0.0021252844298022934, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.1881795827430905e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0010161946134675936
weight_decay:  0.0002386990038646125
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8118598570581526
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.845782345160842
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.90
Split: 01, Run: 03
None time:  1.6306750029325485
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.70
run time now: 5.344856023788452
total time:  5.419724023202434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 1.10
[I 2023-06-12 00:27:47,280] Trial 919 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.006236972533177976, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 5.2571734235666945, 'loop': 0, 'loss': 'CE', 'lr': 0.0010161946134675936, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002386990038646125, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0012831794059505876
weight_decay:  0.003007740572977254
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1156917640473694
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.114977899007499
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.635885266121477
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.913600206375122
total time:  6.963306610006839
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.53
[I 2023-06-12 00:27:54,883] Trial 920 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.0004259498452897813, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.758054023348989, 'loop': 0, 'loss': 'CE', 'lr': 0.0012831794059505876, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.003007740572977254, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.00010425330973874959
weight_decay:  0.00013988318003350534
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9525380420964211
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.90
Split: 01, Run: 02
None time:  2.3770549909677356
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.40% Test: 68.10%
Split: 01, Run: 03
None time:  4.450670048827305
None Run 03:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 68.10
run time now: 8.835466146469116
total time:  8.883646277012303
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 67.20 ± 1.15
[I 2023-06-12 00:28:04,371] Trial 921 finished with value: 66.5333251953125 and parameters: {'Fwd': 1.1878532915925704e-06, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 4.359325165591991, 'loop': 0, 'loss': 'CE', 'lr': 0.00010425330973874959, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00013988318003350534, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0014744377846045529
weight_decay:  5.11362997476296e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2769018469844013
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.9626479651778936
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.5589456690941006
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.851027965545654
total time:  6.902173276990652
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.46
[I 2023-06-12 00:28:11,881] Trial 922 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.017577742929870598, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.375739998337627, 'loop': 0, 'loss': 'CE', 'lr': 0.0014744377846045529, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.11362997476296e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0011711991713757432
weight_decay:  0.02275553329666099
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.045360636897385
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.30%
Split: 01, Run: 02
None time:  3.9460360850207508
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 70.00%
Split: 01, Run: 03
None time:  3.7424023901112378
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 9.821740865707397
total time:  9.873246222967282
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.36
[I 2023-06-12 00:28:22,612] Trial 923 finished with value: 70.33333587646484 and parameters: {'Fwd': 3.7069668200870447e-06, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 8.96618399273887, 'loop': 0, 'loss': 'MSE', 'lr': 0.0011711991713757432, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.02275553329666099, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.002915500512242665
weight_decay:  1.6106645505048276e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1141430381685495
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  2.148155767004937
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.350009355926886
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
run time now: 6.66028618812561
total time:  6.7132608438842
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.40
[I 2023-06-12 00:28:29,914] Trial 924 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0006976784975003798, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 8.390299152953386, 'loop': 0, 'loss': 'CE', 'lr': 0.002915500512242665, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6106645505048276e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001840240348249264
weight_decay:  1.0895729727287258e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0959864710457623
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  2.2749514158349484
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.3842903880868107
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.804116725921631
total time:  6.874950502999127
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.15
[I 2023-06-12 00:28:37,432] Trial 925 finished with value: 71.5999984741211 and parameters: {'Fwd': 1.3692553614143468e-05, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.0225907613449525, 'loop': 0, 'loss': 'CE', 'lr': 0.001840240348249264, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0895729727287258e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.005873528901209589
weight_decay:  7.030547900472843e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5608782949857414
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.4855948239564896
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.9280509629752487
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.10
run time now: 7.028247356414795
total time:  7.096422665053979
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.23
  Final Train: 99.17 ± 0.83
   Final Test: 69.57 ± 0.45
[I 2023-06-12 00:28:45,167] Trial 926 finished with value: 70.66667175292969 and parameters: {'Fwd': 0.0004852215937734504, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.154926725152321, 'loop': 0, 'loss': 'CE', 'lr': 0.005873528901209589, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.030547900472843e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.001360584457978611
weight_decay:  1.9917787008275727e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4334015708882362
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.3426973959431052
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.1281188169959933
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.40
run time now: 3.956007957458496
total time:  4.010448495857418
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 68.90 ± 0.44
[I 2023-06-12 00:28:49,858] Trial 927 finished with value: 69.93333435058594 and parameters: {'Fwd': 3.20361081484936e-05, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 3.623251375070361, 'loop': 0, 'loss': 'CE', 'lr': 0.001360584457978611, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.9917787008275727e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.0015302931629582316
weight_decay:  0.00010202713498667486
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.373366334941238
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  2.187178477179259
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.438798091141507
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 7.05394983291626
total time:  7.100773676065728
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.61
[I 2023-06-12 00:28:57,643] Trial 928 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.03889342352880537, 'K': 8, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 7.193567109149763, 'loop': 0, 'loss': 'CE', 'lr': 0.0015302931629582316, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010202713498667486, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.008122743536019056
weight_decay:  4.886310464215144e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.918383790878579
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 02
None time:  2.401811429997906
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.20% Test: 68.90%
Split: 01, Run: 03
None time:  4.427195145981386
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.70
run time now: 8.795391321182251
total time:  8.85479012108408
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 68.57 ± 0.23
[I 2023-06-12 00:29:07,047] Trial 929 finished with value: 68.26667022705078 and parameters: {'Fwd': 0.07748697451834614, 'K': 9, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 7.751190248359243, 'loop': 0, 'loss': 'CE', 'lr': 0.008122743536019056, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.886310464215144e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.7000000000000001
lr:  0.0012426660296540844
weight_decay:  3.100632967522298e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.006788092898205
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.097329323878512
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.434064278844744
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.593037366867065
total time:  6.6552319538313895
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.50
[I 2023-06-12 00:29:14,322] Trial 930 finished with value: 71.93333435058594 and parameters: {'Fwd': 1.5325275587384092e-06, 'K': 4, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 5.431272858935965, 'loop': 0, 'loss': 'CE', 'lr': 0.0012426660296540844, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.100632967522298e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  1.0
lr:  0.0011096971307919259
weight_decay:  3.724163223194112e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3539296879898757
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.328901620116085
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.9970787870697677
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 6.727982997894287
total time:  6.7752470129635185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.67
[I 2023-06-12 00:29:21,921] Trial 931 finished with value: 71.66666412353516 and parameters: {'Fwd': 8.000845868936512e-05, 'K': 8, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 9.261736485835808, 'loop': 0, 'loss': 'CE', 'lr': 0.0011096971307919259, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.724163223194112e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001726858283057248
weight_decay:  8.92209532684005e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3206299981102347
None Run 01:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 46.10
Split: 01, Run: 02
None time:  1.3428288951981813
None Run 02:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 99.17
   Final Test: 55.00
Split: 01, Run: 03
None time:  1.6032427728641778
None Run 03:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 97.50
   Final Test: 57.30
run time now: 4.319107532501221
total time:  4.372329276055098
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.40 ± 5.63
  Final Train: 98.89 ± 1.27
   Final Test: 52.80 ± 5.92
[I 2023-06-12 00:29:26,923] Trial 932 finished with value: 54.39999771118164 and parameters: {'Fwd': 0.0022356638104918613, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 6.960773516467976, 'loop': 0, 'loss': 'CE', 'lr': 0.001726858283057248, 'softmaxF': False, 'useGCN': False, 'weight_decay': 8.92209532684005e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0014060481709368266
weight_decay:  2.3662886708716782e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1742510511539876
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.9001073590479791
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  2.1693052668124437
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.3032732009887695
total time:  6.3664035059046
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.59
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 1.03
[I 2023-06-12 00:29:33,837] Trial 933 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.00024874160097980116, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 7.99406861472095, 'loop': 0, 'loss': 'CE', 'lr': 0.0014060481709368266, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3662886708716782e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.45
lr:  0.001281442050559549
weight_decay:  0.0003579894365958918
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.088281990028918
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.187289783032611
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  2.4759657559916377
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.79446005821228
total time:  6.839290102943778
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.68
[I 2023-06-12 00:29:41,260] Trial 934 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.0031110687236991772, 'K': 3, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.205229490317362, 'loop': 0, 'loss': 'CE', 'lr': 0.001281442050559549, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0003579894365958918, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0009755815975449897
weight_decay:  6.81704633027828e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.253434948856011
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.1158403500448912
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.3575301030650735
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.78293514251709
total time:  6.836699390085414
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.31
[I 2023-06-12 00:29:48,790] Trial 935 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.028936447700434968, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 9.617556358203752, 'loop': 0, 'loss': 'CE', 'lr': 0.0009755815975449897, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.81704633027828e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0006749673152140812
weight_decay:  1.852648897288242e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2051628672052175
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.042915557976812
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 70.00%
Split: 01, Run: 03
None time:  4.284790129866451
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 8.582506656646729
total time:  8.631852554855868
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.57
[I 2023-06-12 00:29:57,974] Trial 936 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.05197212233349642, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.5026104722563005, 'loop': 0, 'loss': 'CE', 'lr': 0.0006749673152140812, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.852648897288242e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.009101030647269848
weight_decay:  1.4473683658949141e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 70.40% Test: 69.30%
Split: 01, Run: 01
None time:  4.511556782992557
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 98.33%, Valid: 70.00% Test: 69.20%
Split: 01, Run: 02
None time:  4.774176551029086
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 97.50%, Valid: 70.40% Test: 68.90%
Split: 01, Run: 03
None time:  4.662415392929688
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 69.30
run time now: 13.99930739402771
total time:  14.054244037019089
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.23
  Final Train: 99.17 ± 0.00
   Final Test: 69.47 ± 0.29
[I 2023-06-12 00:30:12,704] Trial 937 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.012125064083758736, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.714835406448685, 'loop': 0, 'loss': 'CE', 'lr': 0.009101030647269848, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4473683658949141e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.00035849123418951
weight_decay:  0.0010993105418482362
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.020062471041456
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.2646527991164476
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 03
None time:  2.1214780050795525
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.50
run time now: 6.452200412750244
total time:  6.508982964092866
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.53 ± 1.53
  Final Train: 100.00 ± 0.00
   Final Test: 68.57 ± 1.62
[I 2023-06-12 00:30:19,872] Trial 938 finished with value: 68.53333282470703 and parameters: {'Fwd': 1.0159925760928995e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 3.2413639448104385, 'loop': 0, 'loss': 'CE', 'lr': 0.00035849123418951, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0010993105418482362, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0001926267531168578
weight_decay:  0.0006710948096756719
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.370841027935967
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  2.354081064928323
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.3803312149830163
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.60
run time now: 7.155543804168701
total time:  7.204595239134505
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 0.79
[I 2023-06-12 00:30:27,690] Trial 939 finished with value: 68.66666412353516 and parameters: {'Fwd': 3.145739829669802e-06, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.2966313882131715, 'loop': 0, 'loss': 'CE', 'lr': 0.0001926267531168578, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006710948096756719, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.001993939388766582
weight_decay:  3.9391324131393454e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1706972119864076
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.2503892011009157
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  2.322109989123419
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 6.79642128944397
total time:  6.863769744988531
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.29
[I 2023-06-12 00:30:35,134] Trial 940 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.04348255754420292, 'K': 7, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 4.778735651561695, 'loop': 0, 'loss': 'CE', 'lr': 0.001993939388766582, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.9391324131393454e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.001569676334124091
weight_decay:  1.1588362113445145e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.336179713020101
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.981008472153917
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  2.20013087708503
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.569118976593018
total time:  6.6230845709796995
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.40
[I 2023-06-12 00:30:42,323] Trial 941 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0011004537124410776, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 5.873154423038314, 'loop': 0, 'loss': 'CE', 'lr': 0.001569676334124091, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.1588362113445145e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.005117160914260241
weight_decay:  0.00045793108349073084
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.00% Test: 68.30%
Split: 01, Run: 01
None time:  4.142004461027682
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.60% Test: 68.10%
Split: 01, Run: 02
None time:  4.233912705909461
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.20% Test: 67.00%
Split: 01, Run: 03
None time:  4.623506332049146
None Run 03:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 67.00
run time now: 13.048541069030762
total time:  13.110839064000174
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.93 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 67.77 ± 0.67
[I 2023-06-12 00:30:56,076] Trial 942 finished with value: 65.93334197998047 and parameters: {'Fwd': 0.008970880350241617, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.1777388757070595, 'loop': 0, 'loss': 'MSE', 'lr': 0.005117160914260241, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00045793108349073084, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0022758882729460063
weight_decay:  0.00018893534024949171
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3481812439858913
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.5072805401869118
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.3619692218489945
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
run time now: 6.267242431640625
total time:  6.312286638189107
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.20
[I 2023-06-12 00:31:02,975] Trial 943 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.06107471136358862, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.9927353228810682, 'loop': 0, 'loss': 'CE', 'lr': 0.0022758882729460063, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00018893534024949171, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001362120927641424
weight_decay:  4.857730919041699e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8329631770029664
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.120425160974264
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.40%
Split: 01, Run: 03
None time:  4.444996044971049
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 8.447815418243408
total time:  8.496348723070696
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.25
[I 2023-06-12 00:31:12,040] Trial 944 finished with value: 71.86666107177734 and parameters: {'Fwd': 0.022438687816351152, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 7.370320413890768, 'loop': 0, 'loss': 'CE', 'lr': 0.001362120927641424, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.857730919041699e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0011827254006291006
weight_decay:  1.6113985811291753e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1712317389901727
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  1.9065928829368204
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  2.1638305990491062
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 6.290884733200073
total time:  6.346867780899629
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 1.19
[I 2023-06-12 00:31:19,073] Trial 945 finished with value: 70.13333892822266 and parameters: {'Fwd': 0.000126211808460653, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 6.555735342324052, 'loop': 0, 'loss': 'CE', 'lr': 0.0011827254006291006, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6113985811291753e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.00039519193193063426
weight_decay:  2.659217339565374e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2164995709899813
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.28323298599571
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  3.540112619055435
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.80
run time now: 8.099813222885132
total time:  8.149704040028155
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.15
[I 2023-06-12 00:31:27,909] Trial 946 finished with value: 70.0666732788086 and parameters: {'Fwd': 0.00020137839534354078, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 9.423906333689494, 'loop': 0, 'loss': 'CE', 'lr': 0.00039519193193063426, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.659217339565374e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0010815898556551207
weight_decay:  2.991793392709219e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4925301580224186
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.1919950658921152
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  2.5775117268785834
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.50
run time now: 7.308536767959595
total time:  7.360208995174617
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.20 ± 0.61
[I 2023-06-12 00:31:35,951] Trial 947 finished with value: 70.73333740234375 and parameters: {'Fwd': 0.03368703704244577, 'K': 8, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 8.204943839606502, 'loop': 1, 'loss': 'CE', 'lr': 0.0010815898556551207, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.991793392709219e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.001463492227901829
weight_decay:  0.041624801526173594
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0463195219635963
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.4276141128502786
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.2644340051338077
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.80
run time now: 6.789469242095947
total time:  6.840646413853392
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.10 ± 0.62
[I 2023-06-12 00:31:43,417] Trial 948 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.07415423962430394, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 3.490262746186618, 'loop': 0, 'loss': 'CE', 'lr': 0.001463492227901829, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.041624801526173594, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.0029456383009789956
weight_decay:  6.588432101935462e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4506762681994587
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 99.17
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.0642601989675313
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.3900394330266863
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.00
run time now: 6.960751056671143
total time:  7.010654832934961
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.31
  Final Train: 99.72 ± 0.48
   Final Test: 69.57 ± 0.49
[I 2023-06-12 00:31:50,989] Trial 949 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.001892294222024266, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 6.882788658844326, 'loop': 0, 'loss': 'CE', 'lr': 0.0029456383009789956, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.588432101935462e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.001286536063110382
weight_decay:  0.001466128058546153
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.055901356972754
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.175415316829458
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.333624013932422
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.615715026855469
total time:  6.669406086904928
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.40
[I 2023-06-12 00:31:58,275] Trial 950 finished with value: 71.93333435058594 and parameters: {'Fwd': 4.509473781477267e-05, 'K': 8, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.695198339320594, 'loop': 0, 'loss': 'CE', 'lr': 0.001286536063110382, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001466128058546153, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.001618789346847044
weight_decay:  2.0738330258466408e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.40% Test: 56.00%
Split: 01, Run: 01
None time:  3.0513152058701962
None Run 01:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 55.80
Split: 01, Run: 02
None time:  1.1075768459122628
None Run 02:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 61.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.40% Test: 63.30%
Split: 01, Run: 03
None time:  2.8744769850745797
None Run 03:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 63.40
run time now: 7.089175701141357
total time:  7.1603796950075775
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.00 ± 5.05
  Final Train: 100.00 ± 0.00
   Final Test: 60.23 ± 3.96
[I 2023-06-12 00:32:06,012] Trial 951 finished with value: 59.0 and parameters: {'Fwd': 0.04900032240121568, 'K': 8, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 8.718435048460407, 'loop': 0, 'loss': 'CE', 'lr': 0.001618789346847044, 'softmaxF': False, 'useGCN': False, 'weight_decay': 2.0738330258466408e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.001211077136900715
weight_decay:  3.387184498029122e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.653787737013772
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.7869306299835443
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  3.0918252100236714
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 8.589630603790283
total time:  8.64630879694596
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.15
[I 2023-06-12 00:32:15,337] Trial 952 finished with value: 70.80000305175781 and parameters: {'Fwd': 0.0007699955540848868, 'K': 8, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.749489798091595, 'loop': 2, 'loss': 'CE', 'lr': 0.001211077136900715, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.387184498029122e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.001384973554704155
weight_decay:  4.474884239953347e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3233499529305845
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.825442569097504
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.5972201409749687
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.00
run time now: 6.856159448623657
total time:  6.908442351967096
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.27 ± 0.64
[I 2023-06-12 00:32:22,906] Trial 953 finished with value: 71.79999542236328 and parameters: {'Fwd': 1.1934291800841062e-05, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 7.579745136583826, 'loop': 0, 'loss': 'CE', 'lr': 0.001384973554704155, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.474884239953347e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0008100382225384657
weight_decay:  5.575399022565744e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3094808619935066
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.800703986082226
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  2.033041519112885
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.20
run time now: 5.197238206863403
total time:  5.254633269039914
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 1.41
[I 2023-06-12 00:32:28,760] Trial 954 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.005440348353267415, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 2.9659542794750173, 'loop': 0, 'loss': 'CE', 'lr': 0.0008100382225384657, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.575399022565744e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.75
lr:  0.002547002450168801
weight_decay:  1.5319387318241875e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7447950488422066
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.242460375884548
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  1.9661261308938265
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
run time now: 5.9987475872039795
total time:  6.054922003066167
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.68
[I 2023-06-12 00:32:35,516] Trial 955 finished with value: 71.13333892822266 and parameters: {'Fwd': 0.027187304257936626, 'K': 7, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 7.083167094665184, 'loop': 0, 'loss': 'CE', 'lr': 0.002547002450168801, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5319387318241875e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0018227074977569182
weight_decay:  8.968530554114143e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.317910247016698
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.0843909808900207
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 03
None time:  2.3366462630219758
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.7878053188323975
total time:  6.839726350037381
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.25
[I 2023-06-12 00:32:42,986] Trial 956 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.09890592973047897, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.9752276813524245, 'loop': 0, 'loss': 'CE', 'lr': 0.0018227074977569182, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.968530554114143e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0010868058447750573
weight_decay:  2.5751543581659365e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.162417621118948
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.126725611044094
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.443163408199325
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.50
run time now: 6.782678127288818
total time:  6.8310881338547915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.59
[I 2023-06-12 00:32:50,413] Trial 957 finished with value: 71.5999984741211 and parameters: {'Fwd': 1.9290083632487183e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.759922654962818, 'loop': 0, 'loss': 'CE', 'lr': 0.0010868058447750573, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.5751543581659365e-05, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.00012961680807770343
weight_decay:  9.154568493773441e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.378978237044066
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  2.240488155046478
None Run 02:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  2.5663156141526997
None Run 03:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 69.00
run time now: 7.251851797103882
total time:  7.309504854027182
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 68.53 ± 0.50
[I 2023-06-12 00:32:58,410] Trial 958 finished with value: 67.79999542236328 and parameters: {'Fwd': 5.086175989028167e-06, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 5.354675397733046, 'loop': 0, 'loss': 'CE', 'lr': 0.00012961680807770343, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.154568493773441e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.00017531901663971254
weight_decay:  0.00011548330770905221
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2862583950627595
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  2.521250799065456
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.3821372748352587
None Run 03:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 7.243819236755371
total time:  7.301279932027683
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.93
[I 2023-06-12 00:33:06,290] Trial 959 finished with value: 68.60000610351562 and parameters: {'Fwd': 0.015563341167951893, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 6.0714960448634265, 'loop': 0, 'loss': 'CE', 'lr': 0.00017531901663971254, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00011548330770905221, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0014816835008005995
weight_decay:  4.133785520299278e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1993840241339058
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.121909944107756
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.3272117080632597
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 6.724535703659058
total time:  6.773561357986182
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.40
[I 2023-06-12 00:33:13,666] Trial 960 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.03762541000047089, 'K': 8, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 1.9930895276721872, 'loop': 0, 'loss': 'CE', 'lr': 0.0014816835008005995, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.133785520299278e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.008095306298738558
weight_decay:  0.0023408882541775156
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1493289628997445
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 99.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  2.564611000008881
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 98.33
   Final Test: 68.90
Split: 01, Run: 03
None time:  2.0324448901228607
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 69.40
run time now: 6.7946391105651855
total time:  6.8456270499154925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.58
  Final Train: 98.89 ± 0.48
   Final Test: 69.13 ± 0.25
[I 2023-06-12 00:33:21,179] Trial 961 finished with value: 70.53333282470703 and parameters: {'Fwd': 2.300377773467826e-06, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 9.186472249386723, 'loop': 0, 'loss': 'CE', 'lr': 0.008095306298738558, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0023408882541775156, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.0013026383988963977
weight_decay:  0.000574229609375466
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 69.50%
Split: 01, Run: 01
None time:  3.731846757000312
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.20%
Split: 01, Run: 02
None time:  4.764280908042565
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.30%
Split: 01, Run: 03
None time:  4.2131417382042855
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
run time now: 12.761214971542358
total time:  12.861378841102123
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.33 ± 0.23
[I 2023-06-12 00:33:35,021] Trial 962 finished with value: 69.86666870117188 and parameters: {'Fwd': 0.06586149589049402, 'K': 8, 'alpha': 0.8, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.7000000000000001, 'lambda2': 4.529079027631983, 'loop': 0, 'loss': 'MSE', 'lr': 0.0013026383988963977, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000574229609375466, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.0017070672678723797
weight_decay:  1.8251537653901843e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.096852664137259
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  2.0865941080264747
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  2.143894949927926
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.374035358428955
total time:  6.42158407298848
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.65
[I 2023-06-12 00:33:41,984] Trial 963 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.003826506422915851, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 4.177873935986684, 'loop': 0, 'loss': 'CE', 'lr': 0.0017070672678723797, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.8251537653901843e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.55
lr:  0.00014256296305995182
weight_decay:  1.0265311008974481e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3658667379058897
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  2.0743126459419727
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.00
Split: 01, Run: 03
None time:  2.2161404897924513
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.70
run time now: 6.707053899765015
total time:  6.75824357313104
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.20 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 67.03 ± 1.23
[I 2023-06-12 00:33:49,324] Trial 964 finished with value: 67.19998931884766 and parameters: {'Fwd': 0.00016515270449848725, 'K': 8, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.75, 'lambda2': 5.5800696849418845, 'loop': 0, 'loss': 'CE', 'lr': 0.00014256296305995182, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0265311008974481e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.00043972412932868915
weight_decay:  0.0008808455464142668
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1522075401153415
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.3039695161860436
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.213859518058598
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.722314357757568
total time:  6.771903674118221
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.25
[I 2023-06-12 00:33:56,776] Trial 965 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.0072989726387255914, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 6.406738250717569, 'loop': 0, 'loss': 'CE', 'lr': 0.00043972412932868915, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0008808455464142668, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0008777161030497
weight_decay:  1.2829552673777281e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.290920903906226
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.9474017859902233
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.519065784988925
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 6.818003177642822
total time:  6.8672735509462655
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.70
[I 2023-06-12 00:34:04,212] Trial 966 finished with value: 71.0666732788086 and parameters: {'Fwd': 3.5785886075422755e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.75, 'lambda2': 6.603700646377587, 'loop': 0, 'loss': 'CE', 'lr': 0.0008777161030497, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2829552673777281e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0011586698375959468
weight_decay:  0.07812324743427151
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5424677939154208
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.461873380932957
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.5578095340169966
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
run time now: 4.614479303359985
total time:  4.6701637951191515
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.53
[I 2023-06-12 00:34:09,495] Trial 967 finished with value: 70.4666748046875 and parameters: {'Fwd': 8.953363577284125e-06, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 4.8644659288064815, 'loop': 0, 'loss': 'CE', 'lr': 0.0011586698375959468, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.07812324743427151, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0010283655955444628
weight_decay:  3.4708030602379084e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0231748579535633
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.2845725789666176
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.5760230829473585
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.939499139785767
total time:  6.99262445513159
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.45
[I 2023-06-12 00:34:17,146] Trial 968 finished with value: 71.4000015258789 and parameters: {'Fwd': 5.513231521917939e-05, 'K': 8, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 6.814166076414024, 'loop': 0, 'loss': 'CE', 'lr': 0.0010283655955444628, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.4708030602379084e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.004079075055584302
weight_decay:  6.315476420715375e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2192363091744483
None Run 01:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 46.40
Split: 01, Run: 02
None time:  1.4564317788463086
None Run 02:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 56.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.20% Test: 65.50%
Split: 01, Run: 03
None time:  2.8076020751614124
None Run 03:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.20
run time now: 5.535809516906738
total time:  5.5937315199989825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.20 ± 10.22
  Final Train: 100.00 ± 0.00
   Final Test: 55.97 ± 9.40
[I 2023-06-12 00:34:23,424] Trial 969 finished with value: 56.20000076293945 and parameters: {'Fwd': 0.053328013788710854, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.5, 'lambda2': 8.938763344229141, 'loop': 0, 'loss': 'CE', 'lr': 0.004079075055584302, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.315476420715375e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.5
lr:  0.0021507044399952254
weight_decay:  0.004978821270863946
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0281114960089326
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.995386830996722
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  2.196294865803793
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 6.27030086517334
total time:  6.321139158913866
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.91
[I 2023-06-12 00:34:30,306] Trial 970 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.02030094941182763, 'K': 8, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 7.665992305873353, 'loop': 0, 'loss': 'CE', 'lr': 0.0021507044399952254, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004978821270863946, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0013698964885983914
weight_decay:  2.6123517128167265e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9560701509471983
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.3329586039762944
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.129819242982194
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.4636616706848145
total time:  6.511431084014475
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.21
[I 2023-06-12 00:34:37,381] Trial 971 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.04432375212040862, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 8.029819098383424, 'loop': 0, 'loss': 'CE', 'lr': 0.0013698964885983914, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.6123517128167265e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.55
lr:  0.0015290478207171932
weight_decay:  2.303366951845067e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1890485410112888
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.8615781080443412
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.3813990589696914
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.48049521446228
total time:  6.535567675950006
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.15
[I 2023-06-12 00:34:44,535] Trial 972 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.03982474438905548, 'K': 6, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 7.455576033124472, 'loop': 0, 'loss': 'CE', 'lr': 0.0015290478207171932, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.303366951845067e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0048043334180832365
weight_decay:  2.9260933967000757e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0255518259946257
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 02
None time:  2.108615256845951
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  2.1835859261918813
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.30
run time now: 6.446100473403931
total time:  6.550807228079066
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.67
[I 2023-06-12 00:34:51,786] Trial 973 finished with value: 70.0 and parameters: {'Fwd': 0.03048660813961328, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 7.945905358223653, 'loop': 0, 'loss': 'CE', 'lr': 0.0048043334180832365, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.9260933967000757e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.5
lr:  0.00045562089803374096
weight_decay:  2.3931620046806363e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0919747669249773
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.2543352250941098
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.4967898030299693
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 6.8915650844573975
total time:  6.941977513954043
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.15
[I 2023-06-12 00:34:59,445] Trial 974 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.0005264094185305942, 'K': 6, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 1.5508701574505102, 'loop': 0, 'loss': 'CE', 'lr': 0.00045562089803374096, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.3931620046806363e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.00022443726836507893
weight_decay:  1.8293048024687697e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2405885600019246
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 70.20%
Split: 01, Run: 02
None time:  4.536634541116655
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 70.30%
Split: 01, Run: 03
None time:  4.380583812016994
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 11.232111930847168
total time:  11.297126427059993
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.07 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.61
[I 2023-06-12 00:35:11,394] Trial 975 finished with value: 69.0666732788086 and parameters: {'Fwd': 0.045493782428272955, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 8.380162380596426, 'loop': 0, 'loss': 'CE', 'lr': 0.00022443726836507893, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.8293048024687697e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8500000000000001
lr:  0.0006040163266283492
weight_decay:  3.4600364115207393e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7592369681224227
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.2760464639868587
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.323941439855844
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.50
run time now: 6.40628719329834
total time:  6.460693180793896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.32
[I 2023-06-12 00:35:18,458] Trial 976 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.06263653054068441, 'K': 5, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 7.710368245173478, 'loop': 0, 'loss': 'CE', 'lr': 0.0006040163266283492, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.4600364115207393e-06, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.75
lr:  0.0014129378028669578
weight_decay:  1.710265581351347e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2092778889928013
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.301837582141161
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.0421732789836824
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 6.598334312438965
total time:  6.647447460098192
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.42
[I 2023-06-12 00:35:25,743] Trial 977 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.07893597731563944, 'K': 6, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 7.86788201822634, 'loop': 0, 'loss': 'CE', 'lr': 0.0014129378028669578, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.710265581351347e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.0002779431675656545
weight_decay:  3.876566409557031e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.544424633961171
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.3403258610051125
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.3806613250635564
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.60
run time now: 7.3164215087890625
total time:  7.365940721007064
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 70.07 ± 0.55
[I 2023-06-12 00:35:33,654] Trial 978 finished with value: 69.53333282470703 and parameters: {'Fwd': 0.037102540737511056, 'K': 7, 'alpha': 0.65, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 7.2833596267054, 'loop': 0, 'loss': 'CE', 'lr': 0.0002779431675656545, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.876566409557031e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.45
lr:  0.003325783369973191
weight_decay:  2.2668837741364664e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2294496069662273
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  2.188050915952772
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.225534942932427
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 6.694658279418945
total time:  6.753108564997092
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.23
[I 2023-06-12 00:35:41,070] Trial 979 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.053539684258860895, 'K': 6, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 8.285432054509245, 'loop': 0, 'loss': 'CE', 'lr': 0.003325783369973191, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2668837741364664e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.7000000000000001
lr:  0.00022564514918193022
weight_decay:  0.08817124190291269
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 55.40% Test: 57.20%
Split: 01, Run: 01
None time:  3.7393681660760194
None Run 01:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 57.20
Split: 01, Run: 02
None time:  2.216979216784239
None Run 02:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 45.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.80% Test: 59.30%
Split: 01, Run: 03
None time:  3.872896635904908
None Run 03:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 59.30
run time now: 9.881744384765625
total time:  9.942947532050312
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.27 ± 5.90
  Final Train: 100.00 ± 0.00
   Final Test: 53.93 ± 7.55
[I 2023-06-12 00:35:51,593] Trial 980 finished with value: 53.266666412353516 and parameters: {'Fwd': 0.010773677281581528, 'K': 6, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 7.770670603757144, 'loop': 0, 'loss': 'MSE', 'lr': 0.00022564514918193022, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.08817124190291269, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.001632178797984186
weight_decay:  0.00014580758487418196
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.340616319794208
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 96.67
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.866364006884396
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 97.50
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.344202243955806
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 95.00
   Final Test: 70.20
run time now: 6.603528738021851
total time:  6.656539479969069
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.12
  Final Train: 96.39 ± 1.27
   Final Test: 69.87 ± 0.49
[I 2023-06-12 00:35:58,870] Trial 981 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.00010760961642169164, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.6000000000000001, 'lambda2': 0.2434459408411307, 'loop': 0, 'loss': 'CE', 'lr': 0.001632178797984186, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00014580758487418196, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.75
lr:  0.0020117534542871958
weight_decay:  0.018476369699691512
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9146894100122154
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.2883979910984635
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.0967579579446465
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
run time now: 6.347689151763916
total time:  6.4126539919525385
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.35
[I 2023-06-12 00:36:05,992] Trial 982 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.028873980021022698, 'K': 7, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 5.111650857268361, 'loop': 0, 'loss': 'CE', 'lr': 0.0020117534542871958, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.018476369699691512, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0013677558512751994
weight_decay:  0.0002796624572190545
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.283399309962988
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.0311054789926857
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 71.30%
Split: 01, Run: 03
None time:  4.441502300091088
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.20
run time now: 8.812106370925903
total time:  8.865378125803545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 70.23 ± 0.84
[I 2023-06-12 00:36:15,598] Trial 983 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.04646384629067459, 'K': 7, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.971815905171956, 'loop': 0, 'loss': 'CE', 'lr': 0.0013677558512751994, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002796624572190545, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0012362891747330102
weight_decay:  2.8583566498741276e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0116808731108904
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.267232008976862
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.2949524018913507
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.621917009353638
total time:  6.674642418976873
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.31
[I 2023-06-12 00:36:22,992] Trial 984 finished with value: 72.0 and parameters: {'Fwd': 0.06202450358007796, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 8.783311170659811, 'loop': 0, 'loss': 'CE', 'lr': 0.0012362891747330102, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8583566498741276e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.0015234270394456524
weight_decay:  2.5594522732048102e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9745138240978122
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 68.60%
Split: 01, Run: 02
None time:  4.330865686992183
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  2.1630061890464276
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 8.521001100540161
total time:  8.569790838984773
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 1.39
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.72
[I 2023-06-12 00:36:32,199] Trial 985 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.0621512578134433, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8, 'lambda2': 8.434011799703539, 'loop': 0, 'loss': 'CE', 'lr': 0.0015234270394456524, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.5594522732048102e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.55
lr:  0.0017847958919516387
weight_decay:  3.1732495363384075e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3071082988753915
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 99.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.2788795051164925
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 98.33
   Final Test: 70.10
Split: 01, Run: 03
None time:  1.7057323169428855
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 99.17
   Final Test: 69.80
run time now: 6.354271173477173
total time:  6.410979292821139
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.50
  Final Train: 98.89 ± 0.48
   Final Test: 69.73 ± 0.40
[I 2023-06-12 00:36:39,292] Trial 986 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.07907936107553012, 'K': 5, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 1.0125831976715682, 'loop': 0, 'loss': 'CE', 'lr': 0.0017847958919516387, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.1732495363384075e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0013245956431781976
weight_decay:  1.4143424881286666e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9472123940940946
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.311143257888034
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.70%
Split: 01, Run: 03
None time:  4.3585867988877
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 8.666240453720093
total time:  8.71551503194496
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.25
[I 2023-06-12 00:36:48,572] Trial 987 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.05530173906790078, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 8.645180974723292, 'loop': 0, 'loss': 'CE', 'lr': 0.0013245956431781976, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.4143424881286666e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0007163232668335622
weight_decay:  1.737370375698855e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1565782639663666
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.1909939341712743
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 70.20%
Split: 01, Run: 03
None time:  4.235221709124744
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 8.63007116317749
total time:  8.678038956131786
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.73 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.49
[I 2023-06-12 00:36:57,897] Trial 988 finished with value: 70.73332977294922 and parameters: {'Fwd': 0.05619383507869005, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.907880606975084, 'loop': 0, 'loss': 'CE', 'lr': 0.0007163232668335622, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.737370375698855e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.0026405886650723563
weight_decay:  1.2646748234907484e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3961636119056493
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  2.170830895192921
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  1.8103610239923
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.10
run time now: 6.432243585586548
total time:  6.482688358053565
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.42
[I 2023-06-12 00:37:04,952] Trial 989 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.08404398783024139, 'K': 7, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 9.008427290462814, 'loop': 0, 'loss': 'CE', 'lr': 0.0026405886650723563, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.2646748234907484e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.0013755723348319645
weight_decay:  3.189228892619449e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2181256299372762
None Run 01:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 57.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 54.40% Test: 54.90%
Split: 01, Run: 02
None time:  2.797524868976325
None Run 02:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 54.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.00% Test: 59.90%
Split: 01, Run: 03
None time:  3.202779500046745
None Run 03:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.50
run time now: 7.281564235687256
total time:  7.339244821108878
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.80 ± 3.30
  Final Train: 100.00 ± 0.00
   Final Test: 57.13 ± 2.30
[I 2023-06-12 00:37:12,817] Trial 990 finished with value: 57.79999923706055 and parameters: {'Fwd': 0.06416519674129545, 'K': 7, 'alpha': 0.65, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 8.63915947263531, 'loop': 0, 'loss': 'CE', 'lr': 0.0013755723348319645, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.189228892619449e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.001637336410087407
weight_decay:  1.9696984859091538e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2166781208943576
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.112959017045796
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.196459253085777
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.57466721534729
total time:  6.62971339491196
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.38
[I 2023-06-12 00:37:20,106] Trial 991 finished with value: 71.66667175292969 and parameters: {'Fwd': 0.04510169433638514, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 8.62153307185254, 'loop': 0, 'loss': 'CE', 'lr': 0.001637336410087407, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.9696984859091538e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.75
lr:  0.001222770421703696
weight_decay:  1.8153271744855474e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9798660448286682
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.80% Test: 67.70%
Split: 01, Run: 02
None time:  4.3868429670110345
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  2.169934483943507
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 8.586166143417358
total time:  8.637311462080106
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 1.14
[I 2023-06-12 00:37:29,333] Trial 992 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.05122284209748394, 'K': 7, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 9.062684105613233, 'loop': 0, 'loss': 'CE', 'lr': 0.001222770421703696, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.8153271744855474e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0014542123500861576
weight_decay:  1.3406736679140417e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.44142490811646
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.3505874851252884
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.3787648531142622
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.30
run time now: 7.214737415313721
total time:  7.280016459990293
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.25
[I 2023-06-12 00:37:37,324] Trial 993 finished with value: 71.33333587646484 and parameters: {'Fwd': 0.039248820953198385, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 8.901801039540096, 'loop': 1, 'loss': 'CE', 'lr': 0.0014542123500861576, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3406736679140417e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.0004967507941217337
weight_decay:  1.0847714610983794e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.218694657087326
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 69.80%
Split: 01, Run: 02
None time:  4.520303298020735
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 70.20%
Split: 01, Run: 03
None time:  4.255582204787061
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.80
run time now: 11.04742431640625
total time:  11.099345358088613
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.12
[I 2023-06-12 00:37:49,041] Trial 994 finished with value: 70.0666732788086 and parameters: {'Fwd': 0.07176564101684667, 'K': 7, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.693043589183265, 'loop': 0, 'loss': 'CE', 'lr': 0.0004967507941217337, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0847714610983794e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.0044353632783734375
weight_decay:  3.27573803056256e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0781390708871186
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.35783415986225
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 69.60%
Split: 01, Run: 03
None time:  4.094789596972987
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 8.590874195098877
total time:  8.642645940883085
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.15
[I 2023-06-12 00:37:58,284] Trial 995 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.05770602851113415, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.480197598385034, 'loop': 0, 'loss': 'CE', 'lr': 0.0044353632783734375, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.27573803056256e-06, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0013369480744071466
weight_decay:  2.2034727238439353e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2712037668097764
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.9511672609951347
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.3192427449394017
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.611367702484131
total time:  6.669901438057423
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.20
[I 2023-06-12 00:38:05,626] Trial 996 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.04377591837943849, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.516544362297205, 'loop': 0, 'loss': 'CE', 'lr': 0.0013369480744071466, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2034727238439353e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0008565475578756009
weight_decay:  1.5368266759659815e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.36790304700844
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.501214158954099
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.4577978120651096
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 7.3751444816589355
total time:  7.433992502046749
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.30
[I 2023-06-12 00:38:13,674] Trial 997 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.035060150189265935, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 8.5320031657218, 'loop': 2, 'loss': 'CE', 'lr': 0.0008565475578756009, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.5368266759659815e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0009559457102741715
weight_decay:  2.2983139941344595e-06
dropout:  0.0
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.073233034927398
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  2.041281197918579
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 69.80%
Split: 01, Run: 03
None time:  4.670441085938364
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 8.836143255233765
total time:  8.885301280999556
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.20 ± 0.56
[I 2023-06-12 00:38:23,192] Trial 998 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.09988734238867343, 'K': 7, 'alpha': 0.5, 'dropout': 0.0, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.343729005279146, 'loop': 0, 'loss': 'CE', 'lr': 0.0009559457102741715, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.2983139941344595e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0010510013281374157
weight_decay:  2.215515620034163e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.819727601017803
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 02
None time:  1.869905186118558
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  1.9930153999011964
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.00
run time now: 5.727388143539429
total time:  5.775744430022314
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 68.53 ± 0.64
[I 2023-06-12 00:38:29,757] Trial 999 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.04240000959737091, 'K': 7, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 8.161745257162943, 'loop': 0, 'loss': 'CE', 'lr': 0.0010510013281374157, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.215515620034163e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.0033404975046882274
weight_decay:  2.62305243336085e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.146901862928644
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.1081967558711767
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 03
None time:  2.216831608908251
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.20
run time now: 6.523785591125488
total time:  6.5923948308918625
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.66
[I 2023-06-12 00:38:37,090] Trial 1000 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.032497611863797606, 'K': 7, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.686730749764116, 'loop': 0, 'loss': 'CE', 'lr': 0.0033404975046882274, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.62305243336085e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.003056673410730043
weight_decay:  1.974619208360614e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.80% Test: 68.10%
Split: 01, Run: 01
None time:  4.309454023139551
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.60% Test: 68.50%
Split: 01, Run: 02
None time:  3.9385805539786816
None Run 02:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03
None time:  2.3712783730588853
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 67.80
run time now: 10.676862716674805
total time:  10.744904737919569
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 68.13 ± 0.35
[I 2023-06-12 00:38:48,548] Trial 1001 finished with value: 66.46666717529297 and parameters: {'Fwd': 0.04437496746756937, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 8.173208192368218, 'loop': 0, 'loss': 'MSE', 'lr': 0.003056673410730043, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.974619208360614e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0003053412257400882
weight_decay:  4.853729095201757e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.096082960953936
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.462679612915963
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 70.00%
Split: 01, Run: 03
None time:  4.0943639520555735
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 8.708902835845947
total time:  8.76136093121022
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.25
[I 2023-06-12 00:38:58,211] Trial 1002 finished with value: 69.79999542236328 and parameters: {'Fwd': 0.025763824829552646, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.886851488413795, 'loop': 0, 'loss': 'CE', 'lr': 0.0003053412257400882, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.853729095201757e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.0007786100289156516
weight_decay:  1.6090034275611278e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.363002970814705
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.7142621779348701
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.20% Test: 70.10%
Split: 01, Run: 03
None time:  4.285171256866306
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.40
run time now: 8.413457870483398
total time:  8.471827948000282
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.50
[I 2023-06-12 00:39:07,354] Trial 1003 finished with value: 70.86666870117188 and parameters: {'Fwd': 0.05220547641989688, 'K': 7, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.560444056555362, 'loop': 0, 'loss': 'CE', 'lr': 0.0007786100289156516, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.6090034275611278e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.002372420005908118
weight_decay:  1.3814327014923787e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.304529287153855
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  1.9963377029635012
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.1818866031244397
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.30
run time now: 6.530606985092163
total time:  6.576997119933367
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.40
[I 2023-06-12 00:39:14,579] Trial 1004 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.07094742169878987, 'K': 7, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.503743443631738, 'loop': 0, 'loss': 'CE', 'lr': 0.002372420005908118, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3814327014923787e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0036987292812365323
weight_decay:  2.491220646186359e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2603149639908224
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.2981235389597714
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  2.3015086541417986
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
run time now: 6.911305665969849
total time:  6.976873780135065
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.23
[I 2023-06-12 00:39:22,170] Trial 1005 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.0420684996767093, 'K': 7, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.774263818019548, 'loop': 0, 'loss': 'CE', 'lr': 0.0036987292812365323, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.491220646186359e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.4
lr:  0.0027457972373920816
weight_decay:  1.3006351537576543e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1268357508815825
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.1603300608694553
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.70
Split: 01, Run: 03
None time:  1.7770067271776497
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.70
run time now: 6.113117694854736
total time:  6.166865736013278
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.68
[I 2023-06-12 00:39:29,059] Trial 1006 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.03359383236169476, 'K': 6, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 8.322782437636825, 'loop': 0, 'loss': 'CE', 'lr': 0.0027457972373920816, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.3006351537576543e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.45
lr:  0.00017905172644526798
weight_decay:  1.0318411347499161e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5013353840913624
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 69.80%
Split: 01, Run: 02
None time:  4.529539251932874
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.20% Test: 70.40%
Split: 01, Run: 03
None time:  4.128291970817372
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 11.213517427444458
total time:  11.26164736202918
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.27 ± 1.57
[I 2023-06-12 00:39:40,865] Trial 1007 finished with value: 68.46666717529297 and parameters: {'Fwd': 0.05835627921369501, 'K': 7, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 8.173066456934569, 'loop': 0, 'loss': 'CE', 'lr': 0.00017905172644526798, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0318411347499161e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0011550771845353699
weight_decay:  4.279137943802127e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1145848219748586
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.3335272748954594
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 70.70%
Split: 01, Run: 03
None time:  4.2900242761243135
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
run time now: 8.790764808654785
total time:  8.842476126970723
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.35
[I 2023-06-12 00:39:50,292] Trial 1008 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.04865288241455925, 'K': 7, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 8.635582811957494, 'loop': 0, 'loss': 'CE', 'lr': 0.0011550771845353699, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.279137943802127e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.0012748371392955983
weight_decay:  1.475385880043957e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3353305589407682
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.60% Test: 60.00%
Split: 01, Run: 02
None time:  2.319643528899178
None Run 02:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 60.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.80% Test: 51.00%
Split: 01, Run: 03
None time:  2.8115877718664706
None Run 03:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 51.10
run time now: 6.515272617340088
total time:  6.567859517177567
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.40 ± 7.26
  Final Train: 100.00 ± 0.00
   Final Test: 52.43 ± 7.00
[I 2023-06-12 00:39:57,472] Trial 1009 finished with value: 52.39999771118164 and parameters: {'Fwd': 0.07583162725436127, 'K': 7, 'alpha': 0.5, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.799463837906044, 'loop': 0, 'loss': 'CE', 'lr': 0.0012748371392955983, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.475385880043957e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0009590446190652561
weight_decay:  2.759042277426388e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.967034569941461
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.2047297300305218
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  1.7847983189858496
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 6.006093502044678
total time:  6.064927340019494
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 1.44
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 1.41
[I 2023-06-12 00:40:04,210] Trial 1010 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.03750089350437198, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 1.421243993440017, 'loop': 0, 'loss': 'CE', 'lr': 0.0009590446190652561, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.759042277426388e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0011417748767798752
weight_decay:  1.953646723851278e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.251652013976127
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.56023512291722
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 97.50%, Valid: 71.80% Test: 70.50%
Split: 01, Run: 03
None time:  4.556668949080631
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 97.50
   Final Test: 70.40
run time now: 8.419153213500977
total time:  8.48342130286619
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.70
  Final Train: 99.17 ± 1.44
   Final Test: 69.83 ± 0.49
[I 2023-06-12 00:40:13,405] Trial 1011 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.027269510724197817, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 1.2771214730820288, 'loop': 0, 'loss': 'CE', 'lr': 0.0011417748767798752, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.953646723851278e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.0013341510309977924
weight_decay:  4.85407129408213e-06
dropout:  0.1
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.045203856192529
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.230440974002704
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  2.063990157097578
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
run time now: 6.3885767459869385
total time:  6.449946602107957
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.20
[I 2023-06-12 00:40:20,505] Trial 1012 finished with value: 71.26666259765625 and parameters: {'Fwd': 0.06313818826812742, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.1, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.679246534894252, 'loop': 0, 'loss': 'CE', 'lr': 0.0013341510309977924, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.85407129408213e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.00039963108206133224
weight_decay:  6.691757951206801e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9941900328267366
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.294656236888841
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.39827723801136
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.60
run time now: 6.743562698364258
total time:  6.806412499863654
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.12
[I 2023-06-12 00:40:27,945] Trial 1013 finished with value: 70.0 and parameters: {'Fwd': 0.04571444092734824, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 4.317652656943729, 'loop': 0, 'loss': 'CE', 'lr': 0.00039963108206133224, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.691757951206801e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0012163204212409368
weight_decay:  0.01094782186946059
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0637468909844756
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.185624994104728
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.3680376030970365
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.6677868366241455
total time:  6.715221208985895
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.53
[I 2023-06-12 00:40:35,208] Trial 1014 finished with value: 72.0 and parameters: {'Fwd': 0.03506092980457554, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.8319433971041974, 'loop': 0, 'loss': 'CE', 'lr': 0.0012163204212409368, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.01094782186946059, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.001079707817618198
weight_decay:  0.0002946520779893403
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.137735428987071
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.0918460059911013
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.40%
Split: 01, Run: 03
None time:  4.441230460070074
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 8.720358610153198
total time:  8.780104520032182
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.53
[I 2023-06-12 00:40:44,592] Trial 1015 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.031685840645233936, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.7492587363840926, 'loop': 0, 'loss': 'CE', 'lr': 0.001079707817618198, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002946520779893403, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0011769368504437406
weight_decay:  0.04195867661112645
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2898317801300436
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.1779873750638217
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 70.30%
Split: 01, Run: 03
None time:  4.590109752025455
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 9.109890460968018
total time:  9.167276776162907
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.56
[I 2023-06-12 00:40:54,406] Trial 1016 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.021852383154132477, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.852634367811612, 'loop': 0, 'loss': 'CE', 'lr': 0.0011769368504437406, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.04195867661112645, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.001439512979562335
weight_decay:  0.00021874995241021812
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.027714060153812
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.27724735904485
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.102109660860151
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.455788612365723
total time:  6.503020718926564
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.23
[I 2023-06-12 00:41:01,511] Trial 1017 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.035180103704550186, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.6647206716780056, 'loop': 0, 'loss': 'CE', 'lr': 0.001439512979562335, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00021874995241021812, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0019047631078761553
weight_decay:  2.8644395472117007e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.218925468157977
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.0959841751027852
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.1237144670449197
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 6.488117218017578
total time:  6.540428902953863
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.29
[I 2023-06-12 00:41:08,686] Trial 1018 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.022659630813190546, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 4.095654428969613, 'loop': 0, 'loss': 'CE', 'lr': 0.0019047631078761553, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.8644395472117007e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0009106662854245814
weight_decay:  3.7064228904970068e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9192636269144714
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.984998333035037
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 03
None time:  2.2098061819560826
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.164895534515381
total time:  6.226894684135914
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 68.90 ± 1.25
[I 2023-06-12 00:41:15,633] Trial 1019 finished with value: 70.0 and parameters: {'Fwd': 0.029692451327384087, 'K': 7, 'alpha': 0.9, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 3.983408345590385, 'loop': 0, 'loss': 'CE', 'lr': 0.0009106662854245814, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.7064228904970068e-06, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0003566458893256721
weight_decay:  0.0037323988802709794
dropout:  0.2
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.051110206870362
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.201950180111453
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  2.717170058982447
None Run 03:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 7.0219035148620605
total time:  7.071937608066946
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 0.20
[I 2023-06-12 00:41:23,286] Trial 1020 finished with value: 70.06666564941406 and parameters: {'Fwd': 0.0403645273942048, 'K': 7, 'alpha': 0.9, 'dropout': 0.2, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 4.039508524060734, 'loop': 0, 'loss': 'CE', 'lr': 0.0003566458893256721, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0037323988802709794, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0012915631618024457
weight_decay:  0.0560636729241918
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.24257468781434
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.286741974996403
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.30%
Split: 01, Run: 03
None time:  4.25831162603572
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
run time now: 8.841309547424316
total time:  8.89523169095628
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.35
[I 2023-06-12 00:41:32,830] Trial 1021 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.02573228563477568, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.3165110307071077, 'loop': 0, 'loss': 'MSE', 'lr': 0.0012915631618024457, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0560636729241918, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0037968132560831946
weight_decay:  0.007773216644524993
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1554278468247503
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.9696456061210483
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  1.8426292960066348
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.015552997589111
total time:  6.065309153171256
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.20 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 69.30 ± 0.87
[I 2023-06-12 00:41:39,603] Trial 1022 finished with value: 71.20000457763672 and parameters: {'Fwd': 0.048097490211981564, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 3.6521631957785785, 'loop': 0, 'loss': 'CE', 'lr': 0.0037968132560831946, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.007773216644524993, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0015604832602817812
weight_decay:  0.00019134989517005126
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.286308193113655
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.8905361769720912
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.4039216660894454
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.637475252151489
total time:  6.6842099039349705
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.10
[I 2023-06-12 00:41:46,871] Trial 1023 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.03699743619170086, 'K': 7, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.891458963839319, 'loop': 0, 'loss': 'CE', 'lr': 0.0015604832602817812, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00019134989517005126, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0010149786437867322
weight_decay:  0.03662422218874955
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9386899939272553
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.2509451650548726
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.167221975978464
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.4052183628082275
total time:  6.466110951034352
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.32
[I 2023-06-12 00:41:54,085] Trial 1024 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.01862892666277566, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 6.235694616625802, 'loop': 0, 'loss': 'CE', 'lr': 0.0010149786437867322, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.03662422218874955, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.00021129553397862734
weight_decay:  0.029228748977584953
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.146482646930963
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 02
None time:  1.8672064528800547
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.40% Test: 68.00%
Split: 01, Run: 03
None time:  3.9183559680823237
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.20
run time now: 7.980039596557617
total time:  8.036641171202064
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.00 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 67.83 ± 0.47
[I 2023-06-12 00:42:02,833] Trial 1025 finished with value: 68.0 and parameters: {'Fwd': 0.053506091655357656, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 9.150210400807413, 'loop': 0, 'loss': 'CE', 'lr': 0.00021129553397862734, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.029228748977584953, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.00015087268366020665
weight_decay:  0.03742259072022218
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.239583272021264
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.20% Test: 69.10%
Split: 01, Run: 02
None time:  4.316020034020767
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.40% Test: 70.00%
Split: 01, Run: 03
None time:  4.088460267987102
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 10.689067363739014
total time:  10.74727934692055
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 68.47 ± 1.25
[I 2023-06-12 00:42:14,209] Trial 1026 finished with value: 67.73332977294922 and parameters: {'Fwd': 0.06908939402830755, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 8.107168879258317, 'loop': 0, 'loss': 'CE', 'lr': 0.00015087268366020665, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.03742259072022218, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.001200764572521559
weight_decay:  0.009981108812460667
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3136533540673554
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.136069542961195
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  2.2831253020558506
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.779356956481934
total time:  6.826223518932238
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.64
[I 2023-06-12 00:42:21,628] Trial 1027 finished with value: 71.60000610351562 and parameters: {'Fwd': 0.03093577747837043, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 4.176407373618063, 'loop': 0, 'loss': 'CE', 'lr': 0.001200764572521559, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.009981108812460667, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0013722903186754655
weight_decay:  0.043356614387159514
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0907086909282953
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  2.313200285192579
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.70%
Split: 01, Run: 03
None time:  4.238310311920941
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 8.693113803863525
total time:  8.755933796055615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.90
[I 2023-06-12 00:42:31,049] Trial 1028 finished with value: 71.26667022705078 and parameters: {'Fwd': 0.08103058267670124, 'K': 7, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 6.310510773246125, 'loop': 0, 'loss': 'CE', 'lr': 0.0013722903186754655, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.043356614387159514, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.001692289005896306
weight_decay:  0.0043672484516214215
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3680432250257581
None Run 01:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 95.00
   Final Test: 49.20
Split: 01, Run: 02
None time:  1.3829529448412359
None Run 02:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 99.17
   Final Test: 56.90
Split: 01, Run: 03
None time:  1.500208401819691
None Run 03:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 59.70
run time now: 4.312942028045654
total time:  4.358376934891567
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.13 ± 5.49
  Final Train: 98.06 ± 2.68
   Final Test: 55.27 ± 5.44
[I 2023-06-12 00:42:36,122] Trial 1029 finished with value: 56.133331298828125 and parameters: {'Fwd': 0.04272520680856823, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.556062282011767, 'loop': 1, 'loss': 'CE', 'lr': 0.001692289005896306, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0043672484516214215, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0014570950671864008
weight_decay:  0.058211685467444985
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.939961165888235
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.128602006006986
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.70%
Split: 01, Run: 03
None time:  4.054767485940829
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 8.172638893127441
total time:  8.219776540063322
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 70.13 ± 0.58
[I 2023-06-12 00:42:44,936] Trial 1030 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.024686165973477323, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.8, 'lambda2': 3.237190569403733, 'loop': 0, 'loss': 'CE', 'lr': 0.0014570950671864008, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.058211685467444985, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.00012463231376703501
weight_decay:  0.029259719916784475
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.60% Test: 67.50%
Split: 01, Run: 01
None time:  4.558153057005256
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.20% Test: 68.10%
Split: 01, Run: 02
None time:  4.213996408041567
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.90
Split: 01, Run: 03
None time:  2.186521272175014
None Run 03:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 69.20
run time now: 11.01229190826416
total time:  11.069693074095994
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 67.93 ± 1.25
[I 2023-06-12 00:42:56,740] Trial 1031 finished with value: 67.26666259765625 and parameters: {'Fwd': 0.09884187330055437, 'K': 7, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 3.511631166166549, 'loop': 0, 'loss': 'CE', 'lr': 0.00012463231376703501, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.029259719916784475, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0012526239532912006
weight_decay:  0.014845565577186836
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9635985079221427
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.3686478917952627
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.60%
Split: 01, Run: 03
None time:  4.488839918049052
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 8.87015438079834
total time:  8.92675533494912
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.55
[I 2023-06-12 00:43:06,324] Trial 1032 finished with value: 72.0 and parameters: {'Fwd': 0.05685238388224464, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.326357514561439, 'loop': 0, 'loss': 'CE', 'lr': 0.0012526239532912006, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.014845565577186836, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0011123786127552474
weight_decay:  0.00020904425729660438
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.026939770905301
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.372330332873389
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 70.40%
Split: 01, Run: 03
None time:  4.269975994946435
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 8.718252182006836
total time:  8.766186333959922
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.46
[I 2023-06-12 00:43:15,710] Trial 1033 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.03596256660979478, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.371744855826936, 'loop': 0, 'loss': 'CE', 'lr': 0.0011123786127552474, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00020904425729660438, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0023668732760260226
weight_decay:  0.01967281808699861
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0157811800017953
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  2.13375869509764
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.345650180010125
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.10
run time now: 6.547224998474121
total time:  6.604872661875561
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.57
[I 2023-06-12 00:43:22,899] Trial 1034 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.06085302496351165, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.229435275296321, 'loop': 0, 'loss': 'CE', 'lr': 0.0023668732760260226, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.01967281808699861, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0012400770184230968
weight_decay:  0.01707643723708455
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7504344061017036
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.461410511052236
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  1.9210840370506048
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 6.185816287994385
total time:  6.240280709927902
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 1.51
[I 2023-06-12 00:43:29,763] Trial 1035 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.05054941155954243, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 8.511596920162297, 'loop': 0, 'loss': 'CE', 'lr': 0.0012400770184230968, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.01707643723708455, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0013611431337196285
weight_decay:  8.248723151544305e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2849466509651393
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.064002698054537
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.0209343030583113
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.41712212562561
total time:  6.46653157309629
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.12
[I 2023-06-12 00:43:36,868] Trial 1036 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.04197634088299746, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.478402785931436, 'loop': 0, 'loss': 'CE', 'lr': 0.0013611431337196285, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.248723151544305e-05, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0013688094539313117
weight_decay:  0.01053318661072627
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1034157590474933
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.154881240101531
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  2.1410701090935618
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.447561740875244
total time:  6.506852580001578
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.31
[I 2023-06-12 00:43:44,033] Trial 1037 finished with value: 72.0 and parameters: {'Fwd': 0.07918834404826285, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.50917813046485, 'loop': 0, 'loss': 'CE', 'lr': 0.0013688094539313117, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01053318661072627, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.001317072782401386
weight_decay:  0.011132765686795536
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3763408539816737
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.1202934170141816
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.50%
Split: 01, Run: 03
None time:  4.601862884126604
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 9.155137538909912
total time:  9.203867906937376
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.36
[I 2023-06-12 00:43:53,872] Trial 1038 finished with value: 72.0 and parameters: {'Fwd': 0.08207879680046648, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.511906066634557, 'loop': 0, 'loss': 'CE', 'lr': 0.001317072782401386, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.011132765686795536, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0013680591630467016
weight_decay:  0.014080821877144574
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.708893776172772
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.37401480297558
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  2.2399247519206256
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.375474214553833
total time:  6.426267812028527
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.38
[I 2023-06-12 00:44:01,155] Trial 1039 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.09042132091773913, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.456752855119884, 'loop': 0, 'loss': 'CE', 'lr': 0.0013680591630467016, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.014080821877144574, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0013120198873320663
weight_decay:  0.01370127802195599
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0937020080164075
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.3357783569954336
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  1.4813527690712363
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.40
run time now: 3.959958553314209
total time:  4.01535780611448
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 68.80 ± 0.36
[I 2023-06-12 00:44:05,852] Trial 1040 finished with value: 70.00000762939453 and parameters: {'Fwd': 0.08243059188032299, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 8.759842260813155, 'loop': 0, 'loss': 'CE', 'lr': 0.0013120198873320663, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01370127802195599, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.001348384683891588
weight_decay:  0.013536585112376215
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0736355038825423
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.3783208201639354
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.9910286960657686
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.489572525024414
total time:  6.547179348999634
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.42
[I 2023-06-12 00:44:13,060] Trial 1041 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.08030499289949687, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.364793604530513, 'loop': 0, 'loss': 'CE', 'lr': 0.001348384683891588, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.013536585112376215, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0014466494826598552
weight_decay:  0.011373890971217542
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0637859869748354
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.247927414951846
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 03
None time:  0.848194238031283
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 3.213070869445801
total time:  3.2651623620186
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 1.91
  Final Train: 100.00 ± 0.00
   Final Test: 68.57 ± 2.10
[I 2023-06-12 00:44:16,928] Trial 1042 finished with value: 69.60000610351562 and parameters: {'Fwd': 0.09853754621312981, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 0.9500000000000001, 'lambda2': 8.330873105182535, 'loop': 0, 'loss': 'CE', 'lr': 0.0014466494826598552, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.011373890971217542, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.001231248565462034
weight_decay:  0.010725317521228144
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3519006380811334
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.2907469698693603
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.9565758609678596
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.6485595703125
total time:  6.702250443166122
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.45
[I 2023-06-12 00:44:24,372] Trial 1043 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.06072322710220816, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.127863267776478, 'loop': 0, 'loss': 'CE', 'lr': 0.001231248565462034, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.010725317521228144, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.001463464962857982
weight_decay:  0.006716273547057661
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.60%
Split: 01, Run: 01
None time:  4.171381370164454
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 69.60%
Split: 01, Run: 02
None time:  3.851664896821603
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 69.60%
Split: 01, Run: 03
None time:  4.3570010389667
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.60
run time now: 12.443943500518799
total time:  12.512495424132794
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.00
[I 2023-06-12 00:44:37,472] Trial 1044 finished with value: 69.5999984741211 and parameters: {'Fwd': 0.06131083534143947, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.314267789205546, 'loop': 0, 'loss': 'MSE', 'lr': 0.001463464962857982, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.006716273547057661, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0002981221065655592
weight_decay:  0.02393166328366522
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.086367170792073
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  2.1819152859970927
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.447835362982005
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 6.765672922134399
total time:  6.8156681440304965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.80
[I 2023-06-12 00:44:44,872] Trial 1045 finished with value: 69.86666870117188 and parameters: {'Fwd': 0.0726043992276043, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.539504543414388, 'loop': 0, 'loss': 'CE', 'lr': 0.0002981221065655592, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.02393166328366522, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0011846714253043033
weight_decay:  0.01803892064589151
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9249410489574075
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  2.144834698177874
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  2.0433475968893617
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.80
run time now: 6.164880990982056
total time:  6.2190598889719695
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 1.55
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 1.01
[I 2023-06-12 00:44:51,686] Trial 1046 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.07287592892064702, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 8.667061342401656, 'loop': 0, 'loss': 'CE', 'lr': 0.0011846714253043033, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01803892064589151, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0013614655584897818
weight_decay:  0.007818369691035255
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0851595369167626
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.149892807006836
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  2.409929463872686
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.7092413902282715
total time:  6.765625039115548
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.32
[I 2023-06-12 00:44:59,088] Trial 1047 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.08480613784229911, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 8.383401445281093, 'loop': 0, 'loss': 'CE', 'lr': 0.0013614655584897818, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.007818369691035255, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0012867825105256814
weight_decay:  0.006426361236393421
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1572857471182942
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.2304730019532144
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.4694762260187417
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.901763439178467
total time:  6.959977544145659
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.35
[I 2023-06-12 00:45:06,611] Trial 1048 finished with value: 72.0 and parameters: {'Fwd': 0.06628526720787409, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.110811361156108, 'loop': 0, 'loss': 'CE', 'lr': 0.0012867825105256814, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.006426361236393421, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0015059972003602037
weight_decay:  0.013988812695928056
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.202126479940489
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.22878379910253
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.386231879936531
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.870098829269409
total time:  6.9173855681438
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.35
[I 2023-06-12 00:45:14,110] Trial 1049 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.04965635881934057, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 8.702573600721623, 'loop': 0, 'loss': 'CE', 'lr': 0.0015059972003602037, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.013988812695928056, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.0005094620292501389
weight_decay:  0.009118017229238346
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2310382530558854
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.9958715860266238
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.1478520471137017
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 6.425124406814575
total time:  6.480638320092112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.15
[I 2023-06-12 00:45:21,276] Trial 1050 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.056441142537852616, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.33701572333394, 'loop': 0, 'loss': 'CE', 'lr': 0.0005094620292501389, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.009118017229238346, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.001189352199522701
weight_decay:  0.011022420157194337
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1080392880830914
None Run 01:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 52.50
Split: 01, Run: 02
None time:  1.2460405139718205
None Run 02:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 99.17
   Final Test: 62.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 65.60% Test: 66.10%
Split: 01, Run: 03
None time:  2.806385272881016
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 99.17
   Final Test: 66.10
run time now: 5.2113282680511475
total time:  5.258760441094637
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.80 ± 8.53
  Final Train: 99.44 ± 0.48
   Final Test: 60.47 ± 7.09
[I 2023-06-12 00:45:27,159] Trial 1051 finished with value: 59.79999923706055 and parameters: {'Fwd': 0.07425080359395368, 'K': 7, 'alpha': 0.8, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 2.7336247813382593, 'loop': 0, 'loss': 'CE', 'lr': 0.001189352199522701, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.011022420157194337, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.00010288304487456824
weight_decay:  0.008873093731771774
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.60% Test: 66.30%
Split: 01, Run: 01
None time:  4.01370638795197
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.60% Test: 67.20%
Split: 01, Run: 02
None time:  4.503173856996
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.60% Test: 68.60%
Split: 01, Run: 03
None time:  4.302855657879263
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 68.70
run time now: 12.867149591445923
total time:  12.924221167108044
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.93 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 67.10 ± 1.60
[I 2023-06-12 00:45:40,643] Trial 1052 finished with value: 65.9333267211914 and parameters: {'Fwd': 0.046047386494344, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.022919931116673, 'loop': 0, 'loss': 'CE', 'lr': 0.00010288304487456824, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.008873093731771774, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0013804097673048388
weight_decay:  0.011684778310469393
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9771209680475295
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.270430776057765
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.300036232918501
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.597612380981445
total time:  6.647960867965594
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.29
[I 2023-06-12 00:45:47,865] Trial 1053 finished with value: 72.0 and parameters: {'Fwd': 0.06478067236984104, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.82103289339012, 'loop': 0, 'loss': 'CE', 'lr': 0.0013804097673048388, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.011684778310469393, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0012719909914664098
weight_decay:  0.010707311117986777
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1047083409503102
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.3614123770967126
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 71.10%
Split: 01, Run: 03
None time:  4.287018369883299
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.30
run time now: 8.799611568450928
total time:  8.84947398188524
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 1.00
[I 2023-06-12 00:45:57,400] Trial 1054 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.044713075308303415, 'K': 7, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.54156249974562, 'loop': 0, 'loss': 'CE', 'lr': 0.0012719909914664098, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.010707311117986777, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0010965048235979703
weight_decay:  0.01302523889648933
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6863994589075446
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.677354563958943
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  1.6291654009837657
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.90
run time now: 5.038548946380615
total time:  5.089127449085936
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.56
[I 2023-06-12 00:46:03,247] Trial 1055 finished with value: 71.0 and parameters: {'Fwd': 0.0926604135567566, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 8.459762378668083, 'loop': 0, 'loss': 'CE', 'lr': 0.0010965048235979703, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01302523889648933, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0014977232191843196
weight_decay:  0.0270050104139622
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.269476335030049
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.3593970187939703
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 71.00%
Split: 01, Run: 03
None time:  3.582967221038416
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 8.260982990264893
total time:  8.319623356917873
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.21
[I 2023-06-12 00:46:12,264] Trial 1056 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.05367129948983401, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.236851934772194, 'loop': 0, 'loss': 'CE', 'lr': 0.0014977232191843196, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0270050104139622, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.0013661921922564436
weight_decay:  0.01631227202745221
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0828941939398646
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.9901997530832887
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  1.9766685639042407
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.0976243019104
total time:  6.149735857965425
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.47 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 69.43 ± 1.07
[I 2023-06-12 00:46:18,980] Trial 1057 finished with value: 70.46666717529297 and parameters: {'Fwd': 0.07094287683973305, 'K': 6, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 8.851250288871464, 'loop': 0, 'loss': 'CE', 'lr': 0.0013661921922564436, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01631227202745221, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.001168032954136172
weight_decay:  0.008074350670004286
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.105786909116432
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.1274340611416847
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.70%
Split: 01, Run: 03
None time:  4.446912248851731
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 8.729082584381104
total time:  8.783770354930311
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.61
[I 2023-06-12 00:46:28,525] Trial 1058 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.04231670456208295, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.065437701895393, 'loop': 0, 'loss': 'CE', 'lr': 0.001168032954136172, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.008074350670004286, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.001279568757588049
weight_decay:  0.007289076994401173
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.085532641969621
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.355014153989032
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.70%
Split: 01, Run: 03
None time:  4.318079323042184
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 8.835427284240723
total time:  8.931808038847521
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.66
[I 2023-06-12 00:46:38,210] Trial 1059 finished with value: 72.0 and parameters: {'Fwd': 0.05620927452668546, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.1585659935333856, 'loop': 0, 'loss': 'CE', 'lr': 0.001279568757588049, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.007289076994401173, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0015288303701089746
weight_decay:  0.01204334735336756
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0817532029468566
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.2576237679459155
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.1918967140372843
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.582363605499268
total time:  6.631241930881515
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.26
[I 2023-06-12 00:46:45,500] Trial 1060 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.09904693473266771, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.649087436547262, 'loop': 0, 'loss': 'CE', 'lr': 0.0015288303701089746, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01204334735336756, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.0013847802588752291
weight_decay:  0.016667473803552744
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5270577350165695
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.2077780759427696
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.303446268895641
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
run time now: 4.087137937545776
total time:  4.14524536812678
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.35
[I 2023-06-12 00:46:50,252] Trial 1061 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.039316526409217255, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 8.302934344223228, 'loop': 0, 'loss': 'CE', 'lr': 0.0013847802588752291, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.016667473803552744, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.006698866775555997
weight_decay:  0.0960334563614521
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.80% Test: 67.10%
Split: 01, Run: 01
None time:  3.9143457009922713
None Run 01:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.80% Test: 66.90%
Split: 01, Run: 02
None time:  3.9502700970042497
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 66.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.40% Test: 67.50%
Split: 01, Run: 03
None time:  4.066686576930806
None Run 03:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 67.50
run time now: 11.98405933380127
total time:  12.039867413928732
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 67.17 ± 0.31
[I 2023-06-12 00:47:02,911] Trial 1062 finished with value: 65.33333587646484 and parameters: {'Fwd': 0.06806698731875976, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 8.535665005856927, 'loop': 0, 'loss': 'MSE', 'lr': 0.006698866775555997, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0960334563614521, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0011263496900335282
weight_decay:  0.006479448441485405
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0258227181620896
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.2025730737950653
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.2148795819375664
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.10
run time now: 3.496195077896118
total time:  3.5481589899864048
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 70.37 ± 0.75
[I 2023-06-12 00:47:07,043] Trial 1063 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.052792502052073774, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.9500000000000001, 'lambda2': 3.0973035416494685, 'loop': 0, 'loss': 'CE', 'lr': 0.0011263496900335282, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.006479448441485405, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0012416990677444476
weight_decay:  0.018881549245729524
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.208793933968991
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.4423069360200316
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.962277201935649
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.20
run time now: 6.6581408977508545
total time:  6.71304089599289
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.17 ± 0.96
[I 2023-06-12 00:47:14,600] Trial 1064 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.03512951238590209, 'K': 7, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.034554329530598, 'loop': 0, 'loss': 'CE', 'lr': 0.0012416990677444476, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.018881549245729524, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0010428601102972846
weight_decay:  0.020484682601130632
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.08041188493371
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 70.40%
Split: 01, Run: 02
None time:  4.379230065038428
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 70.20%
Split: 01, Run: 03
None time:  4.378019049065188
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 10.885389804840088
total time:  10.944951956160367
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.87 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.69
[I 2023-06-12 00:47:26,274] Trial 1065 finished with value: 69.86666107177734 and parameters: {'Fwd': 0.07811300806410254, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.05, 'lambda2': 8.831945630594184, 'loop': 0, 'loss': 'CE', 'lr': 0.0010428601102972846, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.020484682601130632, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.000173567133614274
weight_decay:  0.02253162168361901
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.20% Test: 68.40%
Split: 01, Run: 01
None time:  4.708985497010872
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 70.00%
Split: 01, Run: 02
None time:  4.661553543061018
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.20% Test: 70.10%
Split: 01, Run: 03
None time:  4.31935827084817
None Run 03:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 13.745871782302856
total time:  13.805137774907053
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.20 ± 1.48
[I 2023-06-12 00:47:40,828] Trial 1066 finished with value: 68.46666717529297 and parameters: {'Fwd': 0.04599198934606562, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 9.110368972448375, 'loop': 0, 'loss': 'CE', 'lr': 0.000173567133614274, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.02253162168361901, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.35000000000000003
lr:  0.005558562809166577
weight_decay:  0.015759725264107568
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8670395729131997
None Run 01:
Highest Train: 96.67
Highest Valid: 71.00
  Final Train: 89.17
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.6295689011458308
None Run 02:
Highest Train: 96.67
Highest Valid: 71.80
  Final Train: 93.33
   Final Test: 70.40
Split: 01, Run: 03
None time:  0.862409592140466
None Run 03:
Highest Train: 96.67
Highest Valid: 69.60
  Final Train: 92.50
   Final Test: 70.00
run time now: 2.408940553665161
total time:  2.466519898036495
None All runs:
Highest Train: 96.67 ± 0.00
Highest Valid: 70.80 ± 1.11
  Final Train: 91.67 ± 2.20
   Final Test: 69.83 ± 0.67
[I 2023-06-12 00:47:43,996] Trial 1067 finished with value: 70.79999542236328 and parameters: {'Fwd': 0.060037826629893286, 'K': 7, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 30, 'lambda1': 0.9500000000000001, 'lambda2': 0.004379123235622728, 'loop': 0, 'loss': 'CE', 'lr': 0.005558562809166577, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.015759725264107568, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0015407453821975126
weight_decay:  0.05262174418074129
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3818925849627703
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.7228090870194137
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03
None time:  2.5074068210087717
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 7.661275148391724
total time:  7.709685035981238
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.65
[I 2023-06-12 00:47:52,407] Trial 1068 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.09933814888050975, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 8.687191993258265, 'loop': 1, 'loss': 'CE', 'lr': 0.0015407453821975126, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.05262174418074129, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0013815704621883747
weight_decay:  0.00878118861947034
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3198951068334281
None Run 01:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 97.50
   Final Test: 52.70
Split: 01, Run: 02
None time:  1.1462446341756731
None Run 02:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 46.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 97.50%, Valid: 60.60% Test: 62.40%
Split: 01, Run: 03
None time:  2.7902620541863143
None Run 03:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 97.50
   Final Test: 62.10
run time now: 5.301735162734985
total time:  5.36027923412621
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.80 ± 7.69
  Final Train: 98.33 ± 1.44
   Final Test: 53.63 ± 8.04
[I 2023-06-12 00:47:58,383] Trial 1069 finished with value: 51.80000305175781 and parameters: {'Fwd': 0.038271210562452466, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 1.1205803887610535, 'loop': 0, 'loss': 'CE', 'lr': 0.0013815704621883747, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00878118861947034, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.0012144814227339862
weight_decay:  0.022156922952991397
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8837936269119382
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  2.3418629760853946
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  1.8789532561786473
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.156367301940918
total time:  6.2128853420726955
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 1.32
[I 2023-06-12 00:48:05,253] Trial 1070 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.05079592294253225, 'K': 6, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 1.939097668947185, 'loop': 0, 'loss': 'CE', 'lr': 0.0012144814227339862, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.022156922952991397, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0014280732639946126
weight_decay:  0.01632606159960274
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0928617790341377
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.24403297691606
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.1594611320178956
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 6.547428131103516
total time:  6.6063271530438215
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.52
[I 2023-06-12 00:48:12,455] Trial 1071 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.0761209115580883, 'K': 7, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 9.004669245673297, 'loop': 0, 'loss': 'CE', 'lr': 0.0014280732639946126, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.01632606159960274, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.008597635646464876
weight_decay:  0.0030638284038812242
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 70.00% Test: 70.00%
Split: 01, Run: 01
None time:  4.703667843947187
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 99.17
   Final Test: 70.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 69.80% Test: 69.50%
Split: 01, Run: 02
None time:  4.139273946871981
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 99.17
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.5352833420038223
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 99.17
   Final Test: 69.60
run time now: 11.433586835861206
total time:  11.493015764979646
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.07 ± 0.31
  Final Train: 99.17 ± 0.00
   Final Test: 69.77 ± 0.29
[I 2023-06-12 00:48:24,645] Trial 1072 finished with value: 70.0666732788086 and parameters: {'Fwd': 0.03127872984463309, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.414057318086156, 'loop': 0, 'loss': 'CE', 'lr': 0.008597635646464876, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0030638284038812242, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0013011072986472856
weight_decay:  0.013424393752389671
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2551282909698784
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  2.1983017749153078
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.00% Test: 70.50%
Split: 01, Run: 03
None time:  4.503912294050679
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.40
run time now: 9.001179456710815
total time:  9.046694981865585
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.76
[I 2023-06-12 00:48:34,355] Trial 1073 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.06033819983747195, 'K': 7, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.05597892140574, 'loop': 0, 'loss': 'CE', 'lr': 0.0013011072986472856, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.013424393752389671, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0011435254284010168
weight_decay:  0.004057561290027704
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9468369730748236
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.3009080009069294
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 70.60%
Split: 01, Run: 03
None time:  4.229965847218409
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 8.527429580688477
total time:  8.588897901121527
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.64
[I 2023-06-12 00:48:43,624] Trial 1074 finished with value: 71.73333740234375 and parameters: {'Fwd': 0.04468220588583375, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 8.18903753360816, 'loop': 0, 'loss': 'CE', 'lr': 0.0011435254284010168, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.004057561290027704, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.0015824623963815452
weight_decay:  0.0052158102818622085
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1208414791617543
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.7103069790173322
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.205362357199192
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.089910984039307
total time:  6.137321759015322
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.21
[I 2023-06-12 00:48:50,430] Trial 1075 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.0787686560126938, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 7.861932673439001, 'loop': 0, 'loss': 'CE', 'lr': 0.0015824623963815452, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0052158102818622085, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0013708945840416248
weight_decay:  0.053938176812454754
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0609943389426917
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.076079858932644
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.151785426074639
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.3383097648620605
total time:  6.399623767938465
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.21
[I 2023-06-12 00:48:57,634] Trial 1076 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.03826159938009137, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.274728597281836, 'loop': 0, 'loss': 'CE', 'lr': 0.0013708945840416248, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.053938176812454754, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.00028247061856274356
weight_decay:  0.06281928672532466
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1425658678635955
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.6513861289713532
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  2.224036968080327
None Run 03:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 6.06821346282959
total time:  6.125758504960686
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.67 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 68.50 ± 1.22
[I 2023-06-12 00:49:04,385] Trial 1077 finished with value: 68.66666412353516 and parameters: {'Fwd': 0.03291392761123523, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 0.7176295196902336, 'loop': 0, 'loss': 'CE', 'lr': 0.00028247061856274356, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.06281928672532466, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0010415031482237393
weight_decay:  0.034725154455112116
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.929537621093914
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.173605039017275
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.4929360197857022
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.649821519851685
total time:  6.696598818991333
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.26
[I 2023-06-12 00:49:11,629] Trial 1078 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.00032606451340094777, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 8.22122277035356, 'loop': 0, 'loss': 'CE', 'lr': 0.0010415031482237393, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.034725154455112116, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.001238199626616637
weight_decay:  0.08047523305042492
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1604942709673196
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.291565656894818
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  1.941830402938649
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.70
run time now: 6.435301780700684
total time:  6.491303579183295
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.67
[I 2023-06-12 00:49:18,826] Trial 1079 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.03600474878140581, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 7.958970947570498, 'loop': 0, 'loss': 'CE', 'lr': 0.001238199626616637, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.08047523305042492, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0001165938517558557
weight_decay:  0.04138167285681252
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.80% Test: 67.00%
Split: 01, Run: 01
None time:  4.491266808938235
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 66.30
Split: 01, Run: 02
None time:  2.0677447631023824
None Run 02:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.00
Split: 01, Run: 03
None time:  2.198748743860051
None Run 03:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.70
run time now: 8.806638240814209
total time:  8.857392663834617
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.20 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 65.33 ± 1.19
[I 2023-06-12 00:49:28,246] Trial 1080 finished with value: 66.20000457763672 and parameters: {'Fwd': 0.040140310751211654, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 8.257443721713015, 'loop': 0, 'loss': 'CE', 'lr': 0.0001165938517558557, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04138167285681252, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.00011715612486396194
weight_decay:  0.02372267840624945
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.40% Test: 52.80%
Split: 01, Run: 01
None time:  3.9621427450329065
None Run 01:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 52.80
Split: 01, Run: 02
None time:  2.1401737278793007
None Run 02:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 45.60
Split: 01, Run: 03
None time:  2.11708728200756
None Run 03:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 45.60
run time now: 8.27000379562378
total time:  8.32828458189033
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 48.33 ± 2.66
  Final Train: 100.00 ± 0.00
   Final Test: 48.00 ± 4.16
[I 2023-06-12 00:49:37,292] Trial 1081 finished with value: 48.33333206176758 and parameters: {'Fwd': 0.04925589221702706, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 6.089212356343036, 'loop': 0, 'loss': 'MSE', 'lr': 0.00011715612486396194, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.02372267840624945, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0014713463149499308
weight_decay:  0.027590251153594106
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.099744054954499
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  2.085594024974853
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.00% Test: 70.70%
Split: 01, Run: 03
None time:  4.425819894997403
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.50
run time now: 8.662013530731201
total time:  8.710445002885535
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.82
[I 2023-06-12 00:49:46,665] Trial 1082 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.032345965603703244, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 5.927739899490809, 'loop': 0, 'loss': 'CE', 'lr': 0.0014713463149499308, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.027590251153594106, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.001142646320127089
weight_decay:  0.005952461661933374
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.10398010793142
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.361786307999864
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 70.40%
Split: 01, Run: 03
None time:  4.325742264045402
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.30
run time now: 8.839933156967163
total time:  8.897123399190605
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.44
[I 2023-06-12 00:49:56,123] Trial 1083 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.028783294654074074, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.9056211678512405, 'loop': 0, 'loss': 'CE', 'lr': 0.001142646320127089, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.005952461661933374, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0013303290701735862
weight_decay:  0.03637735163531676
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6386159039102495
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.1097749690525234
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.348778496030718
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.145745515823364
total time:  6.2065199399366975
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.35
[I 2023-06-12 00:50:02,988] Trial 1084 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.04242398988653922, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.3379410255888984, 'loop': 0, 'loss': 'CE', 'lr': 0.0013303290701735862, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03637735163531676, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0015825753936531887
weight_decay:  0.04675325983580502
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.13935688091442
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.306225192034617
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.2333570041228086
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.724395513534546
total time:  6.771136855008081
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.26
[I 2023-06-12 00:50:10,469] Trial 1085 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.02555757688034569, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.3885782360511283, 'loop': 0, 'loss': 'CE', 'lr': 0.0015825753936531887, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04675325983580502, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.006701863727336859
weight_decay:  0.07940482029102845
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.4551176661625504
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.83
   Final Test: 70.40
Split: 01, Run: 02
None time:  4.359732139157131
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 91.67
   Final Test: 70.40
Split: 01, Run: 03
None time:  3.142909800168127
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 97.50
   Final Test: 69.50
run time now: 11.00558853149414
total time:  11.065556277986616
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.31
  Final Train: 95.00 ± 3.00
   Final Test: 70.10 ± 0.52
[I 2023-06-12 00:50:22,114] Trial 1086 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.04098279523953134, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.4626934489634333, 'loop': 2, 'loss': 'CE', 'lr': 0.006701863727336859, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07940482029102845, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.001429464065025355
weight_decay:  0.05981510013589089
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.318253403995186
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.1586145299952477
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.0610190520528704
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.5845627784729
total time:  6.635375331155956
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.10
[I 2023-06-12 00:50:29,430] Trial 1087 finished with value: 72.0 and parameters: {'Fwd': 0.03745964492107431, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 9.331544031094989, 'loop': 0, 'loss': 'CE', 'lr': 0.001429464065025355, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.05981510013589089, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0013311608647223064
weight_decay:  0.033956126809971426
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.088309746934101
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.212676069000736
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  2.238216381985694
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.587246656417847
total time:  6.642560724169016
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.36
[I 2023-06-12 00:50:36,714] Trial 1088 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.030296343852825258, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.4286319937109915, 'loop': 0, 'loss': 'CE', 'lr': 0.0013311608647223064, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.033956126809971426, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.001589526369261231
weight_decay:  0.021916953323245343
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.314360945019871
None Run 01:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 97.50
   Final Test: 56.10
Split: 01, Run: 02
None time:  1.1930263000540435
None Run 02:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 98.33
   Final Test: 56.70
Split: 01, Run: 03
None time:  1.4296397760044783
None Run 03:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 97.50
   Final Test: 59.40
run time now: 3.9886481761932373
total time:  4.036820170003921
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 57.47 ± 3.24
  Final Train: 97.78 ± 0.48
   Final Test: 57.40 ± 1.76
[I 2023-06-12 00:50:41,395] Trial 1089 finished with value: 57.4666633605957 and parameters: {'Fwd': 0.02675747061648902, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 3.452410904695652, 'loop': 0, 'loss': 'CE', 'lr': 0.001589526369261231, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.021916953323245343, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0014484801251152767
weight_decay:  0.048824753188257734
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.013000688981265
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.0743437751661986
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.1541938779409975
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.285183429718018
total time:  6.332488551037386
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.20
[I 2023-06-12 00:50:48,354] Trial 1090 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.04311414442923944, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.0890196640516883, 'loop': 0, 'loss': 'CE', 'lr': 0.0014484801251152767, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.048824753188257734, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0013460162537425812
weight_decay:  0.04922261382323678
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.249655791791156
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.3797658579424024
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.4023275470826775
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
run time now: 7.085882902145386
total time:  7.134491707896814
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.35
[I 2023-06-12 00:50:56,097] Trial 1091 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.02886155020764047, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.0445428548655213, 'loop': 0, 'loss': 'CE', 'lr': 0.0013460162537425812, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04922261382323678, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0016222909312616743
weight_decay:  0.03752303527508907
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0572344770189375
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.2727082879282534
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.2742245050612837
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.649298429489136
total time:  6.70108389807865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.21
[I 2023-06-12 00:51:03,511] Trial 1092 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.02044621811626305, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.2242146002853525, 'loop': 0, 'loss': 'CE', 'lr': 0.0016222909312616743, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03752303527508907, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0015347818800005829
weight_decay:  0.05444953770090751
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8868793218862265
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.1883801848161966
None Run 02:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  2.1596536869183183
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.295444488525391
total time:  6.354639792116359
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.61
[I 2023-06-12 00:51:10,583] Trial 1093 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.028545097716394924, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 3.086237811826867, 'loop': 0, 'loss': 'CE', 'lr': 0.0015347818800005829, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.05444953770090751, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0013710244423619402
weight_decay:  0.03644123025951044
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0721138301305473
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.8683863489422947
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.3491092540789396
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.342575788497925
total time:  6.400976649019867
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.31
[I 2023-06-12 00:51:17,574] Trial 1094 finished with value: 72.0 and parameters: {'Fwd': 0.026963603872231255, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.1427486423205684, 'loop': 0, 'loss': 'CE', 'lr': 0.0013710244423619402, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03644123025951044, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.00031721721675195943
weight_decay:  0.04911547469025655
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5719126348849386
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.439526234054938
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 69.80%
Split: 01, Run: 03
None time:  3.989971677074209
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.90
run time now: 8.049713373184204
total time:  8.097119755111635
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 69.50 ± 0.36
[I 2023-06-12 00:51:26,312] Trial 1095 finished with value: 69.79999542236328 and parameters: {'Fwd': 0.023711577540710415, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.9166670060892863, 'loop': 0, 'loss': 'CE', 'lr': 0.00031721721675195943, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04911547469025655, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0013505910942396687
weight_decay:  0.03778566407672888
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3001525059808046
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.9931707081850618
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 71.80% Test: 70.40%
Split: 01, Run: 03
None time:  4.23970770300366
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.50
run time now: 8.589189529418945
total time:  8.643510643858463
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.52
[I 2023-06-12 00:51:35,590] Trial 1096 finished with value: 71.93333435058594 and parameters: {'Fwd': 0.030996525699087462, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.563352152685489, 'loop': 0, 'loss': 'CE', 'lr': 0.0013505910942396687, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03778566407672888, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0016683822078617386
weight_decay:  0.031272857092309155
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.362507657846436
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  2.2614527319092304
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  2.085552959004417
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.760961532592773
total time:  6.824360753176734
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.55
[I 2023-06-12 00:51:43,097] Trial 1097 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.03421931222824542, 'K': 7, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.8932373074517628, 'loop': 0, 'loss': 'CE', 'lr': 0.0016683822078617386, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.031272857092309155, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0007403535388163463
weight_decay:  0.04806028523683862
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1726761288009584
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.7197343760635704
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 03
None time:  2.1694399199914187
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 6.115536212921143
total time:  6.16535577387549
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.13 ± 0.90
[I 2023-06-12 00:51:49,896] Trial 1098 finished with value: 69.93333435058594 and parameters: {'Fwd': 0.02110994237078371, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 3.2945949883807337, 'loop': 0, 'loss': 'CE', 'lr': 0.0007403535388163463, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04806028523683862, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.0014731313639855372
weight_decay:  0.07308395505868417
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.80% Test: 69.70%
Split: 01, Run: 01
None time:  3.6998406001366675
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 69.80%
Split: 01, Run: 02
None time:  3.96201565512456
None Run 02:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.00% Test: 69.70%
Split: 01, Run: 03
None time:  4.116944320965558
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.70
run time now: 11.83178162574768
total time:  11.878128763986751
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.12
[I 2023-06-12 00:52:02,406] Trial 1099 finished with value: 69.5999984741211 and parameters: {'Fwd': 0.04469062268777922, 'K': 6, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.25790179649237, 'loop': 0, 'loss': 'MSE', 'lr': 0.0014731313639855372, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07308395505868417, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0013358785373318407
weight_decay:  0.06803361539766131
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1660504590254277
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.338498992146924
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.0763744928408414
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.668208122253418
total time:  6.724637493956834
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.26
[I 2023-06-12 00:52:09,836] Trial 1100 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.00023218588012114696, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.8968977906305806, 'loop': 0, 'loss': 'CE', 'lr': 0.0013358785373318407, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.06803361539766131, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.001660693923674624
weight_decay:  0.061381830882293466
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1692499378696084
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  2.153931293869391
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.253119957866147
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.641322135925293
total time:  6.709788059815764
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.55
[I 2023-06-12 00:52:17,175] Trial 1101 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.00020539065482623022, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 6.446042951437387, 'loop': 0, 'loss': 'CE', 'lr': 0.001660693923674624, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.061381830882293466, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0002390350010597967
weight_decay:  0.0839037195197033
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6937934400048107
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02
None time:  1.9964966459665447
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.7246689070016146
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 66.80
run time now: 5.460235118865967
total time:  5.522252297028899
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 68.80 ± 2.11
[I 2023-06-12 00:52:23,463] Trial 1102 finished with value: 69.5999984741211 and parameters: {'Fwd': 0.00017253890506214062, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 1.0, 'lambda2': 2.687152410221843, 'loop': 0, 'loss': 'CE', 'lr': 0.0002390350010597967, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0839037195197033, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0014715434902348432
weight_decay:  0.05953010592362085
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.09360911604017
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.1216243291273713
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.2999847810715437
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.571644306182861
total time:  6.6199543999973685
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.49
[I 2023-06-12 00:52:30,776] Trial 1103 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.0002134293303154385, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 6.148368666226506, 'loop': 0, 'loss': 'CE', 'lr': 0.0014715434902348432, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.05953010592362085, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0013039437665547523
weight_decay:  0.07318010482082543
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.050782569218427
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.9446679279208183
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.55038605700247
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 99.17
   Final Test: 70.90
run time now: 6.594832897186279
total time:  6.64150344603695
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 0.46
  Final Train: 99.72 ± 0.48
   Final Test: 70.07 ± 0.74
[I 2023-06-12 00:52:38,056] Trial 1104 finished with value: 72.06666564941406 and parameters: {'Fwd': 0.00022788343793527795, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.599434352823727, 'loop': 0, 'loss': 'CE', 'lr': 0.0013039437665547523, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07318010482082543, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0013439695965821717
weight_decay:  0.06616022771898848
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8327036020345986
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  2.331324713071808
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.134276089956984
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.70
run time now: 6.347255706787109
total time:  6.392520677996799
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.90
[I 2023-06-12 00:52:45,160] Trial 1105 finished with value: 71.46666717529297 and parameters: {'Fwd': 0.00026253366125514256, 'K': 7, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.6759544677054476, 'loop': 0, 'loss': 'CE', 'lr': 0.0013439695965821717, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.06616022771898848, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0015115416916462595
weight_decay:  0.08089255999307517
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.429179538972676
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.3872921771835536
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.277591228019446
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.30
run time now: 7.144547462463379
total time:  7.190152448834851
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.42
[I 2023-06-12 00:52:53,077] Trial 1106 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.00027787191564811994, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.768706701048383, 'loop': 0, 'loss': 'CE', 'lr': 0.0015115416916462595, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.08089255999307517, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0013070780878615105
weight_decay:  0.09312478520071556
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.80% Test: 51.90%
Split: 01, Run: 01
None time:  2.568517035804689
None Run 01:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 51.80
Split: 01, Run: 02
None time:  0.35061325994320214
None Run 02:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 48.80
Split: 01, Run: 03
None time:  1.112919804174453
None Run 03:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 55.20
run time now: 4.077929258346558
total time:  4.135491051943973
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 52.80 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 51.93 ± 3.20
[I 2023-06-12 00:52:57,795] Trial 1107 finished with value: 52.79999923706055 and parameters: {'Fwd': 0.00044948077916020536, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 0, 'lambda1': 1.0, 'lambda2': 2.610733300350561, 'loop': 0, 'loss': 'CE', 'lr': 0.0013070780878615105, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.09312478520071556, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0001341430963988616
weight_decay:  0.06763311510501657
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3164142798632383
None Run 01:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 98.33
   Final Test: 66.10
Split: 01, Run: 02
None time:  1.2703959601931274
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 95.83
   Final Test: 67.40
Split: 01, Run: 03
None time:  1.3840747268404812
None Run 03:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 95.00
   Final Test: 64.50
run time now: 4.042853832244873
total time:  4.105977177154273
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.33 ± 1.21
  Final Train: 96.39 ± 1.73
   Final Test: 66.00 ± 1.45
[I 2023-06-12 00:53:02,599] Trial 1108 finished with value: 67.33332824707031 and parameters: {'Fwd': 0.00023671220846839666, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 2.968013739510895, 'loop': 0, 'loss': 'CE', 'lr': 0.0001341430963988616, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.06763311510501657, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.00033563608898541013
weight_decay:  0.052135128336136885
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.160648198099807
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.2771409531123936
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  2.581871109083295
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.70
run time now: 7.068999290466309
total time:  7.116855504224077
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.93 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.37 ± 0.35
[I 2023-06-12 00:53:10,333] Trial 1109 finished with value: 69.9333267211914 and parameters: {'Fwd': 0.0003049037339451888, 'K': 7, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.825730675978126, 'loop': 0, 'loss': 'CE', 'lr': 0.00033563608898541013, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.052135128336136885, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.006345786689073859
weight_decay:  0.06686631372245397
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.323552055982873
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 94.17
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.3478554929606616
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 95.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  2.2922704331576824
None Run 03:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 98.33
   Final Test: 69.30
run time now: 7.011884689331055
total time:  7.069290034007281
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.42
  Final Train: 95.83 ± 2.20
   Final Test: 69.33 ± 0.35
[I 2023-06-12 00:53:18,101] Trial 1110 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.00020953301313672993, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.2982734012027226, 'loop': 0, 'loss': 'CE', 'lr': 0.006345786689073859, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.06686631372245397, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0004867831280803895
weight_decay:  0.07133285468104474
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.988517363090068
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.1193836890161037
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.40
Split: 01, Run: 03
None time:  1.8976769419386983
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.70
run time now: 6.183546304702759
total time:  6.253640113864094
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.47 ± 1.79
  Final Train: 100.00 ± 0.00
   Final Test: 68.20 ± 1.61
[I 2023-06-12 00:53:25,135] Trial 1111 finished with value: 69.46666717529297 and parameters: {'Fwd': 0.00026709736587635135, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 1.0, 'lambda2': 2.4187159749764646, 'loop': 1, 'loss': 'CE', 'lr': 0.0004867831280803895, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07133285468104474, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0011089997286549812
weight_decay:  0.0461482575354868
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0071833881083876
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.2227372149936855
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.561234711902216
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.838630437850952
total time:  6.888494671089575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.55
[I 2023-06-12 00:53:32,717] Trial 1112 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.0003196709237641191, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.0569783598281126, 'loop': 0, 'loss': 'CE', 'lr': 0.0011089997286549812, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0461482575354868, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0004539429331360771
weight_decay:  0.09254122195804239
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5329041718505323
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.1235069050453603
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.00
Split: 01, Run: 03
None time:  2.0872911291662604
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.70
run time now: 5.787749528884888
total time:  5.837697034934536
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.07 ± 1.42
  Final Train: 100.00 ± 0.00
   Final Test: 68.77 ± 0.80
[I 2023-06-12 00:53:39,302] Trial 1113 finished with value: 69.06666564941406 and parameters: {'Fwd': 0.00018238590838437482, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 1.0, 'lambda2': 2.8731447235727656, 'loop': 0, 'loss': 'CE', 'lr': 0.0004539429331360771, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.09254122195804239, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.004883122854702091
weight_decay:  0.0964106736856224
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1720196940004826
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 94.17
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.402468784013763
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 95.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.280398896196857
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 93.33
   Final Test: 69.20
run time now: 6.911368370056152
total time:  6.965531813213602
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 0.00
  Final Train: 94.17 ± 0.83
   Final Test: 69.63 ± 0.45
[I 2023-06-12 00:53:47,002] Trial 1114 finished with value: 70.80000305175781 and parameters: {'Fwd': 0.00025939483672400267, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.278995385123335, 'loop': 0, 'loss': 'CE', 'lr': 0.004883122854702091, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0964106736856224, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  1.0
lr:  0.001428845386035836
weight_decay:  0.03134569237823822
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.117416593944654
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.0306986840441823
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.2921733839903027
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 97.50
   Final Test: 71.10
run time now: 6.490263223648071
total time:  6.539016013033688
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.12
  Final Train: 99.17 ± 1.44
   Final Test: 70.13 ± 0.84
[I 2023-06-12 00:53:54,325] Trial 1115 finished with value: 71.86666870117188 and parameters: {'Fwd': 0.0002977119764573774, 'K': 6, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 1.7796964931214294, 'loop': 0, 'loss': 'CE', 'lr': 0.001428845386035836, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03134569237823822, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.008405016247139132
weight_decay:  0.04700273891274593
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0110445199534297
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 94.17
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.6362475480418652
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 95.83
   Final Test: 69.50
Split: 01, Run: 03
None time:  2.3527444519568235
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 97.50
   Final Test: 69.50
run time now: 7.0534348487854
total time:  7.113957695895806
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.33 ± 0.12
  Final Train: 95.83 ± 1.67
   Final Test: 69.43 ± 0.12
[I 2023-06-12 00:54:02,048] Trial 1116 finished with value: 70.33333587646484 and parameters: {'Fwd': 0.00033440603959511206, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.0517325270151, 'loop': 0, 'loss': 'CE', 'lr': 0.008405016247139132, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04700273891274593, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.001635069006349702
weight_decay:  0.0593025930801754
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.112119822995737
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.258311582962051
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.8527261619456112
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.2688610553741455
total time:  6.315930557902902
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.93 ± 0.40
[I 2023-06-12 00:54:09,041] Trial 1117 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.00036428643687114946, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.512064608821338, 'loop': 0, 'loss': 'CE', 'lr': 0.001635069006349702, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0593025930801754, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.007577334414494845
weight_decay:  0.09864699263232866
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5396301271393895
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 96.67
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.1063489080406725
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 95.83
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.49870765209198
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 96.67
   Final Test: 68.80
run time now: 7.196776866912842
total time:  7.247086724033579
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.50
  Final Train: 96.39 ± 0.48
   Final Test: 69.47 ± 0.58
[I 2023-06-12 00:54:16,950] Trial 1118 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.00015085130037532124, 'K': 7, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.8844733571595578, 'loop': 0, 'loss': 'CE', 'lr': 0.007577334414494845, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.09864699263232866, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0012953559404219922
weight_decay:  0.03616813957678784
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1006471659056842
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 69.60%
Split: 01, Run: 02
None time:  4.5000893720425665
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 69.70%
Split: 01, Run: 03
None time:  4.088595696957782
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.70
run time now: 10.740389108657837
total time:  10.792794469976798
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 69.57 ± 0.15
[I 2023-06-12 00:54:28,326] Trial 1119 finished with value: 70.26667022705078 and parameters: {'Fwd': 0.0001881939690414233, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 2.323197859404136, 'loop': 0, 'loss': 'MSE', 'lr': 0.0012953559404219922, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03616813957678784, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0011748155824251234
weight_decay:  0.0536743672326102
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8198233370203525
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 02
None time:  0.7775083011947572
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 67.10
Split: 01, Run: 03
None time:  0.4840646719094366
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.90
run time now: 2.136871576309204
total time:  2.1959095830097795
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.87 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 67.63 ± 1.10
[I 2023-06-12 00:54:31,208] Trial 1120 finished with value: 68.86666870117188 and parameters: {'Fwd': 0.00020333267782625047, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 20, 'lambda1': 1.0, 'lambda2': 2.681829639193154, 'loop': 0, 'loss': 'CE', 'lr': 0.0011748155824251234, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0536743672326102, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0009825575542510357
weight_decay:  0.06871031174584083
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.207542150048539
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.0245316810905933
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.5618773931637406
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.8443284034729
total time:  6.901979231042787
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.31
[I 2023-06-12 00:54:38,684] Trial 1121 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.0002586498135989046, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.3441828608264204, 'loop': 0, 'loss': 'CE', 'lr': 0.0009825575542510357, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.06871031174584083, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0013968123618179659
weight_decay:  0.06458684647416933
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2454678788781166
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.2224073491524905
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.0793411638587713
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 6.597161293029785
total time:  6.649389329133555
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.20
[I 2023-06-12 00:54:46,085] Trial 1122 finished with value: 71.86666107177734 and parameters: {'Fwd': 0.04489207258645907, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.573755747655006, 'loop': 0, 'loss': 'CE', 'lr': 0.0013968123618179659, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.06458684647416933, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0015370663173963608
weight_decay:  0.04080518543910238
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.176510473014787
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.3188507130835205
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.877307120943442
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.424016952514648
total time:  6.476918067084625
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.36
[I 2023-06-12 00:54:53,233] Trial 1123 finished with value: 71.5999984741211 and parameters: {'Fwd': 0.00016868680267360023, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.2532196240194007, 'loop': 0, 'loss': 'CE', 'lr': 0.0015370663173963608, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04080518543910238, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.001279997169414201
weight_decay:  0.037157414079549374
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2315754699520767
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.2541715619154274
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  1.9173235651105642
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.456546068191528
total time:  6.516917322995141
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.83 ± 0.67
[I 2023-06-12 00:55:00,440] Trial 1124 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.00023274011989483917, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.0169371804925067, 'loop': 0, 'loss': 'CE', 'lr': 0.001279997169414201, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.037157414079549374, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  1.0
lr:  0.0010750332902598522
weight_decay:  0.045946293244158984
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.21495737391524
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.485311872093007
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 03
None time:  2.0919983710628003
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 5.837142467498779
total time:  5.887313967105001
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 69.47 ± 0.15
[I 2023-06-12 00:55:06,998] Trial 1125 finished with value: 71.53333282470703 and parameters: {'Fwd': 0.0001228595112733647, 'K': 1, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.8672216829048067, 'loop': 0, 'loss': 'CE', 'lr': 0.0010750332902598522, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.045946293244158984, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0017148060031228162
weight_decay:  0.07219785271263135
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9373535651247948
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.26485767099075
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  2.131782381096855
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.40
run time now: 6.386529207229614
total time:  6.445189945166931
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.68
[I 2023-06-12 00:55:14,114] Trial 1126 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.05399642656449863, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 2.713739908233688, 'loop': 0, 'loss': 'CE', 'lr': 0.0017148060031228162, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07219785271263135, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0002698946458562071
weight_decay:  0.03206980294641323
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0863819108344615
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 95.83
   Final Test: 67.60
Split: 01, Run: 02
None time:  1.4319330260623246
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 95.83
   Final Test: 65.30
Split: 01, Run: 03
None time:  1.4901695870794356
None Run 03:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 95.00
   Final Test: 62.00
run time now: 4.0507917404174805
total time:  4.104878993006423
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.73 ± 2.34
  Final Train: 95.56 ± 0.48
   Final Test: 64.97 ± 2.81
[I 2023-06-12 00:55:18,891] Trial 1127 finished with value: 66.73333740234375 and parameters: {'Fwd': 0.00013296400055599412, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 1.87352147540546, 'loop': 0, 'loss': 'CE', 'lr': 0.0002698946458562071, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03206980294641323, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.00066510048678777
weight_decay:  0.054594991146452276
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0847117118537426
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  2.1478184890002012
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.60% Test: 70.00%
Split: 01, Run: 03
None time:  4.242549187969416
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.00
run time now: 8.525042295455933
total time:  8.573863441124558
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.42
[I 2023-06-12 00:55:28,082] Trial 1128 finished with value: 70.60000610351562 and parameters: {'Fwd': 0.051499854281984815, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.166079177179445, 'loop': 0, 'loss': 'CE', 'lr': 0.00066510048678777, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.054594991146452276, 'weightedloss': True}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0011924563693685383
weight_decay:  0.029067894591001456
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3173746580723673
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.8662789920344949
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 70.60%
Split: 01, Run: 03
None time:  4.358217285014689
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 8.592355012893677
total time:  8.641291107982397
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.93 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.62
[I 2023-06-12 00:55:37,510] Trial 1129 finished with value: 71.9333267211914 and parameters: {'Fwd': 0.037250210659892306, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.1945478113465207, 'loop': 0, 'loss': 'CE', 'lr': 0.0011924563693685383, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.029067894591001456, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0014150584035226349
weight_decay:  0.07643242917138324
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9327956240158528
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  2.0096733088139445
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 68.30
Split: 01, Run: 03
None time:  1.9846813899930567
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.40
run time now: 5.974929094314575
total time:  6.022224999032915
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.40 ± 1.59
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 1.10
[I 2023-06-12 00:55:44,262] Trial 1130 finished with value: 70.4000015258789 and parameters: {'Fwd': 0.01571679063036841, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 3.404169856042349, 'loop': 0, 'loss': 'CE', 'lr': 0.0014150584035226349, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07643242917138324, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0013162437567279795
weight_decay:  0.026977294795619708
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1073877590242773
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.3054300830699503
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.155178152024746
None Run 03:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.80
run time now: 6.6229963302612305
total time:  6.682855025865138
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.13 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.17
[I 2023-06-12 00:55:51,506] Trial 1131 finished with value: 72.13333129882812 and parameters: {'Fwd': 0.050211758516126415, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.473828730749144, 'loop': 0, 'loss': 'CE', 'lr': 0.0013162437567279795, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.026977294795619708, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0012456309986498164
weight_decay:  0.04892144958192178
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.078161528101191
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.2963107461109757
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 71.60% Test: 70.30%
Split: 01, Run: 03
None time:  4.274270795052871
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 8.699612379074097
total time:  8.750697510084137
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.55
[I 2023-06-12 00:56:00,871] Trial 1132 finished with value: 72.0 and parameters: {'Fwd': 0.03501042003606181, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.122686565897174, 'loop': 0, 'loss': 'CE', 'lr': 0.0012456309986498164, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04892144958192178, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0003768470270382033
weight_decay:  0.04631253599524912
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.408483562991023
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.520984690869227
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.512994698015973
None Run 03:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 7.495138645172119
total time:  7.544267263030633
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.38
[I 2023-06-12 00:56:09,034] Trial 1133 finished with value: 70.20000457763672 and parameters: {'Fwd': 0.00036377310485884233, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.6834332561307828, 'loop': 2, 'loss': 'CE', 'lr': 0.0003768470270382033, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04631253599524912, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  1.0
lr:  0.001119753489877875
weight_decay:  0.043807514782174
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4047909821383655
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  2.3609997569583356
None Run 02:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 70.50%
Split: 01, Run: 03
None time:  3.683596703922376
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.50
run time now: 8.525921106338501
total time:  8.589564542053267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.77 ± 0.67
[I 2023-06-12 00:56:18,370] Trial 1134 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.04494803064777339, 'K': 6, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.3725088817753313, 'loop': 0, 'loss': 'CE', 'lr': 0.001119753489877875, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.043807514782174, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.004137774171642301
weight_decay:  0.04097292942813316
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 96.67%, Valid: 70.40% Test: 69.90%
Split: 01, Run: 01
None time:  4.538782468996942
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 97.50
   Final Test: 70.10
Split: 01, Run: 02
None time:  2.2093748468905687
None Run 02:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 97.50
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.3824225219432265
None Run 03:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 98.33
   Final Test: 69.90
run time now: 9.182655572891235
total time:  9.24732853891328
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.53 ± 0.23
  Final Train: 97.78 ± 0.48
   Final Test: 70.07 ± 0.15
[I 2023-06-12 00:56:28,327] Trial 1135 finished with value: 70.53333282470703 and parameters: {'Fwd': 0.03882773257568339, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 1.8095546799628073, 'loop': 0, 'loss': 'CE', 'lr': 0.004137774171642301, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.04097292942813316, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0001008349979018337
weight_decay:  0.029011068040210936
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3316339820157737
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.20% Test: 67.40%
Split: 01, Run: 02
None time:  4.325216762954369
None Run 02:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 67.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.00% Test: 68.30%
Split: 01, Run: 03
None time:  4.353266017977148
None Run 03:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 68.30
run time now: 11.059499979019165
total time:  11.108342015882954
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.53 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 67.17 ± 1.21
[I 2023-06-12 00:56:39,980] Trial 1136 finished with value: 66.53333282470703 and parameters: {'Fwd': 0.030635359973776446, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.6232845198351415, 'loop': 0, 'loss': 'CE', 'lr': 0.0001008349979018337, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.029011068040210936, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0006410047878667779
weight_decay:  0.023648076695416714
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9478070018813014
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.354109161067754
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 03
None time:  1.8859444549307227
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.50
run time now: 6.233700275421143
total time:  6.288901030085981
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.33 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 69.00 ± 1.80
[I 2023-06-12 00:56:46,943] Trial 1137 finished with value: 69.33333587646484 and parameters: {'Fwd': 0.02542405287788667, 'K': 7, 'alpha': 1.0, 'dropout': 0.6000000000000001, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 2.422615799351481, 'loop': 0, 'loss': 'CE', 'lr': 0.0006410047878667779, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.023648076695416714, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.001307290050180722
weight_decay:  0.03359716138409679
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.182718878844753
None Run 01:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.7997582731768489
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.40% Test: 71.10%
Split: 01, Run: 03
None time:  4.4716025239322335
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.10
run time now: 8.503750085830688
total time:  8.55550389084965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 70.20 ± 0.90
[I 2023-06-12 00:56:56,185] Trial 1138 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.05229116976242379, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.9598915568151454, 'loop': 0, 'loss': 'CE', 'lr': 0.001307290050180722, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03359716138409679, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0003155878546120608
weight_decay:  0.057099866257950424
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.223650310887024
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.2567440550774336
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  2.426149434875697
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.956599235534668
total time:  7.013599697966129
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 0.32
[I 2023-06-12 00:57:03,829] Trial 1139 finished with value: 70.0 and parameters: {'Fwd': 0.00036629766640061234, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.4564939937212826, 'loop': 0, 'loss': 'CE', 'lr': 0.0003155878546120608, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.057099866257950424, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0015640885487609472
weight_decay:  0.035879330346014045
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2620042078197002
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.9927650999743491
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.3871044791303575
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
run time now: 6.691994667053223
total time:  6.749930071877316
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.30
[I 2023-06-12 00:57:11,252] Trial 1140 finished with value: 71.73332977294922 and parameters: {'Fwd': 0.04324404160516567, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.9910435085830995, 'loop': 0, 'loss': 'CE', 'lr': 0.0015640885487609472, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.035879330346014045, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0010180046788110424
weight_decay:  0.031791654772904826
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.39099233597517
None Run 01:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.5812485690694302
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.4305484748911113
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.70
run time now: 7.447093963623047
total time:  7.503396435175091
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.70 ± 0.10
[I 2023-06-12 00:57:19,375] Trial 1141 finished with value: 70.5999984741211 and parameters: {'Fwd': 0.0009259592469867204, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 1.156371419379254, 'loop': 1, 'loss': 'MSE', 'lr': 0.0010180046788110424, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.031791654772904826, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0011780847967011049
weight_decay:  0.026269011527845713
dropout:  0.4
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2445163389202207
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.007080795010552
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03
None time:  2.007630694890395
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 99.17
   Final Test: 70.30
run time now: 6.307767152786255
total time:  6.368996789911762
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 0.23
  Final Train: 99.72 ± 0.48
   Final Test: 69.93 ± 0.47
[I 2023-06-12 00:57:26,346] Trial 1142 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.00022639540181964264, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.2001941624660555, 'loop': 0, 'loss': 'CE', 'lr': 0.0011780847967011049, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.026269011527845713, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0014419552784661676
weight_decay:  0.059163745211390936
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2724850468803197
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.973984669195488
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  2.1924003509338945
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 6.4887778759002686
total time:  6.5442942248191684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.67 ± 0.21
[I 2023-06-12 00:57:33,540] Trial 1143 finished with value: 71.80000305175781 and parameters: {'Fwd': 0.06184221848899939, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.713306796602604, 'loop': 0, 'loss': 'CE', 'lr': 0.0014419552784661676, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.059163745211390936, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0013187948626941558
weight_decay:  0.025415714630958285
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8903072730172426
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.9702792270109057
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  2.191015941090882
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.0995032787323
total time:  6.149473319994286
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.67 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.60
[I 2023-06-12 00:57:40,352] Trial 1144 finished with value: 70.66666412353516 and parameters: {'Fwd': 0.01911563472187815, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 3.071183119812846, 'loop': 0, 'loss': 'CE', 'lr': 0.0013187948626941558, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.025415714630958285, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.000859945380449436
weight_decay:  0.07532662507528026
dropout:  0.5
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1252402558457106
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.367773036006838
None Run 02:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  2.28578542615287
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.833099126815796
total time:  6.879857761086896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 70.03 ± 0.67
[I 2023-06-12 00:57:47,976] Trial 1145 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.029729980051628687, 'K': 7, 'alpha': 1.0, 'dropout': 0.5, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.5822682288034553, 'loop': 0, 'loss': 'CE', 'lr': 0.000859945380449436, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07532662507528026, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0015183011005689467
weight_decay:  0.00010250219390990113
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3746294020675123
None Run 01:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.30
Split: 01, Run: 02
None time:  1.134148980025202
None Run 02:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.30
Split: 01, Run: 03
None time:  1.1729096740018576
None Run 03:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 46.30
run time now: 3.732191801071167
total time:  3.7889942459296435
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 46.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 46.30 ± 0.00
[I 2023-06-12 00:57:52,399] Trial 1146 finished with value: 46.79999923706055 and parameters: {'Fwd': 0.04864892239585178, 'K': 7, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 3.3206235564987177, 'loop': 0, 'loss': 'CE', 'lr': 0.0015183011005689467, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010250219390990113, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.001212116722845687
weight_decay:  0.0553466278232063
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0928520599845797
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  2.3620814429596066
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 99.17%, Valid: 71.60% Test: 70.40%
Split: 01, Run: 03
None time:  4.454092727042735
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 8.956338167190552
total time:  9.003978720167652
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.87 ± 0.64
[I 2023-06-12 00:58:02,116] Trial 1147 finished with value: 72.0 and parameters: {'Fwd': 0.03679673574819898, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.1333722872763974, 'loop': 0, 'loss': 'CE', 'lr': 0.001212116722845687, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0553466278232063, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0009514630658240487
weight_decay:  0.021350709153980747
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.033001117873937
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  2.2479073519352823
None Run 02:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 67.80
Split: 01, Run: 03
None time:  1.9579227541107684
None Run 03:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.80
run time now: 6.288076639175415
total time:  6.337531781056896
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.27 ± 1.53
  Final Train: 100.00 ± 0.00
   Final Test: 69.53 ± 1.55
[I 2023-06-12 00:58:09,292] Trial 1148 finished with value: 70.26666259765625 and parameters: {'Fwd': 0.00048171382391757505, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 7.893714277427831, 'loop': 0, 'loss': 'CE', 'lr': 0.0009514630658240487, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.021350709153980747, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0013649609077987946
weight_decay:  7.344147766166335e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.323420748813078
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  2.0613694777712226
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.278668622020632
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.72992467880249
total time:  6.794510578038171
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 69.90 ± 0.26
[I 2023-06-12 00:58:16,758] Trial 1149 finished with value: 72.0 and parameters: {'Fwd': 0.0001695421151531171, 'K': 7, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 2.0609153079000664, 'loop': 0, 'loss': 'CE', 'lr': 0.0013649609077987946, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.344147766166335e-05, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.001088466061473944
weight_decay:  0.03990124002234657
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.013129970058799
None Run 01:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.9165805948432535
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  2.47900634794496
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 99.17
   Final Test: 70.70
run time now: 6.463412284851074
total time:  6.511743878014386
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 0.70
  Final Train: 99.72 ± 0.48
   Final Test: 70.00 ± 0.62
[I 2023-06-12 00:58:24,017] Trial 1150 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.00014062152715877893, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.7743563357447054, 'loop': 0, 'loss': 'CE', 'lr': 0.001088466061473944, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03990124002234657, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.00041878749252410695
weight_decay:  0.00012943331735106614
dropout:  0.9
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.00% Test: 68.90%
Split: 01, Run: 01
None time:  4.485444243066013
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.9950064870063215
None Run 02:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 70.80%
Split: 01, Run: 03
None time:  4.5969535240437835
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.60
run time now: 11.12287425994873
total time:  11.190391384996474
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.13 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 69.73 ± 0.81
[I 2023-06-12 00:58:35,951] Trial 1151 finished with value: 70.13333129882812 and parameters: {'Fwd': 0.05816067692006688, 'K': 7, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9500000000000001, 'lambda2': 3.249887172881993, 'loop': 0, 'loss': 'CE', 'lr': 0.00041878749252410695, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012943331735106614, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0012750125279213937
weight_decay:  0.09202200508424979
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8532281890511513
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  2.183962724870071
None Run 02:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 03
None time:  2.4607414109632373
None Run 03:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
run time now: 6.572921276092529
total time:  6.66029496002011
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 69.97 ± 0.55
[I 2023-06-12 00:58:43,319] Trial 1152 finished with value: 71.79999542236328 and parameters: {'Fwd': 0.039853269387729554, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 7.769671446577357, 'loop': 0, 'loss': 'CE', 'lr': 0.0012750125279213937, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.09202200508424979, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0015972987391046226
weight_decay:  0.07063593302863308
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9347965598572046
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  2.02350366092287
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.90
Split: 01, Run: 03
None time:  2.1264013000763953
None Run 03:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.20
run time now: 6.137030124664307
total time:  6.190157321980223
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 69.63 ± 0.67
[I 2023-06-12 00:58:50,152] Trial 1153 finished with value: 70.80000305175781 and parameters: {'Fwd': 0.0246269051391961, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 110, 'lambda1': 0.9500000000000001, 'lambda2': 3.044406108737855, 'loop': 0, 'loss': 'CE', 'lr': 0.0015972987391046226, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07063593302863308, 'weightedloss': False}. Best is trial 605 with value: 72.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0014416169462493557
weight_decay:  8.599005354217531e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[3327, 3703], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327], adj_t=[3327, 3327, nnz=9104])
num_train tensor(120)
num_noise 0
noise: tensor(0)
data feature 3703
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=3703, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=6, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(3703, 64)
      (1): GCNConv(64, 6)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
