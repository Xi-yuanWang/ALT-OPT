[I 2023-06-12 00:12:20,417] A new study created in RDB with name: PubMed_ALTOPT
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.05
lr:  0.008776067019418658
weight_decay:  0.0815348423280955
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3235012621153146
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.2520379440393299
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  1.3720978579949588
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.40
run time now: 5.513173818588257
total time:  7.313033324899152
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 76.83 ± 0.38
[I 2023-06-12 00:12:28,419] Trial 0 finished with value: 78.66666412353516 and parameters: {'Fwd': 0.00032601452271666093, 'K': 2, 'alpha': 0.05, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.05, 'lambda2': 1.4195170997931295, 'loop': 1, 'loss': 'CE', 'lr': 0.008776067019418658, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0815348423280955, 'weightedloss': False}. Best is trial 0 with value: 78.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.5
lr:  0.0032002525643192365
weight_decay:  7.194279032921646e-06
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0941, Train: 100.00%, Valid: 78.80% Test: 77.30%
Split: 01, Run: 01
None time:  2.3243146140594035
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02
None time:  1.0991205577738583
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  1.289209078066051
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.70
run time now: 4.749793529510498
total time:  4.800064906012267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 77.63 ± 1.14
[I 2023-06-12 00:12:33,573] Trial 1 finished with value: 79.13333129882812 and parameters: {'Fwd': 0.00038342924319538534, 'K': 2, 'alpha': 0.5, 'dropout': 0.2, 'gnnepoch': 80, 'lambda1': 0.45, 'lambda2': 9.646400174867237, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032002525643192365, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.194279032921646e-06, 'weightedloss': False}. Best is trial 1 with value: 79.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.00010211093571672342
weight_decay:  0.0009639944303940641
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4006823340896517
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.4091573371551931
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  0.408811824163422
None Run 03:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
run time now: 1.2892110347747803
total time:  1.337702709948644
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 71.00 ± 0.00
[I 2023-06-12 00:12:35,276] Trial 2 finished with value: 71.4000015258789 and parameters: {'Fwd': 0.004443582980355981, 'K': 10, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 10, 'lambda1': 0.35000000000000003, 'lambda2': 5.882638740251495, 'loop': 0, 'loss': 'CE', 'lr': 0.00010211093571672342, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009639944303940641, 'weightedloss': True}. Best is trial 1 with value: 79.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.00026777133427402283
weight_decay:  0.0899785843373769
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9822517309803516
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 75.70
Split: 01, Run: 02
None time:  2.0001014771405607
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.10
Split: 01, Run: 03
None time:  1.7535132199991494
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.20
run time now: 5.774348258972168
total time:  5.827511855168268
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 76.33 ± 0.78
[I 2023-06-12 00:12:41,538] Trial 3 finished with value: 79.13333129882812 and parameters: {'Fwd': 2.867146334102046e-05, 'K': 6, 'alpha': 0.9, 'dropout': 0.2, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 9.138333024414607, 'loop': 1, 'loss': 'MSE', 'lr': 0.00026777133427402283, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0899785843373769, 'weightedloss': False}. Best is trial 1 with value: 79.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.00041990439709973685
weight_decay:  2.441019881846215e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.974120008992031
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 70.70
Split: 01, Run: 02
None time:  5.125827447976917
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 03
None time:  2.144845893839374
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 71.70
run time now: 10.321087121963501
total time:  10.36506530502811
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.27 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 70.33 ± 1.58
[I 2023-06-12 00:12:52,371] Trial 4 finished with value: 73.26667022705078 and parameters: {'Fwd': 0.00036397859561331804, 'K': 10, 'alpha': 0.1, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.6000000000000001, 'lambda2': 4.299042776192476, 'loop': 2, 'loss': 'MSE', 'lr': 0.00041990439709973685, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.441019881846215e-06, 'weightedloss': False}. Best is trial 1 with value: 79.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9
lr:  0.0033745555808960383
weight_decay:  9.90272898753863e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3275081389583647
None Run 01:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 42.10
Split: 01, Run: 02
None time:  1.402116223005578
None Run 02:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 74.50
Split: 01, Run: 03
None time:  0.5002353210002184
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 71.50
run time now: 2.2673656940460205
total time:  2.312214884907007
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.20 ± 18.54
  Final Train: 100.00 ± 0.00
   Final Test: 62.70 ± 17.90
[I 2023-06-12 00:12:55,199] Trial 5 finished with value: 66.20000457763672 and parameters: {'Fwd': 0.0030897793188564074, 'K': 3, 'alpha': 0.9, 'dropout': 0.1, 'gnnepoch': 10, 'lambda1': 0.35000000000000003, 'lambda2': 8.591105226330862, 'loop': 1, 'loss': 'MSE', 'lr': 0.0033745555808960383, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.90272898753863e-05, 'weightedloss': True}. Best is trial 1 with value: 79.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.00015768811568043158
weight_decay:  3.587009802307004e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6719891638495028
None Run 01:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 44.80
Split: 01, Run: 02
None time:  0.7076935400255024
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.60
Split: 01, Run: 03
None time:  0.6873822840861976
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.00
run time now: 2.104888439178467
total time:  2.1466641258448362
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.20 ± 15.24
  Final Train: 100.00 ± 0.00
   Final Test: 63.47 ± 16.17
[I 2023-06-12 00:12:57,666] Trial 6 finished with value: 66.20000457763672 and parameters: {'Fwd': 0.00017675649146618334, 'K': 2, 'alpha': 0.9, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.4, 'lambda2': 0.6929001415815583, 'loop': 0, 'loss': 'MSE', 'lr': 0.00015768811568043158, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.587009802307004e-06, 'weightedloss': True}. Best is trial 1 with value: 79.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.75
lr:  0.0003352244187028976
weight_decay:  0.0011060384827098462
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.136004198109731
None Run 01:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 70.50
Split: 01, Run: 02
None time:  1.0848030850756913
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 98.33
   Final Test: 77.10
Split: 01, Run: 03
None time:  0.7627831790596247
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 98.33
   Final Test: 79.40
run time now: 3.0246665477752686
total time:  3.066948028979823
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.40 ± 3.08
  Final Train: 98.89 ± 0.96
   Final Test: 75.67 ± 4.62
[I 2023-06-12 00:13:01,095] Trial 7 finished with value: 78.4000015258789 and parameters: {'Fwd': 0.0013142780338881476, 'K': 3, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 1.0, 'lambda2': 6.091700533448485, 'loop': 2, 'loss': 'CE', 'lr': 0.0003352244187028976, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0011060384827098462, 'weightedloss': True}. Best is trial 1 with value: 79.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.0012189527958586628
weight_decay:  0.004946859078443736
dropout:  0.0
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4697630011942238
None Run 01:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 02
None time:  1.4352696421556175
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03
None time:  1.2583354371599853
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.80
run time now: 4.2248876094818115
total time:  4.282976810121909
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 73.10 ± 1.30
[I 2023-06-12 00:13:05,753] Trial 8 finished with value: 74.53333282470703 and parameters: {'Fwd': 0.022099992662141903, 'K': 1, 'alpha': 0.4, 'dropout': 0.0, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 8.444785809247083, 'loop': 2, 'loss': 'CE', 'lr': 0.0012189527958586628, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004946859078443736, 'weightedloss': True}. Best is trial 1 with value: 79.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.7000000000000001
lr:  0.000702185890192774
weight_decay:  0.02849618494481141
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6176727951969951
None Run 01:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.20
Split: 01, Run: 02
None time:  0.5714155021123588
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.80% Test: 62.00%
Split: 01, Run: 03
None time:  2.063587989890948
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.00
run time now: 3.3047335147857666
total time:  3.3551951141562313
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.27 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 63.47 ± 1.27
[I 2023-06-12 00:13:09,575] Trial 9 finished with value: 64.26667022705078 and parameters: {'Fwd': 9.165709072938221e-05, 'K': 4, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 20, 'lambda1': 0.8, 'lambda2': 0.22460974032341485, 'loop': 0, 'loss': 'MSE', 'lr': 0.000702185890192774, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.02849618494481141, 'weightedloss': False}. Best is trial 1 with value: 79.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.45
lr:  0.0019271737022301535
weight_decay:  2.096411627246161e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2801683759316802
None Run 01:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.2061957530677319
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.20
Split: 01, Run: 03
None time:  1.323241325095296
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 74.90
run time now: 3.8531341552734375
total time:  3.899938212009147
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.20 ± 3.67
  Final Train: 100.00 ± 0.00
   Final Test: 71.43 ± 3.04
[I 2023-06-12 00:13:13,889] Trial 10 finished with value: 73.20000457763672 and parameters: {'Fwd': 2.7487152918424117e-06, 'K': 6, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.05, 'lambda2': 9.815060639041786, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019271737022301535, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.096411627246161e-05, 'weightedloss': False}. Best is trial 1 with value: 79.13333129882812.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.003315040475977677
weight_decay:  8.471997884858667e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.724312638863921
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.8655041840393096
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.7080134160351008
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 6.359869003295898
total time:  6.412292903987691
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.64
[I 2023-06-12 00:13:20,726] Trial 11 finished with value: 80.26666259765625 and parameters: {'Fwd': 2.6433007682621912e-05, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.2, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 9.921483742907768, 'loop': 1, 'loss': 'MSE', 'lr': 0.003315040475977677, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.471997884858667e-05, 'weightedloss': False}. Best is trial 11 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.00403450117296386
weight_decay:  3.672564901626868e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5091695520095527
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02
None time:  1.486880982061848
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.7064317702315748
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.747147083282471
total time:  5.800311073195189
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.85
[I 2023-06-12 00:13:26,944] Trial 12 finished with value: 78.9333267211914 and parameters: {'Fwd': 1.411199326848934e-05, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.2, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 9.904236864863947, 'loop': 1, 'loss': 'MSE', 'lr': 0.00403450117296386, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.672564901626868e-05, 'weightedloss': False}. Best is trial 11 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.30000000000000004
lr:  0.002187572321032164
weight_decay:  1.0083396922312761e-05
dropout:  0.0
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6016662679612637
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 74.40
Split: 01, Run: 02
None time:  1.4457947849296033
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.013316674157977
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 4.111490726470947
total time:  4.1563019710592926
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.87 ± 3.01
  Final Train: 100.00 ± 0.00
   Final Test: 76.43 ± 1.76
[I 2023-06-12 00:13:31,534] Trial 13 finished with value: 76.86666870117188 and parameters: {'Fwd': 1.3460450751824651e-06, 'K': 8, 'alpha': 0.30000000000000004, 'dropout': 0.0, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 7.753315844945015, 'loop': 1, 'loss': 'MSE', 'lr': 0.002187572321032164, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0083396922312761e-05, 'weightedloss': False}. Best is trial 11 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.30000000000000004
lr:  0.004472588867864178
weight_decay:  1.0578593303266122e-06
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4643813918810338
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 02
None time:  1.5049148830585182
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 03
None time:  1.4494714147876948
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.60
run time now: 4.491132736206055
total time:  4.570814145030454
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.73 ± 1.67
  Final Train: 100.00 ± 0.00
   Final Test: 75.87 ± 0.74
[I 2023-06-12 00:13:36,619] Trial 14 finished with value: 77.73333740234375 and parameters: {'Fwd': 0.08671442768127177, 'K': 5, 'alpha': 0.30000000000000004, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.75, 'lambda2': 7.420768001171372, 'loop': 2, 'loss': 'MSE', 'lr': 0.004472588867864178, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0578593303266122e-06, 'weightedloss': False}. Best is trial 11 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.0062820385760465275
weight_decay:  0.0001046145018886989
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.60% Test: 75.10%
Split: 01, Run: 01
None time:  2.4830330319236964
None Run 01:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.00% Test: 75.70%
Split: 01, Run: 02
None time:  2.5495466308202595
None Run 02:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.20% Test: 76.50%
Split: 01, Run: 03
None time:  2.159071131842211
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.80
run time now: 7.240829706192017
total time:  7.286984740989283
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.27 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 75.83 ± 0.85
[I 2023-06-12 00:13:44,483] Trial 15 finished with value: 77.26667022705078 and parameters: {'Fwd': 2.63701454039314e-05, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.5, 'lambda2': 9.868552272756332, 'loop': 0, 'loss': 'MSE', 'lr': 0.0062820385760465275, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001046145018886989, 'weightedloss': False}. Best is trial 11 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.009929652443394821
weight_decay:  1.1817358805554899e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6252405471168458
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.6837199481669813
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.0171813829801977
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 75.40
run time now: 2.3730263710021973
total time:  2.410305141005665
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.07 ± 5.95
  Final Train: 100.00 ± 0.00
   Final Test: 74.07 ± 4.36
[I 2023-06-12 00:13:47,454] Trial 16 finished with value: 76.0666732788086 and parameters: {'Fwd': 6.363101328615333e-06, 'K': 7, 'alpha': 0.55, 'dropout': 0.30000000000000004, 'gnnepoch': 30, 'lambda1': 0.5, 'lambda2': 7.487336797096198, 'loop': 1, 'loss': 'MSE', 'lr': 0.009929652443394821, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1817358805554899e-05, 'weightedloss': False}. Best is trial 11 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.2
lr:  0.002402380422958828
weight_decay:  0.00013964903700743346
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4921852911356837
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 02
None time:  1.4061658189166337
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 03
None time:  1.6008524459321052
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.40
run time now: 4.538515567779541
total time:  4.577005916042253
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.53 ± 3.79
  Final Train: 100.00 ± 0.00
   Final Test: 75.73 ± 2.80
[I 2023-06-12 00:13:52,482] Trial 17 finished with value: 76.53333282470703 and parameters: {'Fwd': 6.872313368963582e-05, 'K': 5, 'alpha': 0.2, 'dropout': 0.1, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 8.77962004097162, 'loop': 2, 'loss': 'MSE', 'lr': 0.002402380422958828, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00013964903700743346, 'weightedloss': False}. Best is trial 11 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.0012038786573776883
weight_decay:  3.770175765736464e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7765310970135033
None Run 01:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 74.70
Split: 01, Run: 02
None time:  1.5165568280499429
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 03
None time:  1.4928719010204077
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.10
run time now: 4.821002006530762
total time:  4.876117466017604
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.93 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 73.57 ± 1.33
[I 2023-06-12 00:13:57,756] Trial 18 finished with value: 75.93333435058594 and parameters: {'Fwd': 9.504814557773033e-06, 'K': 1, 'alpha': 0.4, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 1.0, 'lambda2': 6.755666911326216, 'loop': 0, 'loss': 'CE', 'lr': 0.0012038786573776883, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.770175765736464e-05, 'weightedloss': False}. Best is trial 11 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  1.0
lr:  0.006449520060021922
weight_decay:  7.153593980194316e-06
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5283088369760662
None Run 01:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 64.10
Split: 01, Run: 02
None time:  0.5965502229519188
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 03
None time:  1.0509677240625024
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.80
run time now: 2.2488133907318115
total time:  2.316834779921919
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 9.27
  Final Train: 100.00 ± 0.00
   Final Test: 72.60 ± 7.42
[I 2023-06-12 00:14:00,572] Trial 19 finished with value: 73.5999984741211 and parameters: {'Fwd': 0.0005462120974736118, 'K': 4, 'alpha': 1.0, 'dropout': 0.1, 'gnnepoch': 40, 'lambda1': 0.8500000000000001, 'lambda2': 4.424804127361265, 'loop': 1, 'loss': 'MSE', 'lr': 0.006449520060021922, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.153593980194316e-06, 'weightedloss': False}. Best is trial 11 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.0030334039629268846
weight_decay:  0.0003307147673960515
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1491, Train: 100.00%, Valid: 81.40% Test: 79.90%
Split: 01, Run: 01
None time:  3.32197542488575
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  1.213810081128031
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  0.9919302691705525
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.70
run time now: 5.573023319244385
total time:  5.625014256918803
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 79.03 ± 0.85
[I 2023-06-12 00:14:06,635] Trial 20 finished with value: 81.0666732788086 and parameters: {'Fwd': 6.588604738619063e-05, 'K': 7, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 8.193349344822003, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030334039629268846, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003307147673960515, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.0030849047910859735
weight_decay:  0.0004578437512944869
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6438007769174874
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  0.996546199079603
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 03
None time:  1.0642989850603044
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 74.50
run time now: 3.752845048904419
total time:  3.7999919198919088
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.73 ± 1.42
  Final Train: 100.00 ± 0.00
   Final Test: 76.23 ± 1.75
[I 2023-06-12 00:14:10,891] Trial 21 finished with value: 78.73333740234375 and parameters: {'Fwd': 5.6426471228880466e-05, 'K': 7, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 9.07680289402724, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030849047910859735, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004578437512944869, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.0016235546336473984
weight_decay:  3.409514566589007e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2998, Train: 100.00%, Valid: 75.00% Test: 74.70%
Split: 01, Run: 01
None time:  3.7125955398660153
None Run 01:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 74.60
Split: 01, Run: 02
None time:  1.3688810269813985
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.3504427538719028
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.80
run time now: 6.479223012924194
total time:  6.531134573975578
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.73 ± 2.47
  Final Train: 100.00 ± 0.00
   Final Test: 76.63 ± 1.96
[I 2023-06-12 00:14:17,814] Trial 22 finished with value: 77.73332977294922 and parameters: {'Fwd': 0.00011536449349510707, 'K': 9, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 8.12131923795917, 'loop': 1, 'loss': 'MSE', 'lr': 0.0016235546336473984, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.409514566589007e-05, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.5
lr:  0.002924868178545388
weight_decay:  0.00022899430198304146
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3212111920583993
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.50
Split: 01, Run: 02
None time:  0.9077462458517402
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  1.0358303969260305
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.00
run time now: 3.308192729949951
total time:  3.3601678020786494
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 76.57 ± 0.93
[I 2023-06-12 00:14:21,602] Trial 23 finished with value: 78.19999694824219 and parameters: {'Fwd': 3.43353591380593e-05, 'K': 7, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 9.990880809131214, 'loop': 1, 'loss': 'MSE', 'lr': 0.002924868178545388, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00022899430198304146, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8
lr:  0.004714871505861856
weight_decay:  0.0003601740893561208
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.17881262418814
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 75.80
Split: 01, Run: 02
None time:  1.3269746589940041
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.362703647930175
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.10
run time now: 3.9126124382019043
total time:  3.963813694892451
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 77.20 ± 1.45
[I 2023-06-12 00:14:26,023] Trial 24 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.00020230176662783755, 'K': 6, 'alpha': 0.8, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 9.088827515897234, 'loop': 1, 'loss': 'MSE', 'lr': 0.004714871505861856, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003601740893561208, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8
lr:  0.005086928453270978
weight_decay:  0.00045075417450995953
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.40% Test: 76.10%
Split: 01, Run: 01
None time:  1.8178971621673554
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 76.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.20% Test: 78.70%
Split: 01, Run: 02
None time:  2.4786435218993574
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.20% Test: 77.70%
Split: 01, Run: 03
None time:  2.5060436117928475
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.80
run time now: 6.844250440597534
total time:  6.89414427196607
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.47 ± 1.23
[I 2023-06-12 00:14:33,367] Trial 25 finished with value: 79.26667022705078 and parameters: {'Fwd': 0.00015966706327327264, 'K': 6, 'alpha': 0.8, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 0.6000000000000001, 'lambda2': 8.976573202866625, 'loop': 0, 'loss': 'MSE', 'lr': 0.005086928453270978, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00045075417450995953, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.004973376886317986
weight_decay:  0.0020589315194632983
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3590511470101774
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 74.80
Split: 01, Run: 02
None time:  1.2969915200956166
None Run 02:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.80
Split: 01, Run: 03
None time:  1.298641567118466
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.00
run time now: 3.9970858097076416
total time:  4.048849196173251
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.07 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 74.53 ± 1.42
[I 2023-06-12 00:14:37,938] Trial 26 finished with value: 77.0666732788086 and parameters: {'Fwd': 1.698698662671105e-05, 'K': 9, 'alpha': 0.75, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.75, 'lambda2': 7.948729703853119, 'loop': 2, 'loss': 'MSE', 'lr': 0.004973376886317986, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0020589315194632983, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.001871476698866145
weight_decay:  8.067807960177537e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4867258828599006
None Run 01:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 02
None time:  2.63654669187963
None Run 02:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 03
None time:  2.5852638438809663
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.20
run time now: 7.754474401473999
total time:  7.806392031954601
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 72.20 ± 0.00
[I 2023-06-12 00:14:46,272] Trial 27 finished with value: 73.19999694824219 and parameters: {'Fwd': 5.235719380950613e-05, 'K': 7, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.0, 'lambda2': 7.016600980342439, 'loop': 1, 'loss': 'CE', 'lr': 0.001871476698866145, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.067807960177537e-05, 'weightedloss': True}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.65
lr:  0.006602768443337476
weight_decay:  0.0002567426415208956
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2539531767833978
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 02
None time:  1.1531427311711013
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.70
Split: 01, Run: 03
None time:  1.429494580021128
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 76.10
run time now: 3.8792684078216553
total time:  3.9309757901355624
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.60 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 76.23 ± 0.61
[I 2023-06-12 00:14:50,638] Trial 28 finished with value: 78.60000610351562 and parameters: {'Fwd': 5.092978233747255e-06, 'K': 5, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 8.28674940568086, 'loop': 1, 'loss': 'MSE', 'lr': 0.006602768443337476, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002567426415208956, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.00383036416633414
weight_decay:  6.170456291116437e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.549276074860245
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.50
Split: 01, Run: 02
None time:  1.5230000771116465
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.60
Split: 01, Run: 03
None time:  1.5508208749815822
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.20
run time now: 4.692849636077881
total time:  4.742229557828978
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.73 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 74.77 ± 1.02
[I 2023-06-12 00:14:55,926] Trial 29 finished with value: 76.73333740234375 and parameters: {'Fwd': 0.00019352684786626425, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.1, 'lambda2': 9.170747030915832, 'loop': 1, 'loss': 'CE', 'lr': 0.00383036416633414, 'softmaxF': False, 'useGCN': True, 'weight_decay': 6.170456291116437e-05, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.0
lr:  0.007951246828381017
weight_decay:  0.00016901422917884598
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0903322878293693
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 74.60
Split: 01, Run: 02
None time:  0.8691589480731636
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.70
Split: 01, Run: 03
None time:  1.0302540978882462
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.70
run time now: 3.0296661853790283
total time:  3.0736929608974606
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.87 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 74.00 ± 0.52
[I 2023-06-12 00:14:59,529] Trial 30 finished with value: 75.86666870117188 and parameters: {'Fwd': 1.645601506519462e-05, 'K': 6, 'alpha': 0.0, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 3.069983519294369, 'loop': 1, 'loss': 'MSE', 'lr': 0.007951246828381017, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00016901422917884598, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8
lr:  0.005155135342497737
weight_decay:  0.0004211114095041065
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.80% Test: 76.10%
Split: 01, Run: 01
None time:  2.5785562698729336
None Run 01:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.60% Test: 76.20%
Split: 01, Run: 02
None time:  2.4661325667984784
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.80% Test: 75.70%
Split: 01, Run: 03
None time:  2.542392607079819
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 75.70
run time now: 7.627456426620483
total time:  7.664817557903007
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 75.90 ± 0.20
[I 2023-06-12 00:15:07,639] Trial 31 finished with value: 78.06666564941406 and parameters: {'Fwd': 0.00012958692307150668, 'K': 6, 'alpha': 0.8, 'dropout': 0.30000000000000004, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 9.047014444972266, 'loop': 0, 'loss': 'MSE', 'lr': 0.005155135342497737, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004211114095041065, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.0025075103556155896
weight_decay:  0.000403794170500728
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.00% Test: 76.30%
Split: 01, Run: 01
None time:  2.803599987877533
None Run 01:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 02
None time:  1.2175552749540657
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 80.20% Test: 78.70%
Split: 01, Run: 03
None time:  2.669104191940278
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.70
run time now: 6.73901104927063
total time:  6.782968566054478
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.40 ± 2.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 1.71
[I 2023-06-12 00:15:14,900] Trial 32 finished with value: 79.4000015258789 and parameters: {'Fwd': 0.00023915946032125233, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 9.230406127849857, 'loop': 0, 'loss': 'MSE', 'lr': 0.0025075103556155896, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000403794170500728, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.7000000000000001
lr:  0.0026460148289371927
weight_decay:  0.000236713672405271
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.80% Test: 76.30%
Split: 01, Run: 01
None time:  2.9712945439387113
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 02
None time:  1.1757595529779792
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 80.40% Test: 77.10%
Split: 01, Run: 03
None time:  3.073416210943833
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.10
run time now: 7.265798807144165
total time:  7.310240883147344
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.73 ± 1.81
  Final Train: 100.00 ± 0.00
   Final Test: 76.53 ± 0.49
[I 2023-06-12 00:15:22,786] Trial 33 finished with value: 78.73333740234375 and parameters: {'Fwd': 0.0006122145935020286, 'K': 8, 'alpha': 0.7000000000000001, 'dropout': 0.2, 'gnnepoch': 120, 'lambda1': 0.55, 'lambda2': 9.424772970570016, 'loop': 0, 'loss': 'MSE', 'lr': 0.0026460148289371927, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000236713672405271, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.6000000000000001
lr:  0.00347643948313598
weight_decay:  0.0008673267745570398
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.381520451977849
None Run 01:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 75.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.80% Test: 76.50%
Split: 01, Run: 02
None time:  2.648458052193746
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 03
None time:  1.4178520548157394
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.00
run time now: 5.498388290405273
total time:  5.542823298135772
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.47 ± 1.67
  Final Train: 100.00 ± 0.00
   Final Test: 76.20 ± 0.92
[I 2023-06-12 00:15:28,741] Trial 34 finished with value: 77.46666717529297 and parameters: {'Fwd': 0.0002612417452693211, 'K': 7, 'alpha': 0.6000000000000001, 'dropout': 0.1, 'gnnepoch': 120, 'lambda1': 0.4, 'lambda2': 8.464322470588119, 'loop': 0, 'loss': 'MSE', 'lr': 0.00347643948313598, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008673267745570398, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.002560005214908762
weight_decay:  6.7655372806444e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8078633199911565
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  1.8742816199082881
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  2.11096741608344
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.835947513580322
total time:  6.8861880821641535
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 77.50 ± 1.05
[I 2023-06-12 00:15:36,049] Trial 35 finished with value: 79.73332977294922 and parameters: {'Fwd': 5.4501953176254e-05, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.55, 'lambda2': 9.410545326174313, 'loop': 1, 'loss': 'MSE', 'lr': 0.002560005214908762, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.7655372806444e-05, 'weightedloss': False}. Best is trial 20 with value: 81.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.0016308630800190974
weight_decay:  6.266588524462078e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.33375173388049
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 02
None time:  1.8301707650534809
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  1.803220132831484
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.10
run time now: 5.049852132797241
total time:  5.10755088320002
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 1.85
[I 2023-06-12 00:15:41,703] Trial 36 finished with value: 81.33333587646484 and parameters: {'Fwd': 3.254363763525761e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 9.339513797973689, 'loop': 1, 'loss': 'MSE', 'lr': 0.0016308630800190974, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.266588524462078e-05, 'weightedloss': True}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0014996172924092192
weight_decay:  0.00011562658189151232
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7568022250197828
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 02
None time:  1.249126638052985
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 98.33
   Final Test: 77.30
Split: 01, Run: 03
None time:  1.2475493580568582
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.70
run time now: 3.299283504486084
total time:  3.3497717091813684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.13 ± 5.90
  Final Train: 99.44 ± 0.96
   Final Test: 76.00 ± 4.49
[I 2023-06-12 00:15:45,492] Trial 37 finished with value: 78.13333129882812 and parameters: {'Fwd': 3.68893774618669e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 8.61918397558096, 'loop': 1, 'loss': 'CE', 'lr': 0.0014996172924092192, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011562658189151232, 'weightedloss': True}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.000811843970480752
weight_decay:  2.3001518109084836e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5518262588884681
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  0.5490538361482322
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  0.5686111720278859
None Run 03:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 1.7149019241333008
total time:  1.7622976119164377
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.80 ± 0.00
[I 2023-06-12 00:15:47,660] Trial 38 finished with value: 70.20000457763672 and parameters: {'Fwd': 9.345825326369705e-05, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 0, 'lambda1': 0.30000000000000004, 'lambda2': 7.812623268504137, 'loop': 1, 'loss': 'MSE', 'lr': 0.000811843970480752, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.3001518109084836e-05, 'weightedloss': True}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.003368657420026055
weight_decay:  0.00016977184836480867
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1520171568263322
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 74.00
Split: 01, Run: 02
None time:  0.936703909188509
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 03
None time:  1.4273100751452148
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
run time now: 3.5629661083221436
total time:  3.609211331931874
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.40 ± 2.27
  Final Train: 100.00 ± 0.00
   Final Test: 76.53 ± 2.30
[I 2023-06-12 00:15:51,732] Trial 39 finished with value: 79.4000015258789 and parameters: {'Fwd': 2.5486164759016817e-05, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 9.388556105078365, 'loop': 1, 'loss': 'MSE', 'lr': 0.003368657420026055, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00016977184836480867, 'weightedloss': True}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.75
lr:  0.00204636746728137
weight_decay:  6.933582710946928e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2928225679788738
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  1.2533313541207463
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 03
None time:  1.4109716890379786
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 98.33
   Final Test: 78.50
run time now: 4.004641056060791
total time:  4.045858565950766
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 0.95
  Final Train: 99.44 ± 0.96
   Final Test: 77.60 ± 0.82
[I 2023-06-12 00:15:56,275] Trial 40 finished with value: 79.33333587646484 and parameters: {'Fwd': 0.0003789720970051278, 'K': 4, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 8.691050602649428, 'loop': 2, 'loss': 'CE', 'lr': 0.00204636746728137, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.933582710946928e-05, 'weightedloss': True}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.55
lr:  0.002491215445057662
weight_decay:  5.926245939308773e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5733343390747905
None Run 01:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 76.10
Split: 01, Run: 02
None time:  1.5355609050020576
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.3061060179024935
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 77.20
run time now: 4.463326454162598
total time:  4.511985719902441
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.40 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 77.17 ± 1.05
[I 2023-06-12 00:16:01,342] Trial 41 finished with value: 78.4000015258789 and parameters: {'Fwd': 5.034774383025325e-05, 'K': 7, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.4, 'lambda2': 9.498308122662904, 'loop': 1, 'loss': 'MSE', 'lr': 0.002491215445057662, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.926245939308773e-05, 'weightedloss': True}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.004027134861033404
weight_decay:  9.576389239146771e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3985422258265316
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  0.9963717269711196
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.4385246629826725
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.70
run time now: 3.885507106781006
total time:  3.93540320196189
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.60
[I 2023-06-12 00:16:05,671] Trial 42 finished with value: 79.13333129882812 and parameters: {'Fwd': 8.367588444518429e-05, 'K': 8, 'alpha': 0.65, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 9.462412554850559, 'loop': 1, 'loss': 'MSE', 'lr': 0.004027134861033404, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.576389239146771e-05, 'weightedloss': True}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.75
lr:  0.003268950904368674
weight_decay:  4.681525008442185e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2448759800754488
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 02
None time:  1.1983788618817925
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.3785957868676633
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 76.70
run time now: 3.8655905723571777
total time:  3.9110222591552883
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 76.67 ± 1.35
[I 2023-06-12 00:16:10,065] Trial 43 finished with value: 79.5999984741211 and parameters: {'Fwd': 3.344574236572565e-05, 'K': 6, 'alpha': 0.75, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 9.99370752524815, 'loop': 1, 'loss': 'MSE', 'lr': 0.003268950904368674, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.681525008442185e-05, 'weightedloss': False}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.9
lr:  0.0016081080215640856
weight_decay:  2.2552514549796766e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7596119970548898
None Run 01:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 02
None time:  1.1705846211407334
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 03
None time:  1.0375963980332017
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 3.0089001655578613
total time:  3.0575669889803976
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.07 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 76.57 ± 1.30
[I 2023-06-12 00:16:13,676] Trial 44 finished with value: 79.06665802001953 and parameters: {'Fwd': 1.872677209016309e-05, 'K': 5, 'alpha': 0.9, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 8.29688884229423, 'loop': 1, 'loss': 'MSE', 'lr': 0.0016081080215640856, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2552514549796766e-05, 'weightedloss': True}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.0028148573211726
weight_decay:  0.000145476223962776
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7150034359656274
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 02
None time:  2.033434512093663
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.3375392251182348
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 76.60
run time now: 5.1294944286346436
total time:  5.176369698951021
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.07 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 76.93 ± 0.58
[I 2023-06-12 00:16:19,261] Trial 45 finished with value: 79.06666564941406 and parameters: {'Fwd': 7.462311257345786e-05, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 110, 'lambda1': 0.55, 'lambda2': 8.806364395685318, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028148573211726, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000145476223962776, 'weightedloss': False}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0020907378090920144
weight_decay:  0.0006471779986696478
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0481381891295314
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.456660286989063
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  0.8244515769183636
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 3.371809244155884
total time:  3.4158959600608796
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 0.81
[I 2023-06-12 00:16:23,165] Trial 46 finished with value: 80.79999542236328 and parameters: {'Fwd': 9.146349265685479e-06, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 60, 'lambda1': 0.15000000000000002, 'lambda2': 9.45357176308195, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020907378090920144, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006471779986696478, 'weightedloss': False}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0020744153189269725
weight_decay:  0.0014339615815063605
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0564009121153504
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 02
None time:  2.259298738790676
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 03
None time:  2.409588106907904
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.00
run time now: 6.7756781578063965
total time:  6.823538014898077
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.73 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 76.40 ± 0.36
[I 2023-06-12 00:16:30,467] Trial 47 finished with value: 77.73333740234375 and parameters: {'Fwd': 9.044035176654971e-06, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.1, 'gnnepoch': 60, 'lambda1': 0.15000000000000002, 'lambda2': 9.701612209862592, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020744153189269725, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0014339615815063605, 'weightedloss': True}. Best is trial 36 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0013161977757559576
weight_decay:  0.0006767481502592912
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1822283300571144
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.243958994979039
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.4169931719079614
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.892749786376953
total time:  4.946453502867371
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 79.47 ± 1.25
[I 2023-06-12 00:16:35,869] Trial 48 finished with value: 81.53333282470703 and parameters: {'Fwd': 3.979867008319731e-06, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 50, 'lambda1': 0.05, 'lambda2': 8.246034073718224, 'loop': 2, 'loss': 'MSE', 'lr': 0.0013161977757559576, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006767481502592912, 'weightedloss': False}. Best is trial 48 with value: 81.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.9500000000000001
lr:  0.001006980262109759
weight_decay:  0.0006095280501591056
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1234442919958383
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  1.0594177460297942
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  1.068539029918611
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.00
run time now: 3.3141720294952393
total time:  3.417070942930877
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 72.00 ± 0.00
[I 2023-06-12 00:16:39,745] Trial 49 finished with value: 73.4000015258789 and parameters: {'Fwd': 4.3086433712285545e-06, 'K': 4, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 40, 'lambda1': 0.0, 'lambda2': 8.049140992520535, 'loop': 2, 'loss': 'MSE', 'lr': 0.001006980262109759, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006095280501591056, 'weightedloss': False}. Best is trial 48 with value: 81.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8
lr:  0.001417553356682082
weight_decay:  0.0027041045654275556
dropout:  0.0
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.753466472029686
None Run 01:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 02
None time:  0.9080908549949527
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.0886748949997127
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.90
run time now: 2.79171085357666
total time:  2.838391182012856
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.47 ± 7.57
  Final Train: 100.00 ± 0.00
   Final Test: 75.13 ± 6.10
[I 2023-06-12 00:16:43,099] Trial 50 finished with value: 76.46666717529297 and parameters: {'Fwd': 1.846094478425923e-06, 'K': 5, 'alpha': 0.8, 'dropout': 0.0, 'gnnepoch': 40, 'lambda1': 0.1, 'lambda2': 6.270922567036455, 'loop': 2, 'loss': 'MSE', 'lr': 0.001417553356682082, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0027041045654275556, 'weightedloss': False}. Best is trial 48 with value: 81.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  1.0
lr:  0.0018723392830442263
weight_decay:  0.000843977174898508
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.494236207101494
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  0.8317461300175637
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  0.8609231400769204
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.50
run time now: 3.23598575592041
total time:  3.277180502889678
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 2.16
  Final Train: 100.00 ± 0.00
   Final Test: 77.50 ± 1.73
[I 2023-06-12 00:16:46,846] Trial 51 finished with value: 79.86666870117188 and parameters: {'Fwd': 1.0519302844077844e-05, 'K': 6, 'alpha': 1.0, 'dropout': 0.2, 'gnnepoch': 50, 'lambda1': 0.05, 'lambda2': 8.627459881820345, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018723392830442263, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000843977174898508, 'weightedloss': False}. Best is trial 48 with value: 81.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.0012907818355673865
weight_decay:  0.0003294686467881127
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.168093192856759
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.3013002390507609
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  0.9268415330443531
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 79.90
run time now: 4.443978548049927
total time:  4.502283507026732
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 78.93 ± 0.95
[I 2023-06-12 00:16:51,909] Trial 52 finished with value: 81.33333587646484 and parameters: {'Fwd': 4.2006545283743925e-06, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.2, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 8.94863089416723, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012907818355673865, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003294686467881127, 'weightedloss': False}. Best is trial 48 with value: 81.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.0012284601313462516
weight_decay:  0.0003220410725438849
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.592415879946202
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 02
None time:  1.4467885801568627
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  0.9898555991239846
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.80
run time now: 4.090518236160278
total time:  4.15334791992791
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 1.80
  Final Train: 100.00 ± 0.00
   Final Test: 77.87 ± 0.95
[I 2023-06-12 00:16:56,500] Trial 53 finished with value: 81.13333129882812 and parameters: {'Fwd': 2.8684027233368724e-06, 'K': 6, 'alpha': 0.9, 'dropout': 0.2, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 7.415622172024742, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012284601313462516, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003220410725438849, 'weightedloss': False}. Best is trial 48 with value: 81.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.9
lr:  0.0012333238123417585
weight_decay:  0.0002637032755520611
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.411168470978737
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.0340795579832047
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.603618772001937
None Run 03:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 79.60
run time now: 5.095972299575806
total time:  5.146392566850409
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.07 ± 1.85
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 1.05
[I 2023-06-12 00:17:02,079] Trial 54 finished with value: 82.06666564941406 and parameters: {'Fwd': 2.53952750874469e-06, 'K': 5, 'alpha': 0.9, 'dropout': 0.1, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 7.377022060176429, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012333238123417585, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002637032755520611, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.9
lr:  0.0012742685456550204
weight_decay:  0.0003266547692820933
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3010595571249723
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.6962998828385025
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  1.0884789528790861
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.70
run time now: 5.12635350227356
total time:  5.166915526846424
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 78.90 ± 1.11
[I 2023-06-12 00:17:07,694] Trial 55 finished with value: 80.79999542236328 and parameters: {'Fwd': 1.1313972717977776e-06, 'K': 5, 'alpha': 0.9, 'dropout': 0.1, 'gnnepoch': 50, 'lambda1': 0.25, 'lambda2': 7.336182189722548, 'loop': 2, 'loss': 'MSE', 'lr': 0.0012742685456550204, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003266547692820933, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.8500000000000001
lr:  0.0010329818137049284
weight_decay:  0.00026816092946634437
dropout:  0.0
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5161994460504502
None Run 01:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 42.20
Split: 01, Run: 02
None time:  0.7173590650781989
None Run 02:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 03
None time:  1.054868380073458
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.80
run time now: 2.324169635772705
total time:  2.376565596787259
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.80 ± 19.06
  Final Train: 100.00 ± 0.00
   Final Test: 65.27 ± 19.98
[I 2023-06-12 00:17:10,516] Trial 56 finished with value: 66.79999542236328 and parameters: {'Fwd': 2.9603631257574732e-06, 'K': 3, 'alpha': 0.8500000000000001, 'dropout': 0.0, 'gnnepoch': 30, 'lambda1': 0.25, 'lambda2': 7.677849367762157, 'loop': 1, 'loss': 'MSE', 'lr': 0.0010329818137049284, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00026816092946634437, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8500000000000001
lr:  0.000587672252603408
weight_decay:  0.0012883529852683398
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8504911169875413
None Run 01:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 72.90
Split: 01, Run: 02
None time:  0.9939147920813411
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 03
None time:  0.9818735609296709
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 98.33
   Final Test: 79.10
run time now: 2.869201183319092
total time:  2.9226900511421263
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 1.71
  Final Train: 99.44 ± 0.96
   Final Test: 75.87 ± 3.11
[I 2023-06-12 00:17:13,893] Trial 57 finished with value: 78.20000457763672 and parameters: {'Fwd': 2.1085528924729817e-06, 'K': 5, 'alpha': 0.8500000000000001, 'dropout': 0.1, 'gnnepoch': 60, 'lambda1': 0.35000000000000003, 'lambda2': 7.141774128272155, 'loop': 1, 'loss': 'CE', 'lr': 0.000587672252603408, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0012883529852683398, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.0011504351797242747
weight_decay:  0.0005872825945048748
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6687090070918202
None Run 01:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 02
None time:  2.9814535030163825
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 74.00
Split: 01, Run: 03
None time:  1.910228522028774
None Run 03:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 70.30
run time now: 6.599338054656982
total time:  6.662507550092414
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.47 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 73.20 ± 2.59
[I 2023-06-12 00:17:21,126] Trial 58 finished with value: 75.46666717529297 and parameters: {'Fwd': 3.1612742739458443e-06, 'K': 2, 'alpha': 0.9, 'dropout': 0.1, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 6.692966954178351, 'loop': 1, 'loss': 'MSE', 'lr': 0.0011504351797242747, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0005872825945048748, 'weightedloss': True}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.9
lr:  0.0008829952022861023
weight_decay:  0.00019521692384857504
dropout:  0.0
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6775692291557789
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 02
None time:  0.9985294200014323
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  0.7758806850761175
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.20
run time now: 3.492033004760742
total time:  3.5544619420543313
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 77.17 ± 0.95
[I 2023-06-12 00:17:25,140] Trial 59 finished with value: 80.4000015258789 and parameters: {'Fwd': 5.849137189457212e-06, 'K': 4, 'alpha': 0.9, 'dropout': 0.0, 'gnnepoch': 50, 'lambda1': 0.1, 'lambda2': 7.569258580555079, 'loop': 1, 'loss': 'MSE', 'lr': 0.0008829952022861023, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00019521692384857504, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  1.0
lr:  0.0013157716049879069
weight_decay:  0.00029086518427634994
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3149347801227123
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 02
None time:  1.1164943720214069
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 03
None time:  1.0064729831647128
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.40
run time now: 3.4842419624328613
total time:  3.534901143051684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 77.10 ± 0.26
[I 2023-06-12 00:17:29,172] Trial 60 finished with value: 79.13333129882812 and parameters: {'Fwd': 1.032569935298427e-06, 'K': 8, 'alpha': 1.0, 'dropout': 0.4, 'gnnepoch': 40, 'lambda1': 0.35000000000000003, 'lambda2': 8.077199763247688, 'loop': 2, 'loss': 'MSE', 'lr': 0.0013157716049879069, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00029086518427634994, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0016986216923996012
weight_decay:  0.0006091699802104761
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2811117190867662
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.2850865619257092
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.3162995839957148
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.30
run time now: 3.9283900260925293
total time:  3.9769072299823165
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 0.79
[I 2023-06-12 00:17:33,682] Trial 61 finished with value: 80.73333740234375 and parameters: {'Fwd': 4.13014198133408e-06, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 60, 'lambda1': 0.15000000000000002, 'lambda2': 8.40975253765229, 'loop': 1, 'loss': 'MSE', 'lr': 0.0016986216923996012, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006091699802104761, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.001485550911693597
weight_decay:  0.00012562199721547024
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8822443161625415
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  1.370490944944322
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.5695055518299341
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.30
run time now: 3.86691951751709
total time:  3.917551001999527
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 77.63 ± 1.07
[I 2023-06-12 00:17:38,125] Trial 62 finished with value: 80.86666870117188 and parameters: {'Fwd': 7.274319141669895e-06, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 7.8503934575228005, 'loop': 1, 'loss': 'MSE', 'lr': 0.001485550911693597, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012562199721547024, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  1.0
lr:  0.0013726964037176737
weight_decay:  0.00012228809115240015
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9603924639523029
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 74.90
Split: 01, Run: 02
None time:  1.4025315470062196
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  2.608599927974865
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.00
run time now: 5.014161586761475
total time:  5.067232955945656
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.00 ± 1.93
  Final Train: 100.00 ± 0.00
   Final Test: 77.20 ± 2.10
[I 2023-06-12 00:17:43,658] Trial 63 finished with value: 79.0 and parameters: {'Fwd': 7.032697457966282e-06, 'K': 5, 'alpha': 1.0, 'dropout': 0.1, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 7.68279831880603, 'loop': 1, 'loss': 'MSE', 'lr': 0.0013726964037176737, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00012228809115240015, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.0011345609186479788
weight_decay:  0.00015031142497678348
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2200584020465612
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  3.2066466209944338
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.3149493529926986
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.780117750167847
total time:  5.824729060987011
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 78.80 ± 1.30
[I 2023-06-12 00:17:50,039] Trial 64 finished with value: 81.73332977294922 and parameters: {'Fwd': 1.8364073750048432e-06, 'K': 6, 'alpha': 0.9, 'dropout': 0.2, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.198311292329334, 'loop': 1, 'loss': 'MSE', 'lr': 0.0011345609186479788, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00015031142497678348, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8
lr:  0.0011141667072337505
weight_decay:  0.00022194135013463382
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1620566509664059
None Run 01:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 75.70
Split: 01, Run: 02
None time:  1.1409028838388622
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.4625431559979916
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.40
run time now: 3.8073322772979736
total time:  3.858912296127528
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 2.39
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 1.97
[I 2023-06-12 00:17:54,369] Trial 65 finished with value: 80.53333282470703 and parameters: {'Fwd': 1.791759574851155e-06, 'K': 5, 'alpha': 0.8, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 8.878260261391365, 'loop': 1, 'loss': 'MSE', 'lr': 0.0011141667072337505, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00022194135013463382, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0009183837535134037
weight_decay:  0.000328358453439123
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9521671268157661
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  1.1902134490665048
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 03
None time:  1.1734425169415772
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.70
run time now: 3.360386610031128
total time:  3.4092807369306684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 77.87 ± 0.74
[I 2023-06-12 00:17:58,201] Trial 66 finished with value: 80.86666870117188 and parameters: {'Fwd': 2.3655260686597474e-06, 'K': 7, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.303271128611458, 'loop': 1, 'loss': 'MSE', 'lr': 0.0009183837535134037, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000328358453439123, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8500000000000001
lr:  0.001154041285087692
weight_decay:  0.0001879829762801207
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6629541320726275
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  1.0582939088344574
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0680, Train: 100.00%, Valid: 81.40% Test: 81.30%
Split: 01, Run: 03
None time:  2.826808544108644
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.595454454421997
total time:  5.6481342560146
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.80 ± 3.22
  Final Train: 100.00 ± 0.00
   Final Test: 76.80 ± 3.70
[I 2023-06-12 00:18:04,262] Trial 67 finished with value: 78.79999542236328 and parameters: {'Fwd': 1.4233729906314343e-06, 'K': 6, 'alpha': 0.8500000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 7.27070722792695, 'loop': 1, 'loss': 'MSE', 'lr': 0.001154041285087692, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001879829762801207, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.35000000000000003
lr:  0.0017806305590773405
weight_decay:  0.0004583207591465438
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0322496329899877
None Run 01:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02
None time:  0.8295072978362441
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.70
Split: 01, Run: 03
None time:  0.8022433938458562
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 74.90
run time now: 2.7104954719543457
total time:  2.7567032938823104
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.40 ± 2.03
  Final Train: 100.00 ± 0.00
   Final Test: 72.90 ± 2.50
[I 2023-06-12 00:18:07,507] Trial 68 finished with value: 74.4000015258789 and parameters: {'Fwd': 3.6920967377532805e-06, 'K': 7, 'alpha': 0.35000000000000003, 'dropout': 0.2, 'gnnepoch': 50, 'lambda1': 0.1, 'lambda2': 8.00277506272433, 'loop': 1, 'loss': 'CE', 'lr': 0.0017806305590773405, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004583207591465438, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.0007238306800118632
weight_decay:  8.959068320930715e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0108, Train: 100.00%, Valid: 76.60% Test: 74.80%
Split: 01, Run: 01
None time:  4.93714304594323
None Run 01:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.00
Split: 01, Run: 02
None time:  1.90488545387052
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  2.3618050899822265
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.00
run time now: 9.24537706375122
total time:  9.300774854142219
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.80 ± 1.80
  Final Train: 100.00 ± 0.00
   Final Test: 73.30 ± 1.57
[I 2023-06-12 00:18:17,420] Trial 69 finished with value: 74.80000305175781 and parameters: {'Fwd': 2.789227741912511e-06, 'K': 6, 'alpha': 0.9, 'dropout': 0.1, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 6.969822235780018, 'loop': 1, 'loss': 'MSE', 'lr': 0.0007238306800118632, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.959068320930715e-05, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.0015843139677761485
weight_decay:  0.00014171410816675464
dropout:  0.0
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6044005251023918
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 02
None time:  1.1576798481401056
None Run 02:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.20
Split: 01, Run: 03
None time:  0.8082541681360453
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 75.40
run time now: 2.6532037258148193
total time:  2.722681515151635
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.47 ± 2.41
  Final Train: 100.00 ± 0.00
   Final Test: 72.47 ± 2.81
[I 2023-06-12 00:18:20,688] Trial 70 finished with value: 72.46666717529297 and parameters: {'Fwd': 4.930815707593781e-06, 'K': 8, 'alpha': 0.2, 'dropout': 0.0, 'gnnepoch': 30, 'lambda1': 0.4, 'lambda2': 8.92659059666961, 'loop': 1, 'loss': 'MSE', 'lr': 0.0015843139677761485, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00014171410816675464, 'weightedloss': True}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0013314622274204573
weight_decay:  0.00017880234418509987
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7669958239421248
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.5174169049132615
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.0108879879117012
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.10
run time now: 4.337550163269043
total time:  4.379731738939881
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 78.97 ± 1.21
[I 2023-06-12 00:18:25,542] Trial 71 finished with value: 80.80000305175781 and parameters: {'Fwd': 7.342736106091735e-06, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.2, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 7.7848355883534355, 'loop': 1, 'loss': 'MSE', 'lr': 0.0013314622274204573, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00017880234418509987, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  1.0
lr:  0.0010317864256054862
weight_decay:  0.00010533014299824665
dropout:  0.2
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0038155079819262
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 02
None time:  1.1172089490573853
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 03
None time:  1.0400839939247817
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 75.80
run time now: 3.204464912414551
total time:  3.25275260489434
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 75.87 ± 0.31
[I 2023-06-12 00:18:29,280] Trial 72 finished with value: 78.93333435058594 and parameters: {'Fwd': 1.5384072963675487e-06, 'K': 5, 'alpha': 1.0, 'dropout': 0.2, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 7.509558047099422, 'loop': 1, 'loss': 'MSE', 'lr': 0.0010317864256054862, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00010533014299824665, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.75
lr:  0.0014453732470527186
weight_decay:  0.0003035993344912953
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0392239571083337
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  1.9735109619796276
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  0.9450750821270049
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.10
run time now: 4.999935626983643
total time:  5.042253162013367
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 1.79
  Final Train: 100.00 ± 0.00
   Final Test: 77.63 ± 1.82
[I 2023-06-12 00:18:34,801] Trial 73 finished with value: 80.46666717529297 and parameters: {'Fwd': 3.4911937314183783e-06, 'K': 6, 'alpha': 0.75, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 8.164968284615979, 'loop': 1, 'loss': 'MSE', 'lr': 0.0014453732470527186, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003035993344912953, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8500000000000001
lr:  0.001728595660762412
weight_decay:  0.00014321661202202507
dropout:  0.1
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.132999252062291
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  0.8425254721660167
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 03
None time:  0.7520017339847982
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.80
run time now: 3.788449287414551
total time:  3.843614008044824
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.53 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 76.67 ± 1.10
[I 2023-06-12 00:18:39,147] Trial 74 finished with value: 79.53333282470703 and parameters: {'Fwd': 2.198859846915953e-06, 'K': 7, 'alpha': 0.8500000000000001, 'dropout': 0.1, 'gnnepoch': 50, 'lambda1': 0.35000000000000003, 'lambda2': 8.52615087487048, 'loop': 1, 'loss': 'MSE', 'lr': 0.001728595660762412, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00014321661202202507, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0012444321348835429
weight_decay:  0.0009197423191352963
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1651, Train: 100.00%, Valid: 80.60% Test: 76.50%
Split: 01, Run: 01
None time:  3.0857984800823033
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  2.4085812519770116
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  1.6699591248761863
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.20
run time now: 7.209567070007324
total time:  7.255350121064112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 77.53 ± 1.47
[I 2023-06-12 00:18:46,907] Trial 75 finished with value: 81.26666259765625 and parameters: {'Fwd': 1.1726233228732284e-05, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 7.88096824289544, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012444321348835429, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009197423191352963, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.8
lr:  0.0022433488532113926
weight_decay:  0.0009985086656034874
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.017919820966199
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  1.0689390520565212
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.414954778039828
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.20
run time now: 4.543537855148315
total time:  4.587197608081624
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 1.40
[I 2023-06-12 00:18:52,035] Trial 76 finished with value: 80.93333435058594 and parameters: {'Fwd': 1.4017384893843312e-05, 'K': 7, 'alpha': 0.8, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 8.73339851387806, 'loop': 1, 'loss': 'MSE', 'lr': 0.0022433488532113926, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009985086656034874, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.9
lr:  0.0011418689943320127
weight_decay:  0.0003858961477130869
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0998397388029844
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  0.9577652330044657
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 03
None time:  1.362326803151518
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.10
run time now: 3.462658166885376
total time:  3.5021466170437634
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 77.47 ± 1.60
[I 2023-06-12 00:18:56,037] Trial 77 finished with value: 80.86666870117188 and parameters: {'Fwd': 5.085932518132649e-06, 'K': 5, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 8.365624288693857, 'loop': 1, 'loss': 'MSE', 'lr': 0.0011418689943320127, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003858961477130869, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.000881697097671672
weight_decay:  0.00023084619697166073
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2681846199557185
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 02
None time:  1.1452786610461771
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 03
None time:  1.2531428521033376
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.40
run time now: 3.7120275497436523
total time:  3.7676126109436154
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.40 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 76.80 ± 0.60
[I 2023-06-12 00:19:00,271] Trial 78 finished with value: 79.4000015258789 and parameters: {'Fwd': 1.1667434407618762e-05, 'K': 8, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 9.09320161642675, 'loop': 1, 'loss': 'MSE', 'lr': 0.000881697097671672, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00023084619697166073, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.45
lr:  0.0018939775420527788
weight_decay:  0.0007627425615972403
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.252087441040203
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 98.33
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.171737986849621
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.2264575329609215
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.30
run time now: 3.6921989917755127
total time:  3.7440969001036137
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.64
  Final Train: 99.44 ± 0.96
   Final Test: 78.87 ± 1.27
[I 2023-06-12 00:19:04,458] Trial 79 finished with value: 80.0666732788086 and parameters: {'Fwd': 1.8807735214408984e-05, 'K': 6, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 9.686976738020288, 'loop': 1, 'loss': 'CE', 'lr': 0.0018939775420527788, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007627425615972403, 'weightedloss': True}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0012456458636343603
weight_decay:  0.0004948857451350149
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4950208070222288
None Run 01:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.0966211950872093
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.3812369368970394
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.20
run time now: 4.013982534408569
total time:  4.051691115833819
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.57 ± 0.65
[I 2023-06-12 00:19:09,038] Trial 80 finished with value: 81.80000305175781 and parameters: {'Fwd': 2.5981422477926193e-06, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 7.4736152825292255, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012456458636343603, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004948857451350149, 'weightedloss': False}. Best is trial 54 with value: 82.06666564941406.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0012702164203162254
weight_decay:  0.0004664044610896143
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6287623799871653
None Run 01:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.0394939589314163
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  0.8131874210666865
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.40
run time now: 3.5263822078704834
total time:  3.5685682559851557
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 1.21
[I 2023-06-12 00:19:13,114] Trial 81 finished with value: 82.26667022705078 and parameters: {'Fwd': 2.445779019583189e-06, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 7.421037217858997, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012702164203162254, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004664044610896143, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.0012965402550960104
weight_decay:  0.0005025646119789928
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.094378156820312
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.125190278980881
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.4444894730113447
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.20
run time now: 4.714226722717285
total time:  4.764230472967029
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.25
[I 2023-06-12 00:19:18,456] Trial 82 finished with value: 80.66666412353516 and parameters: {'Fwd': 2.4368336242098513e-06, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 6.795816343719182, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012965402550960104, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005025646119789928, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  1.0
lr:  0.0012110664104724362
weight_decay:  0.0010418383723463213
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5200081430375576
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.1342536169104278
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.1025055251084268
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.10
run time now: 3.8058230876922607
total time:  3.858271824894473
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 3.06
  Final Train: 100.00 ± 0.00
   Final Test: 77.43 ± 1.22
[I 2023-06-12 00:19:22,848] Trial 83 finished with value: 79.73333740234375 and parameters: {'Fwd': 1.4810828322980316e-06, 'K': 6, 'alpha': 1.0, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 7.545507649118824, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012110664104724362, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0010418383723463213, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.0010183883814999445
weight_decay:  0.00047204823828346016
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3770869059953839
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 02
None time:  1.0893232359085232
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.3834616739768535
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.40
run time now: 3.896660327911377
total time:  3.9472278628963977
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 77.40 ± 0.40
[I 2023-06-12 00:19:27,224] Trial 84 finished with value: 80.86666870117188 and parameters: {'Fwd': 3.59448238856688e-06, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 90, 'lambda1': 0.35000000000000003, 'lambda2': 7.362567728168101, 'loop': 1, 'loss': 'MSE', 'lr': 0.0010183883814999445, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00047204823828346016, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0015567414450377165
weight_decay:  0.0007832960795840343
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.461025591008365
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 02
None time:  1.5578578361310065
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.5398961971513927
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.607445240020752
total time:  5.6549048570450395
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 1.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.87 ± 1.45
[I 2023-06-12 00:19:33,430] Trial 85 finished with value: 81.5999984741211 and parameters: {'Fwd': 5.8838055112128624e-06, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.4, 'lambda2': 7.916049619416819, 'loop': 1, 'loss': 'MSE', 'lr': 0.0015567414450377165, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007832960795840343, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8500000000000001
lr:  0.001585138183193868
weight_decay:  0.0015881680989736024
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4622182638850063
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 02
None time:  0.9824912510812283
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.7461976120248437
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.50
run time now: 4.246889352798462
total time:  4.2974057260435075
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 77.83 ± 1.42
[I 2023-06-12 00:19:38,277] Trial 86 finished with value: 81.5999984741211 and parameters: {'Fwd': 4.95197293654987e-06, 'K': 8, 'alpha': 0.8500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 7.986215468828916, 'loop': 1, 'loss': 'MSE', 'lr': 0.001585138183193868, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0015881680989736024, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0015340016155103958
weight_decay:  0.001873367224327153
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6422436931170523
None Run 01:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  2.0525757258292288
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 73.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0213, Train: 100.00%, Valid: 76.20% Test: 74.10%
Split: 01, Run: 03
None time:  5.206688959849998
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 73.90
run time now: 9.949053049087524
total time:  10.005286166910082
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 74.43 ± 1.01
[I 2023-06-12 00:19:48,714] Trial 87 finished with value: 75.66666412353516 and parameters: {'Fwd': 5.942858117372143e-06, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 8.107136164430807, 'loop': 1, 'loss': 'MSE', 'lr': 0.0015340016155103958, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001873367224327153, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0016676699446057021
weight_decay:  0.0007098762887047687
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1699852840974927
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  0.820403773104772
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.043665625853464
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.00
run time now: 4.080575942993164
total time:  4.129348212154582
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 1.40
[I 2023-06-12 00:19:53,271] Trial 88 finished with value: 80.66666412353516 and parameters: {'Fwd': 1.9002939984023727e-06, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 8.542718740795213, 'loop': 1, 'loss': 'MSE', 'lr': 0.0016676699446057021, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0007098762887047687, 'weightedloss': True}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0014267584141633056
weight_decay:  0.0013036232951848807
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.815238227834925
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.8799766728188843
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 75.00
Split: 01, Run: 03
None time:  2.093446178128943
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 3.835085153579712
total time:  3.8820051678922027
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.20 ± 6.24
  Final Train: 100.00 ± 0.00
   Final Test: 74.27 ± 4.54
[I 2023-06-12 00:19:57,719] Trial 89 finished with value: 76.19999694824219 and parameters: {'Fwd': 1.1288697254602625e-06, 'K': 8, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 9.238832647102159, 'loop': 1, 'loss': 'MSE', 'lr': 0.0014267584141633056, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0013036232951848807, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0019171802553103958
weight_decay:  0.00054939795900062
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7958629580680281
None Run 01:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.7508453058544546
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.681169067043811
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.2786078453063965
total time:  5.333260246086866
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.93 ± 6.53
  Final Train: 100.00 ± 0.00
   Final Test: 75.47 ± 5.17
[I 2023-06-12 00:20:03,540] Trial 90 finished with value: 77.9333267211914 and parameters: {'Fwd': 4.088502108804159e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 40, 'lambda1': 0.35000000000000003, 'lambda2': 6.528232225159902, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019171802553103958, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00054939795900062, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002242172768985877
weight_decay:  0.0008295115910854011
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1408583458978683
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 02
None time:  1.9882954158820212
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.7199585859198123
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
run time now: 4.920718431472778
total time:  4.978364972863346
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.99
[I 2023-06-12 00:20:09,146] Trial 91 finished with value: 81.0666732788086 and parameters: {'Fwd': 6.1468589747367205e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.30000000000000004, 'lambda2': 7.887689477472244, 'loop': 1, 'loss': 'MSE', 'lr': 0.002242172768985877, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008295115910854011, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0015837937578619707
weight_decay:  0.0010173435960232314
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8517991709522903
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.8270776600111276
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.5034496490843594
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.228261709213257
total time:  5.267433833098039
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 1.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.45
[I 2023-06-12 00:20:14,994] Trial 92 finished with value: 80.4000015258789 and parameters: {'Fwd': 4.555492734130501e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 7.021566209537176, 'loop': 1, 'loss': 'MSE', 'lr': 0.0015837937578619707, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0010173435960232314, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.8
lr:  0.001111128804975112
weight_decay:  0.001747254838903125
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3854015890974551
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 02
None time:  1.319877261063084
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 75.00
Split: 01, Run: 03
None time:  2.7667791799176484
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.513756036758423
total time:  5.566868667956442
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 76.40 ± 1.45
[I 2023-06-12 00:20:21,178] Trial 93 finished with value: 79.79999542236328 and parameters: {'Fwd': 7.986071034377656e-06, 'K': 8, 'alpha': 0.8, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 7.657428244156327, 'loop': 1, 'loss': 'MSE', 'lr': 0.001111128804975112, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001747254838903125, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0013101789410733492
weight_decay:  0.0026715793505753213
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.31459242105484
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  2.032708217855543
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.0760738849639893
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.20
run time now: 5.472526550292969
total time:  5.514856058172882
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.77 ± 1.29
[I 2023-06-12 00:20:27,247] Trial 94 finished with value: 82.0 and parameters: {'Fwd': 2.478514325322573e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.2, 'lambda2': 7.938494161215649, 'loop': 1, 'loss': 'MSE', 'lr': 0.0013101789410733492, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0026715793505753213, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0013987649934567744
weight_decay:  0.00639448133907866
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6179953610990196
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  1.8545785150490701
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 03
None time:  2.4619517100509256
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.20
run time now: 6.983947038650513
total time:  7.026124787982553
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 77.30 ± 0.78
[I 2023-06-12 00:20:34,818] Trial 95 finished with value: 80.5999984741211 and parameters: {'Fwd': 2.7667095497277173e-06, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 8.24714619163447, 'loop': 1, 'loss': 'MSE', 'lr': 0.0013987649934567744, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00639448133907866, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.001766707250819885
weight_decay:  0.0023538395524938705
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8045795599464327
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.3308096600230783
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.2579785089474171
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.40
run time now: 4.446197271347046
total time:  4.500290570082143
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.13 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 0.62
[I 2023-06-12 00:20:39,800] Trial 96 finished with value: 82.13333129882812 and parameters: {'Fwd': 1.7454950627437076e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 7.208219632501962, 'loop': 1, 'loss': 'MSE', 'lr': 0.001766707250819885, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0023538395524938705, 'weightedloss': False}. Best is trial 81 with value: 82.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0018265646107346817
weight_decay:  0.002851369619152034
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1839, Train: 100.00%, Valid: 82.80% Test: 78.40%
Split: 01, Run: 01
None time:  3.3688929879572242
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.9545626791659743
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.3235956120770425
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.70
run time now: 6.697200298309326
total time:  6.745772291207686
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.83 ± 0.51
[I 2023-06-12 00:20:47,136] Trial 97 finished with value: 82.53333282470703 and parameters: {'Fwd': 1.7557516340054431e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 7.262595521390204, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018265646107346817, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002851369619152034, 'weightedloss': False}. Best is trial 97 with value: 82.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.001814892373033509
weight_decay:  0.0025268977244496623
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1844, Train: 100.00%, Valid: 82.60% Test: 78.40%
Split: 01, Run: 01
None time:  3.663719888078049
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.1566807341296226
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  1.682797685964033
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 76.50
run time now: 6.5472025871276855
total time:  6.587498777080327
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.07 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 1.37
[I 2023-06-12 00:20:54,274] Trial 98 finished with value: 82.0666732788086 and parameters: {'Fwd': 1.7501573310428727e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 7.217488666560978, 'loop': 1, 'loss': 'MSE', 'lr': 0.001814892373033509, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0025268977244496623, 'weightedloss': False}. Best is trial 97 with value: 82.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0022985498938639637
weight_decay:  0.0027739385150697743
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9080055919475853
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 02
None time:  1.2524294999893755
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 98.33
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.1234283179510385
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.50
run time now: 3.334399938583374
total time:  3.3868635760154575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.53 ± 2.91
  Final Train: 99.44 ± 0.96
   Final Test: 76.10 ± 4.28
[I 2023-06-12 00:20:58,122] Trial 99 finished with value: 77.5333251953125 and parameters: {'Fwd': 1.7003466221893942e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 7.1858543989994885, 'loop': 1, 'loss': 'CE', 'lr': 0.0022985498938639637, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0027739385150697743, 'weightedloss': False}. Best is trial 97 with value: 82.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0018413669523216299
weight_decay:  0.0026773178256944107
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.815521796932444
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.10
Split: 01, Run: 02
None time:  2.055850184056908
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 74.70
Split: 01, Run: 03
None time:  1.7046118848957121
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 74.20
run time now: 6.623349189758301
total time:  6.668124817078933
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 75.00 ± 0.98
[I 2023-06-12 00:21:05,179] Trial 100 finished with value: 76.73333740234375 and parameters: {'Fwd': 1.2831403791442072e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 7.101654908523681, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018413669523216299, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0026773178256944107, 'weightedloss': False}. Best is trial 97 with value: 82.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0020680358977301916
weight_decay:  0.004723506887593588
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4209734301548451
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.050714640878141
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  2.1731370619963855
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.10
run time now: 4.694096565246582
total time:  4.739845438161865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.72
[I 2023-06-12 00:21:10,418] Trial 101 finished with value: 81.5999984741211 and parameters: {'Fwd': 2.320400736394241e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 7.29892806170036, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020680358977301916, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004723506887593588, 'weightedloss': False}. Best is trial 97 with value: 82.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0020417373995312797
weight_decay:  0.00400125777088147
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.67862176313065
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 02
None time:  1.2087846470531076
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  1.0907615879550576
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.70
run time now: 4.028372049331665
total time:  4.083392621949315
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 1.44
[I 2023-06-12 00:21:15,043] Trial 102 finished with value: 82.4000015258789 and parameters: {'Fwd': 2.176918041223777e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 7.3579098171397215, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020417373995312797, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00400125777088147, 'weightedloss': False}. Best is trial 97 with value: 82.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0017596101103029786
weight_decay:  0.0038903070346378455
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5092702060937881
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  2.6345309400931
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  2.2355010511819273
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.80
run time now: 6.426029682159424
total time:  6.479169698199257
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 78.97 ± 1.36
[I 2023-06-12 00:21:22,047] Trial 103 finished with value: 82.4000015258789 and parameters: {'Fwd': 1.0113636584294405e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 7.491204293093673, 'loop': 1, 'loss': 'MSE', 'lr': 0.0017596101103029786, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0038903070346378455, 'weightedloss': False}. Best is trial 97 with value: 82.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.002688813160726946
weight_decay:  0.004836799789766554
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1627663250546902
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 02
None time:  1.1030982451047748
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 03
None time:  1.4448844350408763
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.70
run time now: 4.763290643692017
total time:  4.805578229948878
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 77.23 ± 1.29
[I 2023-06-12 00:21:27,425] Trial 104 finished with value: 80.53333282470703 and parameters: {'Fwd': 1.0446602082689812e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 6.875126357183221, 'loop': 1, 'loss': 'MSE', 'lr': 0.002688813160726946, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004836799789766554, 'weightedloss': False}. Best is trial 97 with value: 82.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002076077104288313
weight_decay:  0.003217795852714664
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1758, Train: 100.00%, Valid: 79.80% Test: 78.80%
Split: 01, Run: 01
None time:  3.672689009923488
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.696636504959315
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  1.1191701099742204
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 79.20
run time now: 6.533447742462158
total time:  6.585325432009995
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 78.97 ± 0.21
[I 2023-06-12 00:21:34,594] Trial 105 finished with value: 81.00000762939453 and parameters: {'Fwd': 1.4128066301535776e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 6.598994656556666, 'loop': 1, 'loss': 'MSE', 'lr': 0.002076077104288313, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003217795852714664, 'weightedloss': False}. Best is trial 97 with value: 82.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.0024541130605338756
weight_decay:  0.006733635865172556
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5409061340615153
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.883189738029614
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.014068563003093
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.30
run time now: 5.534784555435181
total time:  5.612867736956105
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 1.53
  Final Train: 100.00 ± 0.00
   Final Test: 77.33 ± 1.77
[I 2023-06-12 00:21:40,688] Trial 106 finished with value: 78.93333435058594 and parameters: {'Fwd': 1.861418922171865e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.55, 'lambda2': 7.464948372220576, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024541130605338756, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.006733635865172556, 'weightedloss': False}. Best is trial 97 with value: 82.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0017527579140569822
weight_decay:  0.0021361705862199777
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6899189949035645
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.241336887003854
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  2.204629770014435
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.80
run time now: 5.186446666717529
total time:  5.2375838190782815
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 0.10
[I 2023-06-12 00:21:46,393] Trial 107 finished with value: 82.73332977294922 and parameters: {'Fwd': 1.2788196124167418e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 7.131047750637999, 'loop': 1, 'loss': 'MSE', 'lr': 0.0017527579140569822, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0021361705862199777, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0018392948802464365
weight_decay:  0.0021044597933961595
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.549861751962453
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  2.22317233402282
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.9167592320591211
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 77.40
run time now: 6.737865209579468
total time:  6.809752692934126
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.13 ± 2.21
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 0.65
[I 2023-06-12 00:21:53,677] Trial 108 finished with value: 80.13333892822266 and parameters: {'Fwd': 1.5662741063256319e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 6.946560417414041, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018392948802464365, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0021044597933961595, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.00168883876451629
weight_decay:  0.0037277336653925752
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4899626758415252
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 02
None time:  1.2675654259510338
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  2.731785431969911
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.20
run time now: 5.543686389923096
total time:  5.595314135076478
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 77.80 ± 1.31
[I 2023-06-12 00:21:59,807] Trial 109 finished with value: 81.86666870117188 and parameters: {'Fwd': 1.2438310547847579e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 7.063015940916325, 'loop': 1, 'loss': 'MSE', 'lr': 0.00168883876451629, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0037277336653925752, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0017259982764894406
weight_decay:  0.0037474832743036885
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1532941958867013
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  2.643256302922964
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  3.014701677020639
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.00
run time now: 7.856493949890137
total time:  7.907441642135382
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.70
[I 2023-06-12 00:22:08,257] Trial 110 finished with value: 80.86666107177734 and parameters: {'Fwd': 1.2384673970061936e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 6.464149400431928, 'loop': 1, 'loss': 'MSE', 'lr': 0.0017259982764894406, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0037474832743036885, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0019584499585705802
weight_decay:  0.002321099213609256
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5323922450188547
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 02
None time:  1.529415569966659
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  2.158951697871089
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.30
run time now: 5.386370420455933
total time:  5.430792629951611
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 77.57 ± 2.05
[I 2023-06-12 00:22:14,129] Trial 111 finished with value: 81.20000457763672 and parameters: {'Fwd': 2.047913488509471e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.55, 'lambda2': 7.14478480269956, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019584499585705802, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002321099213609256, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0014575290300168511
weight_decay:  0.00398031938396746
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1612959338817745
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 02
None time:  1.495072907069698
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 03
None time:  1.7115022740326822
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.00
run time now: 5.410233974456787
total time:  5.451283656060696
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 77.50 ± 1.41
[I 2023-06-12 00:22:20,154] Trial 112 finished with value: 81.33333587646484 and parameters: {'Fwd': 1.0314166205004433e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 6.734611145664193, 'loop': 1, 'loss': 'MSE', 'lr': 0.0014575290300168511, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00398031938396746, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0017408583733394681
weight_decay:  0.0075086578120396215
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.859884198056534
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.0988936468493193
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.477020493010059
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.70
run time now: 4.491772174835205
total time:  4.546621243003756
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 0.89
[I 2023-06-12 00:22:25,226] Trial 113 finished with value: 81.13333129882812 and parameters: {'Fwd': 2.6470511049625806e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 7.672485878111074, 'loop': 1, 'loss': 'MSE', 'lr': 0.0017408583733394681, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0075086578120396215, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.002215874458369915
weight_decay:  0.002190706027377547
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8657724549993873
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 02
None time:  1.0464383468497545
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.2518011629581451
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.80
run time now: 4.218358516693115
total time:  4.259639726020396
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.57 ± 0.87
[I 2023-06-12 00:22:30,038] Trial 114 finished with value: 82.53333282470703 and parameters: {'Fwd': 1.3487026317660077e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 7.300704600324021, 'loop': 1, 'loss': 'MSE', 'lr': 0.002215874458369915, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002190706027377547, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.0023646686810058003
weight_decay:  0.001661994284438431
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1639340471010655
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.0657428379636258
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  0.9416031138971448
None Run 03:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 76.30
run time now: 3.219790458679199
total time:  3.2733952628914267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 2.73
  Final Train: 100.00 ± 0.00
   Final Test: 77.63 ± 1.16
[I 2023-06-12 00:22:33,840] Trial 115 finished with value: 79.93333435058594 and parameters: {'Fwd': 1.3173100864906799e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 7.264364264122033, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023646686810058003, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001661994284438431, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0020667608816246
weight_decay:  0.0022216705238668026
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7702328788582236
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  0.6721559348516166
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.2676731401588768
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.10
run time now: 3.762498140335083
total time:  3.812704280950129
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.87 ± 0.32
[I 2023-06-12 00:22:38,092] Trial 116 finished with value: 82.53333282470703 and parameters: {'Fwd': 1.0059865515147148e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 6.908521635119531, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020667608816246, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0022216705238668026, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0028185962082591318
weight_decay:  0.0032746280823824007
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7387505560182035
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  1.2961361138150096
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.2445055819116533
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.10
run time now: 5.328221321105957
total time:  5.3973183198831975
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 1.89
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 0.92
[I 2023-06-12 00:22:44,061] Trial 117 finished with value: 80.9333267211914 and parameters: {'Fwd': 1.5440668504721868e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 6.160211891739253, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028185962082591318, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0032746280823824007, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002170898773116169
weight_decay:  0.002378920058138639
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0932064410299063
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.7392606299836189
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 98.33
   Final Test: 78.90
Split: 01, Run: 03
None time:  1.0302761469502002
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 98.33
   Final Test: 78.30
run time now: 2.9151322841644287
total time:  2.9577569160610437
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.60 ± 4.57
  Final Train: 98.89 ± 0.96
   Final Test: 76.07 ± 4.40
[I 2023-06-12 00:22:47,475] Trial 118 finished with value: 76.5999984741211 and parameters: {'Fwd': 3.1350279875700744e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 6.377870527684402, 'loop': 1, 'loss': 'CE', 'lr': 0.002170898773116169, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002378920058138639, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0019908276288231655
weight_decay:  0.002048650520309738
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3232, Train: 100.00%, Valid: 81.60% Test: 77.70%
Split: 01, Run: 01
None time:  3.437814672011882
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  1.0698553510010242
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.0253734779544175
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.40
run time now: 5.581016302108765
total time:  5.629540877882391
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.92
[I 2023-06-12 00:22:53,533] Trial 119 finished with value: 81.66666412353516 and parameters: {'Fwd': 1.2459316554124474e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 6.87228693666908, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019908276288231655, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002048650520309738, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0029367012841352677
weight_decay:  0.0013643981613651937
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.332201319048181
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  2.6849636579863727
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.065082130022347
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.90
run time now: 6.126163721084595
total time:  6.165483241900802
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 78.97 ± 1.21
[I 2023-06-12 00:23:00,299] Trial 120 finished with value: 82.4000015258789 and parameters: {'Fwd': 2.1056585189513807e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.036781417382259, 'loop': 1, 'loss': 'MSE', 'lr': 0.0029367012841352677, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0013643981613651937, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.003029512754522188
weight_decay:  0.001282596509811279
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.930689729982987
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.4509173170663416
None Run 02:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 74.80
Split: 01, Run: 03
None time:  1.010605308925733
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.10
run time now: 4.439648151397705
total time:  4.490495300851762
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.00 ± 3.30
  Final Train: 100.00 ± 0.00
   Final Test: 72.47 ± 2.71
[I 2023-06-12 00:23:05,311] Trial 121 finished with value: 73.0 and parameters: {'Fwd': 1.0329228835132683e-06, 'K': 9, 'alpha': 0.1, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.617773708991535, 'loop': 1, 'loss': 'MSE', 'lr': 0.003029512754522188, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001282596509811279, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.002502698339088866
weight_decay:  0.003584463494081031
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.445510658901185
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.340958908898756
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.1158430820796639
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.20
run time now: 4.964393615722656
total time:  5.018965648952872
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.07 ± 1.67
  Final Train: 100.00 ± 0.00
   Final Test: 78.77 ± 0.67
[I 2023-06-12 00:23:10,927] Trial 122 finished with value: 82.06665802001953 and parameters: {'Fwd': 2.0796666444145158e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 7.064151227996396, 'loop': 1, 'loss': 'MSE', 'lr': 0.002502698339088866, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003584463494081031, 'weightedloss': False}. Best is trial 107 with value: 82.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002681515017098236
weight_decay:  0.0027204300988228456
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.3425654501188546
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.3636748329736292
None Run 02:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.6451509920880198
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.80
run time now: 6.397979736328125
total time:  6.440901475027204
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.93 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 79.23 ± 1.12
[I 2023-06-12 00:23:17,915] Trial 123 finished with value: 82.93333435058594 and parameters: {'Fwd': 2.110038101994924e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.76166646536929, 'loop': 1, 'loss': 'MSE', 'lr': 0.002681515017098236, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0027204300988228456, 'weightedloss': False}. Best is trial 123 with value: 82.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002688500124372204
weight_decay:  0.0015035539453619508
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.005963935982436
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.7942491648718715
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.1052760249003768
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.20
run time now: 5.971508741378784
total time:  6.029336125822738
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.53 ± 0.59
[I 2023-06-12 00:23:24,449] Trial 124 finished with value: 81.53333282470703 and parameters: {'Fwd': 1.9352364978527282e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 5.868872474569157, 'loop': 1, 'loss': 'MSE', 'lr': 0.002688500124372204, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0015035539453619508, 'weightedloss': False}. Best is trial 123 with value: 82.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002441452185777674
weight_decay:  0.0019416933615435607
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2915190260391682
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  0.9883695929311216
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.779634808190167
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.137284517288208
total time:  5.192297102883458
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.95
[I 2023-06-12 00:23:30,219] Trial 125 finished with value: 82.79999542236328 and parameters: {'Fwd': 1.6368170653597397e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.801279010275, 'loop': 1, 'loss': 'MSE', 'lr': 0.002441452185777674, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0019416933615435607, 'weightedloss': False}. Best is trial 123 with value: 82.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.003021971719730041
weight_decay:  0.0057076277976919765
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8251550057902932
None Run 01:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 74.90
Split: 01, Run: 02
None time:  2.7630536179058254
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 74.00
Split: 01, Run: 03
None time:  1.5957278520800173
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.70
run time now: 6.232227563858032
total time:  6.274899242911488
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.87 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 73.87 ± 1.11
[I 2023-06-12 00:23:36,956] Trial 126 finished with value: 75.86666107177734 and parameters: {'Fwd': 1.6773266728973353e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 6.7951410142237165, 'loop': 1, 'loss': 'MSE', 'lr': 0.003021971719730041, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0057076277976919765, 'weightedloss': False}. Best is trial 123 with value: 82.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0023288902303877316
weight_decay:  0.0018134785108208822
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3673, Train: 100.00%, Valid: 82.00% Test: 78.10%
Split: 01, Run: 01
None time:  3.0588787130545825
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.4207743490114808
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.7366567358840257
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.40
run time now: 6.266732215881348
total time:  6.309862093068659
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.53 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.83 ± 0.67
[I 2023-06-12 00:23:43,751] Trial 127 finished with value: 82.53333282470703 and parameters: {'Fwd': 3.2719385004865076e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 7.304315215042794, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023288902303877316, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0018134785108208822, 'weightedloss': False}. Best is trial 123 with value: 82.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0023305385855042844
weight_decay:  0.0019207897212891543
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3309, Train: 100.00%, Valid: 83.00% Test: 78.80%
Split: 01, Run: 01
None time:  3.304847168037668
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.7290046939160675
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.391173521988094
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.90
run time now: 7.478617906570435
total time:  7.530742364004254
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.13 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 78.57 ± 0.29
[I 2023-06-12 00:23:51,850] Trial 128 finished with value: 82.13333892822266 and parameters: {'Fwd': 3.2179189500037838e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.3630102991321715, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023305385855042844, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0019207897212891543, 'weightedloss': False}. Best is trial 123 with value: 82.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002363535871042006
weight_decay:  0.0019063589969315177
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3288, Train: 100.00%, Valid: 83.20% Test: 79.20%
Split: 01, Run: 01
None time:  3.6124298870563507
None Run 01:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 02
None time:  1.2589850900694728
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.0140141169540584
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.933771848678589
total time:  5.98273647390306
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.13 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 79.20 ± 0.20
[I 2023-06-12 00:23:58,303] Trial 129 finished with value: 82.13333129882812 and parameters: {'Fwd': 3.2256972167721154e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 5.852063619552261, 'loop': 1, 'loss': 'MSE', 'lr': 0.002363535871042006, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0019063589969315177, 'weightedloss': False}. Best is trial 123 with value: 82.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0033756346233859095
weight_decay:  0.0014081886873243523
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8412905940786004
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  3.0789083698764443
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  0.9807744980789721
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.945601940155029
total time:  4.996555625926703
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.07 ± 6.58
  Final Train: 100.00 ± 0.00
   Final Test: 75.67 ± 5.56
[I 2023-06-12 00:24:03,933] Trial 130 finished with value: 77.06666564941406 and parameters: {'Fwd': 1.0193052341770897e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 6.33111496848002, 'loop': 1, 'loss': 'MSE', 'lr': 0.0033756346233859095, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0014081886873243523, 'weightedloss': False}. Best is trial 123 with value: 82.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0023360851185201567
weight_decay:  0.0019321246691799893
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1190252490341663
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.1882058770861477
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  0.9623347150627524
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.317960262298584
total time:  5.362285736948252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 0.84
[I 2023-06-12 00:24:09,840] Trial 131 finished with value: 81.33333587646484 and parameters: {'Fwd': 3.2355862184795818e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 5.979144695064596, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023360851185201567, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0019321246691799893, 'weightedloss': False}. Best is trial 123 with value: 82.93333435058594.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0025859788611708565
weight_decay:  0.0021037949756797583
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5067654422018677
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.0726868819911033
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.0243222480639815
None Run 03:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.649686336517334
total time:  4.691202763002366
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.07 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 1.21
[I 2023-06-12 00:24:15,130] Trial 132 finished with value: 83.0666732788086 and parameters: {'Fwd': 3.527036912991222e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 5.745271387351655, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025859788611708565, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0021037949756797583, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0026459951061653477
weight_decay:  0.001270810154872578
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5566820800304413
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.4410174218937755
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  1.5461268560029566
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.593431711196899
total time:  5.651350884931162
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 79.63 ± 1.25
[I 2023-06-12 00:24:21,265] Trial 133 finished with value: 82.4000015258789 and parameters: {'Fwd': 1.4845548770608016e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.609291270739877, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026459951061653477, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001270810154872578, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0027141686720156917
weight_decay:  0.0012945935214960652
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3384, Train: 100.00%, Valid: 81.80% Test: 78.70%
Split: 01, Run: 01
None time:  3.222014115191996
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.419754474889487
None Run 02:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  0.9886084110476077
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.30
run time now: 5.679953098297119
total time:  5.729454861953855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.87 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 79.43 ± 0.90
[I 2023-06-12 00:24:27,434] Trial 134 finished with value: 82.86666870117188 and parameters: {'Fwd': 1.3689557888754016e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.158484226634603, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027141686720156917, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0012945935214960652, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002749233737757526
weight_decay:  0.003045803069055489
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.3340016140136868
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  0.6051118629984558
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  2.1235179158393294
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.60
run time now: 6.11356258392334
total time:  6.160042903851718
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.93 ± 0.85
[I 2023-06-12 00:24:34,035] Trial 135 finished with value: 81.60000610351562 and parameters: {'Fwd': 1.3400780716280972e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.144267048760141, 'loop': 1, 'loss': 'MSE', 'lr': 0.002749233737757526, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003045803069055489, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0030328914585017277
weight_decay:  0.00153501013719452
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9274073271080852
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.645144070032984
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  0.985040619969368
None Run 03:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.90
run time now: 3.605762243270874
total time:  3.6485782340168953
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 8.09
  Final Train: 100.00 ± 0.00
   Final Test: 76.20 ± 5.81
[I 2023-06-12 00:24:38,097] Trial 136 finished with value: 78.93333435058594 and parameters: {'Fwd': 2.2074994151638434e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 5.565000092021004, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030328914585017277, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00153501013719452, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0035813941276803566
weight_decay:  0.001172594841629712
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2082, Train: 100.00%, Valid: 82.80% Test: 79.30%
Split: 01, Run: 01
None time:  3.670277951983735
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 02
None time:  1.1014788469765335
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.212869114940986
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.20
run time now: 7.030433177947998
total time:  7.081899913959205
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.87 ± 0.58
[I 2023-06-12 00:24:45,627] Trial 137 finished with value: 82.0 and parameters: {'Fwd': 2.2700485241629117e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.62469359424183, 'loop': 1, 'loss': 'MSE', 'lr': 0.0035813941276803566, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001172594841629712, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0026784209246055023
weight_decay:  0.004387863342202339
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1088750429917127
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.4073473589960486
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.873252633959055
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.00
run time now: 7.440605163574219
total time:  7.49031524383463
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.55
[I 2023-06-12 00:24:53,571] Trial 138 finished with value: 81.26667022705078 and parameters: {'Fwd': 1.4632135539487154e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 6.815719606948659, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026784209246055023, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004387863342202339, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0024940011023325426
weight_decay:  0.0011206322634242166
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.235707781976089
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 02
None time:  0.8664211509749293
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.0403553999494761
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.50
run time now: 4.190683364868164
total time:  4.2417942269239575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 2.12
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 1.38
[I 2023-06-12 00:24:58,281] Trial 139 finished with value: 81.0 and parameters: {'Fwd': 1.5017331565662377e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 6.478987741943267, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024940011023325426, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0011206322634242166, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0021601246018823537
weight_decay:  0.003180870270019181
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9451978160068393
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 02
None time:  0.9003547711763531
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 03
None time:  1.0953491111285985
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 96.67
   Final Test: 79.30
run time now: 2.9903223514556885
total time:  3.0340364479925483
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.80 ± 4.70
  Final Train: 98.89 ± 1.92
   Final Test: 75.80 ± 4.30
[I 2023-06-12 00:25:01,812] Trial 140 finished with value: 76.79999542236328 and parameters: {'Fwd': 3.9854342888160416e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.45, 'lambda2': 6.963818634085043, 'loop': 1, 'loss': 'CE', 'lr': 0.0021601246018823537, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003180870270019181, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.003221722121058635
weight_decay:  0.001780935539061456
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.360186583828181
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.4522922509349883
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.0473004439845681
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.70
run time now: 4.908848524093628
total time:  4.960832593031228
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.92
[I 2023-06-12 00:25:07,222] Trial 141 finished with value: 80.19999694824219 and parameters: {'Fwd': 1.0006961627514705e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.195977997688103, 'loop': 1, 'loss': 'MSE', 'lr': 0.003221722121058635, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001780935539061456, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0029052998890376452
weight_decay:  0.002123681130706832
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8889553339686245
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 76.10
Split: 01, Run: 02
None time:  1.8773875879123807
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.1312, Train: 100.00%, Valid: 82.00% Test: 79.50%
Split: 01, Run: 03
None time:  3.7728588900063187
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.60
run time now: 7.589575290679932
total time:  7.63313703215681
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 2.05
[I 2023-06-12 00:25:15,349] Trial 142 finished with value: 82.33333587646484 and parameters: {'Fwd': 2.9947252937927496e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.45022738896133, 'loop': 1, 'loss': 'MSE', 'lr': 0.0029052998890376452, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002123681130706832, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0036810042447086595
weight_decay:  0.001350976466620722
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.859058832982555
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.6412655289750546
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.0374998808838427
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 80.30
run time now: 3.5876171588897705
total time:  3.6345912979450077
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.80 ± 7.14
  Final Train: 100.00 ± 0.00
   Final Test: 76.43 ± 6.02
[I 2023-06-12 00:25:19,530] Trial 143 finished with value: 77.79999542236328 and parameters: {'Fwd': 2.4783964166437255e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 6.678837681903876, 'loop': 1, 'loss': 'MSE', 'lr': 0.0036810042447086595, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001350976466620722, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0030212519822124524
weight_decay:  0.0024151842120586032
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5038155522197485
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 02
None time:  1.026313364971429
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.1715845400467515
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.50
run time now: 4.752669811248779
total time:  4.800754691939801
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 1.11
[I 2023-06-12 00:25:24,799] Trial 144 finished with value: 81.06666564941406 and parameters: {'Fwd': 2.0665746767868198e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 6.518786608283215, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030212519822124524, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0024151842120586032, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0027505408118965852
weight_decay:  0.0011068995155188897
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8966002089437097
None Run 01:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 02
None time:  1.0560454740189016
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.008500659139827
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.013055801391602
total time:  5.0588187370449305
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 80.07 ± 0.67
[I 2023-06-12 00:25:30,316] Trial 145 finished with value: 82.4000015258789 and parameters: {'Fwd': 1.5733916585502644e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 7.398760834617941, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027505408118965852, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0011068995155188897, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0028526151544010308
weight_decay:  0.0010589336079000443
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2906, Train: 100.00%, Valid: 82.40% Test: 78.60%
Split: 01, Run: 01
None time:  3.2537787288893014
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.1719, Train: 100.00%, Valid: 81.40% Test: 79.60%
Split: 01, Run: 02
None time:  3.8458901061676443
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  1.0348566770553589
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.80
run time now: 8.182535171508789
total time:  8.229706407990307
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.20 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 79.37 ± 0.67
[I 2023-06-12 00:25:39,011] Trial 146 finished with value: 82.20000457763672 and parameters: {'Fwd': 1.3145397524053388e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.880290396162613, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028526151544010308, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0010589336079000443, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.004063139194033273
weight_decay:  0.005106421436635692
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.477258662926033
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 02
None time:  1.494836213067174
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  0.9040908729657531
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.10
run time now: 4.931630849838257
total time:  4.974743211874738
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 78.83 ± 1.86
[I 2023-06-12 00:25:44,551] Trial 147 finished with value: 81.73332977294922 and parameters: {'Fwd': 1.7861181724640188e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.039611695933495, 'loop': 1, 'loss': 'MSE', 'lr': 0.004063139194033273, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005106421436635692, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9500000000000001
lr:  0.0026235285863307205
weight_decay:  0.0016086320055216765
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5975205430295318
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 75.40
Split: 01, Run: 02
None time:  1.7024209471419454
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.00
Split: 01, Run: 03
None time:  1.776657945010811
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.20
run time now: 5.111023426055908
total time:  5.153703086078167
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.40 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 73.87 ± 1.33
[I 2023-06-12 00:25:50,213] Trial 148 finished with value: 75.4000015258789 and parameters: {'Fwd': 1.0006626642155232e-06, 'K': 1, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 5.711485185835044, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026235285863307205, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0016086320055216765, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0032129868670751687
weight_decay:  0.002961797584624094
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2467487540561706
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.9663864460308105
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.3523116188589483
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.80
run time now: 5.614973306655884
total time:  5.669156496180221
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 79.10 ± 1.21
[I 2023-06-12 00:25:56,441] Trial 149 finished with value: 81.53333282470703 and parameters: {'Fwd': 1.5165556090937028e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 6.272261966704553, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032129868670751687, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.002961797584624094, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0021504470452464288
weight_decay:  0.0022313998721879918
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3519, Train: 100.00%, Valid: 83.00% Test: 78.60%
Split: 01, Run: 01
None time:  3.851903175935149
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.641841143136844
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  1.3980871620588005
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.80
run time now: 6.9750657081604
total time:  7.022449082927778
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 79.50 ± 0.79
[I 2023-06-12 00:26:04,047] Trial 150 finished with value: 82.66666412353516 and parameters: {'Fwd': 3.547569997831303e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 7.627571276151746, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021504470452464288, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0022313998721879918, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0021274951298323784
weight_decay:  0.002452227811782785
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.93300538090989
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.1919187249150127
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.9240028590429574
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.20
run time now: 6.108996391296387
total time:  6.152492722030729
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 0.55
[I 2023-06-12 00:26:10,668] Trial 151 finished with value: 81.79999542236328 and parameters: {'Fwd': 2.954400965148391e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 7.638355194023439, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021274951298323784, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002452227811782785, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0028182453675267834
weight_decay:  0.004088612059051921
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9982061840128154
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 02
None time:  1.4246351020410657
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.0439447241369635
None Run 03:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.30
run time now: 4.514053583145142
total time:  4.564350909087807
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.67 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 2.30
[I 2023-06-12 00:26:15,770] Trial 152 finished with value: 82.66666412353516 and parameters: {'Fwd': 3.817747140228634e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 7.425667938300996, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028182453675267834, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004088612059051921, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002550892481293161
weight_decay:  0.004085521753107069
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0331199569627643
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.3901323578320444
None Run 02:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.5210738040041178
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 80.20
run time now: 4.995396137237549
total time:  5.043835769873112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.00 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 79.33 ± 1.25
[I 2023-06-12 00:26:21,376] Trial 153 finished with value: 83.0 and parameters: {'Fwd': 4.069675694938258e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 7.459084757828441, 'loop': 1, 'loss': 'MSE', 'lr': 0.002550892481293161, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004085521753107069, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002507983783981295
weight_decay:  0.004129663664558365
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8461854800116271
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.8025140699464828
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  0.990668746875599
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.70
run time now: 2.687866687774658
total time:  2.7408525648061186
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.60 ± 6.93
  Final Train: 100.00 ± 0.00
   Final Test: 76.10 ± 5.72
[I 2023-06-12 00:26:24,675] Trial 154 finished with value: 77.5999984741211 and parameters: {'Fwd': 3.3403707977855566e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 7.68277385310422, 'loop': 1, 'loss': 'MSE', 'lr': 0.002507983783981295, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004129663664558365, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0023305776881328085
weight_decay:  0.007549683578916321
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3676, Train: 100.00%, Valid: 82.20% Test: 78.40%
Split: 01, Run: 01
None time:  3.368178406963125
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.9985970801208168
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  2.409833427052945
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.60
run time now: 7.8240907192230225
total time:  7.87598487501964
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.00 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 79.57 ± 1.38
[I 2023-06-12 00:26:33,018] Trial 155 finished with value: 83.0 and parameters: {'Fwd': 4.456255126079659e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 7.222095606889866, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023305776881328085, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007549683578916321, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.25
lr:  0.0019874103702952027
weight_decay:  0.005870124216048954
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5980680810753256
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.90275027602911
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 03
None time:  1.3444914449937642
None Run 03:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 76.00
run time now: 3.886366605758667
total time:  3.9286344598513097
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.73 ± 3.86
  Final Train: 100.00 ± 0.00
   Final Test: 72.83 ± 3.37
[I 2023-06-12 00:26:37,408] Trial 156 finished with value: 73.73332977294922 and parameters: {'Fwd': 4.3830502137554985e-06, 'K': 9, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 7.4951330090229416, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019874103702952027, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005870124216048954, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.002207977673951061
weight_decay:  0.008841368153873458
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4119241200387478
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  1.6855536210350692
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.0882693820167333
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.90
run time now: 4.24355149269104
total time:  4.290792188141495
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.70 ± 1.08
[I 2023-06-12 00:26:42,154] Trial 157 finished with value: 81.33333587646484 and parameters: {'Fwd': 5.074062588830555e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 7.250689766586676, 'loop': 1, 'loss': 'MSE', 'lr': 0.002207977673951061, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008841368153873458, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0020190852845780416
weight_decay:  0.003983573727499237
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.36855214298702776
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.364810778060928
None Run 02:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 03
None time:  0.3626044518314302
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.40
run time now: 1.153010606765747
total time:  1.2220876340288669
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.40 ± 0.00
[I 2023-06-12 00:26:43,905] Trial 158 finished with value: 69.5999984741211 and parameters: {'Fwd': 3.838261880296467e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 0, 'lambda1': 0.6000000000000001, 'lambda2': 7.156435777515763, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020190852845780416, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003983573727499237, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0023547700232434605
weight_decay:  0.008277301961222538
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3665, Train: 100.00%, Valid: 82.40% Test: 78.30%
Split: 01, Run: 01
None time:  3.7495981701649725
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.0569932830985636
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  0.730674851918593
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.625193119049072
total time:  5.6774904588237405
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.49
[I 2023-06-12 00:26:50,186] Trial 159 finished with value: 81.9333267211914 and parameters: {'Fwd': 6.548794256014678e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 7.746394977133612, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023547700232434605, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008277301961222538, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.0022305713388225956
weight_decay:  0.004722660633679454
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9495921949855983
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 02
None time:  1.5469543568324298
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 03
None time:  1.0874552251771092
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.90
run time now: 4.630627632141113
total time:  4.678586637834087
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 77.30 ± 1.42
[I 2023-06-12 00:26:55,401] Trial 160 finished with value: 81.0 and parameters: {'Fwd': 5.446007597251732e-06, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 7.033072890174291, 'loop': 1, 'loss': 'MSE', 'lr': 0.0022305713388225956, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004722660633679454, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002557972184951698
weight_decay:  0.0029022341413721246
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2643872061744332
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.7523979721590877
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  0.8502471589017659
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.70
run time now: 4.91415810585022
total time:  4.970590628916398
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.53 ± 0.38
[I 2023-06-12 00:27:00,953] Trial 161 finished with value: 81.86666870117188 and parameters: {'Fwd': 2.128159910577047e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 7.339306277665288, 'loop': 1, 'loss': 'MSE', 'lr': 0.002557972184951698, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0029022341413721246, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0033735769570941735
weight_decay:  0.01018822392175817
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6575341019779444
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.1191007080487907
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  0.9778348898980767
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.80
run time now: 4.799866437911987
total time:  4.851053869817406
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 79.00 ± 0.75
[I 2023-06-12 00:27:06,292] Trial 162 finished with value: 81.26666259765625 and parameters: {'Fwd': 2.606918754135161e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.860714710258399, 'loop': 1, 'loss': 'MSE', 'lr': 0.0033735769570941735, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.01018822392175817, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0024812058559026194
weight_decay:  0.0031452410764067442
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6402704999782145
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.15328908408992
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  0.8816054100170732
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.20
run time now: 4.723675489425659
total time:  4.777962367981672
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 79.47 ± 0.83
[I 2023-06-12 00:27:11,545] Trial 163 finished with value: 82.26667022705078 and parameters: {'Fwd': 8.322799071948656e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 7.5966809954356345, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024812058559026194, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0031452410764067442, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9
lr:  0.001967170911119129
weight_decay:  0.005699417178317275
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.6423, Train: 100.00%, Valid: 78.00% Test: 72.90%
Split: 01, Run: 01
None time:  2.564916281029582
None Run 01:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 72.90
Split: 01, Run: 02
None time:  1.2455115369521081
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.0595711851492524
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 75.50
run time now: 4.908057451248169
total time:  4.958698004018515
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 2.00
  Final Train: 100.00 ± 0.00
   Final Test: 75.43 ± 2.50
[I 2023-06-12 00:27:16,945] Trial 164 finished with value: 80.06666564941406 and parameters: {'Fwd': 1.249146070757634e-06, 'K': 3, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 7.052101882188351, 'loop': 1, 'loss': 'MSE', 'lr': 0.001967170911119129, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005699417178317275, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0028137616102934145
weight_decay:  0.002233584008727134
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9185802340507507
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.7345549170859158
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.1382650309242308
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.842003583908081
total time:  5.8849961049854755
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 78.97 ± 1.29
[I 2023-06-12 00:27:23,296] Trial 165 finished with value: 82.4000015258789 and parameters: {'Fwd': 1.817212836398442e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 6.701947567536634, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028137616102934145, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002233584008727134, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.002222512480118959
weight_decay:  0.0036531469055397997
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9740357091650367
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  1.6856962470337749
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 72.60
Split: 01, Run: 03
None time:  1.7800104678608477
None Run 03:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 73.80
run time now: 4.485267639160156
total time:  4.537345377961174
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.60 ± 4.04
  Final Train: 100.00 ± 0.00
   Final Test: 71.93 ± 2.27
[I 2023-06-12 00:27:28,289] Trial 166 finished with value: 73.5999984741211 and parameters: {'Fwd': 3.886874511468172e-06, 'K': 9, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 7.434511508699055, 'loop': 1, 'loss': 'MSE', 'lr': 0.002222512480118959, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0036531469055397997, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0031706045420485255
weight_decay:  0.0016045871074660237
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6135163840372115
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.6308386500459164
None Run 02:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 74.60
Split: 01, Run: 03
None time:  1.008943276014179
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.00
run time now: 4.302218675613403
total time:  4.3535117278806865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.47 ± 2.00
  Final Train: 100.00 ± 0.00
   Final Test: 76.83 ± 1.93
[I 2023-06-12 00:27:33,192] Trial 167 finished with value: 78.46666717529297 and parameters: {'Fwd': 2.2253518945673584e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 7.10568857653506, 'loop': 1, 'loss': 'MSE', 'lr': 0.0031706045420485255, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0016045871074660237, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.002561793345808412
weight_decay:  0.002556895458634913
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.3778136011678725
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.656052687903866
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.0048349520657212
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.70
run time now: 7.085929870605469
total time:  7.135586573043838
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.47 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 0.50
[I 2023-06-12 00:27:40,773] Trial 168 finished with value: 82.46666717529297 and parameters: {'Fwd': 1.4167874670542507e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 7.295082568218139, 'loop': 1, 'loss': 'MSE', 'lr': 0.002561793345808412, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002556895458634913, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.002138377755581732
weight_decay:  0.004609845350480669
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6607415839098394
None Run 01:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 02
None time:  1.0831348188221455
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 98.33
   Final Test: 76.40
Split: 01, Run: 03
None time:  1.0364232040010393
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.70
run time now: 2.821441173553467
total time:  2.876839574892074
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.93 ± 2.02
  Final Train: 99.44 ± 0.96
   Final Test: 74.93 ± 2.80
[I 2023-06-12 00:27:44,251] Trial 169 finished with value: 76.9333267211914 and parameters: {'Fwd': 1.1913810399843822e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 7.8188394215537125, 'loop': 1, 'loss': 'CE', 'lr': 0.002138377755581732, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004609845350480669, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.0024691747630757686
weight_decay:  0.002704225840445123
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7069210449699312
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  1.9929301980882883
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  0.9782514940015972
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 4.72238826751709
total time:  4.7725921450182796
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 1.60
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.74
[I 2023-06-12 00:27:49,544] Trial 170 finished with value: 79.9333267211914 and parameters: {'Fwd': 2.7966136761958904e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.45, 'lambda2': 7.363547924023588, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024691747630757686, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002704225840445123, 'weightedloss': True}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002631145383129101
weight_decay:  0.0019879600122840605
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5960737261921167
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.8778155951295048
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  2.3767365249805152
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.30
run time now: 6.905309677124023
total time:  6.950771318050101
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.13 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 79.07 ± 0.32
[I 2023-06-12 00:27:57,071] Trial 171 finished with value: 82.13333892822266 and parameters: {'Fwd': 1.649117019852089e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 6.855930142406799, 'loop': 1, 'loss': 'MSE', 'lr': 0.002631145383129101, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0019879600122840605, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0019208868366276685
weight_decay:  0.003472397118855611
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8857668980490416
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.8826959219295532
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.3704381149727851
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.80
run time now: 6.181226491928101
total time:  6.2291663540527225
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 79.17 ± 0.57
[I 2023-06-12 00:28:03,834] Trial 172 finished with value: 82.0 and parameters: {'Fwd': 1.3931574469625522e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 7.2294281063302135, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019208868366276685, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003472397118855611, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0029624090174813727
weight_decay:  0.0015835206273858485
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0377588470000774
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.2318992458749563
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.2939119178336114
None Run 03:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 79.50
run time now: 4.606323480606079
total time:  4.652751039015129
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.73 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 0.93
[I 2023-06-12 00:28:08,951] Trial 173 finished with value: 82.73333740234375 and parameters: {'Fwd': 1.942648054725819e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 7.562196621095347, 'loop': 1, 'loss': 'MSE', 'lr': 0.0029624090174813727, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0015835206273858485, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9
lr:  0.0029100457681997213
weight_decay:  0.0024572472844582374
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7684899079613388
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  2.0376973040401936
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.3507446069270372
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.70
run time now: 6.243095397949219
total time:  6.296967045869678
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 1.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.70
[I 2023-06-12 00:28:15,683] Trial 174 finished with value: 81.73332977294922 and parameters: {'Fwd': 2.013342235158801e-06, 'K': 8, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 7.593473135222121, 'loop': 1, 'loss': 'MSE', 'lr': 0.0029100457681997213, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0024572472844582374, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0035973362210344807
weight_decay:  0.0017907283714957407
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0044098219368607
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.0047001610510051
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  1.027693459065631
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.70
run time now: 4.087105989456177
total time:  4.135735121089965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.20 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 0.75
[I 2023-06-12 00:28:20,256] Trial 175 finished with value: 82.20000457763672 and parameters: {'Fwd': 3.6114522401360674e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 5.403552210643416, 'loop': 1, 'loss': 'MSE', 'lr': 0.0035973362210344807, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0017907283714957407, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.002279987716239378
weight_decay:  0.00332827692110524
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1423992791678756
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.7743194890208542
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.1617765880655497
None Run 03:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 75.20
run time now: 4.124533176422119
total time:  4.176526493858546
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 2.80
  Final Train: 100.00 ± 0.00
   Final Test: 77.27 ± 1.86
[I 2023-06-12 00:28:24,897] Trial 176 finished with value: 80.0 and parameters: {'Fwd': 4.5974066871988135e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.45, 'lambda2': 7.515221399558703, 'loop': 1, 'loss': 'MSE', 'lr': 0.002279987716239378, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00332827692110524, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0030066792817003887
weight_decay:  0.001466363088841547
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9450769310351461
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 02
None time:  2.292615757090971
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.280073655070737
None Run 03:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 80.00
run time now: 5.567588806152344
total time:  5.609673424158245
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 1.63
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 1.91
[I 2023-06-12 00:28:30,991] Trial 177 finished with value: 82.33332824707031 and parameters: {'Fwd': 2.5113237168949886e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 7.828189445418801, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030066792817003887, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001466363088841547, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0018548396649740503
weight_decay:  0.006427731499027508
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.94582844292745
None Run 01:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 74.70
Split: 01, Run: 02
None time:  5.446009895997122
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 03
None time:  1.7213339710142463
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.40
run time now: 9.159960508346558
total time:  9.210542621091008
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 74.00 ± 0.66
[I 2023-06-12 00:28:40,613] Trial 178 finished with value: 75.5999984741211 and parameters: {'Fwd': 1.8635447133258264e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 7.220980722699462, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018548396649740503, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.006427731499027508, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.002377874446977875
weight_decay:  0.002076974074650159
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2139634098857641
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 02
None time:  0.9846679421607405
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 03
None time:  1.0138182761147618
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.20
run time now: 3.2680232524871826
total time:  3.3145267830695957
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.47 ± 2.21
  Final Train: 100.00 ± 0.00
   Final Test: 76.73 ± 0.55
[I 2023-06-12 00:28:44,499] Trial 179 finished with value: 78.46666717529297 and parameters: {'Fwd': 1.2280535640494242e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.976025328596968, 'loop': 1, 'loss': 'MSE', 'lr': 0.002377874446977875, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.002076974074650159, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.9500000000000001
lr:  0.002117010183225798
weight_decay:  0.011719763625975536
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.258819585898891
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 02
None time:  1.4402637709863484
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.9543850638438016
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.50
run time now: 4.704019784927368
total time:  4.7517657049465925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 77.80 ± 0.66
[I 2023-06-12 00:28:49,828] Trial 180 finished with value: 81.13333129882812 and parameters: {'Fwd': 1.0110170681801375e-06, 'K': 8, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 7.309856269910785, 'loop': 1, 'loss': 'MSE', 'lr': 0.002117010183225798, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.011719763625975536, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0026486534410087854
weight_decay:  0.0027526539031308777
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.543815255863592
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.1783, Train: 100.00%, Valid: 82.80% Test: 79.80%
Split: 01, Run: 02
None time:  3.6981307121459395
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  1.2666468620300293
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 7.55649733543396
total time:  7.616403190884739
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 79.50 ± 1.21
[I 2023-06-12 00:28:58,086] Trial 181 finished with value: 82.53333282470703 and parameters: {'Fwd': 1.5553955811063045e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.661797682690282, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026486534410087854, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0027526539031308777, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0027452614514931685
weight_decay:  0.0027071382142995265
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.406512909801677
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.0031600389629602
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  2.128069797065109
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.70
run time now: 6.660618543624878
total time:  6.716263827867806
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.91
[I 2023-06-12 00:29:05,409] Trial 182 finished with value: 81.80000305175781 and parameters: {'Fwd': 0.0001132033789034464, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 7.49492335714359, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027452614514931685, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0027071382142995265, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0032425746088863773
weight_decay:  0.005013391236470936
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.882594645023346
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.7869287319481373
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 03
None time:  0.8977740840055048
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.00
run time now: 2.613738775253296
total time:  2.6640565781854093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.67 ± 6.99
  Final Train: 100.00 ± 0.00
   Final Test: 75.10 ± 4.97
[I 2023-06-12 00:29:08,564] Trial 183 finished with value: 77.66666412353516 and parameters: {'Fwd': 1.696042363967824e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 6.796998357771259, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032425746088863773, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005013391236470936, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0024500004324587857
weight_decay:  0.0038345260203053477
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2138141919858754
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.0158870329614729
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.757173146121204
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.70
run time now: 5.037136793136597
total time:  5.078507897909731
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 1.76
[I 2023-06-12 00:29:14,131] Trial 184 finished with value: 82.26666259765625 and parameters: {'Fwd': 2.2202549507243356e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.947506910139457, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024500004324587857, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0038345260203053477, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0020479367215256255
weight_decay:  0.002194465081944171
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4964926932007074
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02
None time:  1.1134495320729911
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  2.4976089808624238
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.10
run time now: 5.151203870773315
total time:  5.196755556156859
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 78.60 ± 1.41
[I 2023-06-12 00:29:19,933] Trial 185 finished with value: 81.4000015258789 and parameters: {'Fwd': 2.86394982092235e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 7.698912228387759, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020479367215256255, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002194465081944171, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.003888591243780814
weight_decay:  0.002853134233722185
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.141284819226712
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.0894253579899669
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  0.9781870390288532
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.60
run time now: 4.260642766952515
total time:  4.313270046142861
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 0.99
[I 2023-06-12 00:29:24,794] Trial 186 finished with value: 82.26667022705078 and parameters: {'Fwd': 1.4079305266021304e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 6.320372146838928, 'loop': 1, 'loss': 'MSE', 'lr': 0.003888591243780814, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002853134233722185, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002892029025806344
weight_decay:  0.0016639957287677152
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1691, Train: 100.00%, Valid: 81.40% Test: 77.70%
Split: 01, Run: 01
None time:  3.4628151138313115
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.260499268071726
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  0.9864395230542868
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 79.60
run time now: 5.753704071044922
total time:  5.808263501850888
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 79.03 ± 1.16
[I 2023-06-12 00:29:31,080] Trial 187 finished with value: 81.79999542236328 and parameters: {'Fwd': 1.9009707613715906e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.067882614539527, 'loop': 1, 'loss': 'MSE', 'lr': 0.002892029025806344, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0016639957287677152, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0026022366249250904
weight_decay:  0.0009205089818882629
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2943, Train: 100.00%, Valid: 83.60% Test: 80.10%
Split: 01, Run: 01
None time:  3.687162356916815
None Run 01:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 02
None time:  3.499459713930264
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.399530858034268
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.90
run time now: 8.634522199630737
total time:  8.682868550997227
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 79.77 ± 0.23
[I 2023-06-12 00:29:40,257] Trial 188 finished with value: 82.26667022705078 and parameters: {'Fwd': 3.4142135030789776e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.45, 'lambda2': 6.63927818104193, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026022366249250904, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0009205089818882629, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.002288588911561566
weight_decay:  0.003990444360154403
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8699482968077064
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 75.00
Split: 01, Run: 02
None time:  0.9992619419936091
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 03
None time:  1.6358796199783683
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.30
run time now: 4.550660848617554
total time:  4.60375503404066
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 2.00
  Final Train: 100.00 ± 0.00
   Final Test: 77.43 ± 2.21
[I 2023-06-12 00:29:45,370] Trial 189 finished with value: 81.0 and parameters: {'Fwd': 1.1809918195498388e-06, 'K': 9, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 7.153067152119461, 'loop': 1, 'loss': 'MSE', 'lr': 0.002288588911561566, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003990444360154403, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0034288841760053523
weight_decay:  0.0013698659231680995
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7989855480846018
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.3136730391997844
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  3.030406879959628
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.30
run time now: 5.2257912158966064
total time:  5.274712173035368
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.00 ± 7.12
  Final Train: 100.00 ± 0.00
   Final Test: 76.27 ± 5.78
[I 2023-06-12 00:29:51,212] Trial 190 finished with value: 78.0 and parameters: {'Fwd': 0.002964101512994054, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.6000000000000001, 'lambda2': 8.002498665632439, 'loop': 1, 'loss': 'MSE', 'lr': 0.0034288841760053523, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0013698659231680995, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0026156344161300414
weight_decay:  0.0012976773397410787
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.769066231092438
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.1286981529556215
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  0.9135941369459033
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 5.860717535018921
total time:  5.913970201043412
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 79.53 ± 1.16
[I 2023-06-12 00:29:57,740] Trial 191 finished with value: 82.5999984741211 and parameters: {'Fwd': 1.502712116694584e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.591326281354323, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026156344161300414, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0012976773397410787, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002592820280304733
weight_decay:  0.001956092796577147
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2535472090821713
None Run 01:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.5347466801758856
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  0.8952646921388805
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 71.30
run time now: 4.72866153717041
total time:  4.771662049926817
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 4.73
  Final Train: 100.00 ± 0.00
   Final Test: 76.73 ± 4.82
[I 2023-06-12 00:30:03,067] Trial 192 finished with value: 80.46666717529297 and parameters: {'Fwd': 1.6281669373665789e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 7.297219104008582, 'loop': 1, 'loss': 'MSE', 'lr': 0.002592820280304733, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001956092796577147, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0031314147016921388
weight_decay:  0.002549491060808794
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1859187530353665
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02
None time:  2.2768347279634327
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.1250147989485413
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.635962724685669
total time:  5.6912078380119056
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.20 ± 1.60
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 1.33
[I 2023-06-12 00:30:09,247] Trial 193 finished with value: 82.20000457763672 and parameters: {'Fwd': 1.2623060170792025e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 6.451485833805708, 'loop': 1, 'loss': 'MSE', 'lr': 0.0031314147016921388, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002549491060808794, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0018557142610804368
weight_decay:  0.0012183610940796
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.694316952023655
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  0.9612747440114617
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  1.0183292268775403
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.60
run time now: 4.7392332553863525
total time:  4.816481763962656
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.93 ± 0.65
[I 2023-06-12 00:30:14,606] Trial 194 finished with value: 81.66666412353516 and parameters: {'Fwd': 2.4077151439444814e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 7.059742960521449, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018557142610804368, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0012183610940796, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.002374624386594582
weight_decay:  0.001647177491392368
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6994213580619544
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.5846771690994501
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.296621906105429
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.629761457443237
total time:  5.676749136066064
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 78.77 ± 0.60
[I 2023-06-12 00:30:20,763] Trial 195 finished with value: 82.20000457763672 and parameters: {'Fwd': 1.9174062440530584e-06, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 6.67047510582383, 'loop': 1, 'loss': 'MSE', 'lr': 0.002374624386594582, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001647177491392368, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002775614998487006
weight_decay:  0.002919632989444567
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.683512754039839
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02
None time:  1.5900034881196916
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  1.697307082125917
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.70
run time now: 6.022664785385132
total time:  6.073463117936626
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 79.57 ± 0.51
[I 2023-06-12 00:30:27,302] Trial 196 finished with value: 82.60000610351562 and parameters: {'Fwd': 2.8342209949608526e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 7.481683346436898, 'loop': 1, 'loss': 'MSE', 'lr': 0.002775614998487006, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002919632989444567, 'weightedloss': False}. Best is trial 132 with value: 83.0666732788086.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0021694454247795847
weight_decay:  0.0032041970506086898
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4659253081772476
None Run 01:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.3594773160293698
None Run 02:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.180593408178538
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.50
run time now: 5.063333749771118
total time:  5.116073979996145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.27 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 79.57 ± 0.90
[I 2023-06-12 00:30:32,919] Trial 197 finished with value: 83.26667022705078 and parameters: {'Fwd': 5.850132322043862e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 7.5155660338582075, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021694454247795847, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0032041970506086898, 'weightedloss': False}. Best is trial 197 with value: 83.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002203175645470059
weight_decay:  0.0032688712905422
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3461, Train: 100.00%, Valid: 83.40% Test: 78.70%
Split: 01, Run: 01
None time:  3.3575759150553495
None Run 01:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.1322024220135063
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  2.013313211966306
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.556499481201172
total time:  6.609147696988657
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.20 ± 2.43
  Final Train: 100.00 ± 0.00
   Final Test: 78.93 ± 0.59
[I 2023-06-12 00:30:40,014] Trial 198 finished with value: 82.20000457763672 and parameters: {'Fwd': 6.964278440801518e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 7.578730407826647, 'loop': 1, 'loss': 'MSE', 'lr': 0.002203175645470059, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0032688712905422, 'weightedloss': False}. Best is trial 197 with value: 83.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0020286883927630723
weight_decay:  0.0021869487241464518
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.138767815893516
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 74.30
Split: 01, Run: 02
None time:  0.9290526730474085
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.064151535043493
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.60
run time now: 3.181760787963867
total time:  3.231182770105079
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.13 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 76.37 ± 1.96
[I 2023-06-12 00:30:43,747] Trial 199 finished with value: 78.13333129882812 and parameters: {'Fwd': 4.9857707020168394e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 7.329177506150383, 'loop': 1, 'loss': 'CE', 'lr': 0.0020286883927630723, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0021869487241464518, 'weightedloss': False}. Best is trial 197 with value: 83.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0027101937528788214
weight_decay:  0.0030644367737498973
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0011816069018096
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.7700132101308554
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.6130081170704216
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.90
run time now: 4.444518327713013
total time:  4.494178412016481
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.27 ± 6.70
  Final Train: 100.00 ± 0.00
   Final Test: 76.07 ± 5.70
[I 2023-06-12 00:30:48,707] Trial 200 finished with value: 77.26667022705078 and parameters: {'Fwd': 3.800464058918039e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 7.808492430119919, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027101937528788214, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0030644367737498973, 'weightedloss': True}. Best is trial 197 with value: 83.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0024262697190075818
weight_decay:  0.004100081055661949
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.586393092991784
None Run 01:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 02
None time:  3.211739213904366
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.1488, Train: 100.00%, Valid: 79.80% Test: 78.80%
Split: 01, Run: 03
None time:  3.4379942228551954
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.80
run time now: 10.28486180305481
total time:  10.336245260899886
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 1.75
  Final Train: 100.00 ± 0.00
   Final Test: 79.33 ± 0.50
[I 2023-06-12 00:30:59,556] Trial 201 finished with value: 81.73333740234375 and parameters: {'Fwd': 2.984813436269473e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 7.48857387088216, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024262697190075818, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004100081055661949, 'weightedloss': False}. Best is trial 197 with value: 83.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0017260287159544454
weight_decay:  0.005172948786098419
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3844283421058208
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  0.9777762391604483
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  1.133508938131854
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.50
run time now: 4.805978536605835
total time:  4.853779104072601
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 1.70
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 1.18
[I 2023-06-12 00:31:05,045] Trial 202 finished with value: 81.73333740234375 and parameters: {'Fwd': 1.000143039062097e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 7.068500129029423, 'loop': 1, 'loss': 'MSE', 'lr': 0.0017260287159544454, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005172948786098419, 'weightedloss': False}. Best is trial 197 with value: 83.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0020557765567790474
weight_decay:  0.0025794246942476796
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.896108339074999
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  2.7278596009127796
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.0240251081995666
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.691972255706787
total time:  5.737365759909153
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 77.87 ± 1.27
[I 2023-06-12 00:31:11,347] Trial 203 finished with value: 81.53333282470703 and parameters: {'Fwd': 2.4332088125715316e-05, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 7.484172306093742, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020557765567790474, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0025794246942476796, 'weightedloss': False}. Best is trial 197 with value: 83.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002799322079708182
weight_decay:  0.0068944022844190135
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.067346401978284
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  1.5972605508286506
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  0.846796303987503
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.90
run time now: 4.560679912567139
total time:  4.60072062513791
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.67 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 78.87 ± 1.25
[I 2023-06-12 00:31:16,407] Trial 204 finished with value: 82.66666412353516 and parameters: {'Fwd': 1.0635432094306093e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 6.933477271069681, 'loop': 1, 'loss': 'MSE', 'lr': 0.002799322079708182, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0068944022844190135, 'weightedloss': False}. Best is trial 197 with value: 83.26667022705078.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002826211604211708
weight_decay:  0.005838427506559882
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.473029820015654
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.5030655190348625
None Run 02:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.0156570200342685
None Run 03:
Highest Train: 100.00
Highest Valid: 84.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.0416364669799805
total time:  5.092619167175144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.53 ± 1.17
  Final Train: 100.00 ± 0.00
   Final Test: 79.23 ± 1.56
[I 2023-06-12 00:31:21,993] Trial 205 finished with value: 83.53333282470703 and parameters: {'Fwd': 8.72257557713595e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 6.851885022870475, 'loop': 1, 'loss': 'MSE', 'lr': 0.002826211604211708, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005838427506559882, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0027744237997373014
weight_decay:  0.006840789359003517
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.256035042926669
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.0070476960390806
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  1.3980653749313205
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.714895009994507
total time:  5.765487118856981
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 0.84
[I 2023-06-12 00:31:28,274] Trial 206 finished with value: 80.86666870117188 and parameters: {'Fwd': 6.628858855336775e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 6.90255805896274, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027744237997373014, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006840789359003517, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0030790493272363053
weight_decay:  0.006854646009096863
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9149183370172977
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.4942277800291777
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  0.9220274710096419
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.80
run time now: 3.380516767501831
total time:  3.431728060124442
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.40 ± 7.45
  Final Train: 100.00 ± 0.00
   Final Test: 76.10 ± 5.65
[I 2023-06-12 00:31:32,259] Trial 207 finished with value: 78.4000015258789 and parameters: {'Fwd': 1.072583579795645e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 6.800457543457662, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030790493272363053, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006854646009096863, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0026211608095844884
weight_decay:  0.002047722639130664
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5604322489816695
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  0.8865163971204311
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.9944782159291208
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.497611045837402
total time:  5.543723291018978
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 1.74
[I 2023-06-12 00:31:38,261] Trial 208 finished with value: 81.79999542236328 and parameters: {'Fwd': 9.88199718665299e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.540842345208879, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026211608095844884, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002047722639130664, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002905359766124786
weight_decay:  0.012011383025335014
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8323412879835814
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  1.7644382768776268
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 03
None time:  3.867704732110724
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 74.70
run time now: 7.515510320663452
total time:  7.5547816541511565
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.47 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 74.50 ± 1.21
[I 2023-06-12 00:31:46,295] Trial 209 finished with value: 76.46666717529297 and parameters: {'Fwd': 5.633017655263716e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 7.1891769748892065, 'loop': 1, 'loss': 'MSE', 'lr': 0.002905359766124786, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.012011383025335014, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.003352873736644082
weight_decay:  0.005451244647532648
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8920536320656538
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.1080, Train: 100.00%, Valid: 79.40% Test: 78.40%
Split: 01, Run: 02
None time:  3.5869951019994915
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.4399564489722252
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 75.90
run time now: 6.968514442443848
total time:  7.019444033969194
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 1.78
  Final Train: 100.00 ± 0.00
   Final Test: 77.47 ± 1.38
[I 2023-06-12 00:31:53,947] Trial 210 finished with value: 80.20000457763672 and parameters: {'Fwd': 7.743606670330585e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 6.744863327535296, 'loop': 1, 'loss': 'MSE', 'lr': 0.003352873736644082, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.005451244647532648, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0024488882312494876
weight_decay:  0.003414778524714976
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.539485476911068
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.4840209598187357
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.0166458571329713
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.00
run time now: 5.088980197906494
total time:  5.1444851299747825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 79.03 ± 1.19
[I 2023-06-12 00:31:59,592] Trial 211 finished with value: 82.5999984741211 and parameters: {'Fwd': 4.729408979280169e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 7.030971103948327, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024488882312494876, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003414778524714976, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002481555784968072
weight_decay:  0.0030579964067885906
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6482146789785475
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.6326298811472952
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  0.9792885149363428
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.307655334472656
total time:  5.357225501909852
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 1.57
[I 2023-06-12 00:32:05,442] Trial 212 finished with value: 82.60000610351562 and parameters: {'Fwd': 4.5255125783769456e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 6.991967830838434, 'loop': 1, 'loss': 'MSE', 'lr': 0.002481555784968072, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0030579964067885906, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0023399568033827243
weight_decay:  0.0033133542777024384
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8485548000317067
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.2996319138910621
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 75.20
Split: 01, Run: 03
None time:  1.4433235561009496
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 75.10
run time now: 3.6415185928344727
total time:  3.694549614097923
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.47 ± 4.16
  Final Train: 100.00 ± 0.00
   Final Test: 73.30 ± 3.20
[I 2023-06-12 00:32:09,628] Trial 213 finished with value: 74.46666717529297 and parameters: {'Fwd': 4.401779659259035e-06, 'K': 10, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 6.89625393254315, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023399568033827243, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0033133542777024384, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0028089397328017545
weight_decay:  0.004973208462302178
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2975, Train: 100.00%, Valid: 82.60% Test: 79.00%
Split: 01, Run: 01
None time:  3.6973523581400514
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02, Epoch: 100, Loss: 0.1658, Train: 100.00%, Valid: 80.80% Test: 78.80%
Split: 01, Run: 02
None time:  3.634231188101694
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.0690532817970961
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.50
run time now: 8.450337886810303
total time:  8.502574377926067
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 79.43 ± 0.93
[I 2023-06-12 00:32:18,645] Trial 214 finished with value: 81.66666412353516 and parameters: {'Fwd': 5.738996948510813e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 7.071826107273272, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028089397328017545, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004973208462302178, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002479257619705802
weight_decay:  0.0031178714861049652
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2372603840194643
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.2535423869267106
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.8263298769015819
None Run 03:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 80.40
run time now: 5.37444806098938
total time:  5.430860286811367
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.07 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 79.27 ± 1.55
[I 2023-06-12 00:32:24,611] Trial 215 finished with value: 83.0666732788086 and parameters: {'Fwd': 4.474435704265262e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 6.494810880285327, 'loop': 1, 'loss': 'MSE', 'lr': 0.002479257619705802, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0031178714861049652, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002284307824766884
weight_decay:  0.007879596973037565
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9041348949540406
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.7519477219320834
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.6327223379630595
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.60
run time now: 4.338717699050903
total time:  4.384996965993196
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.13 ± 7.22
  Final Train: 100.00 ± 0.00
   Final Test: 76.00 ± 5.56
[I 2023-06-12 00:32:29,507] Trial 216 finished with value: 78.13333129882812 and parameters: {'Fwd': 4.802396536959539e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 6.499265187199381, 'loop': 1, 'loss': 'MSE', 'lr': 0.002284307824766884, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007879596973037565, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002424012229076173
weight_decay:  0.0017596787476152173
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.5978109911084175
None Run 01:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.1790, Train: 100.00%, Valid: 81.20% Test: 79.00%
Split: 01, Run: 02
None time:  3.339745332952589
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.6360508191864938
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.30
run time now: 8.617875337600708
total time:  8.66850637178868
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 79.40 ± 0.78
[I 2023-06-12 00:32:38,642] Trial 217 finished with value: 82.33333587646484 and parameters: {'Fwd': 8.063797050794022e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.984242786987769, 'loop': 1, 'loss': 'MSE', 'lr': 0.002424012229076173, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0017596787476152173, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002207263135639023
weight_decay:  0.004198193562038169
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.819557646056637
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.0991768869571388
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  0.9298436660319567
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 4.897130012512207
total time:  4.942774133058265
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 1.65
[I 2023-06-12 00:32:44,125] Trial 218 finished with value: 82.26667022705078 and parameters: {'Fwd': 1.3120163823047794e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 6.345015525839525, 'loop': 1, 'loss': 'MSE', 'lr': 0.002207263135639023, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004198193562038169, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0030498816065023812
weight_decay:  0.00223595321701423
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5939563219435513
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  1.7581943650729954
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.0439745269250125
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.60
run time now: 5.4451751708984375
total time:  5.493499091826379
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 1.15
[I 2023-06-12 00:32:50,085] Trial 219 finished with value: 80.86666870117188 and parameters: {'Fwd': 3.9759563081968064e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.20742036889921, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030498816065023812, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00223595321701423, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0024809145447946762
weight_decay:  0.003313137004470566
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.574906743131578
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.12102588894777
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.0648733859416097
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 81.50
run time now: 2.8052773475646973
total time:  2.845985237043351
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.80 ± 7.79
  Final Train: 100.00 ± 0.00
   Final Test: 76.60 ± 6.22
[I 2023-06-12 00:32:53,410] Trial 220 finished with value: 78.79999542236328 and parameters: {'Fwd': 6.1192060987204995e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 7.127240066760726, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024809145447946762, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003313137004470566, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0027071710787607076
weight_decay:  0.0024148899005976437
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4007634550798684
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.326628307113424
None Run 02:
Highest Train: 100.00
Highest Valid: 84.40
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.1379, Train: 100.00%, Valid: 83.60% Test: 79.10%
Split: 01, Run: 03
None time:  3.43961227289401
None Run 03:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.10
run time now: 7.2143330574035645
total time:  7.26186276297085
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.33 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 78.93 ± 0.86
[I 2023-06-12 00:33:01,149] Trial 221 finished with value: 83.33333587646484 and parameters: {'Fwd': 3.571629777120064e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.759193570834122, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027071710787607076, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0024148899005976437, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0027812170377012136
weight_decay:  0.0017648512563344417
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.0584065481089056
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.4799211600329727
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  0.8683721900451928
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.70
run time now: 5.455118417739868
total time:  5.500598971964791
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 78.53 ± 0.96
[I 2023-06-12 00:33:07,169] Trial 222 finished with value: 82.33333587646484 and parameters: {'Fwd': 4.443003206319804e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.797351269540401, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027812170377012136, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0017648512563344417, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0025393304668650646
weight_decay:  0.0029840771263552964
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.4090, Train: 100.00%, Valid: 80.80% Test: 76.80%
Split: 01, Run: 01
None time:  3.724657644983381
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 02
None time:  1.0888496888801455
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  1.3611759450286627
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.60
run time now: 6.233106851577759
total time:  6.296881397021934
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 1.29
  Final Train: 100.00 ± 0.00
   Final Test: 77.87 ± 1.72
[I 2023-06-12 00:33:13,963] Trial 223 finished with value: 81.73332977294922 and parameters: {'Fwd': 3.432484620153974e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 6.951594192683238, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025393304668650646, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0029840771263552964, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.0
lr:  0.002154948907400714
weight_decay:  0.0022897322701629806
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.4641030877828598
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.3672050500754267
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.46017394377849996
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 1.3469841480255127
total time:  1.3996403450146317
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.00
[I 2023-06-12 00:33:15,922] Trial 224 finished with value: 69.80000305175781 and parameters: {'Fwd': 9.7670209632294e-06, 'K': 10, 'alpha': 0.0, 'dropout': 0.9, 'gnnepoch': 10, 'lambda1': 0.6000000000000001, 'lambda2': 6.686658831750131, 'loop': 1, 'loss': 'MSE', 'lr': 0.002154948907400714, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0022897322701629806, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.003149201173821627
weight_decay:  0.004644711210256239
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0624302870128304
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.1330223029945046
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.0466970221605152
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.00
run time now: 4.294156074523926
total time:  4.346510319970548
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 1.26
[I 2023-06-12 00:33:20,796] Trial 225 finished with value: 81.9333267211914 and parameters: {'Fwd': 5.461069812958612e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 4.741512148544322, 'loop': 1, 'loss': 'MSE', 'lr': 0.003149201173821627, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004644711210256239, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0028752880025887874
weight_decay:  0.0034531459693529893
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7385225659236312
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.8980247960425913
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  0.9914807400200516
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.80
run time now: 3.6784064769744873
total time:  3.7309620219748467
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.67 ± 7.05
  Final Train: 100.00 ± 0.00
   Final Test: 75.47 ± 5.33
[I 2023-06-12 00:33:25,095] Trial 226 finished with value: 77.66666412353516 and parameters: {'Fwd': 3.8910740563394025e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 7.279840309954992, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028752880025887874, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0034531459693529893, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0023562758535156394
weight_decay:  0.0061693259451559524
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.123316915007308
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  2.003857356030494
None Run 02:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.4508682289160788
None Run 03:
Highest Train: 100.00
Highest Valid: 84.40
  Final Train: 100.00
   Final Test: 79.90
run time now: 5.622335433959961
total time:  5.672940267017111
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.53 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 79.23 ± 1.51
[I 2023-06-12 00:33:31,301] Trial 227 finished with value: 83.53333282470703 and parameters: {'Fwd': 3.2313660532055144e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 3.0756985376078476, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023562758535156394, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0061693259451559524, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0025154354358977674
weight_decay:  0.009868329437216022
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.4122, Train: 100.00%, Valid: 80.40% Test: 76.50%
Split: 01, Run: 01
None time:  3.599278162000701
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  1.0696710960473865
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 03
None time:  1.2551345240790397
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.70
run time now: 5.982089519500732
total time:  6.044767459854484
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 77.73 ± 1.74
[I 2023-06-12 00:33:37,837] Trial 228 finished with value: 81.66666412353516 and parameters: {'Fwd': 4.938963898239851e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 4.363722068352997, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025154354358977674, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.009868329437216022, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0002515550376304834
weight_decay:  0.006707147737525924
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1239221149589866
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.582582503091544
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 03, Epoch: 100, Loss: 0.5600, Train: 100.00%, Valid: 80.20% Test: 76.30%
Split: 01, Run: 03
None time:  3.6534982309676707
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 76.20
run time now: 6.419579744338989
total time:  6.479930690024048
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.40 ± 5.74
  Final Train: 100.00 ± 0.00
   Final Test: 73.03 ± 3.37
[I 2023-06-12 00:33:44,891] Trial 229 finished with value: 76.4000015258789 and parameters: {'Fwd': 2.810889711149313e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 1.75567992849854, 'loop': 1, 'loss': 'MSE', 'lr': 0.0002515550376304834, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006707147737525924, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.003519400808254385
weight_decay:  0.004926170284496091
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8472570239100605
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.111750383861363
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.6180095931049436
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.50
run time now: 3.629121780395508
total time:  3.6848447620868683
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.13 ± 7.22
  Final Train: 100.00 ± 0.00
   Final Test: 76.17 ± 5.69
[I 2023-06-12 00:33:49,014] Trial 230 finished with value: 78.13333129882812 and parameters: {'Fwd': 7.39568069106169e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 2.7018243957669528, 'loop': 1, 'loss': 'MSE', 'lr': 0.003519400808254385, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004926170284496091, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0023263664673482064
weight_decay:  0.0025690017908001415
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.350284883985296
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.9351262629497796
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.1481495790649205
None Run 03:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 80.30
run time now: 5.480487585067749
total time:  5.5336108398623765
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.87 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 78.77 ± 1.36
[I 2023-06-12 00:33:55,136] Trial 231 finished with value: 82.86666107177734 and parameters: {'Fwd': 3.3615946488283374e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.488839771209995, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023263664673482064, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0025690017908001415, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002322931125750052
weight_decay:  0.00290553483928794
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.251335356850177
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.3824792890809476
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.2256776071153581
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.927954435348511
total time:  4.984234591946006
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.90 ± 1.42
[I 2023-06-12 00:34:00,594] Trial 232 finished with value: 82.4000015258789 and parameters: {'Fwd': 0.0001725070255465745, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.528999259138837, 'loop': 1, 'loss': 'MSE', 'lr': 0.002322931125750052, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00290553483928794, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.00269313038923235
weight_decay:  0.0036370261392095096
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3424, Train: 100.00%, Valid: 81.80% Test: 78.20%
Split: 01, Run: 01
None time:  3.5237481619697064
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  3.215370959136635
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  2.530776476021856
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.10
run time now: 9.318558692932129
total time:  9.35899236612022
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.80 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 79.40 ± 1.13
[I 2023-06-12 00:34:10,400] Trial 233 finished with value: 82.80000305175781 and parameters: {'Fwd': 4.179270457155324e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 5.823540239181596, 'loop': 1, 'loss': 'MSE', 'lr': 0.00269313038923235, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0036370261392095096, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002690490527034049
weight_decay:  0.003937029235685693
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9234481782186776
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  3.068006840068847
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  0.8161872159689665
None Run 03:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 78.80
run time now: 6.856600046157837
total time:  6.899219166021794
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.00 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 78.77 ± 0.85
[I 2023-06-12 00:34:17,797] Trial 234 finished with value: 83.00000762939453 and parameters: {'Fwd': 4.291298703653436e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.73017536153089, 'loop': 1, 'loss': 'MSE', 'lr': 0.002690490527034049, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003937029235685693, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0027362813768203797
weight_decay:  0.003960379282018221
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9440285270102322
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.1928115459159017
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  1.0023918801452965
None Run 03:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.90
run time now: 3.1895134449005127
total time:  3.2339680411387235
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 3.30
  Final Train: 100.00 ± 0.00
   Final Test: 71.40 ± 2.33
[I 2023-06-12 00:34:21,588] Trial 235 finished with value: 72.5999984741211 and parameters: {'Fwd': 4.31432744503459e-06, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.732803449663634, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027362813768203797, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003960379282018221, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002996784055180042
weight_decay:  0.006281406345509141
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.05040472606197
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 76.20
Split: 01, Run: 02
None time:  1.0128559649456292
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.4795528720133007
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.593084335327148
total time:  4.6328731088433415
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 2.05
[I 2023-06-12 00:34:26,673] Trial 236 finished with value: 81.93333435058594 and parameters: {'Fwd': 3.509339489232493e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.2753837832686274, 'loop': 1, 'loss': 'MSE', 'lr': 0.002996784055180042, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006281406345509141, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0027096715088727346
weight_decay:  0.007895796189872201
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.37791269691661
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  0.9967281010467559
None Run 02:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.1840462440159172
None Run 03:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.6178741455078125
total time:  4.672582475002855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.53 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 79.67 ± 1.63
[I 2023-06-12 00:34:31,817] Trial 237 finished with value: 83.53333282470703 and parameters: {'Fwd': 5.639264105800506e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.765322124879661, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027096715088727346, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007895796189872201, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0026756234781134423
weight_decay:  0.00899459131601474
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9853811080101877
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.463948359945789
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.0598161639645696
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.60
run time now: 5.557813405990601
total time:  5.5976787221152335
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.80 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 79.03 ± 0.98
[I 2023-06-12 00:34:37,940] Trial 238 finished with value: 82.80000305175781 and parameters: {'Fwd': 5.53099939291379e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.5944120931939105, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026756234781134423, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00899459131601474, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.003264461910358699
weight_decay:  0.009533168864105365
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0587036882061511
None Run 01:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 02
None time:  1.1148474109359086
None Run 02:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 98.33
   Final Test: 71.20
Split: 01, Run: 03
None time:  0.9670940770301968
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 98.33
   Final Test: 80.20
run time now: 3.189141035079956
total time:  3.2393315751105547
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.33 ± 4.02
  Final Train: 98.89 ± 0.96
   Final Test: 75.10 ± 4.62
[I 2023-06-12 00:34:41,645] Trial 239 finished with value: 76.33333587646484 and parameters: {'Fwd': 5.9362644709856926e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.905568867841303, 'loop': 1, 'loss': 'CE', 'lr': 0.003264461910358699, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.009533168864105365, 'weightedloss': True}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0027033616691168314
weight_decay:  0.012383149610510383
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6134897070005536
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.6135357900056988
None Run 02:
Highest Train: 100.00
Highest Valid: 84.60
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.22298308997415
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.500140428543091
total time:  5.554867428028956
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.27 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 79.03 ± 1.10
[I 2023-06-12 00:34:47,704] Trial 240 finished with value: 83.26667022705078 and parameters: {'Fwd': 7.015774180727754e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.657239194641464, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027033616691168314, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.012383149610510383, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0027052090308658135
weight_decay:  0.005845056186155768
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8238720630761236
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.1982319939415902
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  0.9629996949806809
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.80
run time now: 5.038636207580566
total time:  5.090998325962573
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.93 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 79.13 ± 1.07
[I 2023-06-12 00:34:53,285] Trial 241 finished with value: 82.93333435058594 and parameters: {'Fwd': 6.826371309435263e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.746413947516091, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027052090308658135, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005845056186155768, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0028665723993100685
weight_decay:  0.0080916537139939
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.3523425499442965
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.041767467977479
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  2.405270733172074
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.30
run time now: 6.8509416580200195
total time:  6.897539662895724
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.35
[I 2023-06-12 00:35:00,614] Trial 242 finished with value: 81.33333587646484 and parameters: {'Fwd': 8.263010446401596e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.633361107852206, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028665723993100685, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0080916537139939, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002703262656121682
weight_decay:  0.012883133657722323
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6693998160772026
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.8175906101241708
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  1.0547294840216637
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.70
run time now: 5.593791484832764
total time:  5.634017625125125
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.87 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.53
[I 2023-06-12 00:35:06,720] Trial 243 finished with value: 82.86666870117188 and parameters: {'Fwd': 5.561606857777092e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.792648890113108, 'loop': 1, 'loss': 'MSE', 'lr': 0.002703262656121682, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.012883133657722323, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.003040267239381225
weight_decay:  0.013040713330256666
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2680, Train: 100.00%, Valid: 82.40% Test: 78.20%
Split: 01, Run: 01
None time:  3.7969280581455678
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  0.8106256099417806
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  0.8708149129524827
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.70
run time now: 5.524851083755493
total time:  5.569404084002599
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 79.00 ± 0.82
[I 2023-06-12 00:35:12,838] Trial 244 finished with value: 81.66666412353516 and parameters: {'Fwd': 9.194656005934706e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.799216724284869, 'loop': 1, 'loss': 'MSE', 'lr': 0.003040267239381225, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.013040713330256666, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002725609742067572
weight_decay:  0.014063819903934289
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.803907203953713
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.9354855709243566
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  0.7188079608604312
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.70
run time now: 5.5135204792022705
total time:  5.5547423081006855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.00 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 79.23 ± 1.08
[I 2023-06-12 00:35:18,934] Trial 245 finished with value: 83.0 and parameters: {'Fwd': 6.40152556193664e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.386405445292846, 'loop': 1, 'loss': 'MSE', 'lr': 0.002725609742067572, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.014063819903934289, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0026883501497687637
weight_decay:  0.01351991400896778
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.844230543123558
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 02
None time:  1.3030319919344038
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  1.037466495996341
None Run 03:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.10
run time now: 5.233578443527222
total time:  5.287233628099784
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.07 ± 1.29
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 2.19
[I 2023-06-12 00:35:24,698] Trial 246 finished with value: 83.0666732788086 and parameters: {'Fwd': 5.918774862287247e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.27789355325695, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026883501497687637, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.01351991400896778, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002608368014068722
weight_decay:  0.01606021999471142
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3368455281015486
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  1.6740690330043435
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.1117039029486477
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.60
run time now: 5.172705173492432
total time:  5.221967762103304
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 1.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 1.82
[I 2023-06-12 00:35:30,359] Trial 247 finished with value: 82.0 and parameters: {'Fwd': 6.403879448569113e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.388278672418592, 'loop': 1, 'loss': 'MSE', 'lr': 0.002608368014068722, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.01606021999471142, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.003235795706097966
weight_decay:  0.015423611776303147
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.441684565972537
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  0.8543055530171841
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  2.6805568169802427
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.50
run time now: 6.0265281200408936
total time:  6.079308087006211
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 1.25
[I 2023-06-12 00:35:36,919] Trial 248 finished with value: 81.53333282470703 and parameters: {'Fwd': 6.6503086402557985e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.558066626793622, 'loop': 1, 'loss': 'MSE', 'lr': 0.003235795706097966, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.015423611776303147, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002609916085709189
weight_decay:  0.015809179683434465
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.9775083949789405
None Run 01:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 02
None time:  1.481551529839635
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 03
None time:  1.5289509070571512
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 72.40
run time now: 7.040837526321411
total time:  7.089133483124897
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 73.63 ± 1.50
[I 2023-06-12 00:35:44,479] Trial 249 finished with value: 75.46666717529297 and parameters: {'Fwd': 5.210539458921229e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.214793038456641, 'loop': 1, 'loss': 'MSE', 'lr': 0.002609916085709189, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.015809179683434465, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0029006457894149447
weight_decay:  0.019183723956751546
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2618, Train: 100.00%, Valid: 81.60% Test: 77.60%
Split: 01, Run: 01
None time:  3.6373617390636355
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.063557499088347
None Run 02:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.6907309361267835
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.10
run time now: 6.44063138961792
total time:  6.483768021920696
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.87 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 78.97 ± 1.40
[I 2023-06-12 00:35:51,453] Trial 250 finished with value: 82.86666107177734 and parameters: {'Fwd': 7.325390431496339e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.796607217246942, 'loop': 1, 'loss': 'MSE', 'lr': 0.0029006457894149447, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.019183723956751546, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0030564191270081044
weight_decay:  0.012593756815797852
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.639902878087014
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 76.10
Split: 01, Run: 02
None time:  1.3628851601388305
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  0.9318677540868521
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 3.9807095527648926
total time:  4.023914457997307
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 1.75
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 2.06
[I 2023-06-12 00:35:56,064] Trial 251 finished with value: 81.66666412353516 and parameters: {'Fwd': 7.438989780237712e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.73143107162737, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030564191270081044, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.012593756815797852, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0034391740459019365
weight_decay:  0.02162348478565495
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2789495731703937
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.1156568198930472
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  0.9834863399155438
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.20
run time now: 4.431647777557373
total time:  4.480530914850533
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.47 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 78.57 ± 0.65
[I 2023-06-12 00:36:01,112] Trial 252 finished with value: 82.46666717529297 and parameters: {'Fwd': 1.5199349732965833e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.944856363015005, 'loop': 1, 'loss': 'MSE', 'lr': 0.0034391740459019365, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.02162348478565495, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0023544141422620303
weight_decay:  0.021815859887884568
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9276554519310594
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.9258010920602828
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  0.9270738419145346
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 80.30
run time now: 2.8296914100646973
total time:  2.8716177649330348
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.33 ± 7.75
  Final Train: 100.00 ± 0.00
   Final Test: 75.93 ± 5.92
[I 2023-06-12 00:36:04,458] Trial 253 finished with value: 78.33333587646484 and parameters: {'Fwd': 5.519666899188532e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.498455138198467, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023544141422620303, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.021815859887884568, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.00380642032826113
weight_decay:  0.009725401289643595
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2201, Train: 100.00%, Valid: 81.60% Test: 78.40%
Split: 01, Run: 01
None time:  3.3655338999815285
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.4407506419811398
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  1.077193875098601
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.00
run time now: 5.9328532218933105
total time:  5.984533688053489
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.87 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 79.13 ± 0.81
[I 2023-06-12 00:36:10,982] Trial 254 finished with value: 82.86666870117188 and parameters: {'Fwd': 6.8344348557549495e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.745557829905363, 'loop': 1, 'loss': 'MSE', 'lr': 0.00380642032826113, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.009725401289643595, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0036824190311454596
weight_decay:  0.010225104566586964
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2273, Train: 100.00%, Valid: 82.40% Test: 78.10%
Split: 01, Run: 01
None time:  3.7305157037917525
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.0544545229058713
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.616704965941608
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.20
run time now: 6.45391321182251
total time:  6.494962660130113
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 0.64
[I 2023-06-12 00:36:18,023] Trial 255 finished with value: 82.93334197998047 and parameters: {'Fwd': 7.607189307346004e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.690445863607578, 'loop': 1, 'loss': 'MSE', 'lr': 0.0036824190311454596, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.010225104566586964, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.004012467237738796
weight_decay:  0.009553320609972988
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2024, Train: 100.00%, Valid: 81.80% Test: 78.10%
Split: 01, Run: 01
None time:  3.7004658619407564
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  0.8946651900187135
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.6130941351875663
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.2567033767700195
total time:  6.308008345076814
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.80 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 79.10 ± 1.31
[I 2023-06-12 00:36:24,874] Trial 256 finished with value: 82.80000305175781 and parameters: {'Fwd': 8.356527043879852e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.848714082437947, 'loop': 1, 'loss': 'MSE', 'lr': 0.004012467237738796, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.009553320609972988, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.004176981713808836
weight_decay:  0.00964767093438399
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2269, Train: 100.00%, Valid: 81.80% Test: 77.40%
Split: 01, Run: 01
None time:  3.584211144829169
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  1.4482611690182239
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  1.6582074828911573
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.60
run time now: 6.736457824707031
total time:  6.783228048821911
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.47 ± 1.15
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 1.30
[I 2023-06-12 00:36:32,158] Trial 257 finished with value: 82.46666717529297 and parameters: {'Fwd': 8.2104921018133e-06, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.705883789016751, 'loop': 1, 'loss': 'MSE', 'lr': 0.004176981713808836, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00964767093438399, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.004624915316877649
weight_decay:  0.00939273187658837
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.141100456006825
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.802791021997109
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  0.8748508389107883
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 76.10
run time now: 5.859346866607666
total time:  5.912286591017619
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 77.03 ± 0.90
[I 2023-06-12 00:36:38,689] Trial 258 finished with value: 81.46666717529297 and parameters: {'Fwd': 1.1838462426876819e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.843525007632027, 'loop': 1, 'loss': 'MSE', 'lr': 0.004624915316877649, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00939273187658837, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0032361062539903833
weight_decay:  0.011699516472508234
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.884177068946883
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  1.2121124227996916
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.948810855159536
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.094331979751587
total time:  5.14147450402379
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 78.80 ± 1.22
[I 2023-06-12 00:36:44,298] Trial 259 finished with value: 82.33333587646484 and parameters: {'Fwd': 7.176251826254194e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.190031795553023, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032361062539903833, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.011699516472508234, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0037594420693973013
weight_decay:  0.007931006416958215
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6042541759088635
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.193396981107071
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  0.9084852340165526
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.80
run time now: 4.76332950592041
total time:  4.81343881203793
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 77.73 ± 0.81
[I 2023-06-12 00:36:49,575] Trial 260 finished with value: 81.53333282470703 and parameters: {'Fwd': 9.044191389581004e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.565641294654234, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037594420693973013, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.007931006416958215, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.004220542147598312
weight_decay:  0.010706603200070474
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1967, Train: 100.00%, Valid: 83.00% Test: 78.50%
Split: 01, Run: 01
None time:  3.67192317917943
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.6246838059742004
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.5111621101386845
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.70
run time now: 6.857320308685303
total time:  6.906408621929586
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.73 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.20
[I 2023-06-12 00:36:56,975] Trial 261 finished with value: 82.73333740234375 and parameters: {'Fwd': 6.325365271951268e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.976432607075159, 'loop': 1, 'loss': 'MSE', 'lr': 0.004220542147598312, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.010706603200070474, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.003826415119726035
weight_decay:  0.008526108468834363
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2468, Train: 100.00%, Valid: 81.00% Test: 77.30%
Split: 01, Run: 01
None time:  3.4127848350908607
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 02
None time:  1.1153135451022536
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.0134989109355956
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.00
run time now: 5.593188285827637
total time:  5.644110240973532
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 77.80 ± 0.53
[I 2023-06-12 00:37:03,089] Trial 262 finished with value: 81.86666107177734 and parameters: {'Fwd': 9.67613351045574e-06, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.703905285013671, 'loop': 1, 'loss': 'MSE', 'lr': 0.003826415119726035, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.008526108468834363, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.004583353770802473
weight_decay:  0.010130716189564485
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8595549119636416
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.9238391239196062
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.0207316959276795
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 2.863971710205078
total time:  2.912839172873646
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.47 ± 8.21
  Final Train: 100.00 ± 0.00
   Final Test: 75.57 ± 5.47
[I 2023-06-12 00:37:06,570] Trial 263 finished with value: 78.46666717529297 and parameters: {'Fwd': 6.191246160616322e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.385503235764527, 'loop': 1, 'loss': 'MSE', 'lr': 0.004583353770802473, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.010130716189564485, 'weightedloss': True}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.003617423894684607
weight_decay:  0.014284192576559978
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.671948374947533
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 80.40% Test: 77.30%
Split: 01, Run: 02
None time:  2.793456824030727
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 83.20% Test: 79.90%
Split: 01, Run: 03
None time:  2.4059910690411925
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.90
run time now: 5.919043064117432
total time:  5.9638637288007885
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.67 ± 7.29
  Final Train: 100.00 ± 0.00
   Final Test: 75.47 ± 5.58
[I 2023-06-12 00:37:13,139] Trial 264 finished with value: 77.66666412353516 and parameters: {'Fwd': 4.6225296918811246e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.0400530216640815, 'loop': 0, 'loss': 'MSE', 'lr': 0.003617423894684607, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.014284192576559978, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.005826163315704052
weight_decay:  0.011761606752614628
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.038012963021174
None Run 01:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 02
None time:  1.1112109899986535
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 96.67
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.0541114769876003
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 96.67
   Final Test: 80.60
run time now: 3.2515664100646973
total time:  3.3006609010044485
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.47 ± 6.15
  Final Train: 97.78 ± 1.92
   Final Test: 77.43 ± 5.57
[I 2023-06-12 00:37:17,002] Trial 265 finished with value: 78.46666717529297 and parameters: {'Fwd': 1.3461590772547791e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.051982527597478, 'loop': 1, 'loss': 'CE', 'lr': 0.005826163315704052, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.011761606752614628, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.003699722695270108
weight_decay:  0.018616676349816324
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4231940349563956
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  0.8949219819623977
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.3990410801488906
None Run 03:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 80.60
run time now: 4.775480508804321
total time:  4.819344563875347
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.07 ± 1.42
  Final Train: 100.00 ± 0.00
   Final Test: 79.20 ± 1.23
[I 2023-06-12 00:37:22,442] Trial 266 finished with value: 82.0666732788086 and parameters: {'Fwd': 5.309235720346906e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.441408101244246, 'loop': 1, 'loss': 'MSE', 'lr': 0.003699722695270108, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.018616676349816324, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.004465822756796875
weight_decay:  0.016883939032951708
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2756083451677114
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.9569325251504779
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  2.5475412709638476
None Run 03:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 79.70
run time now: 6.828555107116699
total time:  6.875271836062893
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 1.85
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 1.47
[I 2023-06-12 00:37:29,782] Trial 267 finished with value: 81.66666412353516 and parameters: {'Fwd': 7.403722179043511e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.86743959099369, 'loop': 1, 'loss': 'MSE', 'lr': 0.004465822756796875, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.016883939032951708, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.005378968670458779
weight_decay:  0.01395981073938088
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.342423927038908
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.2352108568884432
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  1.573701350018382
None Run 03:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 78.90
run time now: 5.198871612548828
total time:  5.251242893980816
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.53 ± 1.29
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 0.72
[I 2023-06-12 00:37:35,628] Trial 268 finished with value: 82.53333282470703 and parameters: {'Fwd': 4.901198813271818e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.689587402238125, 'loop': 1, 'loss': 'MSE', 'lr': 0.005378968670458779, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.01395981073938088, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0038815971543658652
weight_decay:  0.008552208073299407
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.733189052902162
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.002443270990625
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.0382444609422237
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.90
run time now: 4.82464075088501
total time:  4.881024644942954
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 0.59
[I 2023-06-12 00:37:41,044] Trial 269 finished with value: 81.73333740234375 and parameters: {'Fwd': 8.280813416267294e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.3228767200720295, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038815971543658652, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.008552208073299407, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.004190315303248566
weight_decay:  0.020712614237776268
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8491491170134395
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.9623101819306612
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  1.7298441708553582
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.80
run time now: 3.5943992137908936
total time:  3.6815288809593767
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.73 ± 7.22
  Final Train: 100.00 ± 0.00
   Final Test: 75.77 ± 5.69
[I 2023-06-12 00:37:45,216] Trial 270 finished with value: 77.73333740234375 and parameters: {'Fwd': 1.0875104153453376e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.550670965324028, 'loop': 1, 'loss': 'MSE', 'lr': 0.004190315303248566, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.020712614237776268, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.003433761780406051
weight_decay:  0.006727720358303298
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.677457763114944
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.80
Split: 01, Run: 02
None time:  1.6708761039189994
None Run 02:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.00
Split: 01, Run: 03
None time:  2.1931746029295027
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.10
run time now: 5.589159965515137
total time:  5.630389880854636
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.33 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 75.63 ± 0.57
[I 2023-06-12 00:37:51,457] Trial 271 finished with value: 77.33334350585938 and parameters: {'Fwd': 6.372818028883528e-06, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.143636693911987, 'loop': 1, 'loss': 'MSE', 'lr': 0.003433761780406051, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.006727720358303298, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002723881332672944
weight_decay:  0.03488744251092567
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9169581150636077
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.0457339631393552
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  0.8767665289342403
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.50
run time now: 4.888348817825317
total time:  4.937571187969297
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 1.71
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 0.76
[I 2023-06-12 00:37:56,999] Trial 272 finished with value: 81.79999542236328 and parameters: {'Fwd': 4.510034089376129e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.877636697680235, 'loop': 1, 'loss': 'MSE', 'lr': 0.002723881332672944, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.03488744251092567, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0030594250295207935
weight_decay:  0.005930967965609289
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5558570770081133
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 02
None time:  1.2261625740211457
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.4267708910629153
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.30
run time now: 5.259793043136597
total time:  5.2990665880497545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.47 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 1.27
[I 2023-06-12 00:38:02,885] Trial 273 finished with value: 82.46666717529297 and parameters: {'Fwd': 0.0002160825500439825, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.144391634650412, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030594250295207935, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.005930967965609289, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0026596840268698525
weight_decay:  0.01334472293682761
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3359435200691223
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  0.7911682839039713
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.9719310030341148
None Run 03:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.158976793289185
total time:  5.208589866058901
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.07 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 79.23 ± 1.26
[I 2023-06-12 00:38:08,615] Trial 274 finished with value: 83.0666732788086 and parameters: {'Fwd': 1.744761719070718e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.907039774475157, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026596840268698525, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.01334472293682761, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0033447081940014755
weight_decay:  0.013532285598158347
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2247, Train: 100.00%, Valid: 81.20% Test: 78.00%
Split: 01, Run: 01
None time:  3.681925383862108
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.4287491790018976
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.6836535700131208
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.00
run time now: 6.845346450805664
total time:  6.885675176046789
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 78.90 ± 0.75
[I 2023-06-12 00:38:15,956] Trial 275 finished with value: 82.33333587646484 and parameters: {'Fwd': 2.086191684805612e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.440639183325139, 'loop': 1, 'loss': 'MSE', 'lr': 0.0033447081940014755, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.013532285598158347, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.004831379754853605
weight_decay:  0.011061659041704062
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1754, Train: 100.00%, Valid: 82.80% Test: 78.80%
Split: 01, Run: 01
None time:  3.7426462329458445
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  1.406296042026952
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  2.0185859540943056
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.50
run time now: 7.217750787734985
total time:  7.271752856206149
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.67 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 78.83 ± 0.31
[I 2023-06-12 00:38:23,746] Trial 276 finished with value: 82.66666412353516 and parameters: {'Fwd': 1.5121314366218866e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.016482979029857, 'loop': 1, 'loss': 'MSE', 'lr': 0.004831379754853605, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.011061659041704062, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0028090077761605257
weight_decay:  0.008009939346655438
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.835231953067705
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.434202181873843
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  1.0020230819936842
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 79.10
run time now: 5.320096492767334
total time:  5.371154594002292
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 0.81
[I 2023-06-12 00:38:29,635] Trial 277 finished with value: 81.86666870117188 and parameters: {'Fwd': 1.1433541377965685e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.664997736239251, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028090077761605257, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.008009939346655438, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002608727211398458
weight_decay:  0.010383858899503402
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8344237632118165
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.3218246919568628
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.0569477141834795
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.20
run time now: 3.259547472000122
total time:  3.313309890916571
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.47 ± 8.03
  Final Train: 100.00 ± 0.00
   Final Test: 76.00 ± 6.10
[I 2023-06-12 00:38:33,576] Trial 278 finished with value: 78.46666717529297 and parameters: {'Fwd': 5.814793702086379e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 6.041714459910383, 'loop': 1, 'loss': 'MSE', 'lr': 0.002608727211398458, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.010383858899503402, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007672072594877333
weight_decay:  0.005811355553367978
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7885938540566713
None Run 01:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 75.10
Split: 01, Run: 02
None time:  0.9744260378647596
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 03
None time:  2.9532062869984657
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.90
run time now: 6.76606297492981
total time:  6.8156791378278285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.73 ± 1.72
  Final Train: 100.00 ± 0.00
   Final Test: 74.37 ± 2.00
[I 2023-06-12 00:38:40,946] Trial 279 finished with value: 75.73333740234375 and parameters: {'Fwd': 8.747667115868423e-06, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.822962316918047, 'loop': 1, 'loss': 'MSE', 'lr': 0.007672072594877333, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.005811355553367978, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.002995719961262022
weight_decay:  0.01405005551389494
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7272487410809845
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 02
None time:  0.9989560758695006
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  0.9065393118653446
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.50
run time now: 3.672111749649048
total time:  3.7256157600786537
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 2.39
  Final Train: 100.00 ± 0.00
   Final Test: 76.20 ± 2.00
[I 2023-06-12 00:38:45,237] Trial 280 finished with value: 79.93334197998047 and parameters: {'Fwd': 3.103605384420114e-05, 'K': 2, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 3.870628159555735, 'loop': 1, 'loss': 'MSE', 'lr': 0.002995719961262022, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.01405005551389494, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0006749321983111004
weight_decay:  0.007535019920744356
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8998204180970788
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.6371176259126514
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 03
None time:  1.7638986308593303
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.40
run time now: 4.349450349807739
total time:  4.414103192975745
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.33 ± 7.22
  Final Train: 100.00 ± 0.00
   Final Test: 74.40 ± 4.44
[I 2023-06-12 00:38:50,193] Trial 281 finished with value: 77.33333587646484 and parameters: {'Fwd': 7.102120858208606e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.3129808933340055, 'loop': 1, 'loss': 'MSE', 'lr': 0.0006749321983111004, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.007535019920744356, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.0035665763684768277
weight_decay:  0.016764751590186807
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0033619229216129
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.269694770919159
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 74.20
Split: 01, Run: 03
None time:  0.9502890368457884
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.40
run time now: 4.275182247161865
total time:  4.3220771020278335
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.20 ± 3.29
  Final Train: 100.00 ± 0.00
   Final Test: 72.30 ± 2.63
[I 2023-06-12 00:38:55,089] Trial 282 finished with value: 73.19999694824219 and parameters: {'Fwd': 4.183064636228407e-06, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.598140199951354, 'loop': 1, 'loss': 'MSE', 'lr': 0.0035665763684768277, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.016764751590186807, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002562215555027208
weight_decay:  0.02472057935599452
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5008202460594475
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.9304547901265323
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.6182120039593428
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 80.40
run time now: 6.101255893707275
total time:  6.167074861936271
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.13 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 1.28
[I 2023-06-12 00:39:01,829] Trial 283 finished with value: 82.13333129882812 and parameters: {'Fwd': 5.394801369400876e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.100906107741692, 'loop': 1, 'loss': 'MSE', 'lr': 0.002562215555027208, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.02472057935599452, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0028672628773627807
weight_decay:  0.011713656410370876
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1873327160719782
None Run 01:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 02
None time:  1.1393077210523188
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 96.67
   Final Test: 77.00
Split: 01, Run: 03
None time:  1.0032907528802752
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 98.33
   Final Test: 77.70
run time now: 3.3776350021362305
total time:  3.418475904967636
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.47 ± 1.96
  Final Train: 98.33 ± 1.67
   Final Test: 75.67 ± 2.94
[I 2023-06-12 00:39:05,828] Trial 284 finished with value: 78.46666717529297 and parameters: {'Fwd': 0.00041151697578210573, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.923712137280821, 'loop': 1, 'loss': 'CE', 'lr': 0.0028672628773627807, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.011713656410370876, 'weightedloss': True}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0023922581433187913
weight_decay:  0.008974754546848596
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3658, Train: 100.00%, Valid: 81.60% Test: 77.70%
Split: 01, Run: 01
None time:  3.3186024830210954
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.2773566220421344
None Run 02:
Highest Train: 100.00
Highest Valid: 84.80
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  0.9844164969399571
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.50
run time now: 5.629456520080566
total time:  5.673639337997884
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.20 ± 2.36
  Final Train: 100.00 ± 0.00
   Final Test: 78.57 ± 0.90
[I 2023-06-12 00:39:12,071] Trial 285 finished with value: 82.19999694824219 and parameters: {'Fwd': 3.883118507816502e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.811380499207048, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023922581433187913, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008974754546848596, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0038729369144157692
weight_decay:  0.00567391134873342
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8988521739374846
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 02
None time:  1.1035275850445032
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  0.7969134550075978
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 76.20
run time now: 2.8441219329833984
total time:  2.8984147429000586
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.07 ± 7.05
  Final Train: 100.00 ± 0.00
   Final Test: 75.30 ± 5.90
[I 2023-06-12 00:39:15,538] Trial 286 finished with value: 77.06666564941406 and parameters: {'Fwd': 9.081016400635921e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 5.4778555923347625, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038729369144157692, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00567391134873342, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0032948481031062505
weight_decay:  0.016829267158036915
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9677000469528139
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.1372, Train: 100.00%, Valid: 80.40% Test: 77.60%
Split: 01, Run: 02
None time:  3.7748158909380436
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  1.0364077710546553
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.40
run time now: 5.82462477684021
total time:  5.863806338049471
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.80 ± 6.42
  Final Train: 100.00 ± 0.00
   Final Test: 74.70 ± 4.76
[I 2023-06-12 00:39:21,904] Trial 287 finished with value: 76.80000305175781 and parameters: {'Fwd': 9.290892944724385e-06, 'K': 10, 'alpha': 0.65, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.205873723469912, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032948481031062505, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.016829267158036915, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0026245421139836256
weight_decay:  0.007391400250006614
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3933, Train: 100.00%, Valid: 80.80% Test: 76.80%
Split: 01, Run: 01
None time:  3.3925626210402697
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 02
None time:  1.3149388611782342
None Run 02:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.1187270579393953
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.30
run time now: 5.875313758850098
total time:  5.928580274805427
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.60 ± 1.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.60 ± 1.76
[I 2023-06-12 00:39:28,459] Trial 288 finished with value: 82.5999984741211 and parameters: {'Fwd': 6.997117183574018e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.673500774329588, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026245421139836256, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007391400250006614, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.0030871884283080343
weight_decay:  0.013212263689829208
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5444944759365171
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.40
Split: 01, Run: 02
None time:  4.182178983930498
None Run 02:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.20
Split: 01, Run: 03
None time:  1.6963707371614873
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 73.70
run time now: 7.472147464752197
total time:  7.516469571972266
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.87 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 74.77 ± 0.93
[I 2023-06-12 00:39:36,469] Trial 289 finished with value: 76.86666870117188 and parameters: {'Fwd': 5.072308508348065e-06, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.946637218602978, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030871884283080343, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.013212263689829208, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.005113652162419992
weight_decay:  0.026087233919023345
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2896705789025873
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  0.8898076058831066
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  2.1346135060302913
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.90
run time now: 5.36755633354187
total time:  5.418825255939737
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 1.24
[I 2023-06-12 00:39:42,440] Trial 290 finished with value: 81.80001068115234 and parameters: {'Fwd': 1.27215734380271e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.31908333794697, 'loop': 1, 'loss': 'MSE', 'lr': 0.005113652162419992, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.026087233919023345, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0022351807724223923
weight_decay:  0.0052561945491641756
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4576634629629552
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  1.5621645841747522
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.2734368271194398
None Run 03:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.60
run time now: 5.341364145278931
total time:  5.387623895891011
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 2.48
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 2.08
[I 2023-06-12 00:39:48,282] Trial 291 finished with value: 82.26667022705078 and parameters: {'Fwd': 1.7842750544479854e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.533416950555383, 'loop': 1, 'loss': 'MSE', 'lr': 0.0022351807724223923, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0052561945491641756, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.004334153951697736
weight_decay:  0.00955194424528378
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6514186339918524
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 75.80
Split: 01, Run: 02
None time:  1.2415971751324832
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.205688341986388
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.80
run time now: 4.148005962371826
total time:  4.190073875011876
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 1.82
[I 2023-06-12 00:39:52,949] Trial 292 finished with value: 81.86666870117188 and parameters: {'Fwd': 3.4967163765413896e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.815492498529515, 'loop': 1, 'loss': 'MSE', 'lr': 0.004334153951697736, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00955194424528378, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002750900194644495
weight_decay:  0.01825835064088199
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.792394916061312
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.5163149358704686
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  0.9221934119705111
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.90
run time now: 3.276111125946045
total time:  3.3163577790837735
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.33 ± 7.78
  Final Train: 100.00 ± 0.00
   Final Test: 75.70 ± 5.63
[I 2023-06-12 00:39:56,904] Trial 293 finished with value: 78.33333587646484 and parameters: {'Fwd': 6.177332064135484e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.22238309765317, 'loop': 1, 'loss': 'MSE', 'lr': 0.002750900194644495, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.01825835064088199, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002439186835451642
weight_decay:  0.007184822661832202
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3297560829669237
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  2.198309801053256
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.1377864321693778
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 80.20
run time now: 5.73710036277771
total time:  5.786391098052263
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.47 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.87 ± 1.40
[I 2023-06-12 00:40:03,144] Trial 294 finished with value: 82.4666748046875 and parameters: {'Fwd': 4.363058337539995e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.1669098283219, 'loop': 1, 'loss': 'MSE', 'lr': 0.002439186835451642, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007184822661832202, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.15000000000000002
lr:  0.0029156651523198226
weight_decay:  4.691959626542533e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.598903245991096
None Run 01:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.70
Split: 01, Run: 02
None time:  1.02257135999389
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.70
Split: 01, Run: 03
None time:  1.3352685368154198
None Run 03:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.90
run time now: 4.009702444076538
total time:  4.061204104917124
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.20 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 73.77 ± 0.12
[I 2023-06-12 00:40:07,678] Trial 295 finished with value: 75.19999694824219 and parameters: {'Fwd': 8.947316793654485e-06, 'K': 10, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.646283734248861, 'loop': 1, 'loss': 'MSE', 'lr': 0.0029156651523198226, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.691959626542533e-06, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0032468286763150307
weight_decay:  0.03304162973774996
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0726589797995985
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 75.70
Split: 01, Run: 02
None time:  3.2868813341483474
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  0.8808056209236383
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.80
run time now: 6.289384365081787
total time:  6.340029509039596
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 2.24
[I 2023-06-12 00:40:14,545] Trial 296 finished with value: 81.20000457763672 and parameters: {'Fwd': 7.204542084856196e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.035644564512256, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032468286763150307, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03304162973774996, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.9
lr:  0.0025986172704953515
weight_decay:  0.011379399732536778
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7642000771593302
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 02
None time:  1.4071176280267537
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 73.60
Split: 01, Run: 03
None time:  1.0099974758923054
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 76.70
run time now: 4.223730087280273
total time:  4.275385865010321
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 75.63 ± 1.76
[I 2023-06-12 00:40:19,325] Trial 297 finished with value: 80.0666732788086 and parameters: {'Fwd': 5.268821730537721e-06, 'K': 4, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.2807418994533695, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025986172704953515, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.011379399732536778, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.00011327161600678906
weight_decay:  0.0047244568558326575
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8050120850093663
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.7478810730390251
None Run 02:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  0.9220691851805896
None Run 03:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
run time now: 2.523552894592285
total time:  2.565793678164482
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.20 ± 0.00
[I 2023-06-12 00:40:22,395] Trial 298 finished with value: 69.4000015258789 and parameters: {'Fwd': 3.4276244521144293e-06, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.397833310224619, 'loop': 1, 'loss': 'MSE', 'lr': 0.00011327161600678906, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0047244568558326575, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.003979615279757623
weight_decay:  0.008445412666395487
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.0366953669581562
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.8594183968380094
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  2.6934792189858854
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.70
run time now: 7.641141891479492
total time:  7.692919447785243
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 1.29
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 1.04
[I 2023-06-12 00:40:30,614] Trial 299 finished with value: 81.73332977294922 and parameters: {'Fwd': 1.1374942201921921e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 4.802961261361911, 'loop': 1, 'loss': 'MSE', 'lr': 0.003979615279757623, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008445412666395487, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0022447598485309263
weight_decay:  0.006371404941081529
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3745, Train: 100.00%, Valid: 82.40% Test: 78.70%
Split: 01, Run: 01
None time:  3.5694249160587788
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  0.9581894201692194
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.695449517806992
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.70
run time now: 6.279154062271118
total time:  6.325704131042585
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.13 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 79.87 ± 1.26
[I 2023-06-12 00:40:37,538] Trial 300 finished with value: 83.13333892822266 and parameters: {'Fwd': 4.251780708547732e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.767583478713825, 'loop': 1, 'loss': 'MSE', 'lr': 0.0022447598485309263, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006371404941081529, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002260513491206428
weight_decay:  0.0059574312957502585
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3359, Train: 100.00%, Valid: 82.60% Test: 78.30%
Split: 01, Run: 01
None time:  3.6563917931634933
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.0480416920036077
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.3977010529488325
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 6.151860952377319
total time:  6.2004462911281735
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 2.16
  Final Train: 100.00 ± 0.00
   Final Test: 78.40 ± 1.08
[I 2023-06-12 00:40:44,230] Trial 301 finished with value: 81.86666870117188 and parameters: {'Fwd': 4.282029705817226e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.152602130269149, 'loop': 1, 'loss': 'MSE', 'lr': 0.002260513491206428, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0059574312957502585, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.0024183892848556625
weight_decay:  0.004705287314920317
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6749800487887114
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.3135337959975004
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 03
None time:  1.091459778835997
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 73.00
run time now: 3.1215035915374756
total time:  3.1720212940126657
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.20 ± 2.78
  Final Train: 100.00 ± 0.00
   Final Test: 71.87 ± 2.23
[I 2023-06-12 00:40:47,941] Trial 302 finished with value: 72.20000457763672 and parameters: {'Fwd': 3.038755920651657e-06, 'K': 10, 'alpha': 0.05, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.6157643622417135, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024183892848556625, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004705287314920317, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0020872053087803155
weight_decay:  0.006737098920228941
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5590, Train: 100.00%, Valid: 82.40% Test: 78.20%
Split: 01, Run: 01
None time:  3.71665183105506
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  2.3177409840282053
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.189225204056129
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.80
run time now: 8.271928310394287
total time:  8.313193359877914
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 1.51
[I 2023-06-12 00:40:56,720] Trial 303 finished with value: 82.0 and parameters: {'Fwd': 4.652886560704741e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.928597809364274, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020872053087803155, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006737098920228941, 'weightedloss': True}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002713326782277043
weight_decay:  0.004295870352388493
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.336290458915755
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.0135018969886005
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.8050561312120408
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.60
run time now: 5.208714723587036
total time:  5.263156849890947
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 79.50 ± 1.65
[I 2023-06-12 00:41:02,533] Trial 304 finished with value: 82.33333587646484 and parameters: {'Fwd': 5.505925763018213e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.462633575129049, 'loop': 1, 'loss': 'MSE', 'lr': 0.002713326782277043, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004295870352388493, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0022749553267760684
weight_decay:  0.014302153124575981
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.107120458036661
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.0019933150615543
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.9567716619931161
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.11589241027832
total time:  5.158593115862459
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 79.07 ± 1.25
[I 2023-06-12 00:41:08,212] Trial 305 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.0013052724506227881, 'K': 10, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 4.68045132448019, 'loop': 1, 'loss': 'MSE', 'lr': 0.0022749553267760684, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.014302153124575981, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002929053340516988
weight_decay:  0.0059452982659243085
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9127679220400751
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 74.50
Split: 01, Run: 02
None time:  1.0316226449795067
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 03
None time:  0.9870900220703334
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 98.33
   Final Test: 77.30
run time now: 2.9817051887512207
total time:  3.0302547849714756
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 0.81
  Final Train: 99.44 ± 0.96
   Final Test: 75.90 ± 1.40
[I 2023-06-12 00:41:11,776] Trial 306 finished with value: 79.13333129882812 and parameters: {'Fwd': 3.488376547279905e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 5.75275305779671, 'loop': 1, 'loss': 'CE', 'lr': 0.002929053340516988, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0059452982659243085, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0025157110212071106
weight_decay:  0.011221415460771185
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.4216153759043664
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  0.9692320851609111
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.4284276568796486
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 80.20
run time now: 5.868205308914185
total time:  5.923174211988226
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 1.31
[I 2023-06-12 00:41:18,189] Trial 307 finished with value: 81.60000610351562 and parameters: {'Fwd': 3.4830450346507085e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.986573036779708, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025157110212071106, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.011221415460771185, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.001961755741591148
weight_decay:  0.020051134252875677
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8711154509801418
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.9114412611816078
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.1728, Train: 100.00%, Valid: 82.80% Test: 79.80%
Split: 01, Run: 03
None time:  3.4716374368872494
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.80
run time now: 5.3645501136779785
total time:  5.425267095211893
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.80 ± 6.81
  Final Train: 100.00 ± 0.00
   Final Test: 75.20 ± 5.37
[I 2023-06-12 00:41:24,155] Trial 308 finished with value: 76.80000305175781 and parameters: {'Fwd': 6.286985492861295e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 5.248803190335624, 'loop': 1, 'loss': 'MSE', 'lr': 0.001961755741591148, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.020051134252875677, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0026718951353660804
weight_decay:  0.007526649226793528
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9592967859935015
None Run 01:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 02
None time:  3.166682522976771
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 74.20
Split: 01, Run: 03
None time:  2.05934867891483
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 74.90
run time now: 7.233086109161377
total time:  7.286350147798657
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.27 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 75.00 ± 0.85
[I 2023-06-12 00:41:32,082] Trial 309 finished with value: 77.26667022705078 and parameters: {'Fwd': 6.705555428931585e-05, 'K': 10, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.331925318083628, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026718951353660804, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.007526649226793528, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0021816601410197607
weight_decay:  0.005404797559107453
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8622529900167137
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.0047192531637847
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.6935056580696255
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.00
run time now: 4.606621980667114
total time:  4.649175200844184
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 1.30
[I 2023-06-12 00:41:37,350] Trial 310 finished with value: 82.39999389648438 and parameters: {'Fwd': 0.00014552374954678997, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 3.925012264146842, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021816601410197607, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005404797559107453, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.003105893475563759
weight_decay:  4.940457108664751e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3333, Train: 100.00%, Valid: 81.20% Test: 77.50%
Split: 01, Run: 01
None time:  3.557915440062061
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 02
None time:  1.090770446928218
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.1291383430361748
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.8590734004974365
total time:  5.91908670309931
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.47 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 1.32
[I 2023-06-12 00:41:43,835] Trial 311 finished with value: 82.46666717529297 and parameters: {'Fwd': 0.020353066216979555, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.997376080236259, 'loop': 1, 'loss': 'MSE', 'lr': 0.003105893475563759, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.940457108664751e-05, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0024193925808586826
weight_decay:  0.004083876371807708
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8974770028144121
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  0.9617823679000139
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  1.4023723488207906
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.40
run time now: 4.311700820922852
total time:  4.355633998056874
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.47 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 0.85
[I 2023-06-12 00:41:48,668] Trial 312 finished with value: 82.46666717529297 and parameters: {'Fwd': 4.035258230425376e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 5.595854800408528, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024193925808586826, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004083876371807708, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0029340223362641048
weight_decay:  1.273704746643887e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9901670350227505
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  1.4133039771113545
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 98.33
   Final Test: 80.00
Split: 01, Run: 03
None time:  0.9444596378598362
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 98.33
   Final Test: 78.30
run time now: 4.398438215255737
total time:  4.443369647022337
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 1.14
  Final Train: 98.89 ± 0.96
   Final Test: 78.37 ± 1.60
[I 2023-06-12 00:41:53,602] Trial 313 finished with value: 81.93334197998047 and parameters: {'Fwd': 0.0002681304220840318, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 0.12756817066764992, 'loop': 1, 'loss': 'MSE', 'lr': 0.0029340223362641048, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.273704746643887e-06, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0034720692921094186
weight_decay:  0.008790143161086752
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.027257523033768
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.3011180388275534
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.290462871082127
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.90
run time now: 4.67927360534668
total time:  4.724267865996808
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 79.33 ± 0.60
[I 2023-06-12 00:41:58,851] Trial 314 finished with value: 82.4666748046875 and parameters: {'Fwd': 2.129517768027047e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.415259294227758, 'loop': 1, 'loss': 'MSE', 'lr': 0.0034720692921094186, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008790143161086752, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002726463455564346
weight_decay:  1.2526360665856374e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.987074235919863
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.1227298439480364
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  0.7962323790416121
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 80.30
run time now: 3.9566452503204346
total time:  4.011656323913485
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 79.50 ± 1.22
[I 2023-06-12 00:42:03,413] Trial 315 finished with value: 82.33333587646484 and parameters: {'Fwd': 2.8139475527161066e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 5.775988096754397, 'loop': 1, 'loss': 'MSE', 'lr': 0.002726463455564346, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2526360665856374e-05, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0008943635836844625
weight_decay:  0.017733875146247528
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5409457799978554
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 02
None time:  1.8877993731293827
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  1.7557803399395198
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.40
run time now: 5.268235921859741
total time:  5.323403293034062
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 1.32
[I 2023-06-12 00:42:09,294] Trial 316 finished with value: 82.4000015258789 and parameters: {'Fwd': 5.436292853077178e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 2.9760026659561998, 'loop': 1, 'loss': 'MSE', 'lr': 0.0008943635836844625, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.017733875146247528, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002438249182798589
weight_decay:  0.013075031373006122
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8959583470132202
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.8139283880591393
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 98.33
   Final Test: 78.90
Split: 01, Run: 03
None time:  0.8204503750894219
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 79.40
run time now: 3.580777883529663
total time:  3.63384118094109
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.00 ± 7.11
  Final Train: 99.44 ± 0.96
   Final Test: 75.97 ± 5.52
[I 2023-06-12 00:42:13,464] Trial 317 finished with value: 78.00000762939453 and parameters: {'Fwd': 5.3277108765273716e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 0.5032301339079583, 'loop': 1, 'loss': 'MSE', 'lr': 0.002438249182798589, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.013075031373006122, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0021877041676708836
weight_decay:  0.006348991952004367
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3118503629229963
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  1.0634190409909934
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  2.3584710829891264
None Run 03:
Highest Train: 100.00
Highest Valid: 84.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.785236597061157
total time:  5.827720395056531
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.93 ± 1.50
  Final Train: 100.00 ± 0.00
   Final Test: 79.63 ± 1.77
[I 2023-06-12 00:42:19,794] Trial 318 finished with value: 82.9333267211914 and parameters: {'Fwd': 7.227199934071725e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 6.207725279513693, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021877041676708836, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006348991952004367, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0019255367878744962
weight_decay:  0.004653116112451502
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.897012688918039
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.4182140410412103
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.0941127710975707
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.70
run time now: 6.4547154903411865
total time:  6.49771687714383
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.87 ± 1.67
  Final Train: 100.00 ± 0.00
   Final Test: 78.77 ± 0.86
[I 2023-06-12 00:42:26,795] Trial 319 finished with value: 81.86666870117188 and parameters: {'Fwd': 7.388091605399882e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 6.192497202914316, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019255367878744962, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004653116112451502, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0021273903118712487
weight_decay:  0.0062063661706850265
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8432921858038753
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.5248028188943863
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.3369224229827523
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 80.10
run time now: 4.753671169281006
total time:  4.79900686792098
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 79.00 ± 1.01
[I 2023-06-12 00:42:32,196] Trial 320 finished with value: 81.73333740234375 and parameters: {'Fwd': 1.0461604687633243e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.391053993876254, 'loop': 2, 'loss': 'MSE', 'lr': 0.0021273903118712487, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0062063661706850265, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002265896453134264
weight_decay:  2.7792619346989192e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.156911397119984
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.0374930119141936
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 74.00
Split: 01, Run: 03
None time:  1.272950991988182
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 80.10
run time now: 4.517528533935547
total time:  4.567242731805891
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.67 ± 4.09
  Final Train: 100.00 ± 0.00
   Final Test: 77.30 ± 3.08
[I 2023-06-12 00:42:37,241] Trial 321 finished with value: 79.66666412353516 and parameters: {'Fwd': 1.599626066543919e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.062428947853349, 'loop': 1, 'loss': 'MSE', 'lr': 0.002265896453134264, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.7792619346989192e-05, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0062961735388683045
weight_decay:  0.0036788228420158607
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8548918669112027
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.020719091873616
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 03
None time:  0.9739398269448429
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.00
run time now: 2.897711992263794
total time:  2.9420674650464207
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.20 ± 6.76
  Final Train: 100.00 ± 0.00
   Final Test: 74.80 ± 4.78
[I 2023-06-12 00:42:40,668] Trial 322 finished with value: 77.20000457763672 and parameters: {'Fwd': 4.040600597939461e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 5.064410883015345, 'loop': 1, 'loss': 'MSE', 'lr': 0.0062961735388683045, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0036788228420158607, 'weightedloss': True}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0020273810338636636
weight_decay:  0.004935283981066827
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0950185358524323
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 02
None time:  1.1373029141686857
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 98.33
   Final Test: 75.60
Split: 01, Run: 03
None time:  1.0541323630604893
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 98.33
   Final Test: 77.70
run time now: 3.334990978240967
total time:  3.3837182510178536
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 0.58
  Final Train: 98.89 ± 0.96
   Final Test: 76.20 ± 1.31
[I 2023-06-12 00:42:44,535] Trial 323 finished with value: 78.9333267211914 and parameters: {'Fwd': 2.6215331667667298e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.90354525583274, 'loop': 1, 'loss': 'CE', 'lr': 0.0020273810338636636, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004935283981066827, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0032105192402768342
weight_decay:  0.027894744228019092
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.973169001052156
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.6844782780390233
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.5485715330578387
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.30
run time now: 5.262904405593872
total time:  5.323838569922373
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.60 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.92
[I 2023-06-12 00:42:50,389] Trial 324 finished with value: 82.60000610351562 and parameters: {'Fwd': 7.133124848013256e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.258797306631804, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032105192402768342, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.027894744228019092, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.000562664727272764
weight_decay:  0.007058228940824271
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.110584327019751
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.5535648511722684
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.0444565580692142
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.40
run time now: 4.756739377975464
total time:  4.802988767856732
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 1.18
[I 2023-06-12 00:42:55,722] Trial 325 finished with value: 82.26667022705078 and parameters: {'Fwd': 8.943703759156091e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.071925479172656, 'loop': 1, 'loss': 'MSE', 'lr': 0.000562664727272764, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007058228940824271, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0024487701427496943
weight_decay:  0.000708317967574708
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3541197709273547
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  1.5948267590720206
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.809756221016869
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.10
run time now: 5.807097673416138
total time:  5.848963179858401
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.85
[I 2023-06-12 00:43:02,101] Trial 326 finished with value: 82.33333587646484 and parameters: {'Fwd': 3.0658213330448412e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.792516904473315, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024487701427496943, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.000708317967574708, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0009719475554105845
weight_decay:  0.00024573955984618875
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.11095212912187
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 02
None time:  1.825633809901774
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  0.7560577031690627
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.30
run time now: 4.744078159332275
total time:  4.790595395956188
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 1.89
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 1.57
[I 2023-06-12 00:43:07,453] Trial 327 finished with value: 81.9333267211914 and parameters: {'Fwd': 4.851336478356279e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.612234870617971, 'loop': 1, 'loss': 'MSE', 'lr': 0.0009719475554105845, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00024573955984618875, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.008936820654149222
weight_decay:  0.0037068173992456177
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0460949218831956
None Run 01:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 73.70
Split: 01, Run: 02
None time:  1.8944284520111978
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.50
Split: 01, Run: 03
None time:  1.3167559560388327
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.10
run time now: 4.308171033859253
total time:  4.368409181013703
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.13 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 73.43 ± 0.31
[I 2023-06-12 00:43:12,352] Trial 328 finished with value: 75.13333129882812 and parameters: {'Fwd': 6.754780110129963e-06, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.9, 'gnnepoch': 20, 'lambda1': 0.8500000000000001, 'lambda2': 4.080276114088295, 'loop': 1, 'loss': 'MSE', 'lr': 0.008936820654149222, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0037068173992456177, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002844527247253665
weight_decay:  0.010392665979739603
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.888804140035063
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  1.5535096768289804
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.0008629749063402
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.30
run time now: 5.492196321487427
total time:  5.535900871036574
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 78.80 ± 1.80
[I 2023-06-12 00:43:18,394] Trial 329 finished with value: 82.4000015258789 and parameters: {'Fwd': 3.6414627060200635e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 3.7052395879783626, 'loop': 1, 'loss': 'MSE', 'lr': 0.002844527247253665, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.010392665979739603, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  1.0
lr:  0.0022708077593218273
weight_decay:  0.0058174899006228796
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.006630705203861
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 74.30
Split: 01, Run: 02
None time:  0.9130114009603858
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 74.70
Split: 01, Run: 03
None time:  2.2463294060435146
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 76.70
run time now: 5.208969354629517
total time:  5.255856193834916
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 1.68
  Final Train: 100.00 ± 0.00
   Final Test: 75.23 ± 1.29
[I 2023-06-12 00:43:24,168] Trial 330 finished with value: 80.53333282470703 and parameters: {'Fwd': 1.3712714382217725e-05, 'K': 3, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 2.299704912189305, 'loop': 1, 'loss': 'MSE', 'lr': 0.0022708077593218273, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0058174899006228796, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.001511403485680371
weight_decay:  0.013497340322843426
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.734122812980786
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.1637363501358777
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.2607781840488315
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.80
run time now: 3.216273784637451
total time:  3.269860853208229
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.73 ± 7.67
  Final Train: 100.00 ± 0.00
   Final Test: 76.23 ± 6.10
[I 2023-06-12 00:43:27,870] Trial 331 finished with value: 77.73333740234375 and parameters: {'Fwd': 2.66901480180082e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 4.876761724959542, 'loop': 1, 'loss': 'MSE', 'lr': 0.001511403485680371, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.013497340322843426, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002585599024770964
weight_decay:  0.007930862449587475
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8119295157957822
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.0800005400087684
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  2.832768965046853
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.20
run time now: 5.792473316192627
total time:  5.843840071931481
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 0.85
[I 2023-06-12 00:43:34,337] Trial 332 finished with value: 82.66666412353516 and parameters: {'Fwd': 4.847509827857863e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 4.56412186145284, 'loop': 1, 'loss': 'MSE', 'lr': 0.002585599024770964, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007930862449587475, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0030479138076445374
weight_decay:  0.020236388697526014
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.897751570912078
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  1.329164681956172
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  2.0113485609181225
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.10
run time now: 6.296680450439453
total time:  6.359781559091061
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.07 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 0.53
[I 2023-06-12 00:43:41,321] Trial 333 finished with value: 82.0666732788086 and parameters: {'Fwd': 6.301141006022861e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 6.435226865518278, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030479138076445374, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.020236388697526014, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0034734556371333156
weight_decay:  0.015253343475432125
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1429842840880156
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  2.9309004929382354
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  1.368462173966691
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.50
run time now: 6.4917755126953125
total time:  6.577558520017192
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 79.07 ± 0.59
[I 2023-06-12 00:43:48,456] Trial 334 finished with value: 81.79999542236328 and parameters: {'Fwd': 4.6671591294165135e-05, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 5.255153283473648, 'loop': 1, 'loss': 'MSE', 'lr': 0.0034734556371333156, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.015253343475432125, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.00213699347235661
weight_decay:  0.0404815663954695
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1461454948876053
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.8728311378508806
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.0206014879513532
None Run 03:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 79.60
run time now: 6.085493803024292
total time:  6.125652716029435
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.93 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 79.50 ± 1.45
[I 2023-06-12 00:43:55,120] Trial 335 finished with value: 82.93333435058594 and parameters: {'Fwd': 8.941728569493614e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 3.332089012401007, 'loop': 1, 'loss': 'MSE', 'lr': 0.00213699347235661, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0404815663954695, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0019293402866537841
weight_decay:  0.046097034560170294
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8799075500573963
None Run 01:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.3465610230341554
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.0237255680840462
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.80
run time now: 6.293131351470947
total time:  6.3345568170771
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.07 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 0.95
[I 2023-06-12 00:44:02,058] Trial 336 finished with value: 82.0666732788086 and parameters: {'Fwd': 9.716029663207264e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 2.9827344403103075, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019293402866537841, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.046097034560170294, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002217148903638891
weight_decay:  0.038180638688249974
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.382287464104593
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 75.10
Split: 01, Run: 02
None time:  1.0384304709732533
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  0.7071864199824631
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.80
run time now: 4.182989835739136
total time:  4.231658906908706
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 2.02
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 2.49
[I 2023-06-12 00:44:06,950] Trial 337 finished with value: 81.33333587646484 and parameters: {'Fwd': 8.63693563848803e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 5.06856372634996, 'loop': 1, 'loss': 'MSE', 'lr': 0.002217148903638891, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.038180638688249974, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0016711500894950827
weight_decay:  0.0001798583828934606
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9154765878338367
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.9121572219301015
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  2.5108384620398283
None Run 03:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 80.00
run time now: 4.394513130187988
total time:  4.443887988105416
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.73 ± 8.12
  Final Train: 100.00 ± 0.00
   Final Test: 76.27 ± 6.12
[I 2023-06-12 00:44:11,922] Trial 338 finished with value: 78.73332977294922 and parameters: {'Fwd': 8.17051939676459e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 3.566279044049287, 'loop': 1, 'loss': 'MSE', 'lr': 0.0016711500894950827, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001798583828934606, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0021093974471175026
weight_decay:  0.051931828055617704
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8556298960465938
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  2.3531799360644072
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.40
Split: 01, Run: 03
None time:  1.0142937139607966
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 73.30
run time now: 4.2741405963897705
total time:  4.315579945920035
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.73 ± 2.27
  Final Train: 100.00 ± 0.00
   Final Test: 72.00 ± 2.34
[I 2023-06-12 00:44:16,749] Trial 339 finished with value: 71.73332977294922 and parameters: {'Fwd': 1.2483243209526083e-05, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 3.6327514205381495, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021093974471175026, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.051931828055617704, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002429250578498818
weight_decay:  0.010873449278571132
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.615133455954492
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  2.21541403606534
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  0.9495273968204856
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 80.60
run time now: 5.897905588150024
total time:  5.944961396977305
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 79.33 ± 1.48
[I 2023-06-12 00:44:23,297] Trial 340 finished with value: 82.66666412353516 and parameters: {'Fwd': 1.628434821505622e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 5.534545306638843, 'loop': 1, 'loss': 'MSE', 'lr': 0.002429250578498818, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.010873449278571132, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0018469273808191598
weight_decay:  0.027358741012177997
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5138104408979416
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 75.70
Split: 01, Run: 02
None time:  1.222832883009687
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 03
None time:  2.433977159904316
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.221849679946899
total time:  5.281338755041361
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 1.56
  Final Train: 100.00 ± 0.00
   Final Test: 77.30 ± 1.90
[I 2023-06-12 00:44:29,086] Trial 341 finished with value: 81.20000457763672 and parameters: {'Fwd': 8.016492288249046e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 3.2325273808751556, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018469273808191598, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.027358741012177997, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002320556985714232
weight_decay:  0.022128043759419205
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.078328711912036
None Run 01:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 72.60
Split: 01, Run: 02
None time:  1.1015915151219815
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 95.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  0.9728797820862383
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 98.33
   Final Test: 78.90
run time now: 3.203906774520874
total time:  3.249696800019592
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.80 ± 2.43
  Final Train: 97.78 ± 2.55
   Final Test: 76.23 ± 3.26
[I 2023-06-12 00:44:32,802] Trial 342 finished with value: 77.79999542236328 and parameters: {'Fwd': 6.086035092773187e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 3.3402078670017783, 'loop': 1, 'loss': 'CE', 'lr': 0.002320556985714232, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.022128043759419205, 'weightedloss': True}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0025705169862632765
weight_decay:  0.0006121650656885589
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2736588509287685
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  3.377647286048159
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.0920832748524845
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.30
run time now: 6.800410747528076
total time:  6.845049118855968
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.81
[I 2023-06-12 00:44:40,198] Trial 343 finished with value: 81.79999542236328 and parameters: {'Fwd': 9.955911092571964e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 2.69931881941504, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025705169862632765, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0006121650656885589, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.007264202420654587
weight_decay:  0.05058863723598004
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.20% Test: 72.80%
Split: 01, Run: 01
None time:  2.986875883070752
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 72.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 82.80% Test: 79.80%
Split: 01, Run: 02
None time:  2.714375547831878
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 82.40% Test: 80.40%
Split: 01, Run: 03
None time:  2.864100452978164
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 8.614315032958984
total time:  8.654245561920106
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 3.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.70 ± 4.26
[I 2023-06-12 00:44:49,362] Trial 344 finished with value: 80.79999542236328 and parameters: {'Fwd': 3.1325111297546645e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 5.328260705913914, 'loop': 0, 'loss': 'MSE', 'lr': 0.007264202420654587, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.05058863723598004, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0028924973307273305
weight_decay:  0.07599242562336209
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0923, Train: 100.00%, Valid: 81.20% Test: 77.20%
Split: 01, Run: 01
None time:  3.6506194800604135
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02
None time:  1.250342020066455
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.1014126189984381
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 79.20
run time now: 6.051983594894409
total time:  6.09206917299889
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.95
[I 2023-06-12 00:44:55,924] Trial 345 finished with value: 81.5999984741211 and parameters: {'Fwd': 5.6070019531036375e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.170460589983938, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028924973307273305, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.07599242562336209, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0010845947606396226
weight_decay:  0.017118285869023177
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8761355299502611
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.6319513190537691
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  3.3850456830114126
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.90
run time now: 5.9430201053619385
total time:  5.990380535833538
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.07 ± 7.53
  Final Train: 100.00 ± 0.00
   Final Test: 75.90 ± 5.84
[I 2023-06-12 00:45:02,329] Trial 346 finished with value: 78.0666732788086 and parameters: {'Fwd': 7.426911489635861e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 4.797917929347322, 'loop': 1, 'loss': 'MSE', 'lr': 0.0010845947606396226, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.017118285869023177, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.000804802281659029
weight_decay:  0.023272617101317672
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.263961474876851
None Run 01:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  1.41536810901016
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  1.711268193088472
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.80
run time now: 6.45080828666687
total time:  6.493923943955451
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.13 ± 2.12
  Final Train: 100.00 ± 0.00
   Final Test: 71.67 ± 1.94
[I 2023-06-12 00:45:09,381] Trial 347 finished with value: 73.13333129882812 and parameters: {'Fwd': 0.00012831613384312748, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 1.3804737662914697, 'loop': 1, 'loss': 'MSE', 'lr': 0.000804802281659029, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.023272617101317672, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0021210871506653836
weight_decay:  0.009916138840495256
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.272341008996591
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  0.9719775340054184
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.1623, Train: 100.00%, Valid: 83.00% Test: 80.50%
Split: 01, Run: 03
None time:  3.4832703517749906
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.30
run time now: 6.781394720077515
total time:  6.8230896750465035
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.67 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 79.27 ± 1.31
[I 2023-06-12 00:45:16,722] Trial 348 finished with value: 82.66666412353516 and parameters: {'Fwd': 0.00020104482351527577, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 4.272889791364597, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021210871506653836, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.009916138840495256, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.003177535229472873
weight_decay:  0.012780213539169279
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7697183229029179
None Run 01:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.9192236370872706
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  0.8953772210516036
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.40
run time now: 2.6362271308898926
total time:  2.6986691469792277
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.40 ± 6.76
  Final Train: 100.00 ± 0.00
   Final Test: 75.50 ± 5.20
[I 2023-06-12 00:45:20,097] Trial 349 finished with value: 77.4000015258789 and parameters: {'Fwd': 1.9323475792184275e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 6.47200281304151, 'loop': 1, 'loss': 'MSE', 'lr': 0.003177535229472873, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.012780213539169279, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.003715087693445811
weight_decay:  0.0076627858352104625
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3123, Train: 100.00%, Valid: 81.80% Test: 77.40%
Split: 01, Run: 01
None time:  3.2636944490950555
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  0.9808487389236689
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  0.9821917458903044
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 77.70
run time now: 5.276504039764404
total time:  5.329479311127216
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.63 ± 0.50
[I 2023-06-12 00:45:25,967] Trial 350 finished with value: 82.13333129882812 and parameters: {'Fwd': 0.00010780656617325082, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.686130535742597, 'loop': 1, 'loss': 'MSE', 'lr': 0.003715087693445811, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0076627858352104625, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002506061351735518
weight_decay:  0.0059706984181136505
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0456881939899176
None Run 01:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 02
None time:  1.3855350310914218
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.3049143750686198
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.90
run time now: 4.789624929428101
total time:  4.834486647043377
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 79.53 ± 0.32
[I 2023-06-12 00:45:31,294] Trial 351 finished with value: 83.26667022705078 and parameters: {'Fwd': 4.2271351231855224e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.4883300108321205, 'loop': 1, 'loss': 'MSE', 'lr': 0.002506061351735518, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0059706984181136505, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0019392451018992725
weight_decay:  0.005564107215177691
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3652, Train: 100.00%, Valid: 83.00% Test: 79.20%
Split: 01, Run: 01
None time:  3.7277830517850816
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 02
None time:  1.8539014151319861
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.3631644861306995
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.10
run time now: 6.997696399688721
total time:  7.039385913871229
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 79.13 ± 1.00
[I 2023-06-12 00:45:38,900] Trial 352 finished with value: 81.73333740234375 and parameters: {'Fwd': 3.89400434488926e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.443817221308851, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019392451018992725, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005564107215177691, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.00025409980770307384
weight_decay:  0.09343628009748053
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0529832949396223
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.3670181969646364
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 03
None time:  0.996804571012035
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.60
run time now: 3.46746563911438
total time:  3.520940620917827
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.93 ± 6.70
  Final Train: 100.00 ± 0.00
   Final Test: 74.00 ± 4.40
[I 2023-06-12 00:45:43,080] Trial 353 finished with value: 76.9333267211914 and parameters: {'Fwd': 2.3823385637340746e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 5.234033235444196, 'loop': 1, 'loss': 'MSE', 'lr': 0.00025409980770307384, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.09343628009748053, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002349033301273567
weight_decay:  0.006714408916418687
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9236552079673856
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.940084407106042
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.0659813869278878
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 76.90
run time now: 4.9827399253845215
total time:  5.025813301093876
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 1.86
  Final Train: 100.00 ± 0.00
   Final Test: 77.53 ± 0.71
[I 2023-06-12 00:45:48,571] Trial 354 finished with value: 80.46666717529297 and parameters: {'Fwd': 4.512476401583716e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 3.2173038472425386, 'loop': 1, 'loss': 'MSE', 'lr': 0.002349033301273567, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006714408916418687, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002491517114419624
weight_decay:  0.005327443593882579
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4655508790165186
None Run 01:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 02
None time:  1.5400926338043064
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  2.467539125820622
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.90
run time now: 6.523301124572754
total time:  6.576143522048369
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 79.37 ± 0.57
[I 2023-06-12 00:45:55,677] Trial 355 finished with value: 82.26667022705078 and parameters: {'Fwd': 3.1017033371705247e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.7000000000000001, 'lambda2': 5.03313646490154, 'loop': 1, 'loss': 'MSE', 'lr': 0.002491517114419624, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005327443593882579, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.00208331952584973
weight_decay:  0.004309616484972938
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.068374545779079
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  1.9438210148364305
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  2.8753649939317256
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.938920021057129
total time:  6.9882041569799185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 79.13 ± 1.36
[I 2023-06-12 00:46:03,115] Trial 356 finished with value: 83.0666732788086 and parameters: {'Fwd': 3.6988904444744836e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 3.4174152641659976, 'loop': 1, 'loss': 'MSE', 'lr': 0.00208331952584973, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004309616484972938, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0019988306899134164
weight_decay:  0.004401688341697552
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.033044173149392
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.2041, Train: 100.00%, Valid: 81.40% Test: 79.10%
Split: 01, Run: 02
None time:  3.957530722953379
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  1.2770746250171214
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 80.10
run time now: 7.310812950134277
total time:  7.35712819499895
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.07 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 79.37 ± 0.67
[I 2023-06-12 00:46:11,079] Trial 357 finished with value: 82.0666732788086 and parameters: {'Fwd': 4.87916303821333e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 3.345506162780314, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019988306899134164, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004401688341697552, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.004822614355073063
weight_decay:  0.0067080013152148715
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.12825372396037
None Run 01:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 02
None time:  1.8620549319311976
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.008876623120159
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.40
run time now: 5.060795307159424
total time:  5.112849517958239
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.47 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 78.87 ± 0.42
[I 2023-06-12 00:46:16,799] Trial 358 finished with value: 82.46666717529297 and parameters: {'Fwd': 5.719806551878442e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 3.5701566180993876, 'loop': 1, 'loss': 'MSE', 'lr': 0.004822614355073063, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0067080013152148715, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0018115457055371976
weight_decay:  0.008598861776813382
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.102058429038152
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  1.3114693241659552
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.244450049009174
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.721214771270752
total time:  4.771942537045106
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.63 ± 1.85
[I 2023-06-12 00:46:22,191] Trial 359 finished with value: 82.26667022705078 and parameters: {'Fwd': 3.914147032756864e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 2.8055627687335867, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018115457055371976, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008598861776813382, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002181781507144208
weight_decay:  0.0047377991147404845
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5198001340031624
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.4313012319616973
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.8863075759727508
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.80
run time now: 5.893099069595337
total time:  5.936124433064833
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 79.03 ± 0.40
[I 2023-06-12 00:46:28,663] Trial 360 finished with value: 82.80001068115234 and parameters: {'Fwd': 2.691919727528991e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 3.32913257336912, 'loop': 1, 'loss': 'MSE', 'lr': 0.002181781507144208, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0047377991147404845, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0015800388267496039
weight_decay:  0.0645165958617697
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6363664409145713
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 02
None time:  1.7461190389003605
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.189909396925941
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.90
run time now: 4.635244369506836
total time:  4.721642761025578
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 1.47
  Final Train: 100.00 ± 0.00
   Final Test: 78.07 ± 1.89
[I 2023-06-12 00:46:33,975] Trial 361 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.0004197511246648134, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 1.0, 'lambda2': 4.032768876452301, 'loop': 1, 'loss': 'MSE', 'lr': 0.0015800388267496039, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0645165958617697, 'weightedloss': True}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0003358015135635202
weight_decay:  0.00038263067787171044
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.969049771083519
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 73.80
Split: 01, Run: 02
None time:  1.0566653180867434
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 75.20
Split: 01, Run: 03
None time:  1.2750073671340942
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 75.30
run time now: 5.351293087005615
total time:  5.4028179629240185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.80 ± 1.31
  Final Train: 100.00 ± 0.00
   Final Test: 74.77 ± 0.84
[I 2023-06-12 00:46:39,869] Trial 362 finished with value: 78.79999542236328 and parameters: {'Fwd': 7.429267001343781e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 6.001404406571422, 'loop': 1, 'loss': 'MSE', 'lr': 0.0003358015135635202, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00038263067787171044, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0014172819695374278
weight_decay:  0.07818027144744356
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1504451371729374
None Run 01:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 72.90
Split: 01, Run: 02
None time:  1.1838489461224526
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 98.33
   Final Test: 76.80
Split: 01, Run: 03
None time:  1.1673379028216004
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 96.67
   Final Test: 76.60
run time now: 3.5509586334228516
total time:  3.6045911558903754
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.73 ± 1.17
  Final Train: 98.33 ± 1.67
   Final Test: 75.43 ± 2.20
[I 2023-06-12 00:46:43,953] Trial 363 finished with value: 77.73332977294922 and parameters: {'Fwd': 4.6417041455569674e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 4.550488178182168, 'loop': 1, 'loss': 'CE', 'lr': 0.0014172819695374278, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.07818027144744356, 'weightedloss': False}. Best is trial 205 with value: 83.53333282470703.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0026503712914596393
weight_decay:  0.03602667908431621
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2707553431391716
None Run 01:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  1.967681162059307
None Run 02:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.0940184271894395
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.90
run time now: 5.385812044143677
total time:  5.436611414887011
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 79.70 ± 0.72
[I 2023-06-12 00:46:49,842] Trial 364 finished with value: 83.66666412353516 and parameters: {'Fwd': 6.390239253670255e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 3.1707164462942274, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026503712914596393, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03602667908431621, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.0026712917936455682
weight_decay:  0.05507646070899631
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.512680310057476
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 02
None time:  1.034553135978058
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  1.1823250628076494
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.40
run time now: 4.777060270309448
total time:  4.821558992145583
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 2.65
  Final Train: 100.00 ± 0.00
   Final Test: 78.77 ± 1.21
[I 2023-06-12 00:46:55,179] Trial 365 finished with value: 81.0 and parameters: {'Fwd': 1.1051139665568363e-05, 'K': 9, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 3.1095357988452, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026712917936455682, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.05507646070899631, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002599059516991735
weight_decay:  0.09819998982153831
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5487510960083455
None Run 01:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 02
None time:  1.5094975871033967
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  2.262294187908992
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.370144844055176
total time:  6.418109525926411
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.73 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 79.00 ± 0.46
[I 2023-06-12 00:47:02,075] Trial 366 finished with value: 82.73332977294922 and parameters: {'Fwd': 5.695306865629837e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 6.405905858991276, 'loop': 1, 'loss': 'MSE', 'lr': 0.002599059516991735, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.09819998982153831, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0020982872148874
weight_decay:  0.027750858298725894
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5918673330452293
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.8833419419825077
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  1.0374016561545432
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.60
run time now: 4.562716722488403
total time:  4.61253949906677
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 79.07 ± 1.01
[I 2023-06-12 00:47:07,261] Trial 367 finished with value: 82.26666259765625 and parameters: {'Fwd': 3.5683502864060395e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 3.4921205081190534, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020982872148874, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.027750858298725894, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0028173938266088717
weight_decay:  0.03603133796522856
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6864140799734741
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 02
None time:  2.4506054630037397
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 73.60
Split: 01, Run: 03
None time:  1.9382870611734688
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 74.90
run time now: 6.125796318054199
total time:  6.168767317896709
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.00 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 74.80 ± 1.15
[I 2023-06-12 00:47:14,082] Trial 368 finished with value: 77.0 and parameters: {'Fwd': 9.132957929495145e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 4.835374021782351, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028173938266088717, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03603133796522856, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.005676777163161523
weight_decay:  0.04129076358948502
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1649, Train: 100.00%, Valid: 84.00% Test: 79.70%
Split: 01, Run: 01
None time:  3.508210245054215
None Run 01:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 02
None time:  1.580959104001522
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.4472725621890277
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.40
run time now: 6.594598770141602
total time:  6.6487797510344535
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.87 ± 1.17
  Final Train: 100.00 ± 0.00
   Final Test: 79.40 ± 0.40
[I 2023-06-12 00:47:21,333] Trial 369 finished with value: 82.86666870117188 and parameters: {'Fwd': 0.00014620560980772745, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 4.282694217503462, 'loop': 1, 'loss': 'MSE', 'lr': 0.005676777163161523, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.04129076358948502, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0023595174335647494
weight_decay:  0.06785890186936017
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9307385771535337
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.7908123689703643
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  0.9407082789111882
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.20
run time now: 4.7142839431762695
total time:  4.759247706038877
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 78.97 ± 0.68
[I 2023-06-12 00:47:26,626] Trial 370 finished with value: 82.9333267211914 and parameters: {'Fwd': 2.510934531500955e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 3.82230387229541, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023595174335647494, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.06785890186936017, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0023712889724894094
weight_decay:  0.06281879425026077
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2759, Train: 100.00%, Valid: 82.40% Test: 79.60%
Split: 01, Run: 01
None time:  4.028347173007205
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.1654, Train: 100.00%, Valid: 80.20% Test: 79.00%
Split: 01, Run: 02
None time:  3.8491952989716083
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  3.2360024119261652
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.30
run time now: 11.185846328735352
total time:  11.233341126935557
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 79.40 ± 0.17
[I 2023-06-12 00:47:38,467] Trial 371 finished with value: 81.33333587646484 and parameters: {'Fwd': 1.312056996423734e-05, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.9500000000000001, 'lambda2': 3.2046222455244178, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023712889724894094, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.06281879425026077, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0021988834505839187
weight_decay:  0.029920144600812493
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.106818008935079
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.6912325040902942
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  1.697602201020345
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.90
run time now: 5.588926315307617
total time:  5.6410075118765235
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 79.27 ± 0.60
[I 2023-06-12 00:47:44,633] Trial 372 finished with value: 82.0 and parameters: {'Fwd': 2.746387891833546e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 3.0243422873487558, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021988834505839187, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.029920144600812493, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0024762019466970063
weight_decay:  0.033461414884098005
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8056714048143476
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 02
None time:  1.4891695270780474
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.6396722991485149
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 79.90
run time now: 4.9852070808410645
total time:  5.030649023130536
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.60 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 79.80 ± 0.17
[I 2023-06-12 00:47:50,149] Trial 373 finished with value: 82.5999984741211 and parameters: {'Fwd': 2.2866945103382996e-05, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 120, 'lambda1': 0.9, 'lambda2': 3.8390069047544975, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024762019466970063, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.033461414884098005, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002050937010679892
weight_decay:  0.07540925420447812
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4305371320806444
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.3084881210234016
None Run 02:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.4042205100413412
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.00
run time now: 4.19636344909668
total time:  4.246273905038834
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.13 ± 2.47
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 0.70
[I 2023-06-12 00:47:54,899] Trial 374 finished with value: 82.13333129882812 and parameters: {'Fwd': 1.436854684085342e-05, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.55, 'lambda2': 3.687568660065104, 'loop': 1, 'loss': 'MSE', 'lr': 0.002050937010679892, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.07540925420447812, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.9500000000000001
lr:  0.0018250020038356233
weight_decay:  0.056613184966172084
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9198594780173153
None Run 01:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.60
Split: 01, Run: 02
None time:  1.4921587680000812
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 03
None time:  1.1272943539079279
None Run 03:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.60
run time now: 4.57860255241394
total time:  4.6315418931189924
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.20 ± 2.16
  Final Train: 100.00 ± 0.00
   Final Test: 71.57 ± 2.63
[I 2023-06-12 00:48:00,053] Trial 375 finished with value: 74.20000457763672 and parameters: {'Fwd': 2.4198057295486597e-06, 'K': 1, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.65, 'lambda2': 3.5318477547385276, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018250020038356233, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.056613184966172084, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0023116821739975267
weight_decay:  0.045985600619332184
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.638874016935006
None Run 01:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  1.1971975041087717
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.219466453883797
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.40
run time now: 5.105929851531982
total time:  5.160876839887351
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 2.66
  Final Train: 100.00 ± 0.00
   Final Test: 78.87 ± 0.81
[I 2023-06-12 00:48:05,743] Trial 376 finished with value: 81.73332977294922 and parameters: {'Fwd': 0.0009324966096438396, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 2.861599135077068, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023116821739975267, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.045985600619332184, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0025061008305743856
weight_decay:  0.003997497784717511
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1915810029022396
None Run 01:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 02
None time:  1.9763802108354867
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.2070210659876466
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.425865411758423
total time:  5.473648906918243
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 79.20 ± 0.17
[I 2023-06-12 00:48:11,706] Trial 377 finished with value: 82.0 and parameters: {'Fwd': 1.5757901160381324e-05, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.6000000000000001, 'lambda2': 3.284414740724439, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025061008305743856, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003997497784717511, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002901246426631209
weight_decay:  0.058170877002612253
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.191119252005592
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 02
None time:  1.3005861989222467
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  3.8905959089752287
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.90
run time now: 6.4368345737457275
total time:  6.487475702073425
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.20 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 79.03 ± 0.81
[I 2023-06-12 00:48:18,713] Trial 378 finished with value: 82.20000457763672 and parameters: {'Fwd': 3.116321139389216e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 90, 'lambda1': 0.65, 'lambda2': 3.3859557680015615, 'loop': 1, 'loss': 'MSE', 'lr': 0.002901246426631209, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.058170877002612253, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002199944932992078
weight_decay:  0.037283904823603116
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5664173681288958
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.9750979898963124
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.298711413051933
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.60
run time now: 4.891048192977905
total time:  4.945956927957013
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 1.39
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 0.60
[I 2023-06-12 00:48:24,180] Trial 379 finished with value: 81.20000457763672 and parameters: {'Fwd': 1.0898703448585821e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 3.0710795231221266, 'loop': 1, 'loss': 'MSE', 'lr': 0.002199944932992078, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.037283904823603116, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0016354770295811786
weight_decay:  0.042490992079449216
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5798022761009634
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.4243499180302024
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03
None time:  2.6722613349556923
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 75.70
run time now: 4.723785638809204
total time:  4.76779605797492
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.87 ± 4.21
  Final Train: 100.00 ± 0.00
   Final Test: 72.37 ± 3.13
[I 2023-06-12 00:48:29,444] Trial 380 finished with value: 73.86666107177734 and parameters: {'Fwd': 7.902010190235305e-06, 'K': 10, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 3.360681600673462, 'loop': 1, 'loss': 'MSE', 'lr': 0.0016354770295811786, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.042490992079449216, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.002702937400972195
weight_decay:  0.0033753585263283
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9850847590714693
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  1.7475859459955245
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.0604150190483779
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.90
run time now: 4.840813875198364
total time:  4.8942949920892715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 77.83 ± 0.40
[I 2023-06-12 00:48:34,889] Trial 381 finished with value: 81.79999542236328 and parameters: {'Fwd': 6.485254761097925e-05, 'K': 9, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 3.788627092926905, 'loop': 1, 'loss': 'MSE', 'lr': 0.002702937400972195, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0033753585263283, 'weightedloss': True}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0031238072689627194
weight_decay:  0.005496806569229984
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3792246028315276
None Run 01:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 90.00
   Final Test: 74.00
Split: 01, Run: 02
None time:  1.2579204810317606
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 98.33
   Final Test: 79.30
Split: 01, Run: 03
None time:  1.2100784010253847
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 98.33
   Final Test: 80.60
run time now: 3.8924200534820557
total time:  3.9341801849659532
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 3.24
  Final Train: 95.56 ± 4.81
   Final Test: 77.97 ± 3.50
[I 2023-06-12 00:48:39,385] Trial 382 finished with value: 78.9333267211914 and parameters: {'Fwd': 2.0924327135401533e-05, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 3.9850487957421077, 'loop': 1, 'loss': 'CE', 'lr': 0.0031238072689627194, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005496806569229984, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.001973560936602846
weight_decay:  0.00450210845907702
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.142235127976164
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.2502403219696134
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.913908062968403
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.80
run time now: 6.359104633331299
total time:  6.407487882999703
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 79.17 ± 0.64
[I 2023-06-12 00:48:46,288] Trial 383 finished with value: 82.26666259765625 and parameters: {'Fwd': 4.010101796297608e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.620198619078705, 'loop': 1, 'loss': 'MSE', 'lr': 0.001973560936602846, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00450210845907702, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0011737390189249402
weight_decay:  0.0064782157860301314
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3709504178259522
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.389912033919245
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  0.38175849290564656
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
run time now: 1.195000171661377
total time:  1.2444700999185443
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.60 ± 0.00
[I 2023-06-12 00:48:48,084] Trial 384 finished with value: 69.80000305175781 and parameters: {'Fwd': 3.8603108172417736e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 0, 'lambda1': 0.65, 'lambda2': 4.386343440409444, 'loop': 1, 'loss': 'MSE', 'lr': 0.0011737390189249402, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0064782157860301314, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0024613478939018397
weight_decay:  0.0008750159445391206
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3184, Train: 100.00%, Valid: 82.80% Test: 79.20%
Split: 01, Run: 01
None time:  3.3938719211146235
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 02
None time:  1.4067985720466822
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.0378613790962845
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 75.80
run time now: 5.897307872772217
total time:  5.945863564964384
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 3.67
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 2.05
[I 2023-06-12 00:48:54,531] Trial 385 finished with value: 81.20000457763672 and parameters: {'Fwd': 6.588143649097413e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 4.212963582771858, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024613478939018397, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008750159445391206, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.0027756762192714304
weight_decay:  0.00290822313050181
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1303487268742174
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 75.50
Split: 01, Run: 02
None time:  1.3874699438456446
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 03
None time:  1.364688635803759
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 5.930408954620361
total time:  5.9791191150434315
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 1.62
  Final Train: 100.00 ± 0.00
   Final Test: 76.93 ± 1.25
[I 2023-06-12 00:49:00,994] Trial 386 finished with value: 80.33333587646484 and parameters: {'Fwd': 0.0002768116268618234, 'K': 10, 'alpha': 0.8, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 3.100772334921035, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027756762192714304, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00290822313050181, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0001756738861573811
weight_decay:  0.0035881268705520585
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5832741199992597
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  1.5575277339667082
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.5796287648845464
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
run time now: 4.768643856048584
total time:  4.819978120969608
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.10 ± 0.00
[I 2023-06-12 00:49:06,429] Trial 387 finished with value: 69.19999694824219 and parameters: {'Fwd': 3.122386390895303e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 2.875324994613523, 'loop': 1, 'loss': 'MSE', 'lr': 0.0001756738861573811, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0035881268705520585, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.009491862678843865
weight_decay:  0.08523052156979727
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.735143322031945
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  1.1603477830067277
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  1.8993554890621454
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.90
run time now: 4.8393189907073975
total time:  4.896340053994209
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 1.00
  Final Train: 100.00 ± 0.00
   Final Test: 77.27 ± 0.78
[I 2023-06-12 00:49:11,902] Trial 388 finished with value: 81.0 and parameters: {'Fwd': 4.58237753563319e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 3.5843784865486557, 'loop': 1, 'loss': 'MSE', 'lr': 0.009491862678843865, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.08523052156979727, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0022804379218152875
weight_decay:  0.0053329503070492995
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0050829239189625
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  1.7853299430571496
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 03
None time:  1.7516948531847447
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.70
run time now: 5.64090895652771
total time:  5.685050392989069
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 76.77 ± 1.69
[I 2023-06-12 00:49:18,223] Trial 389 finished with value: 81.13333129882812 and parameters: {'Fwd': 4.063736480023606e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 5.07926793868277, 'loop': 1, 'loss': 'MSE', 'lr': 0.0022804379218152875, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0053329503070492995, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0033463649664664964
weight_decay:  0.007614402678969101
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2793, Train: 100.00%, Valid: 81.40% Test: 78.00%
Split: 01, Run: 01
None time:  3.7479067631065845
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.4446993919555098
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  1.084110583877191
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.30
run time now: 6.330307483673096
total time:  6.386122911935672
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.20 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 0.72
[I 2023-06-12 00:49:25,203] Trial 390 finished with value: 82.20000457763672 and parameters: {'Fwd': 1.8976515027665493e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 4.182076567368975, 'loop': 1, 'loss': 'MSE', 'lr': 0.0033463649664664964, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007614402678969101, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.002569896109214051
weight_decay:  0.025124006516797973
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2871632061433047
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  0.8169825391378254
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.4914473448880017
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.40
run time now: 4.644977569580078
total time:  4.683102842886001
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 1.56
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 0.75
[I 2023-06-12 00:49:30,466] Trial 391 finished with value: 80.5999984741211 and parameters: {'Fwd': 9.041144999675328e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 2.6026122439752855, 'loop': 1, 'loss': 'MSE', 'lr': 0.002569896109214051, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.025124006516797973, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002072231184585897
weight_decay:  0.004170173353467675
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8787456301506609
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.9398762721102685
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  0.9627740869764239
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 2.832590341567993
total time:  2.8841142680030316
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.33 ± 7.91
  Final Train: 100.00 ± 0.00
   Final Test: 75.93 ± 6.01
[I 2023-06-12 00:49:33,899] Trial 392 finished with value: 78.33333587646484 and parameters: {'Fwd': 2.46452794753405e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.9500000000000001, 'lambda2': 3.0942830282043694, 'loop': 1, 'loss': 'MSE', 'lr': 0.002072231184585897, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004170173353467675, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.006815064553211754
weight_decay:  0.045605898643159865
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8136912810150534
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.0853187718894333
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 75.20
Split: 01, Run: 03
None time:  0.920022513018921
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.10
run time now: 3.869586706161499
total time:  3.910413665929809
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 2.12
  Final Train: 100.00 ± 0.00
   Final Test: 77.13 ± 1.67
[I 2023-06-12 00:49:38,332] Trial 393 finished with value: 80.4000015258789 and parameters: {'Fwd': 4.781138115201178e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 3.4030817065694747, 'loop': 1, 'loss': 'MSE', 'lr': 0.006815064553211754, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.045605898643159865, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0030448269063443477
weight_decay:  0.006399147443550365
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2675, Train: 100.00%, Valid: 82.20% Test: 78.10%
Split: 01, Run: 01
None time:  3.64555686712265
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.0187988090328872
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.1215857230126858
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.835050344467163
total time:  5.876681718975306
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 79.23 ± 1.16
[I 2023-06-12 00:49:44,786] Trial 394 finished with value: 82.33333587646484 and parameters: {'Fwd': 6.482504720519802e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 3.7826766803800895, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030448269063443477, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.006399147443550365, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.001752852722954858
weight_decay:  0.06250360646033064
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0746475579217076
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  0.9373055340256542
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.1695, Train: 100.00%, Valid: 83.40% Test: 80.00%
Split: 01, Run: 03
None time:  3.90827798913233
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.60
run time now: 6.9736127853393555
total time:  7.027032919926569
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 1.03
[I 2023-06-12 00:49:52,353] Trial 395 finished with value: 82.33333587646484 and parameters: {'Fwd': 2.4947580693318392e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.220875243758748, 'loop': 1, 'loss': 'MSE', 'lr': 0.001752852722954858, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.06250360646033064, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002346556158977727
weight_decay:  4.113503905442288e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.037159665953368
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 02
None time:  1.156711048912257
None Run 02:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.6003880540374666
None Run 03:
Highest Train: 100.00
Highest Valid: 84.40
  Final Train: 100.00
   Final Test: 78.90
run time now: 4.840641498565674
total time:  4.8920617969706655
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.73 ± 2.55
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 1.56
[I 2023-06-12 00:49:57,832] Trial 396 finished with value: 82.73332977294922 and parameters: {'Fwd': 0.0006876277652708103, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 5.329306578263229, 'loop': 1, 'loss': 'MSE', 'lr': 0.002346556158977727, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.113503905442288e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002767223801479066
weight_decay:  0.0003118658290270658
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5431921128183603
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  0.5643646740354598
None Run 02:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  0.5744163519702852
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.00
run time now: 1.733949899673462
total time:  1.7845359910279512
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 72.00 ± 0.00
[I 2023-06-12 00:50:00,212] Trial 397 finished with value: 73.4000015258789 and parameters: {'Fwd': 3.381790237679682e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 20, 'lambda1': 0.0, 'lambda2': 9.552107731457465, 'loop': 0, 'loss': 'MSE', 'lr': 0.002767223801479066, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0003118658290270658, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.0024637264704743616
weight_decay:  0.03250221227170042
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3160275779664516
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 02
None time:  0.6306359439622611
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 03
None time:  1.70968081895262
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.00
run time now: 4.740503787994385
total time:  4.800811255117878
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 1.15
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 1.20
[I 2023-06-12 00:50:05,533] Trial 398 finished with value: 81.0666732788086 and parameters: {'Fwd': 0.001881972932510414, 'K': 9, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 6.661739785947502, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024637264704743616, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.03250221227170042, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.003041735438613791
weight_decay:  0.0029428821649437925
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4837016810197383
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.0312312659807503
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.9566073899623007
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.20
run time now: 5.519919395446777
total time:  5.56755399890244
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 1.39
  Final Train: 100.00 ± 0.00
   Final Test: 79.07 ± 1.40
[I 2023-06-12 00:50:11,601] Trial 399 finished with value: 81.79999542236328 and parameters: {'Fwd': 1.2062549359177199e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 2.563736054073754, 'loop': 1, 'loss': 'MSE', 'lr': 0.003041735438613791, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0029428821649437925, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.00197911952884231
weight_decay:  0.008471642061482192
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.5560, Train: 100.00%, Valid: 82.40% Test: 79.10%
Split: 01, Run: 01
None time:  3.905991839012131
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.5535901440307498
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  2.076766151934862
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.20
run time now: 7.646790266036987
total time:  7.694773635827005
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 78.90 ± 0.26
[I 2023-06-12 00:50:19,812] Trial 400 finished with value: 82.4000015258789 and parameters: {'Fwd': 5.517965471658553e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 3.5175466974578278, 'loop': 1, 'loss': 'MSE', 'lr': 0.00197911952884231, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008471642061482192, 'weightedloss': True}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0026001131492777666
weight_decay:  0.005114493760131206
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.193597662029788
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02
None time:  1.2281454210169613
None Run 02:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.2128588429186493
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.10
run time now: 4.704201698303223
total time:  4.758985253050923
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.73 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 1.06
[I 2023-06-12 00:50:25,214] Trial 401 finished with value: 82.73333740234375 and parameters: {'Fwd': 6.0284858342958525e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.8500000000000001, 'lambda2': 5.555151681773287, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026001131492777666, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005114493760131206, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002220667718972499
weight_decay:  0.002494076647877236
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.208069026004523
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 02
None time:  0.8907773471437395
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 98.33
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.0645511541515589
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.50
run time now: 3.2128217220306396
total time:  3.252994173904881
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.50
  Final Train: 99.44 ± 0.96
   Final Test: 77.47 ± 0.75
[I 2023-06-12 00:50:29,046] Trial 402 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.008640255409370313, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 4.928344186436653, 'loop': 1, 'loss': 'CE', 'lr': 0.002220667718972499, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002494076647877236, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.008739574921656473
weight_decay:  0.00013954870093105682
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0152404292020947
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 02
None time:  1.3699858461041003
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.110947353998199
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.40
run time now: 4.540182828903198
total time:  4.593118403106928
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 1.17
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 1.35
[I 2023-06-12 00:50:34,173] Trial 403 finished with value: 81.06665802001953 and parameters: {'Fwd': 0.04742679692828313, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 9.211163373098987, 'loop': 1, 'loss': 'MSE', 'lr': 0.008739574921656473, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00013954870093105682, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0028140311690349274
weight_decay:  0.0005668548461733435
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8269084200728685
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  0.9529412700794637
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.2267365171574056
None Run 03:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 79.50
run time now: 5.056004762649536
total time:  5.108742453856394
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.07 ± 1.62
  Final Train: 100.00 ± 0.00
   Final Test: 78.57 ± 1.07
[I 2023-06-12 00:50:39,787] Trial 404 finished with value: 82.06666564941406 and parameters: {'Fwd': 8.384641345618995e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.432951581180478, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028140311690349274, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005668548461733435, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.005253526557791411
weight_decay:  0.003910799689639088
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3026065491139889
None Run 01:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 73.10
Split: 01, Run: 02
None time:  0.615275643998757
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  0.9803595060948282
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.80
run time now: 2.9453887939453125
total time:  2.994613620918244
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.33 ± 2.10
  Final Train: 100.00 ± 0.00
   Final Test: 75.80 ± 2.36
[I 2023-06-12 00:50:43,316] Trial 405 finished with value: 77.33333587646484 and parameters: {'Fwd': 4.023938387416601e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 8.197378099339355, 'loop': 1, 'loss': 'MSE', 'lr': 0.005253526557791411, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.003910799689639088, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.0005079221242091496
weight_decay:  0.06915659885258156
dropout:  0.0
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8933277181349695
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.2167278139386326
None Run 02:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.10
Split: 01, Run: 03
None time:  1.8515516370534897
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.80
run time now: 4.007008790969849
total time:  4.0623750309459865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.80 ± 5.05
  Final Train: 100.00 ± 0.00
   Final Test: 73.73 ± 3.93
[I 2023-06-12 00:50:47,879] Trial 406 finished with value: 74.80000305175781 and parameters: {'Fwd': 4.6325531129808254e-05, 'K': 10, 'alpha': 0.75, 'dropout': 0.0, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.145642798413597, 'loop': 1, 'loss': 'MSE', 'lr': 0.0005079221242091496, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.06915659885258156, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0006718105696922528
weight_decay:  0.0004113786400119552
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6941591349896044
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.6714938869699836
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 03
None time:  4.54862627806142
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 72.20
run time now: 7.961904048919678
total time:  8.012581809889525
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.53 ± 3.00
  Final Train: 100.00 ± 0.00
   Final Test: 70.47 ± 1.50
[I 2023-06-12 00:50:56,410] Trial 407 finished with value: 71.53333282470703 and parameters: {'Fwd': 6.721558346899671e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 4.618766254495537, 'loop': 1, 'loss': 'MSE', 'lr': 0.0006718105696922528, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0004113786400119552, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0031925012566706725
weight_decay:  0.0065967139924864165
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2948, Train: 100.00%, Valid: 80.40% Test: 77.70%
Split: 01, Run: 01
None time:  3.7780314029660076
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  2.0263301201630384
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.0238983458839357
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 77.90
run time now: 6.874068737030029
total time:  6.919144384097308
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 1.17
  Final Train: 100.00 ± 0.00
   Final Test: 78.03 ± 0.51
[I 2023-06-12 00:51:03,988] Trial 408 finished with value: 81.73333740234375 and parameters: {'Fwd': 2.6233375148942502e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 4.09398534318553, 'loop': 1, 'loss': 'MSE', 'lr': 0.0031925012566706725, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0065967139924864165, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002348767038694483
weight_decay:  9.262708237195564e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3294, Train: 100.00%, Valid: 82.60% Test: 78.90%
Split: 01, Run: 01
None time:  3.7006930829957128
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.588509449036792
None Run 02:
Highest Train: 100.00
Highest Valid: 84.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  3.0461866760160774
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.10
run time now: 8.383579730987549
total time:  8.43050904199481
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 2.21
  Final Train: 100.00 ± 0.00
   Final Test: 78.57 ± 0.50
[I 2023-06-12 00:51:13,027] Trial 409 finished with value: 82.33333587646484 and parameters: {'Fwd': 1.0578108491523068e-05, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 5.267571314051051, 'loop': 1, 'loss': 'MSE', 'lr': 0.002348767038694483, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.262708237195564e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.9500000000000001
lr:  0.0026346017745948816
weight_decay:  9.061939876688191e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7610473800450563
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 02
None time:  1.319815831957385
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  0.7100396850146353
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.80
run time now: 4.828066110610962
total time:  4.878349740058184
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 77.20 ± 1.13
[I 2023-06-12 00:51:18,508] Trial 410 finished with value: 80.20000457763672 and parameters: {'Fwd': 0.0004877316269534425, 'K': 4, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 1.0, 'lambda2': 5.959649261755376, 'loop': 2, 'loss': 'MSE', 'lr': 0.0026346017745948816, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.061939876688191e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002125035959025001
weight_decay:  8.190267729206342e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.4808447959367186
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  1.1556291789747775
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.0857636739965528
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.90
run time now: 5.771543264389038
total time:  5.813876965083182
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 2.02
[I 2023-06-12 00:51:24,929] Trial 411 finished with value: 81.73333740234375 and parameters: {'Fwd': 5.316509519977103e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 3.15905873195007, 'loop': 1, 'loss': 'MSE', 'lr': 0.002125035959025001, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.190267729206342e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.0033148102319859062
weight_decay:  6.113086857977731e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3572, Train: 100.00%, Valid: 82.20% Test: 76.50%
Split: 01, Run: 01
None time:  3.5753071950748563
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 02
None time:  1.0214795710053295
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.0123533781152219
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.30
run time now: 5.662338733673096
total time:  5.704115467146039
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 1.55
  Final Train: 100.00 ± 0.00
   Final Test: 77.27 ± 1.25
[I 2023-06-12 00:51:31,283] Trial 412 finished with value: 81.73333740234375 and parameters: {'Fwd': 3.599946799406721e-06, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 3.858637550817284, 'loop': 1, 'loss': 'MSE', 'lr': 0.0033148102319859062, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.113086857977731e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.003554676233956987
weight_decay:  0.0002210345560255198
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9105308100115508
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.8111443459056318
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  0.8729147240519524
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 79.10
run time now: 3.6425247192382812
total time:  3.6819351059384644
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.20 ± 6.76
  Final Train: 100.00 ± 0.00
   Final Test: 75.67 ± 5.60
[I 2023-06-12 00:51:35,499] Trial 413 finished with value: 77.20000457763672 and parameters: {'Fwd': 7.818622803583008e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 2.857535465742515, 'loop': 1, 'loss': 'MSE', 'lr': 0.003554676233956987, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002210345560255198, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0018416047143910057
weight_decay:  0.010201247216813269
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0927181718870997
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 02
None time:  1.4712675460614264
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 03
None time:  1.5415783759672195
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 75.60
run time now: 5.150729417800903
total time:  5.191601027967408
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.33 ± 3.42
  Final Train: 100.00 ± 0.00
   Final Test: 74.43 ± 2.38
[I 2023-06-12 00:51:41,348] Trial 414 finished with value: 76.33333587646484 and parameters: {'Fwd': 4.590071425644028e-06, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.9, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 5.627941564784237, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018416047143910057, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.010201247216813269, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.002930687714492656
weight_decay:  0.015043023010917644
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6256227479316294
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 02
None time:  1.9979879560414702
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.144091219874099
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.70
run time now: 4.8168113231658936
total time:  4.862558820983395
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 1.04
[I 2023-06-12 00:51:46,852] Trial 415 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.0003340936554072009, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.530985062778368, 'loop': 1, 'loss': 'MSE', 'lr': 0.002930687714492656, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.015043023010917644, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9500000000000001
lr:  0.0024848959642362035
weight_decay:  0.0035117334249535
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.344420673092827
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  0.7541243399027735
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 03
None time:  1.0543047240935266
None Run 03:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.40
run time now: 4.19940972328186
total time:  4.246727869147435
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 1.75
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 1.12
[I 2023-06-12 00:51:51,682] Trial 416 finished with value: 81.66666412353516 and parameters: {'Fwd': 3.0647243108588395e-05, 'K': 9, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.446733094749935, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024848959642362035, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0035117334249535, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9
lr:  0.0010007502528380581
weight_decay:  0.004564736081099302
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.308941547991708
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 02
None time:  1.3931009690277278
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 03
None time:  0.9111868448089808
None Run 03:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 73.60
run time now: 4.650972366333008
total time:  4.702497791033238
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.13 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 72.97 ± 0.85
[I 2023-06-12 00:51:56,914] Trial 417 finished with value: 76.13333129882812 and parameters: {'Fwd': 0.00022251735190623837, 'K': 3, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 6.308643591172225, 'loop': 1, 'loss': 'MSE', 'lr': 0.0010007502528380581, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004564736081099302, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0008056016356004639
weight_decay:  0.007831953558334938
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7006131410598755
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  1.382074954919517
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.5308466700371355
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 79.00
run time now: 4.66156268119812
total time:  4.716085721040145
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 78.57 ± 0.38
[I 2023-06-12 00:52:02,196] Trial 418 finished with value: 82.0666732788086 and parameters: {'Fwd': 9.691705817832774e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 5.988393002121856, 'loop': 1, 'loss': 'MSE', 'lr': 0.0008056016356004639, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.007831953558334938, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0022434830679205976
weight_decay:  0.09482885941178287
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.15178493084386
None Run 01:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.083894934039563
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.7975938860327005
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.70
run time now: 6.079189300537109
total time:  6.125864003086463
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 1.80
  Final Train: 100.00 ± 0.00
   Final Test: 78.90 ± 0.72
[I 2023-06-12 00:52:08,895] Trial 419 finished with value: 81.5999984741211 and parameters: {'Fwd': 3.026911077550431e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 6.719319239584887, 'loop': 1, 'loss': 'MSE', 'lr': 0.0022434830679205976, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.09482885941178287, 'weightedloss': True}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0027473768493975308
weight_decay:  0.0010556720724575648
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7319915951229632
None Run 01:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 02
None time:  0.9653612338006496
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 95.00
   Final Test: 76.50
Split: 01, Run: 03
None time:  1.0533104829955846
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 96.67
   Final Test: 76.40
run time now: 2.794703960418701
total time:  2.8407854540273547
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.53 ± 2.89
  Final Train: 97.22 ± 2.55
   Final Test: 74.73 ± 2.97
[I 2023-06-12 00:52:12,242] Trial 420 finished with value: 77.53333282470703 and parameters: {'Fwd': 1.774850698731057e-05, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 1.0550676207217826, 'loop': 1, 'loss': 'CE', 'lr': 0.0027473768493975308, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0010556720724575648, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0044948384141643045
weight_decay:  0.021268672392591274
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.559794164961204
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 74.90
Split: 01, Run: 02
None time:  0.9177992201875895
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  2.1030630241148174
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.20
run time now: 4.629697322845459
total time:  4.679227401036769
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 1.44
  Final Train: 100.00 ± 0.00
   Final Test: 77.13 ± 2.20
[I 2023-06-12 00:52:17,507] Trial 421 finished with value: 80.79999542236328 and parameters: {'Fwd': 2.161682006767716e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.103183096630495, 'loop': 1, 'loss': 'MSE', 'lr': 0.0044948384141643045, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.021268672392591274, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002512814575782126
weight_decay:  1.8101079329995513e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8350151891354471
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 02
None time:  1.2160411749500781
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.1373190730810165
None Run 03:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 80.20
run time now: 4.242086887359619
total time:  4.282494381768629
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.33 ± 1.17
  Final Train: 100.00 ± 0.00
   Final Test: 79.33 ± 2.04
[I 2023-06-12 00:52:22,369] Trial 422 finished with value: 83.33333587646484 and parameters: {'Fwd': 6.246120134057227e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 3.6937569778563946, 'loop': 1, 'loss': 'MSE', 'lr': 0.002512814575782126, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.8101079329995513e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0020113326230658006
weight_decay:  0.017047927659722757
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.051412781002
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  1.589371426962316
None Run 02:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.1934283999726176
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.40
run time now: 3.8923463821411133
total time:  3.9409647108986974
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.80 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 78.60 ± 1.56
[I 2023-06-12 00:52:26,830] Trial 423 finished with value: 82.79999542236328 and parameters: {'Fwd': 6.094833679720725e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 80, 'lambda1': 0.6000000000000001, 'lambda2': 3.7505306404254117, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020113326230658006, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.017047927659722757, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0015370841944201093
weight_decay:  2.7368966186729315e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.765791092067957
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  2.023981997044757
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.1059099838603288
None Run 03:
Highest Train: 100.00
Highest Valid: 84.40
  Final Train: 100.00
   Final Test: 78.90
run time now: 5.94908595085144
total time:  5.997117317048833
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.53 ± 1.63
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.40
[I 2023-06-12 00:52:33,354] Trial 424 finished with value: 82.53333282470703 and parameters: {'Fwd': 9.367958286534242e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 8.636204968657102, 'loop': 1, 'loss': 'MSE', 'lr': 0.0015370841944201093, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.7368966186729315e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.00589960140133953
weight_decay:  9.056002447829617e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.5836205289233476
None Run 01:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02
None time:  0.994735507061705
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.1499389170203358
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.20
run time now: 5.782174110412598
total time:  5.825518923113123
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.53 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 0.99
[I 2023-06-12 00:52:39,746] Trial 425 finished with value: 82.53334045410156 and parameters: {'Fwd': 6.7870431137711265e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 4.5132963119980944, 'loop': 1, 'loss': 'MSE', 'lr': 0.00589960140133953, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.056002447829617e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.002370150758682381
weight_decay:  0.00011278168094237912
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.381895411061123
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.1423811260610819
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  1.0618603411130607
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 79.70
run time now: 4.635575532913208
total time:  4.684185256017372
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 79.00 ± 1.66
[I 2023-06-12 00:52:44,919] Trial 426 finished with value: 81.80000305175781 and parameters: {'Fwd': 4.603667188145789e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 2.241663550549703, 'loop': 1, 'loss': 'MSE', 'lr': 0.002370150758682381, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011278168094237912, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0025093544194213194
weight_decay:  2.550515145283895e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4149133360479027
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 75.80
Split: 01, Run: 02
None time:  2.1119376779533923
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 74.00
Split: 01, Run: 03
None time:  3.501270119100809
None Run 03:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.20
run time now: 8.072118282318115
total time:  8.113810687093064
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 74.33 ± 1.33
[I 2023-06-12 00:52:53,676] Trial 427 finished with value: 76.20000457763672 and parameters: {'Fwd': 5.203845331727829e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 4.026027565896529, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025093544194213194, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.550515145283895e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.25
lr:  0.0021109140157840743
weight_decay:  5.0541029283247494e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7796649499796331
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.2627985370345414
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 03
None time:  1.5297722718678415
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.90
run time now: 3.620262384414673
total time:  3.671139070065692
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.07 ± 2.05
  Final Train: 100.00 ± 0.00
   Final Test: 71.80 ± 2.15
[I 2023-06-12 00:52:57,873] Trial 428 finished with value: 72.0666732788086 and parameters: {'Fwd': 8.071258123735393e-06, 'K': 10, 'alpha': 0.25, 'dropout': 0.9, 'gnnepoch': 40, 'lambda1': 0.65, 'lambda2': 3.509515725023924, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021109140157840743, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.0541029283247494e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0017395937987489225
weight_decay:  2.4813859240713358e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.83375089103356
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 02
None time:  1.7590671931393445
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.8982928860932589
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.592524528503418
total time:  5.641980574000627
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 0.40
[I 2023-06-12 00:53:04,152] Trial 429 finished with value: 81.5999984741211 and parameters: {'Fwd': 3.8507949637792255e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 3.4117681468372543, 'loop': 1, 'loss': 'MSE', 'lr': 0.0017395937987489225, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.4813859240713358e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002939668417353781
weight_decay:  0.04612581629110408
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7909287640359253
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  1.1572394710965455
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  1.1220993108581752
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.10
run time now: 5.122758150100708
total time:  5.165891516022384
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 1.59
[I 2023-06-12 00:53:09,966] Trial 430 finished with value: 82.0 and parameters: {'Fwd': 5.931662109067018e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 3.6818826051470186, 'loop': 1, 'loss': 'MSE', 'lr': 0.002939668417353781, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.04612581629110408, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.0025574086037183654
weight_decay:  5.2617595880696024e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9355902208480984
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 74.40
Split: 01, Run: 02
None time:  1.1041127780918032
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.2108980938792229
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 77.50
run time now: 4.297714710235596
total time:  4.335576407145709
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 77.00 ± 2.39
[I 2023-06-12 00:53:14,964] Trial 431 finished with value: 81.06666564941406 and parameters: {'Fwd': 1.0796473751799827e-05, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 4.4226108323134286, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025574086037183654, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.2617595880696024e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.001252968626682616
weight_decay:  1.9319937659011395e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5965377788525075
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  1.1236777671147138
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.075302473967895
None Run 03:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 79.80
run time now: 3.842334032058716
total time:  3.8875270260032266
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.87 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 1.96
[I 2023-06-12 00:53:19,362] Trial 432 finished with value: 82.86666870117188 and parameters: {'Fwd': 1.4627057458025399e-05, 'K': 9, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.909952890791686, 'loop': 1, 'loss': 'MSE', 'lr': 0.001252968626682616, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.9319937659011395e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002255949056331264
weight_decay:  0.011310159632129233
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8690402649808675
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.6164712850004435
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  0.8166864509694278
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.10
run time now: 3.3523147106170654
total time:  3.39292164798826
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.87 ± 7.15
  Final Train: 100.00 ± 0.00
   Final Test: 75.40 ± 5.03
[I 2023-06-12 00:53:23,354] Trial 433 finished with value: 77.86666870117188 and parameters: {'Fwd': 3.964169485981117e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.6000000000000001, 'lambda2': 4.744940028933486, 'loop': 1, 'loss': 'MSE', 'lr': 0.002255949056331264, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.011310159632129233, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0003737555564964084
weight_decay:  0.00013502486381347615
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0733232840429991
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02
None time:  0.913411432178691
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 03
None time:  1.077555005904287
None Run 03:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
run time now: 3.114798069000244
total time:  3.1707236669026315
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 69.20 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 69.10 ± 0.00
[I 2023-06-12 00:53:27,080] Trial 434 finished with value: 69.19999694824219 and parameters: {'Fwd': 7.5369577751836484e-06, 'K': 10, 'alpha': 0.5, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 3.248077755865977, 'loop': 1, 'loss': 'MSE', 'lr': 0.0003737555564964084, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00013502486381347615, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0011159939387730205
weight_decay:  2.336918714713587e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6206721900962293
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.001930681988597
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  2.0597455359529704
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.738611221313477
total time:  5.782564127119258
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 1.23
[I 2023-06-12 00:53:33,389] Trial 435 finished with value: 81.46666717529297 and parameters: {'Fwd': 3.620996457792854e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 8.917544658600653, 'loop': 1, 'loss': 'MSE', 'lr': 0.0011159939387730205, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.336918714713587e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0019787107393942774
weight_decay:  0.005914118041864964
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.014849916798994
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.70
Split: 01, Run: 02
None time:  1.420983059098944
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.040657261852175
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.00
run time now: 3.5668439865112305
total time:  3.6116853188723326
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.07 ± 7.18
  Final Train: 100.00 ± 0.00
   Final Test: 76.03 ± 5.49
[I 2023-06-12 00:53:37,624] Trial 436 finished with value: 78.0666732788086 and parameters: {'Fwd': 3.1503369341722874e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 2.976468471765137, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019787107393942774, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005914118041864964, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0027234843699594237
weight_decay:  1.0687035288284442e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9571723029948771
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.7887146389111876
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 03
None time:  0.9759810708928853
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 75.40
run time now: 3.7724459171295166
total time:  3.8132732298690826
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.07 ± 5.25
  Final Train: 100.00 ± 0.00
   Final Test: 73.57 ± 3.71
[I 2023-06-12 00:53:41,953] Trial 437 finished with value: 75.06666564941406 and parameters: {'Fwd': 0.00018719361210732907, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.646123917209539, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027234843699594237, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0687035288284442e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0014103822961474988
weight_decay:  0.027158354917458195
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2944559999741614
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.0345176889095455
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  0.8550767609849572
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.232913255691528
total time:  5.291224119020626
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.77 ± 0.71
[I 2023-06-12 00:53:47,805] Trial 438 finished with value: 81.73333740234375 and parameters: {'Fwd': 5.087620031830851e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 8.022560009625852, 'loop': 1, 'loss': 'MSE', 'lr': 0.0014103822961474988, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.027158354917458195, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.004236150935782472
weight_decay:  0.0004580587896843294
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3052373311948031
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02
None time:  1.193561684107408
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03
None time:  1.07924708398059
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 78.80
run time now: 3.636575222015381
total time:  3.6843384909443557
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.81
[I 2023-06-12 00:53:52,035] Trial 439 finished with value: 80.53333282470703 and parameters: {'Fwd': 6.331306429075282e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.8, 'lambda2': 5.295559693159808, 'loop': 1, 'loss': 'MSE', 'lr': 0.004236150935782472, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0004580587896843294, 'weightedloss': True}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.003161650638832764
weight_decay:  0.0002942095385457357
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.044522606069222
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 76.40
Split: 01, Run: 02
None time:  0.9054381800815463
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 98.33
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.0104023308958858
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.40
run time now: 3.017261505126953
total time:  3.0676112389191985
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 0.72
  Final Train: 99.44 ± 0.96
   Final Test: 77.43 ± 1.05
[I 2023-06-12 00:53:55,658] Trial 440 finished with value: 79.5999984741211 and parameters: {'Fwd': 1.237715036690993e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 3.2035013023863685, 'loop': 1, 'loss': 'CE', 'lr': 0.003161650638832764, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002942095385457357, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.002338409826238471
weight_decay:  7.2412057722464175e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3394, Train: 100.00%, Valid: 82.40% Test: 77.60%
Split: 01, Run: 01
None time:  3.5789232461247593
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  1.5993227399885654
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  1.2456902971025556
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.90
run time now: 6.468850135803223
total time:  6.511768748052418
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 79.07 ± 1.27
[I 2023-06-12 00:54:02,698] Trial 441 finished with value: 82.66666412353516 and parameters: {'Fwd': 8.943661286167127e-06, 'K': 9, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 3.539878769747558, 'loop': 1, 'loss': 'MSE', 'lr': 0.002338409826238471, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.2412057722464175e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.003487726416338089
weight_decay:  0.008822820225834301
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8885717638768256
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.40
Split: 01, Run: 02
None time:  0.9520044790115207
None Run 02:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.7977468059398234
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 80.10
run time now: 3.718794584274292
total time:  3.794889993034303
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.40 ± 7.81
  Final Train: 100.00 ± 0.00
   Final Test: 76.63 ± 6.27
[I 2023-06-12 00:54:07,044] Trial 442 finished with value: 78.4000015258789 and parameters: {'Fwd': 4.303150077377161e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 3.9521016963606894, 'loop': 1, 'loss': 'MSE', 'lr': 0.003487726416338089, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.008822820225834301, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.004818605939973623
weight_decay:  0.0001797527463201966
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9254685349296778
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.4904394529294223
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.1445426871068776
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.50
run time now: 4.611414670944214
total time:  4.668532093986869
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.87 ± 0.55
[I 2023-06-12 00:54:12,336] Trial 443 finished with value: 81.93333435058594 and parameters: {'Fwd': 2.883909615354362e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.797493006064399, 'loop': 1, 'loss': 'MSE', 'lr': 0.004818605939973623, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0001797527463201966, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002546424838845051
weight_decay:  6.0676365116282995e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2458368209190667
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  2.0197166078723967
None Run 02:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  0.9283168199472129
None Run 03:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.60
run time now: 5.238170862197876
total time:  5.291906251106411
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.20 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 78.80 ± 1.22
[I 2023-06-12 00:54:18,152] Trial 444 finished with value: 83.20000457763672 and parameters: {'Fwd': 0.00066405926982645, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 4.193541310810274, 'loop': 1, 'loss': 'MSE', 'lr': 0.002546424838845051, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.0676365116282995e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002946752675450872
weight_decay:  8.02154772796928e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7778666180092841
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 02
None time:  2.7947068179491907
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 74.60
Split: 01, Run: 03
None time:  2.236617603804916
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 72.90
run time now: 6.864732265472412
total time:  6.915868570795283
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 74.37 ± 1.37
[I 2023-06-12 00:54:25,615] Trial 445 finished with value: 76.73333740234375 and parameters: {'Fwd': 0.0012402627176345824, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 9.754717360284898, 'loop': 1, 'loss': 'MSE', 'lr': 0.002946752675450872, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.02154772796928e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.00010180389693081222
weight_decay:  6.229051310961053e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9679142769891769
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  1.4471162571571767
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 98.33
   Final Test: 71.60
Split: 01, Run: 03
None time:  1.0404502740129828
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 98.33
   Final Test: 74.60
run time now: 3.5459649562835693
total time:  3.5981470718979836
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.27 ± 4.55
  Final Train: 98.89 ± 0.96
   Final Test: 71.83 ± 2.66
[I 2023-06-12 00:54:29,804] Trial 446 finished with value: 75.26667022705078 and parameters: {'Fwd': 0.0005508364891169062, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 0.4549987597666849, 'loop': 1, 'loss': 'MSE', 'lr': 0.00010180389693081222, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.229051310961053e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0026002065556867686
weight_decay:  0.005209680280651212
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1621012948453426
None Run 01:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 02
None time:  1.211482359096408
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.6890853228978813
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.80
run time now: 5.131555557250977
total time:  5.177326782839373
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.20 ± 1.64
  Final Train: 100.00 ± 0.00
   Final Test: 78.57 ± 0.75
[I 2023-06-12 00:54:35,473] Trial 447 finished with value: 82.20000457763672 and parameters: {'Fwd': 0.0006620246234901033, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 7.798682665315785, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026002065556867686, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005209680280651212, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002816376216370892
weight_decay:  3.474983721197853e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.519494473002851
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  0.7439547078683972
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.1405, Train: 100.00%, Valid: 82.60% Test: 79.80%
Split: 01, Run: 03
None time:  3.605354896048084
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.90
run time now: 6.919524431228638
total time:  6.969086328987032
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.73 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.57 ± 1.19
[I 2023-06-12 00:54:42,932] Trial 448 finished with value: 82.73333740234375 and parameters: {'Fwd': 0.00029348414208964994, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 4.3172362937882705, 'loop': 1, 'loss': 'MSE', 'lr': 0.002816376216370892, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.474983721197853e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0069419479261523765
weight_decay:  5.147910972253482e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8810133000370115
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.396626451984048
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  0.8840028431732208
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.70
run time now: 3.215535879135132
total time:  3.2623144588433206
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.60 ± 6.81
  Final Train: 100.00 ± 0.00
   Final Test: 75.50 ± 5.16
[I 2023-06-12 00:54:46,721] Trial 449 finished with value: 77.60000610351562 and parameters: {'Fwd': 5.336533274368038e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.6000000000000001, 'lambda2': 5.398542297777808, 'loop': 1, 'loss': 'MSE', 'lr': 0.0069419479261523765, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.147910972253482e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.002134961358885408
weight_decay:  1.2140740211775465e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7659382910933346
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 74.90
Split: 01, Run: 02
None time:  1.4471517382189631
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  0.9972541339229792
None Run 03:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 80.00
run time now: 5.257014989852905
total time:  5.299038939876482
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 2.23
  Final Train: 100.00 ± 0.00
   Final Test: 78.30 ± 2.94
[I 2023-06-12 00:54:52,681] Trial 450 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.0009921919890828659, 'K': 9, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 5.55659729811333, 'loop': 1, 'loss': 'MSE', 'lr': 0.002134961358885408, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2140740211775465e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0025286091860058607
weight_decay:  1.8603673293297527e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.578144485130906
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 02
None time:  2.100950173800811
None Run 02:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.5755209277849644
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 79.10
run time now: 5.295872688293457
total time:  5.3468765169382095
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.27 ± 1.36
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 1.89
[I 2023-06-12 00:54:58,580] Trial 451 finished with value: 82.26667022705078 and parameters: {'Fwd': 3.6933380237041857e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 5.117514286811584, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025286091860058607, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.8603673293297527e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.003133491625975468
weight_decay:  1.947923369652543e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.031284000026062
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 02
None time:  1.1156254960224032
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.6598558579571545
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.70
run time now: 4.861300230026245
total time:  4.903065789025277
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 1.85
[I 2023-06-12 00:55:04,117] Trial 452 finished with value: 82.33333587646484 and parameters: {'Fwd': 0.002381798118839587, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 4.6593422293320845, 'loop': 1, 'loss': 'MSE', 'lr': 0.003133491625975468, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.947923369652543e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0018849337001564381
weight_decay:  1.4451047917288053e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.240541759179905
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 02
None time:  0.9653860020916909
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.8594330758787692
None Run 03:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.00
run time now: 5.114776849746704
total time:  5.160133985802531
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 78.60 ± 1.31
[I 2023-06-12 00:55:09,836] Trial 453 finished with value: 82.4000015258789 and parameters: {'Fwd': 6.8609786873545234e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 6.727963633647646, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018849337001564381, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.4451047917288053e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.003788223521899112
weight_decay:  1.0357658642587316e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9825730121228844
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  1.237827573902905
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.0904293679632246
None Run 03:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.20
run time now: 4.357020378112793
total time:  4.395795746007934
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 79.17 ± 1.55
[I 2023-06-12 00:55:14,726] Trial 454 finished with value: 83.0 and parameters: {'Fwd': 0.0007513271429462645, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.885991050141212, 'loop': 1, 'loss': 'MSE', 'lr': 0.003788223521899112, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0357658642587316e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.0032982884350550605
weight_decay:  6.997527464638894e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.232170956907794
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 75.40
Split: 01, Run: 02
None time:  2.856028945883736
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.0720995678566396
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.223285436630249
total time:  6.264900743030012
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 1.75
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 2.30
[I 2023-06-12 00:55:21,604] Trial 455 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.00039961234651598597, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.759780745231616, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032982884350550605, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.997527464638894e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0036173597512259115
weight_decay:  3.634124127052859e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.606542333960533
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.007592153036967
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.6565920610446483
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.90
run time now: 5.319591999053955
total time:  5.3670558808371425
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.87 ± 1.05
[I 2023-06-12 00:55:27,470] Trial 456 finished with value: 81.73332977294922 and parameters: {'Fwd': 0.0014933672734537627, 'K': 10, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.432802144571161, 'loop': 1, 'loss': 'MSE', 'lr': 0.0036173597512259115, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.634124127052859e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.003739459858754823
weight_decay:  3.942905285517629e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8594398330897093
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.2189749570097774
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  0.9889529701322317
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.50
run time now: 4.115908622741699
total time:  4.15893102507107
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 77.73 ± 0.68
[I 2023-06-12 00:55:32,129] Trial 457 finished with value: 82.33333587646484 and parameters: {'Fwd': 0.0008388197268424937, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.909302771407349, 'loop': 1, 'loss': 'MSE', 'lr': 0.003739459858754823, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.942905285517629e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.004265265305117819
weight_decay:  0.0029945028120340915
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3039, Train: 100.00%, Valid: 77.00% Test: 74.70%
Split: 01, Run: 01
None time:  3.937812466174364
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 74.60
Split: 01, Run: 02
None time:  0.9736861081328243
None Run 02:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 74.80
Split: 01, Run: 03
None time:  1.0224795150570571
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 73.30
run time now: 5.983937740325928
total time:  6.031048737931997
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.13 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 74.23 ± 0.81
[I 2023-06-12 00:55:38,669] Trial 458 finished with value: 76.13333892822266 and parameters: {'Fwd': 0.0005440741978507645, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 7.133069638685007, 'loop': 1, 'loss': 'MSE', 'lr': 0.004265265305117819, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0029945028120340915, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002994170540658881
weight_decay:  9.243490878287431e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1206502879504114
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 73.60
Split: 01, Run: 02
None time:  1.1374219730496407
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.053930721944198
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 98.33
   Final Test: 79.00
run time now: 3.3693184852600098
total time:  3.411597799975425
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 1.51
  Final Train: 99.44 ± 0.96
   Final Test: 76.67 ± 2.77
[I 2023-06-12 00:55:42,567] Trial 459 finished with value: 79.13333129882812 and parameters: {'Fwd': 0.0002954107913937886, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 5.104076428076664, 'loop': 1, 'loss': 'CE', 'lr': 0.002994170540658881, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.243490878287431e-06, 'weightedloss': True}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.004149144501168855
weight_decay:  4.428458299375109e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2928514399100095
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  2.518468608846888
None Run 02:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.196399920154363
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.10
run time now: 6.0578062534332275
total time:  6.110135020921007
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.60 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 78.70 ± 1.06
[I 2023-06-12 00:55:49,247] Trial 460 finished with value: 82.5999984741211 and parameters: {'Fwd': 0.0006192921792264018, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.272627743885805, 'loop': 1, 'loss': 'MSE', 'lr': 0.004149144501168855, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.428458299375109e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.002774193901830987
weight_decay:  9.11201124919319e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4151415680535138
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  2.3443237389437854
None Run 02:
Highest Train: 100.00
Highest Valid: 84.40
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  2.6425873569678515
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 7.450585126876831
total time:  7.498754841974005
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.60 ± 1.59
  Final Train: 100.00 ± 0.00
   Final Test: 78.23 ± 1.91
[I 2023-06-12 00:55:57,242] Trial 461 finished with value: 82.5999984741211 and parameters: {'Fwd': 0.0008512765479741397, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 5.599595853328408, 'loop': 1, 'loss': 'MSE', 'lr': 0.002774193901830987, 'softmaxF': False, 'useGCN': False, 'weight_decay': 9.11201124919319e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.9
lr:  0.0035521258362369366
weight_decay:  4.732346702411013e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2910, Train: 100.00%, Valid: 82.20% Test: 77.60%
Split: 01, Run: 01
None time:  3.3020283880177885
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  1.5591123318299651
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.009500244865194
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 78.50
run time now: 5.913851499557495
total time:  5.963709296891466
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 78.20 ± 0.70
[I 2023-06-12 00:56:03,818] Trial 462 finished with value: 82.4000015258789 and parameters: {'Fwd': 0.000449806090306511, 'K': 9, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 4.4349078326932885, 'loop': 1, 'loss': 'MSE', 'lr': 0.0035521258362369366, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.732346702411013e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0025948391255718657
weight_decay:  6.532657081036038e-06
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6347060578409582
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.2000363629776984
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.1491177121642977
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.70
run time now: 4.034450531005859
total time:  4.09280570782721
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 78.87 ± 0.47
[I 2023-06-12 00:56:08,446] Trial 463 finished with value: 81.0 and parameters: {'Fwd': 8.482318015409781e-05, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 4.890675291929464, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025948391255718657, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.532657081036038e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0032927631395655143
weight_decay:  1.4713005452707128e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0542054891120642
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.70
Split: 01, Run: 02
None time:  2.118726575979963
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 03
None time:  2.386157965986058
None Run 03:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 73.90
run time now: 5.605737209320068
total time:  5.658208573004231
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.60 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 74.50 ± 1.04
[I 2023-06-12 00:56:14,640] Trial 464 finished with value: 76.60000610351562 and parameters: {'Fwd': 0.0011710825076621447, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 5.636079577973873, 'loop': 1, 'loss': 'MSE', 'lr': 0.0032927631395655143, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4713005452707128e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.0029391938453236935
weight_decay:  8.949292350602824e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4576154449023306
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 75.80
Split: 01, Run: 02
None time:  1.034018075093627
None Run 02:
Highest Train: 100.00
Highest Valid: 83.60
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.5045553999952972
None Run 03:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.50
run time now: 5.040652513504028
total time:  5.0919805120211095
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.80 ± 1.74
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 2.01
[I 2023-06-12 00:56:20,320] Trial 465 finished with value: 82.80000305175781 and parameters: {'Fwd': 2.3641442672717105e-06, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 8.40332661112723, 'loop': 1, 'loss': 'MSE', 'lr': 0.0029391938453236935, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.949292350602824e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.003999632379994243
weight_decay:  6.467637737745671e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2797292699106038
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  1.4108707960695028
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 03
None time:  1.1036234889179468
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 77.70
run time now: 4.846231698989868
total time:  4.892213944811374
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 77.10 ± 0.52
[I 2023-06-12 00:56:25,734] Trial 466 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.0008186554554509877, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 6.9432519434200834, 'loop': 1, 'loss': 'MSE', 'lr': 0.003999632379994243, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.467637737745671e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0006234342804109466
weight_decay:  1.2125052789519787e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9943462570663542
None Run 01:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  2.835106644080952
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 03
None time:  2.0110791369806975
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 5.892561674118042
total time:  5.934255035128444
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.67 ± 6.52
  Final Train: 100.00 ± 0.00
   Final Test: 74.60 ± 4.56
[I 2023-06-12 00:56:32,168] Trial 467 finished with value: 77.66666412353516 and parameters: {'Fwd': 3.6146331790338015e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 5.92534692131933, 'loop': 1, 'loss': 'MSE', 'lr': 0.0006234342804109466, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2125052789519787e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.00020078635800100357
weight_decay:  0.013894416234665695
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9986801890190691
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  1.2025211090222
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 75.30
Split: 01, Run: 03
None time:  0.9885881699156016
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 75.50
run time now: 3.240003824234009
total time:  3.290544629096985
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.67 ± 5.12
  Final Train: 100.00 ± 0.00
   Final Test: 73.47 ± 3.35
[I 2023-06-12 00:56:36,164] Trial 468 finished with value: 75.66666412353516 and parameters: {'Fwd': 0.0005980791055776348, 'K': 10, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 7.6587384683442234, 'loop': 1, 'loss': 'MSE', 'lr': 0.00020078635800100357, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.013894416234665695, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0024398047345052685
weight_decay:  3.7884958283904427e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.540365091059357
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 02
None time:  1.0891963420435786
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  0.7511688568629324
None Run 03:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.50
run time now: 4.435957908630371
total time:  4.487881015986204
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.40 ± 0.26
[I 2023-06-12 00:56:41,243] Trial 469 finished with value: 82.5999984741211 and parameters: {'Fwd': 4.5046018357515054e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 4.119528133704639, 'loop': 1, 'loss': 'MSE', 'lr': 0.0024398047345052685, 'softmaxF': False, 'useGCN': False, 'weight_decay': 3.7884958283904427e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.0003227015601823068
weight_decay:  1.539646555467185e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.8484795559197664
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 74.90
Split: 01, Run: 02
None time:  1.152847453020513
None Run 02:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  1.3043494678568095
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 77.60
run time now: 5.355183839797974
total time:  5.4028435768559575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 1.96
  Final Train: 100.00 ± 0.00
   Final Test: 76.50 ± 1.42
[I 2023-06-12 00:56:47,366] Trial 470 finished with value: 81.26666259765625 and parameters: {'Fwd': 0.00511520790177082, 'K': 9, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.65, 'lambda2': 5.451142533370494, 'loop': 2, 'loss': 'MSE', 'lr': 0.0003227015601823068, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.539646555467185e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0013666077992951305
weight_decay:  3.363737978537773e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9324711959343404
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.9306149310432374
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.0758152049966156
None Run 03:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 74.30
run time now: 3.015075206756592
total time:  3.0592929599806666
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.67 ± 4.27
  Final Train: 100.00 ± 0.00
   Final Test: 70.90 ± 2.94
[I 2023-06-12 00:56:51,052] Trial 471 finished with value: 71.66666412353516 and parameters: {'Fwd': 0.0001948916448174558, 'K': 10, 'alpha': 0.65, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 9.151072996838254, 'loop': 1, 'loss': 'MSE', 'lr': 0.0013666077992951305, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.363737978537773e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.006175940561686927
weight_decay:  5.5351680525481156e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1954, Train: 100.00%, Valid: 81.80% Test: 76.90%
Split: 01, Run: 01
None time:  3.7803535601124167
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  0.7064382540993392
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  0.9719572658650577
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.712558031082153
total time:  5.8781966550741345
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 77.73 ± 0.81
[I 2023-06-12 00:56:57,485] Trial 472 finished with value: 81.79999542236328 and parameters: {'Fwd': 0.001114828674275664, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.843212507179452, 'loop': 1, 'loss': 'MSE', 'lr': 0.006175940561686927, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.5351680525481156e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0027330384119502132
weight_decay:  0.0008498607935439855
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8746937171090394
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  1.7092547258362174
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  0.818364969920367
None Run 03:
Highest Train: 100.00
Highest Valid: 83.80
  Final Train: 100.00
   Final Test: 80.30
run time now: 3.4522666931152344
total time:  3.5004590400494635
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 7.92
  Final Train: 100.00 ± 0.00
   Final Test: 76.27 ± 5.90
[I 2023-06-12 00:57:01,490] Trial 473 finished with value: 78.93333435058594 and parameters: {'Fwd': 0.00013125977544842793, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 3.0406570817826264, 'loop': 1, 'loss': 'MSE', 'lr': 0.0027330384119502132, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0008498607935439855, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0016440902988299041
weight_decay:  7.797590698226501e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7854421539232135
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  0.8633601530455053
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  2.7161138230003417
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 77.80
run time now: 5.417243719100952
total time:  5.47070112102665
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.67 ± 1.10
  Final Train: 100.00 ± 0.00
   Final Test: 77.87 ± 0.31
[I 2023-06-12 00:57:07,468] Trial 474 finished with value: 78.66666412353516 and parameters: {'Fwd': 0.0005090001085876824, 'K': 10, 'alpha': 1.0, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 3.372688548889263, 'loop': 1, 'loss': 'MSE', 'lr': 0.0016440902988299041, 'softmaxF': True, 'useGCN': False, 'weight_decay': 7.797590698226501e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0023755477650159876
weight_decay:  2.830018540895413e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.0510054621845484
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  0.8575249370187521
None Run 02:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  2.0089448338840157
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 78.80
run time now: 5.967060089111328
total time:  6.015488752862439
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.53 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 79.10 ± 0.52
[I 2023-06-12 00:57:13,994] Trial 475 finished with value: 82.53333282470703 and parameters: {'Fwd': 2.487901159058815e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 5.75250884014281, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023755477650159876, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.830018540895413e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.35000000000000003
lr:  0.00450465114072023
weight_decay:  9.840838941669687e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9148441429715604
None Run 01:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 02
None time:  0.9673231840133667
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 74.60
Split: 01, Run: 03
None time:  1.0007739830762148
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 72.90
run time now: 2.931152582168579
total time:  2.9815478299278766
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.87 ± 3.49
  Final Train: 100.00 ± 0.00
   Final Test: 72.27 ± 2.71
[I 2023-06-12 00:57:17,476] Trial 476 finished with value: 72.86666870117188 and parameters: {'Fwd': 0.0014727687861050942, 'K': 8, 'alpha': 0.35000000000000003, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 7.364084245565347, 'loop': 1, 'loss': 'MSE', 'lr': 0.00450465114072023, 'softmaxF': False, 'useGCN': False, 'weight_decay': 9.840838941669687e-06, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.0030243391464598772
weight_decay:  6.668495673380583e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.2661, Train: 100.00%, Valid: 81.00% Test: 77.90%
Split: 01, Run: 01
None time:  3.548033872852102
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 02
None time:  1.028117418056354
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.3058403239119798
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 76.90
run time now: 5.92853569984436
total time:  5.975428704870865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 77.07 ± 0.29
[I 2023-06-12 00:57:24,023] Trial 477 finished with value: 80.20000457763672 and parameters: {'Fwd': 0.0006528008298995589, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.572841038700988, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030243391464598772, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.668495673380583e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0009359835966799181
weight_decay:  0.004189162815173685
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7082192420493811
None Run 01:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  1.3470993449445814
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 75.10
Split: 01, Run: 03
None time:  2.261436128988862
None Run 03:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 78.90
run time now: 4.404850006103516
total time:  4.462109059095383
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.47 ± 7.02
  Final Train: 100.00 ± 0.00
   Final Test: 74.40 ± 4.89
[I 2023-06-12 00:57:29,124] Trial 478 finished with value: 77.4666748046875 and parameters: {'Fwd': 0.00036137477462723874, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 30, 'lambda1': 0.8, 'lambda2': 5.202306948572244, 'loop': 1, 'loss': 'MSE', 'lr': 0.0009359835966799181, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.004189162815173685, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.0026169702535491428
weight_decay:  1.6956118414873886e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0440331068821251
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.1447483450174332
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 98.33
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.1200396581552923
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 98.33
   Final Test: 78.40
run time now: 3.361048936843872
total time:  3.404844793025404
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.46
  Final Train: 98.89 ± 0.96
   Final Test: 78.10 ± 0.89
[I 2023-06-12 00:57:33,120] Trial 479 finished with value: 80.26667022705078 and parameters: {'Fwd': 0.00016303839089054994, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 3.68522808148891, 'loop': 1, 'loss': 'CE', 'lr': 0.0026169702535491428, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.6956118414873886e-05, 'weightedloss': True}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0038469878164634967
weight_decay:  0.01121568060296285
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7962337690405548
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.60
Split: 01, Run: 02
None time:  0.8580085621215403
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 03
None time:  0.7262990311719477
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.60
run time now: 2.4258735179901123
total time:  2.472162286983803
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.47 ± 5.80
  Final Train: 100.00 ± 0.00
   Final Test: 75.10 ± 4.82
[I 2023-06-12 00:57:36,159] Trial 480 finished with value: 76.46666717529297 and parameters: {'Fwd': 0.00010364889645082349, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 6.057625495838327, 'loop': 1, 'loss': 'MSE', 'lr': 0.0038469878164634967, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.01121568060296285, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.005507384336351097
weight_decay:  1.8700362806875556e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5192014349158853
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  1.4431180199608207
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  0.7303476789966226
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 77.10
run time now: 4.739346027374268
total time:  4.78382543195039
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 77.43 ± 0.31
[I 2023-06-12 00:57:41,494] Trial 481 finished with value: 79.86666870117188 and parameters: {'Fwd': 0.0003371019831503064, 'K': 9, 'alpha': 0.75, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 0.7532014111445253, 'loop': 1, 'loss': 'MSE', 'lr': 0.005507384336351097, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.8700362806875556e-05, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.002126383449596186
weight_decay:  0.0002343052129323302
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1606058101169765
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.967774648917839
None Run 02:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  1.2183199599385262
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.60
run time now: 5.3968505859375
total time:  5.440396175021306
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.20 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.83 ± 1.00
[I 2023-06-12 00:57:47,448] Trial 482 finished with value: 82.20000457763672 and parameters: {'Fwd': 0.0008895789342091649, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 5.540270529703056, 'loop': 1, 'loss': 'MSE', 'lr': 0.002126383449596186, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002343052129323302, 'weightedloss': False}. Best is trial 364 with value: 83.66666412353516.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.004791087048792091
weight_decay:  1.626200722947075e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3844640019815415
None Run 01:
Highest Train: 100.00
Highest Valid: 83.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.1635451959446073
None Run 02:
Highest Train: 100.00
Highest Valid: 84.20
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.2510179851669818
None Run 03:
Highest Train: 100.00
Highest Valid: 84.00
  Final Train: 100.00
   Final Test: 79.60
run time now: 4.845757961273193
total time:  4.891767835943028
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 83.73 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 79.60 ± 1.10
[I 2023-06-12 00:57:52,863] Trial 483 finished with value: 83.73332977294922 and parameters: {'Fwd': 3.143574667691571e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 8.499978628780571, 'loop': 1, 'loss': 'MSE', 'lr': 0.004791087048792091, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.626200722947075e-06, 'weightedloss': False}. Best is trial 483 with value: 83.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.005171621205425985
weight_decay:  1.0613796500648806e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.685510863084346
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  2.0233977739699185
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  2.1762411389499903
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 5.9339234828948975
total time:  5.986968664918095
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.47 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 77.30 ± 0.26
[I 2023-06-12 00:57:59,390] Trial 484 finished with value: 79.46666717529297 and parameters: {'Fwd': 2.9437032305683125e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 8.567655779979207, 'loop': 1, 'loss': 'MSE', 'lr': 0.005171621205425985, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.0613796500648806e-06, 'weightedloss': False}. Best is trial 483 with value: 83.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.005148417506082193
weight_decay:  4.737857551607516e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0825934109743685
None Run 01:
Highest Train: 100.00
Highest Valid: 83.40
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02
None time:  0.7729255519807339
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.1783070091623813
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 76.90
run time now: 4.0824196338653564
total time:  4.128810898866504
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.40 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 1.08
[I 2023-06-12 00:58:04,113] Trial 485 finished with value: 82.4000015258789 and parameters: {'Fwd': 3.322066258913691e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 8.826189051929639, 'loop': 1, 'loss': 'MSE', 'lr': 0.005148417506082193, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.737857551607516e-06, 'weightedloss': False}. Best is trial 483 with value: 83.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.00012224933491197104
weight_decay:  2.136036002854343e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.067815822083503
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.8506, Train: 100.00%, Valid: 76.60% Test: 71.90%
Split: 01, Run: 02
None time:  3.658641873160377
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 72.00
Split: 01, Run: 03
None time:  3.373069741996005
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 75.50
run time now: 8.150437116622925
total time:  8.194155876990408
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.87 ± 5.03
  Final Train: 100.00 ± 0.00
   Final Test: 72.20 ± 3.20
[I 2023-06-12 00:58:12,847] Trial 486 finished with value: 74.86666107177734 and parameters: {'Fwd': 2.119074630812988e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 8.389121371052552, 'loop': 1, 'loss': 'MSE', 'lr': 0.00012224933491197104, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.136036002854343e-05, 'weightedloss': False}. Best is trial 483 with value: 83.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.004817803712977417
weight_decay:  1.1150382748897523e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9234077231958508
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 02
None time:  1.6274020820856094
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  2.1982353560160846
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 77.40
run time now: 5.799437522888184
total time:  5.853715694043785
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 77.63 ± 0.59
[I 2023-06-12 00:58:19,315] Trial 487 finished with value: 80.46666717529297 and parameters: {'Fwd': 3.951596527491841e-06, 'K': 9, 'alpha': 0.8, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 8.000053158481785, 'loop': 1, 'loss': 'MSE', 'lr': 0.004817803712977417, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.1150382748897523e-05, 'weightedloss': False}. Best is trial 483 with value: 83.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  1.0
lr:  0.005438774083816825
weight_decay:  1.7216244244858035e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.690791886067018
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  1.649217550875619
None Run 02:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  0.9632580990437418
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 78.00
run time now: 4.339775800704956
total time:  4.383133952971548
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.00 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 0.61
[I 2023-06-12 00:58:24,321] Trial 488 finished with value: 82.0 and parameters: {'Fwd': 0.0007414590602895177, 'K': 5, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 1.0, 'lambda2': 6.848363624052607, 'loop': 1, 'loss': 'MSE', 'lr': 0.005438774083816825, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.7216244244858035e-06, 'weightedloss': False}. Best is trial 483 with value: 83.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0034524400742605614
weight_decay:  1.2104260082164694e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5052996531594545
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.3666928210295737
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  1.5277496890630573
None Run 03:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 79.50
run time now: 5.443365812301636
total time:  5.487869939068332
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.93 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.80 ± 0.75
[I 2023-06-12 00:58:30,521] Trial 489 finished with value: 81.93334197998047 and parameters: {'Fwd': 0.0002458011548366806, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 9.37310224938092, 'loop': 1, 'loss': 'MSE', 'lr': 0.0034524400742605614, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.2104260082164694e-06, 'weightedloss': False}. Best is trial 483 with value: 83.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9
lr:  0.000769384037183383
weight_decay:  4.578883045469642e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0285794970113784
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 72.40
Split: 01, Run: 02
None time:  1.054236883064732
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.3823, Train: 100.00%, Valid: 81.20% Test: 76.50%
Split: 01, Run: 03
None time:  3.680138358846307
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 76.40
run time now: 6.826379060745239
total time:  6.869090477004647
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 1.92
  Final Train: 100.00 ± 0.00
   Final Test: 75.13 ± 2.37
[I 2023-06-12 00:58:38,001] Trial 490 finished with value: 79.13333129882812 and parameters: {'Fwd': 4.795525575512539e-06, 'K': 10, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 8.158446927715051, 'loop': 1, 'loss': 'MSE', 'lr': 0.000769384037183383, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.578883045469642e-05, 'weightedloss': False}. Best is trial 483 with value: 83.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.0058887403922634396
weight_decay:  2.6696940244513745e-06
dropout:  0.9
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.7693105759099126
None Run 01:
Highest Train: 100.00
Highest Valid: 83.20
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  1.138501302106306
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.0151071138679981
None Run 03:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 79.30
run time now: 5.971924543380737
total time:  6.014435660094023
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.13 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 79.33 ± 0.65
[I 2023-06-12 00:58:44,554] Trial 491 finished with value: 82.13333129882812 and parameters: {'Fwd': 2.9394305197981473e-06, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 8.44368887806288, 'loop': 1, 'loss': 'MSE', 'lr': 0.0058887403922634396, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.6696940244513745e-06, 'weightedloss': False}. Best is trial 483 with value: 83.73332977294922.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0004781258217440213
weight_decay:  6.251016088746664e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[19717, 500], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717], adj_t=[19717, 19717, nnz=88648])
num_train tensor(60)
num_noise 0
noise: tensor(0)
data feature 500
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=500, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=3, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(500, 64)
      (1): GCNConv(64, 3)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.6221925790887326
None Run 01:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 02
None time:  2.1025338110048324
None Run 02:
Highest Train: 100.00
Highest Valid: 82.80
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  2.3664657729677856
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 78.90
run time now: 7.140653371810913
total time:  7.182561365189031
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 82.33 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.53 ± 0.91
[I 2023-06-12 00:58:52,222] Trial 492 finished with value: 82.33333587646484 and parameters: {'Fwd': 5.238158245529275e-06, 'K': 10, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 8.28613862830495, 'loop': 1, 'loss': 'MSE', 'lr': 0.0004781258217440213, 'softmaxF': False, 'useGCN': False, 'weight_decay': 6.251016088746664e-06, 'weightedloss': False}. Best is trial 483 with value: 83.73332977294922.
