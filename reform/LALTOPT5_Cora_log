[I 2023-06-12 00:12:20,394] A new study created in RDB with name: Cora_ALTOPT
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.001971422250066717
weight_decay:  7.890207636120617e-06
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.407623832812533
None Run 01:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 02
None time:  0.7866661918815225
None Run 02:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 55.10
Split: 01, Run: 03
None time:  0.9636379589792341
None Run 03:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.80
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.7909904799889773
None Run 04:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.30
Split: 02, Run: 02
None time:  0.7543608348350972
None Run 05:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 69.70
Split: 02, Run: 03
None time:  0.7926087570376694
None Run 06:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 59.40
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.9208635760005563
None Run 07:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 56.30
Split: 03, Run: 02
None time:  0.7149734681006521
None Run 08:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 49.00
Split: 03, Run: 03
None time:  0.891532882116735
None Run 09:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.40
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.6823020810261369
None Run 10:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 48.90
Split: 04, Run: 02
None time:  0.797012893948704
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.30
Split: 04, Run: 03
None time:  0.858330714982003
None Run 12:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 58.60
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.657466433942318
None Run 13:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 36.30
Split: 05, Run: 02
None time:  0.7662654020823538
None Run 14:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 64.20
Split: 05, Run: 03
None time:  1.0907471089158207
None Run 15:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 70.10
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6777999829500914
None Run 16:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 37.60
Split: 06, Run: 02
None time:  0.8610832621343434
None Run 17:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 53.30
Split: 06, Run: 03
None time:  0.6318584471009672
None Run 18:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 45.10
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6401788210496306
None Run 19:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 42.80
Split: 07, Run: 02
None time:  0.7748827759642154
None Run 20:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 68.20
Split: 07, Run: 03
None time:  0.8642181640025228
None Run 21:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 54.90
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.6007679649628699
None Run 22:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.70
Split: 08, Run: 02
None time:  1.1796225910075009
None Run 23:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 76.60
Split: 08, Run: 03
None time:  0.7502538671251386
None Run 24:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 71.30
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4697400741279125
None Run 25:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.20
Split: 09, Run: 02
None time:  1.9937084710691124
None Run 26:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 55.00
Split: 09, Run: 03
None time:  0.7758093709126115
None Run 27:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 61.00
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6838605988305062
None Run 28:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 45.40
Split: 10, Run: 02
None time:  0.9858229111414403
None Run 29:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 62.20
Split: 10, Run: 03
None time:  1.4128365870565176
None Run 30:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 68.50
run time now: 3.1052215099334717
total time:  33.58216426195577
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.91 ± 10.29
  Final Train: 100.00 ± 0.00
   Final Test: 59.08 ± 10.60
best run test_acc: 66.75
[I 2023-06-12 00:12:54,643] Trial 0 finished with value: 59.90666580200195 and parameters: {'Fwd': 3.562744210727764e-05, 'K': 3, 'alpha': 0.25, 'dropout': 0.2, 'gnnepoch': 50, 'lambda1': 0.05, 'lambda2': 6.448719540359066, 'loop': 1, 'loss': 'MSE', 'lr': 0.001971422250066717, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.890207636120617e-06, 'weightedloss': True}. Best is trial 0 with value: 59.90666580200195.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.25
lr:  0.0007438363909376682
weight_decay:  0.0007427679613290894
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7390618920326233
None Run 01:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 63.20
Split: 01, Run: 02
None time:  0.7009116890840232
None Run 02:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.00
Split: 01, Run: 03
None time:  0.7916914329398423
None Run 03:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 71.70
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.7298573069274426
None Run 04:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 55.40
Split: 02, Run: 02
None time:  0.7631135070696473
None Run 05:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 60.70
Split: 02, Run: 03
None time:  0.7092688160482794
None Run 06:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 55.40
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.7413936969824135
None Run 07:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 59.30
Split: 03, Run: 02
None time:  0.7726067900657654
None Run 08:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 56.30
Split: 03, Run: 03
None time:  0.7096099618356675
None Run 09:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 58.80
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8600372311193496
None Run 10:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 64.40
Split: 04, Run: 02
None time:  0.7213547660503536
None Run 11:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.50
Split: 04, Run: 03
None time:  0.7076040050014853
None Run 12:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.50
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.84949945891276
None Run 13:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 54.00
Split: 05, Run: 02
None time:  0.9662535111419857
None Run 14:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 55.10
Split: 05, Run: 03
None time:  0.8245927831158042
None Run 15:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 52.50
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.6918911999091506
None Run 16:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 48.70
Split: 06, Run: 02
None time:  0.6916658570989966
None Run 17:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 48.70
Split: 06, Run: 03
None time:  0.7196924691088498
None Run 18:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 48.70
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.8575690460857004
None Run 19:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.10
Split: 07, Run: 02
None time:  0.7506431478541344
None Run 20:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.20
Split: 07, Run: 03
None time:  0.7164237131364644
None Run 21:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 59.80
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.9036938019562513
None Run 22:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.50
Split: 08, Run: 02
None time:  0.8810898750089109
None Run 23:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 71.40
Split: 08, Run: 03
None time:  0.702405451098457
None Run 24:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.60
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.7896883750800043
None Run 25:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.90
Split: 09, Run: 02
None time:  0.7171346910763532
None Run 26:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 56.00
Split: 09, Run: 03
None time:  0.7941448520869017
None Run 27:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.70
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.7162163550965488
None Run 28:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.90
Split: 10, Run: 02
None time:  0.7992251799441874
None Run 29:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.20
Split: 10, Run: 03
None time:  1.0981323239393532
None Run 30:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 71.50
run time now: 2.6418251991271973
total time:  23.956339695025235
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.96 ± 6.85
  Final Train: 100.00 ± 0.00
   Final Test: 60.39 ± 6.97
best run test_acc: 63.9900016784668
[I 2023-06-12 00:13:19,063] Trial 1 finished with value: 60.96000289916992 and parameters: {'Fwd': 8.106312000032944e-05, 'K': 10, 'alpha': 0.25, 'dropout': 0.7000000000000001, 'gnnepoch': 20, 'lambda1': 0.55, 'lambda2': 8.970797043348728, 'loop': 0, 'loss': 'CE', 'lr': 0.0007438363909376682, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007427679613290894, 'weightedloss': False}. Best is trial 1 with value: 60.96000289916992.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.1
lr:  0.00010462884921499649
weight_decay:  0.037411322270117155
dropout:  0.0
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.031180670019239
None Run 01:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.40
Split: 01, Run: 02
None time:  2.2233764671254903
None Run 02:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.40
Split: 01, Run: 03
None time:  2.18517901096493
None Run 03:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.40
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 56.80% Test: 55.40%
Split: 02, Run: 01
None time:  4.120463545899838
None Run 04:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 55.40
Split: 02, Run: 02
None time:  2.0621796250343323
None Run 05:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 53.50
Split: 02, Run: 03
None time:  2.1710972799919546
None Run 06:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 53.50
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.201357582816854
None Run 07:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 44.90
Split: 03, Run: 02
None time:  2.1814131708815694
None Run 08:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 44.90
Split: 03, Run: 03
None time:  2.1230839940253645
None Run 09:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 44.90
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.997818946139887
None Run 10:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 54.40
Split: 04, Run: 02
None time:  2.1345012430101633
None Run 11:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 54.40
Split: 04, Run: 03
None time:  2.2370035820640624
None Run 12:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 54.40
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.122742930892855
None Run 13:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 47.40
Split: 05, Run: 02
None time:  2.1642776399385184
None Run 14:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 47.40
Split: 05, Run: 03
None time:  2.180108776083216
None Run 15:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 47.40
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.1919278900604695
None Run 16:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 45.90
Split: 06, Run: 02
None time:  2.0827427951153368
None Run 17:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 45.90
Split: 06, Run: 03
None time:  2.122598454821855
None Run 18:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 45.90
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.166001091012731
None Run 19:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 57.20
Split: 07, Run: 02
None time:  2.1627313559874892
None Run 20:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 57.20
Split: 07, Run: 03
None time:  2.1756937608588487
None Run 21:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 57.20
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.2153555729892105
None Run 22:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 56.60
Split: 08, Run: 02
None time:  2.2054954839404672
None Run 23:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 56.60
Split: 08, Run: 03
None time:  2.1751750849653035
None Run 24:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 56.60
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.185024806065485
None Run 25:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 58.90
Split: 09, Run: 02
None time:  2.124111703131348
None Run 26:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 52.50
Split: 09, Run: 03
None time:  2.234717963030562
None Run 27:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 52.50
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.1342762720305473
None Run 28:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 58.50
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.80% Test: 62.90%
Split: 10, Run: 02
None time:  4.225461391033605
None Run 29:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 62.90
Split: 10, Run: 03
None time:  2.1128129430580884
None Run 30:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 58.50
run time now: 8.497899055480957
total time:  69.2035024529323
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.17 ± 4.97
  Final Train: 100.00 ± 0.00
   Final Test: 53.65 ± 5.69
best run test_acc: 54.5
[I 2023-06-12 00:14:28,779] Trial 2 finished with value: 54.17333221435547 and parameters: {'Fwd': 1.8020949224068187e-05, 'K': 7, 'alpha': 0.1, 'dropout': 0.0, 'gnnepoch': 120, 'lambda1': 0.65, 'lambda2': 7.763931910735717, 'loop': 0, 'loss': 'MSE', 'lr': 0.00010462884921499649, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.037411322270117155, 'weightedloss': True}. Best is trial 1 with value: 60.96000289916992.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.2
lr:  0.0011783657929260337
weight_decay:  0.0025211942753695137
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1037191189825535
None Run 01:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 54.80
Split: 01, Run: 02
None time:  1.1039599301293492
None Run 02:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 59.60
Split: 01, Run: 03
None time:  1.1520193540491164
None Run 03:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 55.50
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2723699470516294
None Run 04:
Highest Train: 100.00
Highest Valid: 42.00
  Final Train: 100.00
   Final Test: 47.80
Split: 02, Run: 02
None time:  1.1690029490273446
None Run 05:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 58.00
Split: 02, Run: 03
None time:  1.1769191580824554
None Run 06:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 55.60
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.7299376789014786
None Run 07:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 80.00
   Final Test: 53.20
Split: 03, Run: 02
None time:  1.2277597489301115
None Run 08:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 57.40
Split: 03, Run: 03
None time:  1.1346727090422064
None Run 09:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 51.10
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.261580202030018
None Run 10:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.90
Split: 04, Run: 02
None time:  1.1675202450715005
None Run 11:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 63.70
Split: 04, Run: 03
None time:  1.1301460128743201
None Run 12:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 52.70
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.637860595015809
None Run 13:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 94.29
   Final Test: 60.90
Split: 05, Run: 02
None time:  1.231898922007531
None Run 14:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 97.14
   Final Test: 52.20
Split: 05, Run: 03
None time:  1.22053455398418
None Run 15:
Highest Train: 100.00
Highest Valid: 42.00
  Final Train: 97.14
   Final Test: 40.90
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.0816865609958768
None Run 16:
Highest Train: 100.00
Highest Valid: 43.40
  Final Train: 100.00
   Final Test: 37.60
Split: 06, Run: 02
None time:  1.1316223740577698
None Run 17:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 47.40
Split: 06, Run: 03
None time:  1.1819939999841154
None Run 18:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 41.00
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3126802118495107
None Run 19:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 62.20
Split: 07, Run: 02
None time:  1.2077087590005249
None Run 20:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 62.70
Split: 07, Run: 03
None time:  1.299899379024282
None Run 21:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 91.43
   Final Test: 55.30
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1322629749774933
None Run 22:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 44.50
Split: 08, Run: 02
None time:  1.0396608340088278
None Run 23:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 61.30
Split: 08, Run: 03
None time:  1.1619469339493662
None Run 24:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 55.40
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2178535850252956
None Run 25:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 59.70
Split: 09, Run: 02
None time:  1.1245012579020113
None Run 26:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 63.00
Split: 09, Run: 03
None time:  1.1628876158501953
None Run 27:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 82.86
   Final Test: 61.20
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1858123349957168
None Run 28:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 50.70
Split: 10, Run: 02
None time:  1.1702325108926743
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.00
Split: 10, Run: 03
None time:  1.2274469048716128
None Run 30:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 62.20
run time now: 3.6074752807617188
total time:  36.888719082809985
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 56.42 ± 7.92
  Final Train: 98.10 ± 4.94
   Final Test: 55.25 ± 7.54
best run test_acc: 60.099998474121094
[I 2023-06-12 00:15:05,995] Trial 3 finished with value: 56.41999435424805 and parameters: {'Fwd': 0.03329037197153146, 'K': 3, 'alpha': 0.2, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 0.9, 'lambda2': 2.3286994493473836, 'loop': 2, 'loss': 'CE', 'lr': 0.0011783657929260337, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0025211942753695137, 'weightedloss': True}. Best is trial 1 with value: 60.96000289916992.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.25
lr:  0.00011085020904939296
weight_decay:  0.005521035404926447
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5473847449757159
None Run 01:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.60
Split: 01, Run: 02
None time:  0.5157667640596628
None Run 02:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.60
Split: 01, Run: 03
None time:  0.6096588091459125
None Run 03:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 61.70
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.5781051300000399
None Run 04:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 54.30
Split: 02, Run: 02
None time:  0.6313785829115659
None Run 05:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 54.30
Split: 02, Run: 03
None time:  0.5667716600000858
None Run 06:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 54.30
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.5385523701552302
None Run 07:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 46.10
Split: 03, Run: 02
None time:  0.5873371779453009
None Run 08:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 46.10
Split: 03, Run: 03
None time:  0.5175510209519416
None Run 09:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 46.10
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.5554142310284078
None Run 10:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 55.50
Split: 04, Run: 02
None time:  0.5660053570754826
None Run 11:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 55.50
Split: 04, Run: 03
None time:  0.5504124017897993
None Run 12:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 55.50
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.5446843900717795
None Run 13:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 48.20
Split: 05, Run: 02
None time:  0.5194384569767863
None Run 14:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 48.20
Split: 05, Run: 03
None time:  0.5571518221404403
None Run 15:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 48.20
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5892700930126011
None Run 16:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 47.50
Split: 06, Run: 02
None time:  0.5571406299713999
None Run 17:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 47.50
Split: 06, Run: 03
None time:  0.5987858551088721
None Run 18:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 47.50
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.5858113551512361
None Run 19:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 59.10
Split: 07, Run: 02
None time:  0.4978321138769388
None Run 20:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 59.10
Split: 07, Run: 03
None time:  0.5605192668735981
None Run 21:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 59.10
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5769518730230629
None Run 22:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 58.60
Split: 08, Run: 02
None time:  0.5707104578614235
None Run 23:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 58.60
Split: 08, Run: 03
None time:  0.5534862070344388
None Run 24:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 58.60
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.5935363741591573
None Run 25:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 55.50
Split: 09, Run: 02
None time:  0.6054785458836704
None Run 26:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 55.50
Split: 09, Run: 03
None time:  0.5706908979918808
None Run 27:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 55.50
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.5783139169216156
None Run 28:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.30
Split: 10, Run: 02
None time:  0.5630711100529879
None Run 29:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.30
Split: 10, Run: 03
None time:  0.5457679780665785
None Run 30:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.30
run time now: 1.714207410812378
total time:  17.622657811036333
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 55.27 ± 5.27
  Final Train: 100.00 ± 0.00
   Final Test: 54.81 ± 5.61
best run test_acc: 54.87000274658203
[I 2023-06-12 00:15:23,958] Trial 4 finished with value: 55.266666412353516 and parameters: {'Fwd': 4.5287054859145494e-05, 'K': 8, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 30, 'lambda1': 0.8, 'lambda2': 5.929013430488226, 'loop': 1, 'loss': 'CE', 'lr': 0.00011085020904939296, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.005521035404926447, 'weightedloss': False}. Best is trial 1 with value: 60.96000289916992.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.0012177517277470952
weight_decay:  0.0005412087741513721
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0877332538366318
None Run 01:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 47.70
Split: 01, Run: 02
None time:  1.345378935104236
None Run 02:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 60.90
Split: 01, Run: 03
None time:  1.4016043450683355
None Run 03:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.50
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1891482779756188
None Run 04:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 40.70
Split: 02, Run: 02
None time:  1.4861567479092628
None Run 05:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 58.80
Split: 02, Run: 03
None time:  1.1603695040103048
None Run 06:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 60.30
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1607237998396158
None Run 07:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 37.40
Split: 03, Run: 02
None time:  1.3779712829273194
None Run 08:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 54.50
Split: 03, Run: 03
None time:  1.2772720479406416
None Run 09:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 97.14
   Final Test: 62.90
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.36488681496121
None Run 10:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 97.14
   Final Test: 53.20
Split: 04, Run: 02
None time:  1.7043950809165835
None Run 11:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 97.14
   Final Test: 67.00
Split: 04, Run: 03
None time:  1.444862418808043
None Run 12:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 94.29
   Final Test: 71.00
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1493669978808612
None Run 13:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 36.40
Split: 05, Run: 02
None time:  1.1923902691341937
None Run 14:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 38.10
Split: 05, Run: 03
None time:  1.3422802379354835
None Run 15:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 63.40
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.148343563079834
None Run 16:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 37.60
Split: 06, Run: 02
None time:  1.0797224699053913
None Run 17:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 37.60
Split: 06, Run: 03
None time:  1.0919854959938675
None Run 18:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 37.60
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.3569306649733335
None Run 19:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 57.30
Split: 07, Run: 02
None time:  1.4067359690088779
None Run 20:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 71.50
Split: 07, Run: 03
None time:  1.3339467749465257
None Run 21:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 74.30
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.173111456912011
None Run 22:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 41.80
Split: 08, Run: 02
None time:  1.2736533619463444
None Run 23:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 45.70
Split: 08, Run: 03
None time:  1.167982738930732
None Run 24:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 46.40
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.331360578071326
None Run 25:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 40.90
Split: 09, Run: 02
None time:  1.3855678408872336
None Run 26:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 57.60
Split: 09, Run: 03
None time:  1.255045787896961
None Run 27:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 56.60
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1521682438906282
None Run 28:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 45.40
Split: 10, Run: 02
None time:  1.532147736987099
None Run 29:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.00
Split: 10, Run: 03
None time:  1.1101119539234787
None Run 30:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.40
run time now: 3.8261003494262695
total time:  39.01525813806802
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 54.43 ± 11.49
  Final Train: 99.52 ± 1.32
   Final Test: 53.15 ± 11.96
best run test_acc: 60.100006103515625
[I 2023-06-12 00:16:03,490] Trial 5 finished with value: 54.43333435058594 and parameters: {'Fwd': 8.620036389183887e-05, 'K': 3, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.55, 'lambda2': 4.1732843901936425, 'loop': 2, 'loss': 'CE', 'lr': 0.0012177517277470952, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0005412087741513721, 'weightedloss': True}. Best is trial 1 with value: 60.96000289916992.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9500000000000001
lr:  0.0003429018658711467
weight_decay:  1.489363177936635e-05
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5977603590581566
None Run 01:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.20
Split: 01, Run: 02
None time:  2.2756462190300226
None Run 02:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 57.80
Split: 01, Run: 03
None time:  2.558056074893102
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 69.50
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.243436314864084
None Run 04:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 61.20
Split: 02, Run: 02
None time:  2.1476430820766836
None Run 05:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 53.40
Split: 02, Run: 03
None time:  2.6400972697883844
None Run 06:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 66.90
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.81277148402296
None Run 07:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 71.20
Split: 03, Run: 02
None time:  2.825096975080669
None Run 08:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.50
Split: 03, Run: 03
None time:  2.7455743080936372
None Run 09:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 69.20
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.3671203169506043
None Run 10:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 48.90
Split: 04, Run: 02
None time:  2.2806801749393344
None Run 11:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 40.00
Split: 04, Run: 03
None time:  2.2968661091290414
None Run 12:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 40.00
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.7545743919909
None Run 13:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.90
Split: 05, Run: 02
None time:  3.1381387640722096
None Run 14:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.00
Split: 05, Run: 03
None time:  2.7753524999134243
None Run 15:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.20
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.270905451150611
None Run 16:
Highest Train: 100.00
Highest Valid: 43.40
  Final Train: 100.00
   Final Test: 37.60
Split: 06, Run: 02
None time:  2.3389245260041207
None Run 17:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 51.60
Split: 06, Run: 03
None time:  2.373040236067027
None Run 18:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 44.40
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.5815844170283526
None Run 19:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.90
Split: 07, Run: 02
None time:  2.8070161731448025
None Run 20:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.80
Split: 07, Run: 03
None time:  2.677939713001251
None Run 21:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.10
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.795477693201974
None Run 22:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.70
Split: 08, Run: 02
None time:  2.6493839418981224
None Run 23:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.40
Split: 08, Run: 03
None time:  2.5524624958634377
None Run 24:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.20
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.3883080629166216
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 62.40
Split: 09, Run: 02
None time:  2.6135907031130046
None Run 26:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.40
Split: 09, Run: 03
None time:  2.3284722559619695
None Run 27:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 57.90
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.5891964230686426
None Run 28:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.60
Split: 10, Run: 02
None time:  2.4055538040120155
None Run 29:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 74.50
Split: 10, Run: 03
None time:  2.556336530018598
None Run 30:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 65.50
run time now: 7.57766318321228
total time:  76.87279547913931
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 62.81 ± 10.74
  Final Train: 100.00 ± 0.00
   Final Test: 62.20 ± 10.88
best run test_acc: 66.33999633789062
[I 2023-06-12 00:17:20,807] Trial 6 finished with value: 62.81333541870117 and parameters: {'Fwd': 0.007352272938051072, 'K': 3, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 110, 'lambda1': 0.25, 'lambda2': 3.59289035335026, 'loop': 2, 'loss': 'CE', 'lr': 0.0003429018658711467, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.489363177936635e-05, 'weightedloss': True}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  1.0
lr:  0.0005520130341253069
weight_decay:  0.00019880359460015072
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1509433130268008
None Run 01:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 59.00
Split: 01, Run: 02
None time:  1.0506703190039843
None Run 02:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 59.40
Split: 01, Run: 03
None time:  1.0855852388776839
None Run 03:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 55.80
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.1374786340165883
None Run 04:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 57.50
Split: 02, Run: 02
None time:  1.1796233118511736
None Run 05:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.10
Split: 02, Run: 03
None time:  1.0852639051154256
None Run 06:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 55.70
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.679539066972211
None Run 07:
Highest Train: 100.00
Highest Valid: 39.40
  Final Train: 85.71
   Final Test: 36.40
Split: 03, Run: 02
None time:  1.024230662966147
None Run 08:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 50.30
Split: 03, Run: 03
None time:  1.0480604369658977
None Run 09:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 53.10
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0506310351192951
None Run 10:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 54.60
Split: 04, Run: 02
None time:  1.2312595730181783
None Run 11:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.30
Split: 04, Run: 03
None time:  1.6468682119157165
None Run 12:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 59.70
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.5482218861579895
None Run 13:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 49.00
Split: 05, Run: 02
None time:  1.136941323056817
None Run 14:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 54.70
Split: 05, Run: 03
None time:  1.2989169228821993
None Run 15:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 54.30
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1090185190550983
None Run 16:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 32.60
Split: 06, Run: 02
None time:  1.1147018759511411
None Run 17:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 43.90
Split: 06, Run: 03
None time:  1.1269072531722486
None Run 18:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 43.60
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1598522518761456
None Run 19:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 41.10
Split: 07, Run: 02
None time:  1.1329454339575022
None Run 20:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 55.40
Split: 07, Run: 03
None time:  1.187041328055784
None Run 21:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 56.70
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.086826055077836
None Run 22:
Highest Train: 100.00
Highest Valid: 45.60
  Final Train: 100.00
   Final Test: 46.10
Split: 08, Run: 02
None time:  1.211121612926945
None Run 23:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 55.60
Split: 08, Run: 03
None time:  1.2223660429008305
None Run 24:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 53.50
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2456038380041718
None Run 25:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 48.40
Split: 09, Run: 02
None time:  1.0611884591635317
None Run 26:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 53.00
Split: 09, Run: 03
None time:  1.0727927240077406
None Run 27:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 51.20
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1419495379086584
None Run 28:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 46.60
Split: 10, Run: 02
None time:  1.21032828791067
None Run 29:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 62.50
Split: 10, Run: 03
None time:  1.4238468199037015
None Run 30:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 62.70
run time now: 3.8002941608428955
total time:  36.3561868800316
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 53.97 ± 7.62
  Final Train: 99.52 ± 2.61
   Final Test: 52.59 ± 7.66
best run test_acc: 56.44999313354492
[I 2023-06-12 00:17:57,526] Trial 7 finished with value: 53.97333908081055 and parameters: {'Fwd': 6.545968431947501e-05, 'K': 1, 'alpha': 1.0, 'dropout': 0.1, 'gnnepoch': 90, 'lambda1': 0.30000000000000004, 'lambda2': 4.082002649480964, 'loop': 2, 'loss': 'CE', 'lr': 0.0005520130341253069, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.00019880359460015072, 'weightedloss': True}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.1
lr:  0.001038322909566182
weight_decay:  1.9886490035137906e-06
dropout:  0.0
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.538593138102442
None Run 01:
Highest Train: 100.00
Highest Valid: 29.80
  Final Train: 100.00
   Final Test: 33.70
Split: 01, Run: 02
None time:  1.500960909994319
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 91.43
   Final Test: 67.50
Split: 01, Run: 03
None time:  0.9708809109870344
None Run 03:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 97.14
   Final Test: 70.30
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.8247432119678706
None Run 04:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 30.50
Split: 02, Run: 02
None time:  0.7985572281759232
None Run 05:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 49.50
Split: 02, Run: 03
None time:  0.7542979759164155
None Run 06:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 53.10
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.5773590181488544
None Run 07:
Highest Train: 100.00
Highest Valid: 29.60
  Final Train: 100.00
   Final Test: 28.70
Split: 03, Run: 02
None time:  1.4806849118322134
None Run 08:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 68.57
   Final Test: 37.20
Split: 03, Run: 03
None time:  1.8069063159637153
None Run 09:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 68.57
   Final Test: 49.50
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.5725339148193598
None Run 10:
Highest Train: 100.00
Highest Valid: 31.80
  Final Train: 100.00
   Final Test: 34.00
Split: 04, Run: 02
None time:  1.0980877249967307
None Run 11:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 91.43
   Final Test: 62.50
Split: 04, Run: 03
None time:  0.9173491999972612
None Run 12:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 94.29
   Final Test: 67.30
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.5720364670269191
None Run 13:
Highest Train: 100.00
Highest Valid: 28.20
  Final Train: 100.00
   Final Test: 27.20
Split: 05, Run: 02
None time:  1.7856563969980925
None Run 14:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 82.86
   Final Test: 57.20
Split: 05, Run: 03
None time:  0.6490829749964178
None Run 15:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 62.50
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5747436468955129
None Run 16:
Highest Train: 100.00
Highest Valid: 33.00
  Final Train: 100.00
   Final Test: 28.40
Split: 06, Run: 02
None time:  0.5717564828228205
None Run 17:
Highest Train: 100.00
Highest Valid: 33.00
  Final Train: 100.00
   Final Test: 28.40
Split: 06, Run: 03
None time:  0.7870764990802854
None Run 18:
Highest Train: 100.00
Highest Valid: 34.80
  Final Train: 97.14
   Final Test: 32.10
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.5353625549469143
None Run 19:
Highest Train: 100.00
Highest Valid: 26.20
  Final Train: 100.00
   Final Test: 29.10
Split: 07, Run: 02
None time:  0.8709551331121475
None Run 20:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 100.00
   Final Test: 31.60
Split: 07, Run: 03
None time:  0.634863292099908
None Run 21:
Highest Train: 100.00
Highest Valid: 41.00
  Final Train: 100.00
   Final Test: 39.30
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5417059829924256
None Run 22:
Highest Train: 100.00
Highest Valid: 42.00
  Final Train: 100.00
   Final Test: 40.10
Split: 08, Run: 02
None time:  0.8906499629374593
None Run 23:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 94.29
   Final Test: 67.10
Split: 08, Run: 03
None time:  0.9388599060475826
None Run 24:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 94.29
   Final Test: 72.00
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.5626931211445481
None Run 25:
Highest Train: 100.00
Highest Valid: 30.80
  Final Train: 100.00
   Final Test: 28.00
Split: 09, Run: 02
None time:  0.8896611060481519
None Run 26:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 97.14
   Final Test: 42.80
Split: 09, Run: 03
None time:  0.5642223078757524
None Run 27:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 51.50
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.5449865330010653
None Run 28:
Highest Train: 100.00
Highest Valid: 32.20
  Final Train: 100.00
   Final Test: 30.30
Split: 10, Run: 02
None time:  1.141590469982475
None Run 29:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 80.00
   Final Test: 49.50
Split: 10, Run: 03
None time:  0.8811598480679095
None Run 30:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 97.14
   Final Test: 55.70
run time now: 2.5913872718811035
total time:  26.391864052042365
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 46.77 ± 15.51
  Final Train: 95.14 ± 8.79
   Final Test: 45.22 ± 15.23
best run test_acc: 55.32999801635742
[I 2023-06-12 00:18:24,257] Trial 8 finished with value: 46.766666412353516 and parameters: {'Fwd': 0.00012534122334656493, 'K': 2, 'alpha': 0.1, 'dropout': 0.0, 'gnnepoch': 30, 'lambda1': 0.8, 'lambda2': 3.1935169081883927, 'loop': 2, 'loss': 'CE', 'lr': 0.001038322909566182, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.9886490035137906e-06, 'weightedloss': True}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.55
lr:  0.0006442785363783054
weight_decay:  0.001840393776275809
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9109712420031428
None Run 01:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 54.80
Split: 01, Run: 02
None time:  0.9180644790176302
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 65.50
Split: 01, Run: 03
None time:  0.9481938441749662
None Run 03:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 68.00
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.914341886062175
None Run 04:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 58.70
Split: 02, Run: 02
None time:  0.9058549359906465
None Run 05:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 62.10
Split: 02, Run: 03
None time:  0.8832895010709763
None Run 06:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 63.90
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.833266762085259
None Run 07:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 43.40
Split: 03, Run: 02
None time:  1.200082543073222
None Run 08:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 50.50
Split: 03, Run: 03
None time:  0.8773132660426199
None Run 09:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 54.60
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2194225729908794
None Run 10:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.10
Split: 04, Run: 02
None time:  0.9941539028659463
None Run 11:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.60
Split: 04, Run: 03
None time:  0.9312200990971178
None Run 12:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 72.30
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.8620437590871006
None Run 13:
Highest Train: 100.00
Highest Valid: 46.00
  Final Train: 100.00
   Final Test: 46.40
Split: 05, Run: 02
None time:  1.0767545148264617
None Run 14:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 50.40
Split: 05, Run: 03
None time:  0.921219201060012
None Run 15:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 53.70
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9268868800718337
None Run 16:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 46.20
Split: 06, Run: 02
None time:  0.8342423939611763
None Run 17:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 46.20
Split: 06, Run: 03
None time:  1.0715114229824394
None Run 18:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 47.20
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.7189659089781344
None Run 19:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.40
Split: 07, Run: 02
None time:  1.1405255179852247
None Run 20:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.50
Split: 07, Run: 03
None time:  0.8620735569857061
None Run 21:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.40
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.7796304598450661
None Run 22:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 54.20
Split: 08, Run: 02
None time:  0.834549369988963
None Run 23:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 54.90
Split: 08, Run: 03
None time:  0.8901795910205692
None Run 24:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 55.40
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.849183500977233
None Run 25:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 51.60
Split: 09, Run: 02
None time:  0.9031998210120946
None Run 26:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 55.30
Split: 09, Run: 03
None time:  0.8916247459128499
None Run 27:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 56.50
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8707833180669695
None Run 28:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 57.00
Split: 10, Run: 02
None time:  0.8934958118479699
None Run 29:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 59.80
Split: 10, Run: 03
None time:  0.788430661894381
None Run 30:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 63.60
run time now: 2.5740885734558105
total time:  28.247990804025903
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 58.43 ± 7.69
  Final Train: 100.00 ± 0.00
   Final Test: 56.84 ± 7.46
best run test_acc: 59.96000289916992
[I 2023-06-12 00:18:52,870] Trial 9 finished with value: 58.42667007446289 and parameters: {'Fwd': 0.021410838459892508, 'K': 5, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.30000000000000004, 'lambda2': 2.9670744246166745, 'loop': 1, 'loss': 'CE', 'lr': 0.0006442785363783054, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.001840393776275809, 'weightedloss': False}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  1.0
lr:  0.009081797767871576
weight_decay:  3.785108371886213e-05
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.25341083901003
None Run 01:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.70
Split: 01, Run: 02
None time:  1.295138827059418
None Run 02:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.70
Split: 01, Run: 03
None time:  1.3545457269065082
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.70
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.003325582947582
None Run 04:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 59.30
Split: 02, Run: 02
None time:  0.9225045491475612
None Run 05:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 59.30
Split: 02, Run: 03
None time:  0.9024141640402377
None Run 06:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 59.30
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.059445756021887
None Run 07:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 52.80
Split: 03, Run: 02
None time:  1.0255048130638897
None Run 08:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 52.80
Split: 03, Run: 03
None time:  1.0214101909659803
None Run 09:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 52.80
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.699318221071735
None Run 10:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.30
Split: 04, Run: 02
None time:  0.6537287121172994
None Run 11:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.30
Split: 04, Run: 03
None time:  0.7425508941523731
None Run 12:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 60.30
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7749145890120417
None Run 13:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 52.10
Split: 05, Run: 02
None time:  1.835762397851795
None Run 14:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 52.10
Split: 05, Run: 03
None time:  1.8378048068843782
None Run 15:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 52.10
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.7765219090506434
None Run 16:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 51.80
Split: 06, Run: 02
None time:  0.5521161118522286
None Run 17:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 51.80
Split: 06, Run: 03
None time:  0.7837669919244945
None Run 18:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 51.80
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1358643560670316
None Run 19:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 62.10
Split: 07, Run: 02
None time:  1.2280710411723703
None Run 20:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 62.10
Split: 07, Run: 03
None time:  1.1015351109672338
None Run 21:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 62.10
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.1216454389505088
None Run 22:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.40
Split: 08, Run: 02
None time:  1.2773726407904178
None Run 23:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.40
Split: 08, Run: 03
None time:  1.2819377349223942
None Run 24:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.40
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0349801960401237
None Run 25:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 57.90
Split: 09, Run: 02
None time:  1.098262090003118
None Run 26:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 57.90
Split: 09, Run: 03
None time:  1.0165118179284036
None Run 27:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 57.90
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.8962065130472183
None Run 28:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 62.70
Split: 10, Run: 02
None time:  0.9452441718894988
None Run 29:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 62.70
Split: 10, Run: 03
None time:  0.9399582231417298
None Run 30:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 62.70
run time now: 2.812697410583496
total time:  33.04984584101476
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.90 ± 5.54
  Final Train: 100.00 ± 0.00
   Final Test: 59.31 ± 5.54
best run test_acc: 59.30999755859375
[I 2023-06-12 00:19:26,438] Trial 10 finished with value: 59.90000915527344 and parameters: {'Fwd': 0.0015877299002301718, 'K': 6, 'alpha': 1.0, 'dropout': 0.4, 'gnnepoch': 0, 'lambda1': 0.0, 'lambda2': 0.30533007933375966, 'loop': 2, 'loss': 'MSE', 'lr': 0.009081797767871576, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.785108371886213e-05, 'weightedloss': False}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.00031543695273301227
weight_decay:  4.659755431166085e-05
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.48634149390272796
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 64.90
Split: 01, Run: 02
None time:  0.5673534299712628
None Run 02:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.30
Split: 01, Run: 03
None time:  0.33401587000116706
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.00
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.3525206611957401
None Run 04:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 55.40
Split: 02, Run: 02
None time:  0.3517023848835379
None Run 05:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 55.40
Split: 02, Run: 03
None time:  0.9187334789894521
None Run 06:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 67.30
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.43409036681987345
None Run 07:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 49.60
Split: 03, Run: 02
None time:  0.4835837490390986
None Run 08:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 51.50
Split: 03, Run: 03
None time:  0.5434580869041383
None Run 09:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 55.30
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.3469781510066241
None Run 10:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.50
Split: 04, Run: 02
None time:  0.35390642285346985
None Run 11:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.50
Split: 04, Run: 03
None time:  0.3423346630297601
None Run 12:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.50
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.35264636599458754
None Run 13:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 48.90
Split: 05, Run: 02
None time:  0.3356789101380855
None Run 14:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 48.90
Split: 05, Run: 03
None time:  0.3530878371093422
None Run 15:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 48.90
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.8845069399103522
None Run 16:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.60
Split: 06, Run: 02
None time:  1.070027424953878
None Run 17:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 46.70
Split: 06, Run: 03
None time:  0.4870463579427451
None Run 18:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 50.60
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.5064412949141115
None Run 19:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 65.80
Split: 07, Run: 02
None time:  0.3865143428556621
None Run 20:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 59.80
Split: 07, Run: 03
None time:  0.3460391708649695
None Run 21:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 59.80
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.37515948503278196
None Run 22:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 61.10
Split: 08, Run: 02
None time:  0.3883640659041703
None Run 23:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 61.10
Split: 08, Run: 03
None time:  0.37169404909946024
None Run 24:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.20
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.0579931479878724
None Run 25:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 66.20
Split: 09, Run: 02
None time:  0.5242552529089153
None Run 26:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 63.90
Split: 09, Run: 03
None time:  0.3611083591822535
None Run 27:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 56.00
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.3950216048397124
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 67.30
Split: 10, Run: 02
None time:  1.8957922449335456
None Run 29:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.00
Split: 10, Run: 03
None time:  0.3544267569668591
None Run 30:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.90
run time now: 2.671539068222046
total time:  16.47622418985702
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.04 ± 6.38
  Final Train: 100.00 ± 0.00
   Final Test: 58.33 ± 6.68
best run test_acc: 61.17000198364258
[I 2023-06-12 00:19:43,324] Trial 11 finished with value: 59.03999710083008 and parameters: {'Fwd': 1.2064872320818512e-06, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 0, 'lambda1': 0.30000000000000004, 'lambda2': 9.50156098626155, 'loop': 0, 'loss': 'CE', 'lr': 0.00031543695273301227, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.659755431166085e-05, 'weightedloss': False}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.00028522764059400345
weight_decay:  1.240018963432093e-06
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0927471320610493
None Run 01:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.00
Split: 01, Run: 02
None time:  1.1581318569369614
None Run 02:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.20
Split: 01, Run: 03
None time:  1.042692042188719
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.00
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.123702490935102
None Run 04:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 58.70
Split: 02, Run: 02
None time:  1.1514683237764984
None Run 05:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 55.40
Split: 02, Run: 03
None time:  1.084182740887627
None Run 06:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 60.60
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.1178314629942179
None Run 07:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 48.70
Split: 03, Run: 02
None time:  1.1199516500346363
None Run 08:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 51.30
Split: 03, Run: 03
None time:  1.1702485361602157
None Run 09:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 55.40
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.0021789169404656
None Run 10:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.50
Split: 04, Run: 02
None time:  1.0454753499943763
None Run 11:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.50
Split: 04, Run: 03
None time:  1.1127722691744566
None Run 12:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.50
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.313789778854698
None Run 13:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 58.80
Split: 05, Run: 02
None time:  1.0522681490983814
None Run 14:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 48.90
Split: 05, Run: 03
None time:  1.2867384580895305
None Run 15:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.70
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1092904759570956
None Run 16:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 48.70
Split: 06, Run: 02
None time:  1.0836027399636805
None Run 17:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 48.70
Split: 06, Run: 03
None time:  1.01038444112055
None Run 18:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 48.70
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1739808518905193
None Run 19:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.80
Split: 07, Run: 02
None time:  1.1445703539066017
None Run 20:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 64.40
Split: 07, Run: 03
None time:  1.134689339902252
None Run 21:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 64.20
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2288851239718497
None Run 22:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.80
Split: 08, Run: 02
None time:  1.3498403967823833
None Run 23:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.00
Split: 08, Run: 03
None time:  0.9600722671020776
None Run 24:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 61.10
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.4989567450247705
None Run 25:
Highest Train: 100.00
Highest Valid: 59.60
  Final Train: 100.00
   Final Test: 53.40
Split: 09, Run: 02
None time:  1.3041837809141725
None Run 26:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.40
Split: 09, Run: 03
None time:  1.170713546918705
None Run 27:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 55.80
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2362601980566978
None Run 28:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 65.50
Split: 10, Run: 02
None time:  1.201437999960035
None Run 29:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 63.00
Split: 10, Run: 03
None time:  1.2419590938370675
None Run 30:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 68.10
run time now: 3.7246057987213135
total time:  35.27230741502717
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.86 ± 6.42
  Final Train: 100.00 ± 0.00
   Final Test: 59.33 ± 6.88
best run test_acc: 62.219993591308594
[I 2023-06-12 00:20:19,173] Trial 12 finished with value: 59.86000061035156 and parameters: {'Fwd': 0.0013360738610452305, 'K': 10, 'alpha': 0.75, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.45, 'lambda2': 9.967818514091059, 'loop': 0, 'loss': 'CE', 'lr': 0.00028522764059400345, 'softmaxF': False, 'useGCN': True, 'weight_decay': 1.240018963432093e-06, 'weightedloss': False}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.4
lr:  0.00029597209885139916
weight_decay:  0.00010634894148251454
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.869457472115755
None Run 01:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 02
None time:  2.071653245948255
None Run 02:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 65.20
Split: 01, Run: 03
None time:  1.9950210130773485
None Run 03:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 59.90
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.0823109259363264
None Run 04:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 51.30
Split: 02, Run: 02
None time:  2.1010874998755753
None Run 05:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 53.40
Split: 02, Run: 03
None time:  2.076128833927214
None Run 06:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 57.80
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.08478254894726
None Run 07:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.10
Split: 03, Run: 02
None time:  2.1068767399992794
None Run 08:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 65.30
Split: 03, Run: 03
None time:  2.0475475220009685
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.30
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.03061861009337
None Run 10:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.50
Split: 04, Run: 02
None time:  1.752900922903791
None Run 11:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 50.90
Split: 04, Run: 03
None time:  2.086407184135169
None Run 12:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 50.90
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.1353146450128406
None Run 13:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 57.70
Split: 05, Run: 02
None time:  2.287249349988997
None Run 14:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 62.00
Split: 05, Run: 03
None time:  2.184126395964995
None Run 15:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 51.60
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.123505482915789
None Run 16:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 45.80
Split: 06, Run: 02
None time:  2.271233075996861
None Run 17:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 50.70
Split: 06, Run: 03
None time:  2.1596046870108694
None Run 18:
Highest Train: 100.00
Highest Valid: 49.60
  Final Train: 100.00
   Final Test: 50.10
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.3171782239805907
None Run 19:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 74.40
Split: 07, Run: 02
None time:  2.6264731490518898
None Run 20:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.40
Split: 07, Run: 03
None time:  2.1999124749563634
None Run 21:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 75.10
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.3088450499344617
None Run 22:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.60
Split: 08, Run: 02
None time:  2.224414305994287
None Run 23:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 68.20
Split: 08, Run: 03
None time:  2.192398300860077
None Run 24:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.20
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.243233140092343
None Run 25:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 71.50
Split: 09, Run: 02
None time:  2.0797345768660307
None Run 26:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 54.90
Split: 09, Run: 03
None time:  2.211307692108676
None Run 27:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 55.80
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.2011246809270233
None Run 28:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 70.10
Split: 10, Run: 02
None time:  2.1826812920626253
None Run 29:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 70.90
Split: 10, Run: 03
None time:  2.2064908070024103
None Run 30:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 69.30
run time now: 6.615203619003296
total time:  65.02802553214133
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.85 ± 8.46
  Final Train: 100.00 ± 0.00
   Final Test: 61.64 ± 8.66
best run test_acc: 65.53999328613281
[I 2023-06-12 00:21:24,618] Trial 13 finished with value: 61.853336334228516 and parameters: {'Fwd': 0.004789742598849993, 'K': 5, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.45, 'lambda2': 7.8487653100630395, 'loop': 0, 'loss': 'CE', 'lr': 0.00029597209885139916, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00010634894148251454, 'weightedloss': False}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.75
lr:  0.0002338405852925894
weight_decay:  7.766565673885561e-05
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.49344529514201
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 02
None time:  2.510884195799008
None Run 02:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 59.90
Split: 01, Run: 03
None time:  2.3785724118351936
None Run 03:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 63.20
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.3659209408797324
None Run 04:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 56.10
Split: 02, Run: 02
None time:  2.19571714499034
None Run 05:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 60.10
Split: 02, Run: 03
None time:  2.366538015892729
None Run 06:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 54.30
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.3982589130755514
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.80
Split: 03, Run: 02
None time:  2.5173227430786937
None Run 08:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.30
Split: 03, Run: 03
None time:  2.4412326540332288
None Run 09:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 61.20
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.369288375135511
None Run 10:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 50.90
Split: 04, Run: 02
None time:  2.289433100959286
None Run 11:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 57.10
Split: 04, Run: 03
None time:  2.378357281908393
None Run 12:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 50.90
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.4637650558725
None Run 13:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 56.30
Split: 05, Run: 02
None time:  2.4943679629359394
None Run 14:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 53.00
Split: 05, Run: 03
None time:  2.411357522942126
None Run 15:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 51.20
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.3302108959760517
None Run 16:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 49.50
Split: 06, Run: 02
None time:  2.422977785114199
None Run 17:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 49.10
Split: 06, Run: 03
None time:  2.125207528937608
None Run 18:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 48.80
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.4785169379319996
None Run 19:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.60
Split: 07, Run: 02
None time:  2.471455284859985
None Run 20:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.20
Split: 07, Run: 03
None time:  2.384912764886394
None Run 21:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 73.00
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.414707514923066
None Run 22:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.40
Split: 08, Run: 02
None time:  2.5362471018452197
None Run 23:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 74.20
Split: 08, Run: 03
None time:  2.271154582966119
None Run 24:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.90
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.18237059796229
None Run 25:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 56.40
Split: 09, Run: 02
None time:  2.6923677250742912
None Run 26:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.80
Split: 09, Run: 03
None time:  2.3493526419624686
None Run 27:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.10
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.6309366300702095
None Run 28:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.50
Split: 10, Run: 02
None time:  2.564826416084543
None Run 29:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.90
Split: 10, Run: 03
None time:  2.787676762090996
None Run 30:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 8.014296531677246
total time:  73.25825305003673
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.53 ± 8.74
  Final Train: 100.00 ± 0.00
   Final Test: 61.69 ± 8.76
best run test_acc: 64.62001037597656
[I 2023-06-12 00:22:38,334] Trial 14 finished with value: 61.526668548583984 and parameters: {'Fwd': 0.00914070964663714, 'K': 5, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.15000000000000002, 'lambda2': 7.176598598435666, 'loop': 1, 'loss': 'CE', 'lr': 0.0002338405852925894, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.766565673885561e-05, 'weightedloss': True}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.4
lr:  0.0001947196296297048
weight_decay:  1.4850564278185149e-05
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.218903189059347
None Run 01:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 56.50
Split: 01, Run: 02
None time:  4.439841153100133
None Run 02:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 63.90
Split: 01, Run: 03
None time:  2.2079131191130728
None Run 03:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 55.70
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.272146839881316
None Run 04:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 51.70
Split: 02, Run: 02
None time:  2.185596306109801
None Run 05:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 48.80
Split: 02, Run: 03
None time:  2.2267803761642426
None Run 06:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 48.80
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.203117073047906
None Run 07:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 41.30
Split: 03, Run: 02
None time:  2.1828324089292437
None Run 08:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 41.30
Split: 03, Run: 03
None time:  2.246492911828682
None Run 09:
Highest Train: 100.00
Highest Valid: 45.40
  Final Train: 100.00
   Final Test: 41.30
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.1820872030220926
None Run 10:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 46.90
Split: 04, Run: 02
None time:  3.9583768059965223
None Run 11:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 54.70
Split: 04, Run: 03
None time:  2.238245730055496
None Run 12:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 46.90
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.5192593259271234
None Run 13:
Highest Train: 100.00
Highest Valid: 49.80
  Final Train: 100.00
   Final Test: 48.20
Split: 05, Run: 02
None time:  2.907153516076505
None Run 14:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 54.90
Split: 05, Run: 03
None time:  2.9108805460855365
None Run 15:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 51.30
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.6661630210001022
None Run 16:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 42.80
Split: 06, Run: 02
None time:  2.0677820660639554
None Run 17:
Highest Train: 100.00
Highest Valid: 47.00
  Final Train: 100.00
   Final Test: 42.80
Split: 06, Run: 03
None time:  3.290580424014479
None Run 18:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 45.50
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.06195718399249
None Run 19:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 52.00
Split: 07, Run: 02
None time:  2.003218072000891
None Run 20:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 52.00
Split: 07, Run: 03
None time:  2.108123065903783
None Run 21:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 52.00
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  4.24798004492186
None Run 22:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 57.40
Split: 08, Run: 02
None time:  2.1143388729542494
None Run 23:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 50.60
Split: 08, Run: 03
None time:  3.894389786059037
None Run 24:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 56.40
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.155522702028975
None Run 25:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 44.20
Split: 09, Run: 02
None time:  3.149033877067268
None Run 26:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.60
Split: 09, Run: 03
None time:  2.059072880074382
None Run 27:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 44.20
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.049451531842351
None Run 28:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 53.40
Split: 10, Run: 02
None time:  2.110358451027423
None Run 29:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 53.40
Split: 10, Run: 03
None time:  2.0608800968620926
None Run 30:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 53.40
run time now: 6.248468399047852
total time:  76.48853759211488
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.64 ± 5.77
  Final Train: 100.00 ± 0.00
   Final Test: 50.50 ± 6.04
best run test_acc: 53.7400016784668
[I 2023-06-12 00:23:55,332] Trial 15 finished with value: 51.6400032043457 and parameters: {'Fwd': 0.09582440998650442, 'K': 4, 'alpha': 0.4, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 5.45448816790277, 'loop': 1, 'loss': 'MSE', 'lr': 0.0001947196296297048, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4850564278185149e-05, 'weightedloss': False}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.4
lr:  0.0004232408065561201
weight_decay:  0.0001266400635522162
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6429941710084677
None Run 01:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.50
Split: 01, Run: 02
None time:  1.4641772161703557
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.60
Split: 01, Run: 03
None time:  1.4046699828468263
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.30
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.394422291079536
None Run 04:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 51.80
Split: 02, Run: 02
None time:  1.4065485338214785
None Run 05:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 57.20
Split: 02, Run: 03
None time:  1.4523559620138258
None Run 06:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 55.00
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3270865220110863
None Run 07:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.70
Split: 03, Run: 02
None time:  1.374729722039774
None Run 08:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.20
Split: 03, Run: 03
None time:  1.5283607579767704
None Run 09:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.00
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.4160801190882921
None Run 10:
Highest Train: 100.00
Highest Valid: 32.40
  Final Train: 100.00
   Final Test: 29.10
Split: 04, Run: 02
None time:  1.6298030659090728
None Run 11:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 55.30
Split: 04, Run: 03
None time:  1.43860793299973
None Run 12:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 31.00
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2706952160224319
None Run 13:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 56.60
Split: 05, Run: 02
None time:  1.3888994068838656
None Run 14:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 56.70
Split: 05, Run: 03
None time:  1.4797804760746658
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 60.50
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.502551242010668
None Run 16:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 53.80
Split: 06, Run: 02
None time:  1.4990984180476516
None Run 17:
Highest Train: 100.00
Highest Valid: 35.00
  Final Train: 100.00
   Final Test: 30.90
Split: 06, Run: 03
None time:  1.5087373631540686
None Run 18:
Highest Train: 100.00
Highest Valid: 34.00
  Final Train: 100.00
   Final Test: 30.60
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.62668217997998
None Run 19:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 70.00
Split: 07, Run: 02
None time:  1.770864729071036
None Run 20:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.80
Split: 07, Run: 03
None time:  1.7158879288472235
None Run 21:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.00
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.6253275540657341
None Run 22:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 70.80
Split: 08, Run: 02
None time:  1.7996062571182847
None Run 23:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.90
Split: 08, Run: 03
None time:  1.409645376028493
None Run 24:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 62.00
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7132325598504394
None Run 25:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 56.90
Split: 09, Run: 02
None time:  2.2209188889246434
None Run 26:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.80
Split: 09, Run: 03
None time:  1.412059319904074
None Run 27:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 57.70
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.632672952953726
None Run 28:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 66.80
Split: 10, Run: 02
None time:  1.589581694919616
None Run 29:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 64.30
Split: 10, Run: 03
None time:  1.62686048890464
None Run 30:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 67.50
run time now: 4.872215986251831
total time:  46.7803056249395
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.57 ± 11.79
  Final Train: 100.00 ± 0.00
   Final Test: 58.51 ± 12.67
best run test_acc: 64.44999694824219
[I 2023-06-12 00:24:42,565] Trial 16 finished with value: 59.57333755493164 and parameters: {'Fwd': 0.003909546376541858, 'K': 1, 'alpha': 0.4, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 8.510912710684405, 'loop': 0, 'loss': 'CE', 'lr': 0.0004232408065561201, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0001266400635522162, 'weightedloss': True}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.00015619264930867848
weight_decay:  1.069130317327891e-05
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.131024835864082
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.50
Split: 01, Run: 02
None time:  2.0702031969558448
None Run 02:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 62.50
Split: 01, Run: 03
None time:  2.132573777809739
None Run 03:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 62.50
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.1365896840579808
None Run 04:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.90
Split: 02, Run: 02
None time:  2.0510682621970773
None Run 05:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 58.10
Split: 02, Run: 03
None time:  2.099941383814439
None Run 06:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 54.10
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.1471034821588546
None Run 07:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 58.90
Split: 03, Run: 02
None time:  2.213234568014741
None Run 08:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 57.70
Split: 03, Run: 03
None time:  2.1437516170553863
None Run 09:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 60.10
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.2544509251601994
None Run 10:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 57.60
Split: 04, Run: 02
None time:  2.103407469112426
None Run 11:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 55.10
Split: 04, Run: 03
None time:  1.9993725419044495
None Run 12:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 55.10
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.1702629211358726
None Run 13:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 57.20
Split: 05, Run: 02
None time:  2.3100770169403404
None Run 14:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 60.30
Split: 05, Run: 03
None time:  1.8361272991169244
None Run 15:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 56.30
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.7689040089026093
None Run 16:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 49.20
Split: 06, Run: 02
None time:  2.0113084681797773
None Run 17:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 47.30
Split: 06, Run: 03
None time:  1.994982574135065
None Run 18:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.60
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.1559591910336167
None Run 19:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.70
Split: 07, Run: 02
None time:  2.262461867183447
None Run 20:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 70.20
Split: 07, Run: 03
None time:  2.0956519541796297
None Run 21:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 74.50
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.8252512980252504
None Run 22:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 57.60
Split: 08, Run: 02
None time:  2.3406428969465196
None Run 23:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 73.10
Split: 08, Run: 03
None time:  2.062533900141716
None Run 24:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.00
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.9325149930082262
None Run 25:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 60.80
Split: 09, Run: 02
None time:  2.039024349069223
None Run 26:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 56.40
Split: 09, Run: 03
None time:  1.9842799669131637
None Run 27:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 57.80
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.006072132848203
None Run 28:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 67.60
Split: 10, Run: 02
None time:  1.9931285011116415
None Run 29:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 66.40
Split: 10, Run: 03
None time:  1.9259945040103048
None Run 30:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 67.80
run time now: 5.9501426219940186
total time:  63.00568691221997
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.07 ± 7.02
  Final Train: 100.00 ± 0.00
   Final Test: 60.76 ± 7.05
best run test_acc: 62.91999435424805
[I 2023-06-12 00:25:46,018] Trial 17 finished with value: 61.07333755493164 and parameters: {'Fwd': 0.0006570791603236789, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 100, 'lambda1': 0.7000000000000001, 'lambda2': 7.057932242022977, 'loop': 1, 'loss': 'CE', 'lr': 0.00015619264930867848, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.069130317327891e-05, 'weightedloss': False}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.8500000000000001
lr:  0.0003696109893654433
weight_decay:  0.00028102434704980534
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.80% Test: 64.60%
Split: 01, Run: 01
None time:  3.4530089697800577
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.40
Split: 01, Run: 02
None time:  2.042460057185963
None Run 02:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 03
None time:  2.033885403070599
None Run 03:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 63.70
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.0365092831198126
None Run 04:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 55.60
Split: 02, Run: 02
None time:  1.8698155260644853
None Run 05:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 56.90
Split: 02, Run: 03
None time:  2.2163809358607978
None Run 06:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 63.30
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.1109012758824974
None Run 07:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.20
Split: 03, Run: 02
None time:  1.9849905578885227
None Run 08:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 59.20
Split: 03, Run: 03
None time:  2.0544707390945405
None Run 09:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 61.50
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.60% Test: 62.20%
Split: 04, Run: 01
None time:  3.395760213956237
None Run 10:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.00
Split: 04, Run: 02
None time:  2.022672154009342
None Run 11:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 47.20
Split: 04, Run: 03
None time:  2.0289863850921392
None Run 12:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 49.60
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.00% Test: 57.00%
Split: 05, Run: 01
None time:  3.220183700090274
None Run 13:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 56.90
Split: 05, Run: 02
None time:  2.0293230020906776
None Run 14:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.90
Split: 05, Run: 03
None time:  1.9930526791140437
None Run 15:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 51.10
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.9810734370257705
None Run 16:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 47.30
Split: 06, Run: 02
None time:  2.0155409791041166
None Run 17:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 50.70
Split: 06, Run: 03
None time:  1.894724200014025
None Run 18:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 55.90
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 75.20% Test: 74.40%
Split: 07, Run: 01
None time:  3.308551070978865
None Run 19:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 74.20
Split: 07, Run: 02
None time:  1.9542292768601328
None Run 20:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 72.90
Split: 07, Run: 03
None time:  2.0966435798909515
None Run 21:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.60
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 72.20%
Split: 08, Run: 01
None time:  3.246891875984147
None Run 22:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 72.00
Split: 08, Run: 02
None time:  2.170501631917432
None Run 23:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.70
Split: 08, Run: 03
None time:  2.0096733721438795
None Run 24:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.20
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.9973433611448854
None Run 25:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 68.70
Split: 09, Run: 02
None time:  2.054611895000562
None Run 26:
Highest Train: 100.00
Highest Valid: 58.40
  Final Train: 100.00
   Final Test: 53.20
Split: 09, Run: 03
None time:  1.9861744451336563
None Run 27:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 54.70
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.0284543589223176
None Run 28:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 70.10
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.60% Test: 69.30%
Split: 10, Run: 02
None time:  3.2960120469797403
None Run 29:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 69.50
Split: 10, Run: 03
None time:  2.0340582290664315
None Run 30:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 67.00
run time now: 7.38482141494751
total time:  69.06702718115412
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.61 ± 7.39
  Final Train: 100.00 ± 0.00
   Final Test: 61.24 ± 7.89
best run test_acc: 65.72999572753906
[I 2023-06-12 00:26:55,644] Trial 18 finished with value: 61.60667037963867 and parameters: {'Fwd': 0.0036752509943805025, 'K': 4, 'alpha': 0.8500000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 120, 'lambda1': 0.15000000000000002, 'lambda2': 5.080656790657571, 'loop': 0, 'loss': 'MSE', 'lr': 0.0003696109893654433, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00028102434704980534, 'weightedloss': True}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.4
lr:  0.0002089541567876914
weight_decay:  3.7763821462554355e-05
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6734742620028555
None Run 01:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 64.40
Split: 01, Run: 02
None time:  1.7755384759511799
None Run 02:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 68.80
Split: 01, Run: 03
None time:  1.6178158570546657
None Run 03:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 61.70
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.701421206817031
None Run 04:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 55.40
Split: 02, Run: 02
None time:  1.6669756739865988
None Run 05:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 56.30
Split: 02, Run: 03
None time:  1.643762013874948
None Run 06:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 56.70
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.725609086919576
None Run 07:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 48.50
Split: 03, Run: 02
None time:  1.5902785698417574
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 63.10
Split: 03, Run: 03
None time:  1.6587690392043442
None Run 09:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 52.60
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6598675961140543
None Run 10:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 54.00
Split: 04, Run: 02
None time:  1.6889107190072536
None Run 11:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 55.10
Split: 04, Run: 03
None time:  1.697869093855843
None Run 12:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 54.30
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.1809745468199253
None Run 13:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.00
Split: 05, Run: 02
None time:  1.4496386679820716
None Run 14:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 51.20
Split: 05, Run: 03
None time:  1.9806275989394635
None Run 15:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 59.90
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.717848262982443
None Run 16:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 48.30
Split: 06, Run: 02
None time:  1.7345686368644238
None Run 17:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 48.80
Split: 06, Run: 03
None time:  1.7472400779370219
None Run 18:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 48.70
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.0271270980592817
None Run 19:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 72.90
Split: 07, Run: 02
None time:  1.7073117170948535
None Run 20:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 61.80
Split: 07, Run: 03
None time:  1.7913093091920018
None Run 21:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.30
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.7570194799918681
None Run 22:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 58.60
Split: 08, Run: 02
None time:  1.8918424651492387
None Run 23:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 66.10
Split: 08, Run: 03
None time:  1.9019655610900372
None Run 24:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.90
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.730598381953314
None Run 25:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.30
Split: 09, Run: 02
None time:  1.9276225129142404
None Run 26:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 61.80
Split: 09, Run: 03
None time:  1.8216501229908317
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.00
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.775941271102056
None Run 28:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 68.20
Split: 10, Run: 02
None time:  1.8998776539228857
None Run 29:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 66.50
Split: 10, Run: 03
None time:  1.711404955945909
None Run 30:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 63.70
run time now: 5.410677909851074
total time:  53.3321998200845
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 59.57 ± 7.07
  Final Train: 100.00 ± 0.00
   Final Test: 59.76 ± 7.07
best run test_acc: 63.54999923706055
[I 2023-06-12 00:27:49,487] Trial 19 finished with value: 59.56666564941406 and parameters: {'Fwd': 0.0003769447220541554, 'K': 6, 'alpha': 0.4, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 8.234391811425528, 'loop': 2, 'loss': 'CE', 'lr': 0.0002089541567876914, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.7763821462554355e-05, 'weightedloss': False}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.9
lr:  0.00040123236009552036
weight_decay:  3.899499327816397e-06
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.949885271023959
None Run 01:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 65.60
Split: 01, Run: 02
None time:  1.8840708371717483
None Run 02:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 56.10
Split: 01, Run: 03
None time:  1.8813899168744683
None Run 03:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 62.50
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.906725225970149
None Run 04:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 56.80
Split: 02, Run: 02
None time:  1.9581670258194208
None Run 05:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 59.90
Split: 02, Run: 03
None time:  1.9613367051351815
None Run 06:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 56.70
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.9490303760394454
None Run 07:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 64.10
Split: 03, Run: 02
None time:  1.9813992120325565
None Run 08:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.10
Split: 03, Run: 03
None time:  1.8606922198086977
None Run 09:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 66.00
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.552450638031587
None Run 10:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 47.20
Split: 04, Run: 02
None time:  1.9073533080518246
None Run 11:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 47.20
Split: 04, Run: 03
None time:  1.8627343699336052
None Run 12:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.70
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.9661791501566768
None Run 13:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 62.30
Split: 05, Run: 02
None time:  1.9856150741688907
None Run 14:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 54.60
Split: 05, Run: 03
None time:  1.8256294329185039
None Run 15:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.20
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.8268916618544608
None Run 16:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 43.00
Split: 06, Run: 02
None time:  1.9353913839440793
None Run 17:
Highest Train: 100.00
Highest Valid: 47.20
  Final Train: 100.00
   Final Test: 46.30
Split: 06, Run: 03
None time:  1.9330798860173672
None Run 18:
Highest Train: 100.00
Highest Valid: 47.60
  Final Train: 100.00
   Final Test: 46.00
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.017574405996129
None Run 19:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 72.20
Split: 07, Run: 02
None time:  2.1015330981463194
None Run 20:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.50
Split: 07, Run: 03
None time:  2.028289410052821
None Run 21:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.30
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.8999500889331102
None Run 22:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.00
Split: 08, Run: 02
None time:  1.9471404820214957
None Run 23:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.60
Split: 08, Run: 03
None time:  1.8206940840464085
None Run 24:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 66.50
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.9707391660194844
None Run 25:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.80
Split: 09, Run: 02
None time:  2.025811303872615
None Run 26:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 67.40
Split: 09, Run: 03
None time:  1.9169905330054462
None Run 27:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 63.40
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.8362560991663486
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 72.20
Split: 10, Run: 02
None time:  1.8983119600452483
None Run 29:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 64.60
Split: 10, Run: 03
None time:  2.0500560340005904
None Run 30:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.30
run time now: 5.811383247375488
total time:  58.15719596808776
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 61.02 ± 7.99
  Final Train: 100.00 ± 0.00
   Final Test: 61.10 ± 8.57
best run test_acc: 64.22999572753906
[I 2023-06-12 00:28:48,199] Trial 20 finished with value: 61.02000045776367 and parameters: {'Fwd': 0.009604979673708887, 'K': 4, 'alpha': 0.9, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.6000000000000001, 'lambda2': 6.063897764201679, 'loop': 1, 'loss': 'CE', 'lr': 0.00040123236009552036, 'softmaxF': False, 'useGCN': True, 'weight_decay': 3.899499327816397e-06, 'weightedloss': False}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.8500000000000001
lr:  0.0003346608864135461
weight_decay:  0.00021442911423427
dropout:  0.30000000000000004
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.80% Test: 63.50%
Split: 01, Run: 01
None time:  3.3519372190348804
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.40
Split: 01, Run: 02
None time:  2.1044147391803563
None Run 02:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.10
Split: 01, Run: 03
None time:  2.0484767199959606
None Run 03:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 63.20
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.079528255853802
None Run 04:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 54.40
Split: 02, Run: 02
None time:  1.9956985008902848
None Run 05:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 55.20
Split: 02, Run: 03
None time:  1.941643769852817
None Run 06:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 60.40
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.017321154009551
None Run 07:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 61.90
Split: 03, Run: 02
None time:  1.9454101098235697
None Run 08:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 55.40
Split: 03, Run: 03
None time:  1.9250829999800771
None Run 09:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.50
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 59.80% Test: 60.50%
Split: 04, Run: 01
None time:  3.3534526429139078
None Run 10:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 60.80
Split: 04, Run: 02
None time:  2.0046461429446936
None Run 11:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 47.20
Split: 04, Run: 03
None time:  1.8140989190433174
None Run 12:
Highest Train: 100.00
Highest Valid: 48.40
  Final Train: 100.00
   Final Test: 47.20
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 58.20% Test: 56.30%
Split: 05, Run: 01
None time:  3.42239389102906
None Run 13:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 55.70
Split: 05, Run: 02
None time:  2.0396550688892603
None Run 14:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 60.00
Split: 05, Run: 03
None time:  2.0685824188403785
None Run 15:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 50.00
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.0623055901378393
None Run 16:
Highest Train: 100.00
Highest Valid: 46.80
  Final Train: 100.00
   Final Test: 42.90
Split: 06, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.40% Test: 50.40%
Split: 06, Run: 02
None time:  3.385787851177156
None Run 17:
Highest Train: 100.00
Highest Valid: 51.40
  Final Train: 100.00
   Final Test: 50.60
Split: 06, Run: 03
None time:  2.0070294849574566
None Run 18:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 54.70
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.192994269076735
None Run 19:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 73.90
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.60% Test: 72.50%
Split: 07, Run: 02
None time:  3.456802299944684
None Run 20:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.40
Split: 07, Run: 03
None time:  2.1251913669984788
None Run 21:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 72.70
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.00% Test: 71.30%
Split: 08, Run: 01
None time:  3.468631989089772
None Run 22:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 71.20
Split: 08, Run: 02
None time:  2.175666148774326
None Run 23:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 62.50
Split: 08, Run: 03
None time:  2.072397264186293
None Run 24:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.70
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 67.90%
Split: 09, Run: 01
None time:  3.3276419141329825
None Run 25:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.60
Split: 09, Run: 02
None time:  2.1850895271636546
None Run 26:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 51.50
Split: 09, Run: 03
None time:  2.1289176968857646
None Run 27:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 54.10
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.9411879959516227
None Run 28:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 68.60
Split: 10, Run: 02
None time:  2.264913670020178
None Run 29:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 67.20
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 62.80% Test: 66.10%
Split: 10, Run: 03
None time:  3.6712843999266624
None Run 30:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 66.20
run time now: 7.905501127243042
total time:  73.29334465391003
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.55 ± 7.62
  Final Train: 100.00 ± 0.00
   Final Test: 59.91 ± 8.23
best run test_acc: 64.52000427246094
[I 2023-06-12 00:30:01,921] Trial 21 finished with value: 60.54666519165039 and parameters: {'Fwd': 0.004481645713144215, 'K': 4, 'alpha': 0.8500000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 120, 'lambda1': 0.15000000000000002, 'lambda2': 5.069604617791399, 'loop': 0, 'loss': 'MSE', 'lr': 0.0003346608864135461, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021442911423427, 'weightedloss': True}. Best is trial 6 with value: 62.81333541870117.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.0004690430933483842
weight_decay:  2.1446251064043464e-05
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 66.90%
Split: 01, Run: 01
None time:  3.183710268000141
None Run 01:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.00
Split: 01, Run: 02
None time:  1.9942593278829008
None Run 02:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 70.40
Split: 01, Run: 03
None time:  1.8365468902047724
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.80
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.9104656330309808
None Run 04:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 60.60
Split: 02, Run: 02
None time:  1.993533788016066
None Run 05:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 59.50
Split: 02, Run: 03
None time:  1.9692036798223853
None Run 06:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 56.80
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.0397469999734312
None Run 07:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 64.60
Split: 03, Run: 02
None time:  1.9873444768600166
None Run 08:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 59.60
Split: 03, Run: 03
None time:  2.0968902779277414
None Run 09:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.70
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.15822437312454
None Run 10:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 47.50
Split: 04, Run: 02
None time:  2.0757394309621304
None Run 11:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 64.70
Split: 04, Run: 03
None time:  1.9925094968639314
None Run 12:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 56.00
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.993164764950052
None Run 13:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 57.00
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.40% Test: 62.20%
Split: 05, Run: 02
None time:  3.180628244066611
None Run 14:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 62.20
Split: 05, Run: 03
None time:  2.0147281819954515
None Run 15:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 58.30
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 59.20% Test: 59.30%
Split: 06, Run: 01
None time:  3.1736974348314106
None Run 16:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 58.90
Split: 06, Run: 02
None time:  1.954690014012158
None Run 17:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 51.80
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.00% Test: 51.70%
Split: 06, Run: 03
None time:  3.192341457819566
None Run 18:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 51.70
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.0161313998978585
None Run 19:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.80
Split: 07, Run: 02
None time:  2.095306323841214
None Run 20:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 71.90
Split: 07, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 73.00%
Split: 07, Run: 03
None time:  3.2502443089615554
None Run 21:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.60
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.60% Test: 70.70%
Split: 08, Run: 01
None time:  3.1838975169230253
None Run 22:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 70.50
Split: 08, Run: 02
None time:  2.0493102720938623
None Run 23:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.00
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.60% Test: 68.50%
Split: 08, Run: 03
None time:  3.2430837880820036
None Run 24:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.40
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.949807136086747
None Run 25:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 58.20
Split: 09, Run: 02
None time:  2.3174148639664054
None Run 26:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.70
Split: 09, Run: 03
None time:  2.00240068603307
None Run 27:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 57.10
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.0215133170131594
None Run 28:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 70.40
Split: 10, Run: 02
None time:  2.0214288381394
None Run 29:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 71.60
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.40% Test: 72.60%
Split: 10, Run: 03
None time:  2.769914329983294
None Run 30:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 72.60
run time now: 6.863886833190918
total time:  70.18966895784251
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.65 ± 6.60
  Final Train: 100.00 ± 0.00
   Final Test: 63.20 ± 7.02
best run test_acc: 66.19000244140625
[I 2023-06-12 00:31:12,631] Trial 22 finished with value: 63.64666748046875 and parameters: {'Fwd': 0.002291445486468613, 'K': 2, 'alpha': 0.9, 'dropout': 0.2, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 4.616791977007978, 'loop': 0, 'loss': 'MSE', 'lr': 0.0004690430933483842, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.1446251064043464e-05, 'weightedloss': True}. Best is trial 22 with value: 63.64666748046875.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.5
lr:  0.00015266954492127805
weight_decay:  2.0620134454810725e-05
dropout:  0.2
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8055346980690956
None Run 01:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 57.90
Split: 01, Run: 02
None time:  1.666204827837646
None Run 02:
Highest Train: 100.00
Highest Valid: 48.20
  Final Train: 100.00
   Final Test: 45.10
Split: 01, Run: 03
None time:  1.7281459278892726
None Run 03:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 51.10
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.6751627211924642
None Run 04:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 58.20
Split: 02, Run: 02
None time:  1.762020916910842
None Run 05:
Highest Train: 100.00
Highest Valid: 37.60
  Final Train: 100.00
   Final Test: 37.80
Split: 02, Run: 03
None time:  1.712018916849047
None Run 06:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 39.40
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 37.40% Test: 33.80%
Split: 03, Run: 01
None time:  2.705078528029844
None Run 07:
Highest Train: 100.00
Highest Valid: 37.40
  Final Train: 100.00
   Final Test: 34.10
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.20% Test: 50.20%
Split: 03, Run: 02
None time:  2.895910490071401
None Run 08:
Highest Train: 100.00
Highest Valid: 50.20
  Final Train: 100.00
   Final Test: 50.20
Split: 03, Run: 03
None time:  1.7737503130920231
None Run 09:
Highest Train: 100.00
Highest Valid: 42.60
  Final Train: 100.00
   Final Test: 39.30
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.40% Test: 58.30%
Split: 04, Run: 01
None time:  2.9127417819108814
None Run 10:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 58.20
Split: 04, Run: 02
None time:  1.7220724278595299
None Run 11:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 35.30
Split: 04, Run: 03
None time:  1.7332105848472565
None Run 12:
Highest Train: 100.00
Highest Valid: 33.60
  Final Train: 100.00
   Final Test: 31.70
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7865714218933135
None Run 13:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 37.30
Split: 05, Run: 02
None time:  1.7484799791127443
None Run 14:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 33.00
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 51.60% Test: 49.70%
Split: 05, Run: 03
None time:  2.800960548920557
None Run 15:
Highest Train: 100.00
Highest Valid: 51.60
  Final Train: 100.00
   Final Test: 49.50
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 45.80% Test: 43.50%
Split: 06, Run: 01
None time:  2.800167421810329
None Run 16:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 43.60
Split: 06, Run: 02
None time:  1.7302213299553841
None Run 17:
Highest Train: 100.00
Highest Valid: 38.20
  Final Train: 100.00
   Final Test: 33.00
Split: 06, Run: 03
None time:  1.801030474016443
None Run 18:
Highest Train: 100.00
Highest Valid: 38.00
  Final Train: 100.00
   Final Test: 38.20
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7421105678658932
None Run 19:
Highest Train: 100.00
Highest Valid: 34.60
  Final Train: 100.00
   Final Test: 39.60
Split: 07, Run: 02
None time:  1.7271241338457912
None Run 20:
Highest Train: 100.00
Highest Valid: 36.00
  Final Train: 100.00
   Final Test: 38.40
Split: 07, Run: 03
None time:  1.7259075460024178
None Run 21:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 58.10
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.6661295839585364
None Run 22:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 38.10
Split: 08, Run: 02
None time:  1.9158575900364667
None Run 23:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 39.80
Split: 08, Run: 03
None time:  1.839711861917749
None Run 24:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 47.60
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.40% Test: 45.40%
Split: 09, Run: 01
None time:  3.042260166956112
None Run 25:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 45.30
Split: 09, Run: 02
None time:  1.890229474985972
None Run 26:
Highest Train: 100.00
Highest Valid: 39.60
  Final Train: 100.00
   Final Test: 37.50
Split: 09, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.00% Test: 51.70%
Split: 09, Run: 03
None time:  3.061961314175278
None Run 27:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 51.00
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.822725621983409
None Run 28:
Highest Train: 100.00
Highest Valid: 44.80
  Final Train: 100.00
   Final Test: 47.30
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 50.80% Test: 47.50%
Split: 10, Run: 02
None time:  3.0365149830468
None Run 29:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 48.50
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 44.00% Test: 45.50%
Split: 10, Run: 03
None time:  2.8908022581599653
None Run 30:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 45.70
run time now: 7.7708845138549805
total time:  63.597955252975225
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 45.41 ± 8.32
  Final Train: 100.00 ± 0.00
   Final Test: 43.66 ± 8.06
best run test_acc: 52.279998779296875
[I 2023-06-12 00:32:16,779] Trial 23 finished with value: 45.40666580200195 and parameters: {'Fwd': 0.0022731385649189108, 'K': 2, 'alpha': 0.5, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.25, 'lambda2': 4.208829961742927, 'loop': 0, 'loss': 'MSE', 'lr': 0.00015266954492127805, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.0620134454810725e-05, 'weightedloss': True}. Best is trial 22 with value: 63.64666748046875.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.65
lr:  0.0005293639561953068
weight_decay:  6.120220057895432e-06
dropout:  0.4
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.071533408947289
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 67.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.40% Test: 70.40%
Split: 01, Run: 02
None time:  3.1827141831163317
None Run 02:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.60% Test: 68.00%
Split: 01, Run: 03
None time:  3.1641231139656156
None Run 03:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.80
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.927597657078877
None Run 04:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 60.30
Split: 02, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 56.40% Test: 60.00%
Split: 02, Run: 02
None time:  3.259244543965906
None Run 05:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 59.60
Split: 02, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 55.60% Test: 57.40%
Split: 02, Run: 03
None time:  3.140494767110795
None Run 06:
Highest Train: 100.00
Highest Valid: 55.60
  Final Train: 100.00
   Final Test: 57.90
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.0182225769385695
None Run 07:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.30
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.80% Test: 60.60%
Split: 03, Run: 02
None time:  3.201202689902857
None Run 08:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 60.70
Split: 03, Run: 03
None time:  2.033119783969596
None Run 09:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.50
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 49.20% Test: 48.10%
Split: 04, Run: 01
None time:  3.0937421419657767
None Run 10:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 48.90
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.40% Test: 65.00%
Split: 04, Run: 02
None time:  3.2676504300907254
None Run 11:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 65.00
Split: 04, Run: 03
None time:  2.0224229639861733
None Run 12:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 57.70
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.20% Test: 58.10%
Split: 05, Run: 01
None time:  3.2545453950297087
None Run 13:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 58.00
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.00% Test: 62.70%
Split: 05, Run: 02
None time:  3.1402302018832415
None Run 14:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 62.50
Split: 05, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 61.80% Test: 59.50%
Split: 05, Run: 03
None time:  3.161658929893747
None Run 15:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 59.40
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 58.20% Test: 58.30%
Split: 06, Run: 01
None time:  3.2191806081682444
None Run 16:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 58.20
Split: 06, Run: 02
None time:  1.8111058720387518
None Run 17:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 52.50
Split: 06, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 53.20% Test: 51.50%
Split: 06, Run: 03
None time:  3.2076191999949515
None Run 18:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 51.50
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 72.80% Test: 72.30%
Split: 07, Run: 01
None time:  3.1353066528681666
None Run 19:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.10
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 66.40% Test: 70.80%
Split: 07, Run: 02
None time:  3.132417188026011
None Run 20:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 70.40
Split: 07, Run: 03
None time:  1.8688209219835699
None Run 21:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 73.40
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.80% Test: 71.10%
Split: 08, Run: 01
None time:  3.1743948538787663
None Run 22:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 71.10
Split: 08, Run: 02
None time:  1.945605925982818
None Run 23:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.70
Split: 08, Run: 03
None time:  2.072839790955186
None Run 24:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.40
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.006552712060511
None Run 25:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 58.50
Split: 09, Run: 02
None time:  2.122585206059739
None Run 26:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.50
Split: 09, Run: 03
None time:  2.0353380509186536
None Run 27:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 57.60
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.60% Test: 71.60%
Split: 10, Run: 01
None time:  3.168720599031076
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 71.30
Split: 10, Run: 02
None time:  1.9842484791297466
None Run 29:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 70.50
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 72.40%
Split: 10, Run: 03
None time:  3.1675166650675237
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 72.40
run time now: 8.379015922546387
total time:  80.58028877805918
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 63.88 ± 6.47
  Final Train: 100.00 ± 0.00
   Final Test: 63.58 ± 6.80
best run test_acc: 66.30000305175781
[I 2023-06-12 00:33:37,781] Trial 24 finished with value: 63.87999725341797 and parameters: {'Fwd': 0.0008718244532323895, 'K': 2, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.4, 'lambda2': 7.243661245271314, 'loop': 0, 'loss': 'MSE', 'lr': 0.0005293639561953068, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.120220057895432e-06, 'weightedloss': True}. Best is trial 24 with value: 63.87999725341797.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.9
lr:  0.00047388476136607743
weight_decay:  5.614207524971697e-06
dropout:  0.1
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7671856391243637
None Run 01:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.80
Split: 01, Run: 02
None time:  1.5221533300355077
None Run 02:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 69.80
Split: 01, Run: 03
None time:  1.7742704679258168
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 64.90
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4321431198623031
None Run 04:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 54.20
Split: 02, Run: 02
None time:  1.4805132260080427
None Run 05:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 58.00
Split: 02, Run: 03
None time:  1.5081849419511855
None Run 06:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 55.40
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.6556472179945558
None Run 07:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 45.40
Split: 03, Run: 02
None time:  1.5158107250463217
None Run 08:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 60.10
Split: 03, Run: 03
None time:  2.242090709041804
None Run 09:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.70
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6181348708923906
None Run 10:
Highest Train: 100.00
Highest Valid: 51.00
  Final Train: 100.00
   Final Test: 48.30
Split: 04, Run: 02
None time:  1.837612763978541
None Run 11:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.70
Split: 04, Run: 03
None time:  1.52953085093759
None Run 12:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 47.30
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.20% Test: 60.70%
Split: 05, Run: 01
None time:  2.6903743071015924
None Run 13:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 60.60
Split: 05, Run: 02
None time:  1.3939219489693642
None Run 14:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 51.60
Split: 05, Run: 03
None time:  1.5931341261602938
None Run 15:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 52.60
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5635784920305014
None Run 16:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 51.60
Split: 06, Run: 02
None time:  1.5774351269938052
None Run 17:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 51.20
Split: 06, Run: 03
None time:  1.6572659679222852
None Run 18:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 48.00
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7494623339734972
None Run 19:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.30
Split: 07, Run: 02
None time:  1.5379146200139076
None Run 20:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 66.00
Split: 07, Run: 03
None time:  1.5789663400501013
None Run 21:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.80
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.6244167708791792
None Run 22:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.60
Split: 08, Run: 02
None time:  1.4944741979707032
None Run 23:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 63.60
Split: 08, Run: 03
None time:  1.6135411181021482
None Run 24:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 61.50
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.5540019960608333
None Run 25:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 53.30
Split: 09, Run: 02
None time:  1.6086712481919676
None Run 26:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 66.90
Split: 09, Run: 03
None time:  1.6405853810720146
None Run 27:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 55.40
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.6065114291850477
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 68.60
Split: 10, Run: 02
None time:  1.6773612929973751
None Run 29:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 62.30
Split: 10, Run: 03
None time:  1.6819111269433051
None Run 30:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 66.40
run time now: 4.990686655044556
total time:  50.19161345693283
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 60.41 ± 7.45
  Final Train: 100.00 ± 0.00
   Final Test: 59.43 ± 7.79
best run test_acc: 64.02999877929688
[I 2023-06-12 00:34:28,475] Trial 25 finished with value: 60.413333892822266 and parameters: {'Fwd': 0.0008333308575880984, 'K': 2, 'alpha': 0.9, 'dropout': 0.1, 'gnnepoch': 80, 'lambda1': 0.05, 'lambda2': 6.50242184363402, 'loop': 0, 'loss': 'MSE', 'lr': 0.00047388476136607743, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.614207524971697e-06, 'weightedloss': True}. Best is trial 24 with value: 63.87999725341797.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.65
lr:  0.0007930528370918549
weight_decay:  3.2072942986029863e-06
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0794, Train: 100.00%, Valid: 76.00% Test: 72.10%
Split: 01, Run: 01
None time:  4.806715928949416
None Run 01:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 02
None time:  4.5274141661357135
None Run 02:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0712, Train: 100.00%, Valid: 77.00% Test: 74.00%
Split: 01, Run: 03
None time:  4.803089712047949
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 73.60
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.865668090991676
None Run 04:
Highest Train: 100.00
Highest Valid: 58.20
  Final Train: 100.00
   Final Test: 59.80
Split: 02, Run: 02
None time:  2.1200895269867033
None Run 05:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 63.00
Split: 02, Run: 03
None time:  2.209345324197784
None Run 06:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 58.90
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.7233220669440925
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 67.00
Split: 03, Run: 02
None time:  2.422388156875968
None Run 08:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.20
Split: 03, Run: 03, Epoch: 100, Loss: 0.0894, Train: 100.00%, Valid: 66.00% Test: 66.70%
Split: 03, Run: 03
None time:  4.805644582025707
None Run 09:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 66.60
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.8295665939804167
None Run 10:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 70.00
Split: 04, Run: 02
None time:  4.148377711884677
None Run 11:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.10
Split: 04, Run: 03, Epoch: 100, Loss: 0.1071, Train: 100.00%, Valid: 66.60% Test: 67.30%
Split: 04, Run: 03
None time:  4.844670517137274
None Run 12:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 67.50
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.2031493987888098
None Run 13:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 62.50
Split: 05, Run: 02
None time:  3.7504053260199726
None Run 14:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.00
Split: 05, Run: 03
None time:  4.318123205099255
None Run 15:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 63.40
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  3.55883764103055
None Run 16:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 54.40
Split: 06, Run: 02, Epoch: 100, Loss: 0.1235, Train: 100.00%, Valid: 57.20% Test: 56.80%
Split: 06, Run: 02
None time:  4.809123883955181
None Run 17:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 56.80
Split: 06, Run: 03, Epoch: 100, Loss: 0.1110, Train: 100.00%, Valid: 57.20% Test: 57.60%
Split: 06, Run: 03
None time:  4.707645463990048
None Run 18:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 57.50
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.6839002210181206
None Run 19:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.20
Split: 07, Run: 02
None time:  2.6143153868615627
None Run 20:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 71.70
Split: 07, Run: 03
None time:  3.85421631205827
None Run 21:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 73.40
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0976, Train: 100.00%, Valid: 75.40% Test: 77.70%
Split: 08, Run: 01
None time:  4.770667250035331
None Run 22:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 77.80
Split: 08, Run: 02
None time:  3.618811094900593
None Run 23:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.80
Split: 08, Run: 03
None time:  4.122006623074412
None Run 24:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 74.10
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  4.393071555066854
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.00
Split: 09, Run: 02
None time:  2.177287171827629
None Run 26:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 61.20
Split: 09, Run: 03
None time:  2.521823071176186
None Run 27:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 62.40
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.661440775031224
None Run 28:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 71.20
Split: 10, Run: 02
None time:  3.113704324932769
None Run 29:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 71.90
Split: 10, Run: 03
None time:  2.367135608801618
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 72.80
run time now: 8.168600797653198
total time:  106.83509684586897
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.25 ± 6.18
  Final Train: 100.00 ± 0.00
   Final Test: 67.01 ± 6.13
best run test_acc: 68.66999816894531
[I 2023-06-12 00:36:15,756] Trial 26 finished with value: 67.24667358398438 and parameters: {'Fwd': 0.00028832451196043267, 'K': 1, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 5.704197537083779, 'loop': 1, 'loss': 'MSE', 'lr': 0.0007930528370918549, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.2072942986029863e-06, 'weightedloss': True}. Best is trial 26 with value: 67.24667358398438.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.65
lr:  0.0007871646296875606
weight_decay:  2.6357943631432915e-06
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 70.20%
Split: 01, Run: 01
None time:  2.7977318030316383
None Run 01:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 70.30
Split: 01, Run: 02
None time:  2.1456481621135026
None Run 02:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 72.30
Split: 01, Run: 03
None time:  2.0618434648495167
None Run 03:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.20
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.930162878939882
None Run 04:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 62.20
Split: 02, Run: 02
None time:  2.030390150845051
None Run 05:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 61.00
Split: 02, Run: 03
None time:  2.0022212280891836
None Run 06:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.90
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 65.00% Test: 66.10%
Split: 03, Run: 01
None time:  2.970797932939604
None Run 07:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 66.10
Split: 03, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.20% Test: 65.30%
Split: 03, Run: 02
None time:  3.0307003650814295
None Run 08:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 65.20
Split: 03, Run: 03
None time:  1.941212048055604
None Run 09:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.30
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 60.80% Test: 57.80%
Split: 04, Run: 01
None time:  3.0176856089383364
None Run 10:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 57.80
Split: 04, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.80% Test: 68.00%
Split: 04, Run: 02
None time:  3.042174454079941
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.00
Split: 04, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 64.60% Test: 64.10%
Split: 04, Run: 03
None time:  3.047214330174029
None Run 12:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.90
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.0049604380037636
None Run 13:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 60.50
Split: 05, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.40% Test: 64.00%
Split: 05, Run: 02
None time:  3.038498785113916
None Run 14:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.00
Split: 05, Run: 03
None time:  1.8671317382249981
None Run 15:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 61.00
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 57.00% Test: 57.40%
Split: 06, Run: 01
None time:  2.8100108350627124
None Run 16:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 57.60
Split: 06, Run: 02
None time:  2.010394230019301
None Run 17:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 56.20
Split: 06, Run: 03
None time:  1.9623201028443873
None Run 18:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 52.40
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.80% Test: 72.50%
Split: 07, Run: 01
None time:  2.9717340900097042
None Run 19:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 72.50
Split: 07, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.40% Test: 73.60%
Split: 07, Run: 02
None time:  2.9619863932020962
None Run 20:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 73.60
Split: 07, Run: 03
None time:  2.1521325008943677
None Run 21:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 73.60
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.40% Test: 73.00%
Split: 08, Run: 01
None time:  2.940784677164629
None Run 22:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.10
Split: 08, Run: 02
None time:  2.036375285126269
None Run 23:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.40
Split: 08, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.00% Test: 71.40%
Split: 08, Run: 03
None time:  3.0268398539628834
None Run 24:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.30
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.9647085249889642
None Run 25:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 58.20
Split: 09, Run: 02
None time:  2.0189935250673443
None Run 26:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.60
Split: 09, Run: 03
None time:  1.896549052093178
None Run 27:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 58.60
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 67.20% Test: 71.80%
Split: 10, Run: 01
None time:  3.0724444868974388
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 71.40
Split: 10, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 68.40% Test: 72.30%
Split: 10, Run: 02
None time:  3.0001228558830917
None Run 29:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 72.30
Split: 10, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 69.20% Test: 72.60%
Split: 10, Run: 03
None time:  3.0593049060553312
None Run 30:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 72.50
run time now: 9.154651165008545
total time:  75.27791555016302
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.13 ± 6.01
  Final Train: 100.00 ± 0.00
   Final Test: 65.67 ± 6.23
best run test_acc: 67.28999328613281
[I 2023-06-12 00:37:31,556] Trial 27 finished with value: 66.13333129882812 and parameters: {'Fwd': 0.0003185954190293319, 'K': 1, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.35000000000000003, 'lambda2': 5.463966294125763, 'loop': 0, 'loss': 'MSE', 'lr': 0.0007871646296875606, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.6357943631432915e-06, 'weightedloss': True}. Best is trial 26 with value: 67.24667358398438.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.65
lr:  0.0007660433094242137
weight_decay:  1.0732307260960536e-06
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1202, Train: 100.00%, Valid: 75.20% Test: 71.40%
Split: 01, Run: 01
None time:  4.444800168974325
None Run 01:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 71.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.1317, Train: 100.00%, Valid: 75.40% Test: 72.60%
Split: 01, Run: 02
None time:  4.411580929998308
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.1262, Train: 100.00%, Valid: 74.60% Test: 72.20%
Split: 01, Run: 03
None time:  4.445338792167604
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.60
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.6723590409383178
None Run 04:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 64.00
Split: 02, Run: 02
None time:  1.8017244688235223
None Run 05:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.80
Split: 02, Run: 03
None time:  1.8631303131114691
None Run 06:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.60
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.1544, Train: 100.00%, Valid: 66.20% Test: 65.10%
Split: 03, Run: 01
None time:  4.359540809877217
None Run 07:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 65.20
Split: 03, Run: 02
None time:  3.11339231999591
None Run 08:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.60
Split: 03, Run: 03
None time:  2.6529482358600944
None Run 09:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 61.80
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.5601057198364288
None Run 10:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.50
Split: 04, Run: 02
None time:  4.137642342131585
None Run 11:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 62.90
Split: 04, Run: 03, Epoch: 100, Loss: 0.1528, Train: 100.00%, Valid: 61.00% Test: 59.40%
Split: 04, Run: 03
None time:  4.517296222038567
None Run 12:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 59.00
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01, Epoch: 100, Loss: 0.1484, Train: 100.00%, Valid: 69.00% Test: 65.90%
Split: 05, Run: 01
None time:  4.625922929029912
None Run 13:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.10
Split: 05, Run: 02
None time:  2.4519878858700395
None Run 14:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 58.60
Split: 05, Run: 03, Epoch: 100, Loss: 0.1587, Train: 100.00%, Valid: 71.60% Test: 68.70%
Split: 05, Run: 03
None time:  4.389580272138119
None Run 15:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 69.00
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.812875091098249
None Run 16:
Highest Train: 100.00
Highest Valid: 56.80
  Final Train: 100.00
   Final Test: 56.70
Split: 06, Run: 02, Epoch: 100, Loss: 0.1737, Train: 100.00%, Valid: 62.20% Test: 61.30%
Split: 06, Run: 02
None time:  4.487339966930449
None Run 17:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 61.60
Split: 06, Run: 03
None time:  2.051549897994846
None Run 18:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 53.90
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.1628, Train: 100.00%, Valid: 67.80% Test: 71.40%
Split: 07, Run: 01
None time:  4.399734459118918
None Run 19:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 71.20
Split: 07, Run: 02
None time:  2.324723501224071
None Run 20:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.60
Split: 07, Run: 03
None time:  2.07224374380894
None Run 21:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.00
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.9155797290150076
None Run 22:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 75.30
Split: 08, Run: 02, Epoch: 100, Loss: 0.1305, Train: 100.00%, Valid: 71.60% Test: 73.70%
Split: 08, Run: 02
None time:  4.506627984112129
None Run 23:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 73.60
Split: 08, Run: 03
None time:  2.6876896100584418
None Run 24:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.10
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.087044292129576
None Run 25:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.70
Split: 09, Run: 02
None time:  2.074644678970799
None Run 26:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.90
Split: 09, Run: 03
None time:  1.8298308891244233
None Run 27:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 56.50
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.9674173039384186
None Run 28:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 73.00
Split: 10, Run: 02
None time:  2.4816360699478537
None Run 29:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 73.70
Split: 10, Run: 03
None time:  2.2965012351050973
None Run 30:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 73.90
run time now: 6.765748023986816
total time:  94.00106595596299
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.97 ± 5.86
  Final Train: 100.00 ± 0.00
   Final Test: 66.64 ± 6.28
best run test_acc: 69.30999755859375
[I 2023-06-12 00:39:06,069] Trial 28 finished with value: 66.96666717529297 and parameters: {'Fwd': 0.00036985610177762556, 'K': 1, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.4, 'lambda2': 5.68644027477561, 'loop': 1, 'loss': 'MSE', 'lr': 0.0007660433094242137, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0732307260960536e-06, 'weightedloss': True}. Best is trial 26 with value: 67.24667358398438.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.5
lr:  0.0017432946598615684
weight_decay:  1.2994874534923757e-06
dropout:  0.5
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9399632948916405
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 73.10
Split: 01, Run: 02
None time:  1.9200967070646584
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 72.70
Split: 01, Run: 03
None time:  2.2639190340414643
None Run 03:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.00
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.8865553739015013
None Run 04:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 63.50
Split: 02, Run: 02
None time:  3.2713996609672904
None Run 05:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 64.60
Split: 02, Run: 03, Epoch: 100, Loss: 0.0663, Train: 100.00%, Valid: 63.80% Test: 64.90%
Split: 02, Run: 03
None time:  4.422238944098353
None Run 06:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 64.70
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  4.015391560038552
None Run 07:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.20
Split: 03, Run: 02
None time:  2.5097088809125125
None Run 08:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.00
Split: 03, Run: 03
None time:  2.5577638000249863
None Run 09:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.50
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  4.207191330147907
None Run 10:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.40
Split: 04, Run: 02
None time:  1.9755363480653614
None Run 11:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.20
Split: 04, Run: 03
None time:  3.211793300928548
None Run 12:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.20
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.4901490819174796
None Run 13:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 64.00
Split: 05, Run: 02
None time:  1.9089932211209089
None Run 14:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 63.90
Split: 05, Run: 03
None time:  2.7835674250964075
None Run 15:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 64.50
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  3.325366568984464
None Run 16:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 59.60
Split: 06, Run: 02
None time:  2.8404254959896207
None Run 17:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 56.50
Split: 06, Run: 03
None time:  1.9971315641887486
None Run 18:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 58.50
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.9934909120202065
None Run 19:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.70
Split: 07, Run: 02
None time:  2.555837318999693
None Run 20:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 71.10
Split: 07, Run: 03
None time:  2.5055263871327043
None Run 21:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.00
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.173572233878076
None Run 22:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.10
Split: 08, Run: 02
None time:  2.2178274700418115
None Run 23:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.60
Split: 08, Run: 03
None time:  2.032982745906338
None Run 24:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.50
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.977019149111584
None Run 25:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.70
Split: 09, Run: 02
None time:  1.8488162190187722
None Run 26:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 59.20
Split: 09, Run: 03
None time:  2.344190899981186
None Run 27:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 61.70
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.9856220530346036
None Run 28:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 71.20
Split: 10, Run: 02
None time:  2.1106934039853513
None Run 29:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 71.40
Split: 10, Run: 03
None time:  2.0282914750277996
None Run 30:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 71.50
run time now: 6.1527485847473145
total time:  78.83936008391902
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.54 ± 5.40
  Final Train: 100.00 ± 0.00
   Final Test: 67.46 ± 5.11
best run test_acc: 68.30999755859375
[I 2023-06-12 00:40:25,440] Trial 29 finished with value: 67.54000091552734 and parameters: {'Fwd': 0.00017443753691167473, 'K': 1, 'alpha': 0.5, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.5, 'lambda2': 5.917412133968211, 'loop': 1, 'loss': 'MSE', 'lr': 0.0017432946598615684, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.2994874534923757e-06, 'weightedloss': True}. Best is trial 29 with value: 67.54000091552734.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.5
lr:  0.0018842548622207366
weight_decay:  1.3579456001912941e-06
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9496905507985502
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 02
None time:  1.5817203328479081
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 03
None time:  2.250081409001723
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 74.80
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4248286241199821
None Run 04:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 61.60
Split: 02, Run: 02
None time:  2.7807938191108406
None Run 05:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 64.00
Split: 02, Run: 03
None time:  1.8467770440038294
None Run 06:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 64.00
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.6877045778091997
None Run 07:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.60
Split: 03, Run: 02
None time:  2.976709045935422
None Run 08:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 69.00
Split: 03, Run: 03
None time:  1.7787862089462578
None Run 09:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.70
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.6252542270813137
None Run 10:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.80
Split: 04, Run: 02
None time:  1.8479697259608656
None Run 11:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.20
Split: 04, Run: 03
None time:  2.655122847063467
None Run 12:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.00
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.6086426079273224
None Run 13:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.10
Split: 05, Run: 02
None time:  3.103371286066249
None Run 14:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 65.60
Split: 05, Run: 03
None time:  1.9482540299650282
None Run 15:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 67.60
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.847105812979862
None Run 16:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 60.10
Split: 06, Run: 02
None time:  1.6032135169953108
None Run 17:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 55.00
Split: 06, Run: 03
None time:  1.5816003698855639
None Run 18:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 57.70
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.2871406241320074
None Run 19:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.50
Split: 07, Run: 02
None time:  1.7852296971250325
None Run 20:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.70
Split: 07, Run: 03
None time:  1.8777659961488098
None Run 21:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 72.60
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.26117722899653
None Run 22:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.60
Split: 08, Run: 02
None time:  2.124845664948225
None Run 23:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.30
Split: 08, Run: 03
None time:  1.9710456470493227
None Run 24:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 76.20
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  3.140549834817648
None Run 25:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 63.90
Split: 09, Run: 02
None time:  1.5764549891464412
None Run 26:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 60.90
Split: 09, Run: 03
None time:  1.7272402320522815
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 65.90
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.510642457054928
None Run 28:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 70.10
Split: 10, Run: 02
None time:  1.69637579517439
None Run 29:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 69.90
Split: 10, Run: 03
None time:  2.6330482999328524
None Run 30:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 72.60
run time now: 5.859365224838257
total time:  66.18170532607473
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.19 ± 5.84
  Final Train: 100.00 ± 0.00
   Final Test: 67.85 ± 5.41
best run test_acc: 69.25
[I 2023-06-12 00:41:32,073] Trial 30 finished with value: 68.1933364868164 and parameters: {'Fwd': 0.00016512957432390478, 'K': 1, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 6.584738004659592, 'loop': 1, 'loss': 'MSE', 'lr': 0.0018842548622207366, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.3579456001912941e-06, 'weightedloss': True}. Best is trial 30 with value: 68.1933364868164.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.5
lr:  0.002115637392733357
weight_decay:  1.3365960045645307e-06
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.207299569854513
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 02
None time:  1.7013985950034112
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 70.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0891, Train: 100.00%, Valid: 79.80% Test: 75.60%
Split: 01, Run: 03
None time:  3.9565893220715225
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 75.30
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4557964301202446
None Run 04:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 62.50
Split: 02, Run: 02
None time:  2.578207331011072
None Run 05:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 65.20
Split: 02, Run: 03
None time:  1.3997024779673666
None Run 06:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.30
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.9318697610870004
None Run 07:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 71.20
Split: 03, Run: 02
None time:  3.611393398139626
None Run 08:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 68.70
Split: 03, Run: 03
None time:  2.836957183899358
None Run 09:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.60
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.0471481140702963
None Run 10:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.50
Split: 04, Run: 02, Epoch: 100, Loss: 0.0911, Train: 100.00%, Valid: 68.20% Test: 69.10%
Split: 04, Run: 02
None time:  4.006683036917821
None Run 11:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 69.00
Split: 04, Run: 03
None time:  2.8562346671242267
None Run 12:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.10
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.5442637570668012
None Run 13:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 59.40
Split: 05, Run: 02
None time:  3.009666240075603
None Run 14:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 68.00
Split: 05, Run: 03
None time:  2.7229694731067866
None Run 15:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 62.90
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.2139073780272156
None Run 16:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 62.20
Split: 06, Run: 02
None time:  2.1107117000501603
None Run 17:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 59.30
Split: 06, Run: 03
None time:  2.268951348029077
None Run 18:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 57.60
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.610311329131946
None Run 19:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 73.50
Split: 07, Run: 02
None time:  3.3090302869677544
None Run 20:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 73.20
Split: 07, Run: 03
None time:  1.5831929771229625
None Run 21:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.40
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.0980, Train: 100.00%, Valid: 73.80% Test: 75.00%
Split: 08, Run: 01
None time:  4.017380531178787
None Run 22:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 75.00
Split: 08, Run: 02
None time:  2.9191412650980055
None Run 23:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 74.40
Split: 08, Run: 03
None time:  1.428420008160174
None Run 24:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 73.10
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.2870681409258395
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.00
Split: 09, Run: 02
None time:  2.2643491639755666
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 66.20
Split: 09, Run: 03
None time:  1.5762231959961355
None Run 27:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 65.40
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.6733835749328136
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 71.30
Split: 10, Run: 02
None time:  2.127477742964402
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 72.70
Split: 10, Run: 03
None time:  1.589388927910477
None Run 30:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 73.00
run time now: 5.426146745681763
total time:  72.41297545889392
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.39 ± 5.77
  Final Train: 100.00 ± 0.00
   Final Test: 68.10 ± 5.37
best run test_acc: 69.97000122070312
[I 2023-06-12 00:42:45,045] Trial 31 finished with value: 68.38667297363281 and parameters: {'Fwd': 0.00021040002830894857, 'K': 1, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 6.245468564720018, 'loop': 1, 'loss': 'MSE', 'lr': 0.002115637392733357, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.3365960045645307e-06, 'weightedloss': True}. Best is trial 31 with value: 68.38667297363281.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.55
lr:  0.0019287785231451183
weight_decay:  3.2244217921742794e-06
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.3701547340024263
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 02
None time:  2.984468223992735
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 74.20
Split: 01, Run: 03
None time:  3.531845632009208
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 74.70
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4544836499262601
None Run 04:
Highest Train: 100.00
Highest Valid: 61.20
  Final Train: 100.00
   Final Test: 63.80
Split: 02, Run: 02, Epoch: 100, Loss: 0.0927, Train: 100.00%, Valid: 61.60% Test: 64.50%
Split: 02, Run: 02
None time:  3.878247365122661
None Run 05:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 64.10
Split: 02, Run: 03
None time:  2.050008333986625
None Run 06:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 64.40
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.5373023580759764
None Run 07:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 70.40
Split: 03, Run: 02, Epoch: 100, Loss: 0.1063, Train: 100.00%, Valid: 70.60% Test: 70.90%
Split: 03, Run: 02
None time:  4.046158929821104
None Run 08:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 70.70
Split: 03, Run: 03
None time:  2.8174096441362053
None Run 09:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.10
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.661797309992835
None Run 10:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 66.30
Split: 04, Run: 02
None time:  2.7135910489596426
None Run 11:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 67.70
Split: 04, Run: 03
None time:  2.6203140581492335
None Run 12:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.90
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.114109012996778
None Run 13:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 63.70
Split: 05, Run: 02, Epoch: 100, Loss: 0.1106, Train: 100.00%, Valid: 70.00% Test: 67.10%
Split: 05, Run: 02
None time:  4.007100798888132
None Run 14:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 66.70
Split: 05, Run: 03
None time:  1.9471810469403863
None Run 15:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.30
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  2.336312238825485
None Run 16:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 57.40
Split: 06, Run: 02
None time:  2.103442073101178
None Run 17:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 57.40
Split: 06, Run: 03
None time:  2.2859894239809364
None Run 18:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 58.60
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.8152115740813315
None Run 19:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.50
Split: 07, Run: 02
None time:  2.2764888079836965
None Run 20:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 71.40
Split: 07, Run: 03
None time:  1.6362332701683044
None Run 21:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 73.50
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.747090765973553
None Run 22:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 73.20
Split: 08, Run: 02
None time:  1.5632996011991054
None Run 23:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 74.90
Split: 08, Run: 03
None time:  2.119535565143451
None Run 24:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 76.10
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.459659193875268
None Run 25:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 64.40
Split: 09, Run: 02
None time:  2.78747165389359
None Run 26:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 61.30
Split: 09, Run: 03
None time:  1.5590572541113943
None Run 27:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.50
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4932398800738156
None Run 28:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 73.00
Split: 10, Run: 02
None time:  1.5188472820445895
None Run 29:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 72.30
Split: 10, Run: 03
None time:  1.6353844429831952
None Run 30:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 73.00
run time now: 4.79990029335022
total time:  72.71730379201472
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.51 ± 5.61
  Final Train: 100.00 ± 0.00
   Final Test: 68.22 ± 5.36
best run test_acc: 69.20999908447266
[I 2023-06-12 00:43:58,335] Trial 32 finished with value: 68.50666809082031 and parameters: {'Fwd': 0.00013323408713237014, 'K': 1, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 6.486151917657042, 'loop': 1, 'loss': 'MSE', 'lr': 0.0019287785231451183, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.2244217921742794e-06, 'weightedloss': True}. Best is trial 32 with value: 68.50666809082031.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.5
lr:  0.0021793478119327934
weight_decay:  1.0353640116831518e-06
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0903, Train: 100.00%, Valid: 78.20% Test: 72.50%
Split: 01, Run: 01
None time:  3.795749006094411
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 72.70
Split: 01, Run: 02
None time:  1.383016767213121
None Run 02:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 72.10
Split: 01, Run: 03
None time:  3.732268976047635
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 74.70
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.766858150018379
None Run 04:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 65.20
Split: 02, Run: 02
None time:  1.1976207331754267
None Run 05:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 65.50
Split: 02, Run: 03
None time:  2.2395694029983133
None Run 06:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 65.50
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.72975266398862
None Run 07:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 67.80
Split: 03, Run: 02
None time:  1.7285677869804204
None Run 08:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.20
Split: 03, Run: 03
None time:  1.1805952349677682
None Run 09:
Highest Train: 100.00
Highest Valid: 64.20
  Final Train: 100.00
   Final Test: 65.60
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.762589388061315
None Run 10:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 67.40
Split: 04, Run: 02
None time:  2.993118624901399
None Run 11:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 69.30
Split: 04, Run: 03
None time:  2.9936835730914026
None Run 12:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.40
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.2059095290023834
None Run 13:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 59.00
Split: 05, Run: 02
None time:  2.059773384127766
None Run 14:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 68.70
Split: 05, Run: 03
None time:  2.9048899908084422
None Run 15:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 65.30
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.1083, Train: 100.00%, Valid: 59.20% Test: 59.80%
Split: 06, Run: 01
None time:  3.7864430949557573
None Run 16:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 59.80
Split: 06, Run: 02
None time:  0.9834166809450835
None Run 17:
Highest Train: 100.00
Highest Valid: 55.20
  Final Train: 100.00
   Final Test: 55.50
Split: 06, Run: 03
None time:  1.5387767921201885
None Run 18:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.10
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.1918739390093833
None Run 19:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 72.10
Split: 07, Run: 02
None time:  2.004587468924001
None Run 20:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 73.00
Split: 07, Run: 03
None time:  2.646122942911461
None Run 21:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 74.50
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2668673540465534
None Run 22:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 77.60
Split: 08, Run: 02
None time:  1.6147630061022937
None Run 23:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 76.00
Split: 08, Run: 03
None time:  1.9647185429930687
None Run 24:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 76.30
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.5211567010264844
None Run 25:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 64.00
Split: 09, Run: 02
None time:  2.232158843893558
None Run 26:
Highest Train: 100.00
Highest Valid: 64.40
  Final Train: 100.00
   Final Test: 62.20
Split: 09, Run: 03
None time:  2.3100769130978733
None Run 27:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.70
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.6268238578923047
None Run 28:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 72.50
Split: 10, Run: 02
None time:  1.6101180301047862
None Run 29:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 71.60
Split: 10, Run: 03
None time:  1.846433080965653
None Run 30:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 72.80
run time now: 5.109318494796753
total time:  64.44554576510563
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.47 ± 5.66
  Final Train: 100.00 ± 0.00
   Final Test: 68.37 ± 5.55
best run test_acc: 70.04000091552734
[I 2023-06-12 00:45:03,213] Trial 33 finished with value: 68.47333526611328 and parameters: {'Fwd': 0.00015196445941332348, 'K': 1, 'alpha': 0.5, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 6.31197164561142, 'loop': 1, 'loss': 'MSE', 'lr': 0.0021793478119327934, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0353640116831518e-06, 'weightedloss': True}. Best is trial 32 with value: 68.50666809082031.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.55
lr:  0.0028613489515354217
weight_decay:  2.0126710689878703e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.27142271399498
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 73.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.1075, Train: 100.00%, Valid: 78.20% Test: 75.00%
Split: 01, Run: 02
None time:  3.782823583111167
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 75.00
Split: 01, Run: 03
None time:  3.6167205697856843
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 73.40
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2695259940810502
None Run 04:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 63.30
Split: 02, Run: 02
None time:  1.2798625081777573
None Run 05:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 66.70
Split: 02, Run: 03
None time:  1.947077063843608
None Run 06:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 65.10
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.2076623120810837
None Run 07:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.70
Split: 03, Run: 02
None time:  1.9116948537994176
None Run 08:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 65.40
Split: 03, Run: 03, Epoch: 100, Loss: 0.1111, Train: 100.00%, Valid: 70.20% Test: 70.60%
Split: 03, Run: 03
None time:  4.018313070992008
None Run 09:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 70.80
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.2396367939654738
None Run 10:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 63.40
Split: 04, Run: 02
None time:  2.1551611269824207
None Run 11:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 70.30
Split: 04, Run: 03
None time:  1.4001029790379107
None Run 12:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 65.60
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.6058786308858544
None Run 13:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 68.30
Split: 05, Run: 02
None time:  1.1040089661255479
None Run 14:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 63.10
Split: 05, Run: 03
None time:  1.8277667630463839
None Run 15:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 65.00
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.7956497608684003
None Run 16:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 58.10
Split: 06, Run: 02
None time:  1.3142377759795636
None Run 17:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 59.20
Split: 06, Run: 03
None time:  3.778093683999032
None Run 18:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 59.40
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.998200200032443
None Run 19:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 71.50
Split: 07, Run: 02
None time:  1.5204036969225854
None Run 20:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 73.20
Split: 07, Run: 03, Epoch: 100, Loss: 0.1173, Train: 100.00%, Valid: 75.00% Test: 74.60%
Split: 07, Run: 03
None time:  3.9321881979703903
None Run 21:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 74.40
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.8826195059809834
None Run 22:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.70
Split: 08, Run: 02
None time:  1.9693263350054622
None Run 23:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 75.80
Split: 08, Run: 03
None time:  1.3639310849830508
None Run 24:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.10
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3984458621125668
None Run 25:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 63.10
Split: 09, Run: 02
None time:  1.1628507550340146
None Run 26:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.00
Split: 09, Run: 03
None time:  2.515094108879566
None Run 27:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.40
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.3332461179234087
None Run 28:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 70.50
Split: 10, Run: 02
None time:  1.2068537829909474
None Run 29:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 69.60
Split: 10, Run: 03
None time:  1.7947290090378374
None Run 30:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 72.20
run time now: 4.362309217453003
total time:  62.08934911387041
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.51 ± 5.75
  Final Train: 100.00 ± 0.00
   Final Test: 68.03 ± 5.16
best run test_acc: 69.93000030517578
[I 2023-06-12 00:46:05,770] Trial 34 finished with value: 68.51333618164062 and parameters: {'Fwd': 2.919610984202688e-05, 'K': 2, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 6.552799099141131, 'loop': 1, 'loss': 'MSE', 'lr': 0.0028613489515354217, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.0126710689878703e-06, 'weightedloss': True}. Best is trial 34 with value: 68.51333618164062.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.0030469748895042225
weight_decay:  6.3765256374961474e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9931745459325612
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 74.40
Split: 01, Run: 02
None time:  1.9177018550690264
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 03
None time:  1.831614725990221
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 74.40
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.25107431714423
None Run 04:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 61.30
Split: 02, Run: 02
None time:  1.2423167352098972
None Run 05:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 61.70
Split: 02, Run: 03
None time:  1.2258738579694182
None Run 06:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.90
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.1100, Train: 100.00%, Valid: 71.00% Test: 71.00%
Split: 03, Run: 01
None time:  3.926822636043653
None Run 07:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 71.10
Split: 03, Run: 02
None time:  2.864407390821725
None Run 08:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.20
Split: 03, Run: 03
None time:  2.0690568608697504
None Run 09:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.20
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.291722129099071
None Run 10:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 64.40
Split: 04, Run: 02
None time:  1.452220686012879
None Run 11:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.40
Split: 04, Run: 03
None time:  1.6643119079526514
None Run 12:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.90
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.7877128978725523
None Run 13:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 66.10
Split: 05, Run: 02
None time:  1.3580348680261523
None Run 14:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 64.60
Split: 05, Run: 03
None time:  1.238054112996906
None Run 15:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 65.70
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4084414530079812
None Run 16:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 62.30
Split: 06, Run: 02
None time:  1.2280782561283559
None Run 17:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 59.10
Split: 06, Run: 03
None time:  1.3055323439184576
None Run 18:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 58.50
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.2603898821398616
None Run 19:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.20
Split: 07, Run: 02
None time:  1.295056750997901
None Run 20:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 72.50
Split: 07, Run: 03
None time:  2.5157338839489967
None Run 21:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 72.40
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2901876070536673
None Run 22:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 74.00
Split: 08, Run: 02
None time:  1.2993003081064671
None Run 23:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.10
Split: 08, Run: 03
None time:  1.7381503998767585
None Run 24:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 77.40
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2708306519780308
None Run 25:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 65.00
Split: 09, Run: 02
None time:  1.3151726499199867
None Run 26:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 65.80
Split: 09, Run: 03
None time:  3.212421942036599
None Run 27:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 63.50
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  2.1570284890476614
None Run 28:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 72.20
Split: 10, Run: 02
None time:  3.4480298389680684
None Run 29:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 72.00
Split: 10, Run: 03
None time:  1.652522057062015
None Run 30:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 72.70
run time now: 7.283864736557007
total time:  56.052021495997906
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.53 ± 5.66
  Final Train: 100.00 ± 0.00
   Final Test: 68.36 ± 5.12
best run test_acc: 69.81000518798828
[I 2023-06-12 00:47:02,287] Trial 35 finished with value: 68.52666473388672 and parameters: {'Fwd': 2.9268390104833224e-05, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 6.611657846806791, 'loop': 1, 'loss': 'MSE', 'lr': 0.0030469748895042225, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.3765256374961474e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.35000000000000003
lr:  0.00299344140661581
weight_decay:  8.31768542862743e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.622088298201561
None Run 01:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 47.60
Split: 01, Run: 02
None time:  0.7534174241591245
None Run 02:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 59.40
Split: 01, Run: 03
None time:  0.8108274210244417
None Run 03:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 55.90
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.6037593481596559
None Run 04:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 41.00
Split: 02, Run: 02
None time:  0.597690014867112
None Run 05:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 41.00
Split: 02, Run: 03
None time:  1.2275030259042978
None Run 06:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 56.10
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.5803562430664897
None Run 07:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 37.50
Split: 03, Run: 02
None time:  0.6203510127961636
None Run 08:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 55.20
Split: 03, Run: 03
None time:  1.1864771989639848
None Run 09:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 62.30
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.626305891899392
None Run 10:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 40.00
Split: 04, Run: 02
None time:  1.3010458559729159
None Run 11:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 51.30
Split: 04, Run: 03
None time:  0.8248749349731952
None Run 12:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 49.70
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.5221090561244637
None Run 13:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 36.30
Split: 05, Run: 02
None time:  0.8172344691120088
None Run 14:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 56.00
Split: 05, Run: 03
None time:  0.6548157630022615
None Run 15:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 55.50
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5524969641119242
None Run 16:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 37.50
Split: 06, Run: 02
None time:  0.5685284419450909
None Run 17:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 37.50
Split: 06, Run: 03
None time:  0.5734442069660872
None Run 18:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 37.50
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.6509047308936715
None Run 19:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 42.70
Split: 07, Run: 02
None time:  0.8041232030373067
None Run 20:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 42.10
Split: 07, Run: 03
None time:  0.8229048820212483
None Run 21:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.40
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5745495480950922
None Run 22:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 41.40
Split: 08, Run: 02
None time:  0.8842641769442707
None Run 23:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 55.40
Split: 08, Run: 03
None time:  0.6372923769522458
None Run 24:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 66.70
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1441244569141418
None Run 25:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 50.40
Split: 09, Run: 02
None time:  0.7564843830186874
None Run 26:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 56.20
Split: 09, Run: 03
None time:  0.756850334117189
None Run 27:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.10
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.5585854910314083
None Run 28:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 45.40
Split: 10, Run: 02
None time:  0.5490165180526674
None Run 29:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 45.40
Split: 10, Run: 03
None time:  1.6268827219028026
None Run 30:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 58.00
run time now: 2.8221323490142822
total time:  23.907011438161135
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 51.13 ± 8.55
  Final Train: 100.00 ± 0.00
   Final Test: 49.45 ± 9.08
best run test_acc: 56.97999954223633
[I 2023-06-12 00:47:26,763] Trial 36 finished with value: 51.12666320800781 and parameters: {'Fwd': 2.1769490154325766e-05, 'K': 3, 'alpha': 0.35000000000000003, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 0.7000000000000001, 'lambda2': 6.82644268479145, 'loop': 1, 'loss': 'MSE', 'lr': 0.00299344140661581, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.31768542862743e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.003650434952324171
weight_decay:  3.925259753925376e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.024168801959604
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 75.10
Split: 01, Run: 02
None time:  1.8810830188449472
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 74.20
Split: 01, Run: 03
None time:  1.4070009549614042
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 73.60
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2179162891115993
None Run 04:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 61.70
Split: 02, Run: 02
None time:  1.1987827150151134
None Run 05:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 62.90
Split: 02, Run: 03
None time:  1.263865761924535
None Run 06:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 64.90
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.48424883489497
None Run 07:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 68.30
Split: 03, Run: 02
None time:  2.1766491669695824
None Run 08:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.70
Split: 03, Run: 03
None time:  1.3102504489943385
None Run 09:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 65.00
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.7378879899624735
None Run 10:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 66.10
Split: 04, Run: 02
None time:  1.3150866171345115
None Run 11:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 67.10
Split: 04, Run: 03
None time:  2.657277453923598
None Run 12:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 70.40
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.7153671670239419
None Run 13:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 71.40
Split: 05, Run: 02
None time:  1.2628719019703567
None Run 14:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.90
Split: 05, Run: 03
None time:  1.3125026740599424
None Run 15:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 62.60
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.1006, Train: 100.00%, Valid: 58.40% Test: 58.30%
Split: 06, Run: 01
None time:  4.194734669988975
None Run 16:
Highest Train: 100.00
Highest Valid: 58.60
  Final Train: 100.00
   Final Test: 58.10
Split: 06, Run: 02
None time:  2.195357111049816
None Run 17:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 56.30
Split: 06, Run: 03
None time:  1.2937488970346749
None Run 18:
Highest Train: 100.00
Highest Valid: 59.00
  Final Train: 100.00
   Final Test: 59.90
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.4113193000666797
None Run 19:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 72.90
Split: 07, Run: 02
None time:  1.2514023720286787
None Run 20:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.00
Split: 07, Run: 03
None time:  1.2809748940635473
None Run 21:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 72.70
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.2417481080628932
None Run 22:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 75.30
Split: 08, Run: 02
None time:  1.2616004610899836
None Run 23:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.50
Split: 08, Run: 03
None time:  1.331565432017669
None Run 24:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.00
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2892703760880977
None Run 25:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.70
Split: 09, Run: 02
None time:  2.038346122018993
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 66.50
Split: 09, Run: 03
None time:  1.8522126199677587
None Run 27:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.20
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.252429269021377
None Run 28:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 70.80
Split: 10, Run: 02
None time:  1.237168155843392
None Run 29:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 70.20
Split: 10, Run: 03
None time:  1.1596438952255994
None Run 30:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 70.80
run time now: 3.674957275390625
total time:  49.84102709381841
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.93 ± 5.94
  Final Train: 100.00 ± 0.00
   Final Test: 67.76 ± 5.32
best run test_acc: 69.68999481201172
[I 2023-06-12 00:48:17,190] Trial 37 finished with value: 67.92666625976562 and parameters: {'Fwd': 3.1672308135191724e-05, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.9500000000000001, 'lambda2': 7.383201106017845, 'loop': 1, 'loss': 'MSE', 'lr': 0.003650434952324171, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.925259753925376e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.0037920282877102283
weight_decay:  2.444908443573234e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.298922800924629
None Run 01:
Highest Train: 100.00
Highest Valid: 46.60
  Final Train: 100.00
   Final Test: 43.60
Split: 01, Run: 02
None time:  0.5619918110314757
None Run 02:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 38.70
Split: 01, Run: 03
None time:  1.3961293150205165
None Run 03:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 46.20
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.108925259904936
None Run 04:
Highest Train: 100.00
Highest Valid: 45.80
  Final Train: 100.00
   Final Test: 45.10
Split: 02, Run: 02
None time:  0.6005470701493323
None Run 05:
Highest Train: 100.00
Highest Valid: 41.80
  Final Train: 100.00
   Final Test: 48.80
Split: 02, Run: 03
None time:  0.6111955801025033
None Run 06:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 52.90
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.5289462839718908
None Run 07:
Highest Train: 100.00
Highest Valid: 29.60
  Final Train: 100.00
   Final Test: 28.70
Split: 03, Run: 02
None time:  0.6074486409779638
None Run 08:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 48.00
Split: 03, Run: 03
None time:  0.9033991200849414
None Run 09:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 52.50
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.437894341070205
None Run 10:
Highest Train: 100.00
Highest Valid: 48.60
  Final Train: 100.00
   Final Test: 43.40
Split: 04, Run: 02
None time:  0.7476012439001352
None Run 11:
Highest Train: 100.00
Highest Valid: 52.80
  Final Train: 100.00
   Final Test: 46.20
Split: 04, Run: 03
None time:  0.8006234269123524
None Run 12:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 55.50
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.5743037150241435
None Run 13:
Highest Train: 100.00
Highest Valid: 28.20
  Final Train: 100.00
   Final Test: 27.20
Split: 05, Run: 02
None time:  0.5557811411563307
None Run 14:
Highest Train: 100.00
Highest Valid: 54.40
  Final Train: 100.00
   Final Test: 49.70
Split: 05, Run: 03
None time:  0.6937652190681547
None Run 15:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 52.00
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5245417822152376
None Run 16:
Highest Train: 100.00
Highest Valid: 33.00
  Final Train: 100.00
   Final Test: 28.40
Split: 06, Run: 02
None time:  0.6668217901606113
None Run 17:
Highest Train: 100.00
Highest Valid: 34.60
  Final Train: 100.00
   Final Test: 32.00
Split: 06, Run: 03
None time:  0.9602714979555458
None Run 18:
Highest Train: 100.00
Highest Valid: 43.60
  Final Train: 100.00
   Final Test: 41.60
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.58055305108428
None Run 19:
Highest Train: 100.00
Highest Valid: 26.20
  Final Train: 100.00
   Final Test: 29.10
Split: 07, Run: 02
None time:  0.6985695420298725
None Run 20:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 46.20
Split: 07, Run: 03
None time:  0.6773546149488539
None Run 21:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 54.80
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.5996147200930864
None Run 22:
Highest Train: 100.00
Highest Valid: 34.20
  Final Train: 100.00
   Final Test: 27.40
Split: 08, Run: 02
None time:  0.7487817108631134
None Run 23:
Highest Train: 100.00
Highest Valid: 50.00
  Final Train: 100.00
   Final Test: 50.70
Split: 08, Run: 03
None time:  0.776478623971343
None Run 24:
Highest Train: 100.00
Highest Valid: 55.80
  Final Train: 100.00
   Final Test: 54.80
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.5688909799791873
None Run 25:
Highest Train: 100.00
Highest Valid: 30.20
  Final Train: 100.00
   Final Test: 26.60
Split: 09, Run: 02
None time:  0.6408976928796619
None Run 26:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 49.30
Split: 09, Run: 03
None time:  0.6115477229468524
None Run 27:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 52.20
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.568816564977169
None Run 28:
Highest Train: 100.00
Highest Valid: 32.00
  Final Train: 100.00
   Final Test: 30.40
Split: 10, Run: 02
None time:  1.1002098871394992
None Run 29:
Highest Train: 100.00
Highest Valid: 38.80
  Final Train: 100.00
   Final Test: 41.20
Split: 10, Run: 03
None time:  1.5202309070155025
None Run 30:
Highest Train: 100.00
Highest Valid: 45.00
  Final Train: 100.00
   Final Test: 44.60
run time now: 3.2162981033325195
total time:  24.169211979024112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 45.24 ± 10.14
  Final Train: 100.00 ± 0.00
   Final Test: 42.93 ± 9.66
best run test_acc: 50.709999084472656
[I 2023-06-12 00:48:41,862] Trial 38 finished with value: 45.2400016784668 and parameters: {'Fwd': 1.5870928575015046e-05, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 0.8, 'lambda2': 6.472033939975672, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037920282877102283, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.444908443573234e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.55
lr:  0.0012681562940388767
weight_decay:  5.9359389317044825e-06
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.1930244530085474
None Run 01:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02
None time:  2.962681181030348
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 71.00
Split: 01, Run: 03
None time:  3.4014336720574647
None Run 03:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 66.90
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.9197798809036613
None Run 04:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 59.30
Split: 02, Run: 02
None time:  1.4163803949486464
None Run 05:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 60.70
Split: 02, Run: 03
None time:  1.430543869966641
None Run 06:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.30
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.646842289948836
None Run 07:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 65.30
Split: 03, Run: 02, Epoch: 100, Loss: 0.3446, Train: 100.00%, Valid: 65.40% Test: 66.10%
Split: 03, Run: 02
None time:  4.066010067937896
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 66.10
Split: 03, Run: 03
None time:  1.386413699015975
None Run 09:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 55.10
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.814533140975982
None Run 10:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 60.80
Split: 04, Run: 02, Epoch: 100, Loss: 0.3294, Train: 100.00%, Valid: 66.60% Test: 66.80%
Split: 04, Run: 02
None time:  3.9070181739516556
None Run 11:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 66.10
Split: 04, Run: 03
None time:  2.8795212560798973
None Run 12:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.20
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.8985736770555377
None Run 13:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 57.80
Split: 05, Run: 02
None time:  1.3789475730154663
None Run 14:
Highest Train: 100.00
Highest Valid: 56.60
  Final Train: 100.00
   Final Test: 54.70
Split: 05, Run: 03
None time:  2.5587807749398053
None Run 15:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 61.80
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.4425324159674346
None Run 16:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 47.80
Split: 06, Run: 02, Epoch: 100, Loss: 0.3841, Train: 100.00%, Valid: 53.00% Test: 53.10%
Split: 06, Run: 02
None time:  4.09718399704434
None Run 17:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 52.80
Split: 06, Run: 03
None time:  1.4307763471733779
None Run 18:
Highest Train: 100.00
Highest Valid: 49.40
  Final Train: 100.00
   Final Test: 49.90
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.5294285048730671
None Run 19:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.70
Split: 07, Run: 02
None time:  2.118635301012546
None Run 20:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.60
Split: 07, Run: 03
None time:  2.6645690330769867
None Run 21:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 72.50
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01, Epoch: 100, Loss: 0.3221, Train: 100.00%, Valid: 73.80% Test: 75.10%
Split: 08, Run: 01
None time:  3.8260991780553013
None Run 22:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 75.10
Split: 08, Run: 02, Epoch: 100, Loss: 0.2893, Train: 100.00%, Valid: 69.80% Test: 69.50%
Split: 08, Run: 02
None time:  4.245630799094215
None Run 23:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 69.40
Split: 08, Run: 03
None time:  2.195778291905299
None Run 24:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.80
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.7747120950371027
None Run 25:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 65.60
Split: 09, Run: 02
None time:  1.8433230088558048
None Run 26:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 63.70
Split: 09, Run: 03
None time:  3.9241394121199846
None Run 27:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 65.00
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.390745416050777
None Run 28:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 70.50
Split: 10, Run: 02, Epoch: 100, Loss: 0.3391, Train: 100.00%, Valid: 63.80% Test: 67.40%
Split: 10, Run: 02
None time:  4.05459759500809
None Run 29:
Highest Train: 100.00
Highest Valid: 63.80
  Final Train: 100.00
   Final Test: 66.60
Split: 10, Run: 03
None time:  1.4558502731379122
None Run 30:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 71.50
run time now: 8.926672220230103
total time:  78.5831150400918
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 64.12 ± 6.72
  Final Train: 100.00 ± 0.00
   Final Test: 64.20 ± 7.00
best run test_acc: 66.58999633789062
[I 2023-06-12 00:50:00,899] Trial 39 finished with value: 64.12000274658203 and parameters: {'Fwd': 6.462889257431789e-05, 'K': 2, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 7.70395648765902, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012681562940388767, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.9359389317044825e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.25
lr:  0.0026011843502909966
weight_decay:  2.2751210219305025e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5772040209267288
None Run 01:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 47.60
Split: 01, Run: 02
None time:  0.5525866139214486
None Run 02:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 47.60
Split: 01, Run: 03
None time:  0.8144328040070832
None Run 03:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 54.10
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  0.5676853461191058
None Run 04:
Highest Train: 100.00
Highest Valid: 41.40
  Final Train: 100.00
   Final Test: 41.00
Split: 02, Run: 02
None time:  1.1444541728124022
None Run 05:
Highest Train: 100.00
Highest Valid: 46.20
  Final Train: 100.00
   Final Test: 49.40
Split: 02, Run: 03
None time:  0.9253968689590693
None Run 06:
Highest Train: 100.00
Highest Valid: 50.40
  Final Train: 100.00
   Final Test: 56.50
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.591929028974846
None Run 07:
Highest Train: 100.00
Highest Valid: 39.00
  Final Train: 100.00
   Final Test: 37.50
Split: 03, Run: 02
None time:  0.90464299893938
None Run 08:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 50.10
Split: 03, Run: 03
None time:  0.959996652090922
None Run 09:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 58.80
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.5579424018505961
None Run 10:
Highest Train: 100.00
Highest Valid: 39.80
  Final Train: 100.00
   Final Test: 40.00
Split: 04, Run: 02
None time:  0.6549942290876061
None Run 11:
Highest Train: 100.00
Highest Valid: 44.00
  Final Train: 100.00
   Final Test: 41.80
Split: 04, Run: 03
None time:  0.9139924461487681
None Run 12:
Highest Train: 100.00
Highest Valid: 54.20
  Final Train: 100.00
   Final Test: 56.10
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  0.5845835360232741
None Run 13:
Highest Train: 100.00
Highest Valid: 37.00
  Final Train: 100.00
   Final Test: 36.30
Split: 05, Run: 02
None time:  1.3184930828865618
None Run 14:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 50.30
Split: 05, Run: 03
None time:  0.951196022098884
None Run 15:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 59.30
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.5686654848977923
None Run 16:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 37.50
Split: 06, Run: 02
None time:  0.5574574011843652
None Run 17:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 37.50
Split: 06, Run: 03
None time:  0.6055073461029679
None Run 18:
Highest Train: 100.00
Highest Valid: 43.20
  Final Train: 100.00
   Final Test: 37.50
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  0.590353875188157
None Run 19:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 42.70
Split: 07, Run: 02
None time:  0.6074907891452312
None Run 20:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 42.90
Split: 07, Run: 03
None time:  0.6243002959527075
None Run 21:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 42.70
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.6054373879451305
None Run 22:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 41.40
Split: 08, Run: 02
None time:  0.7057890738360584
None Run 23:
Highest Train: 100.00
Highest Valid: 50.80
  Final Train: 100.00
   Final Test: 50.50
Split: 08, Run: 03
None time:  0.7719656338449568
None Run 24:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.40
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.5944076410960406
None Run 25:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 35.90
Split: 09, Run: 02
None time:  0.6902006741147488
None Run 26:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 52.00
Split: 09, Run: 03
None time:  0.797573400195688
None Run 27:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 51.70
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.6246687318198383
None Run 28:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 45.40
Split: 10, Run: 02
None time:  0.5900563129689544
None Run 29:
Highest Train: 100.00
Highest Valid: 46.40
  Final Train: 100.00
   Final Test: 45.40
Split: 10, Run: 03
None time:  0.7527819850947708
None Run 30:
Highest Train: 100.00
Highest Valid: 52.40
  Final Train: 100.00
   Final Test: 54.00
run time now: 2.050947427749634
total time:  22.28040727088228
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 47.77 ± 6.59
  Final Train: 100.00 ± 0.00
   Final Test: 46.63 ± 7.23
best run test_acc: 52.659996032714844
[I 2023-06-12 00:50:23,646] Trial 40 finished with value: 47.77333068847656 and parameters: {'Fwd': 1.1112131275536323e-05, 'K': 3, 'alpha': 0.25, 'dropout': 0.8, 'gnnepoch': 40, 'lambda1': 0.7000000000000001, 'lambda2': 6.947452490849624, 'loop': 1, 'loss': 'MSE', 'lr': 0.0026011843502909966, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.2751210219305025e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.45
lr:  0.0023431328590214177
weight_decay:  1.0980700358943086e-06
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.0412830559071153
None Run 01:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 72.80
Split: 01, Run: 02
None time:  2.253599319141358
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 74.60
Split: 01, Run: 03
None time:  1.755871471017599
None Run 03:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 74.00
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4137960949447006
None Run 04:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 61.20
Split: 02, Run: 02
None time:  1.4133152468129992
None Run 05:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.80
Split: 02, Run: 03
None time:  1.588594292057678
None Run 06:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 62.60
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.826670761918649
None Run 07:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.50
Split: 03, Run: 02
None time:  1.9028353460598737
None Run 08:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.10
Split: 03, Run: 03
None time:  1.5316018851008266
None Run 09:
Highest Train: 100.00
Highest Valid: 68.20
  Final Train: 100.00
   Final Test: 68.90
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.7848905760329217
None Run 10:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 69.10
Split: 04, Run: 02
None time:  1.2274579531513155
None Run 11:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.50
Split: 04, Run: 03
None time:  1.6041260289493948
None Run 12:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 63.00
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.01948686898686
None Run 13:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 65.20
Split: 05, Run: 02
None time:  1.4819079309236258
None Run 14:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.10
Split: 05, Run: 03
None time:  1.3958100629970431
None Run 15:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 62.00
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  3.474867488956079
None Run 16:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 57.60
Split: 06, Run: 02
None time:  1.3912284069228917
None Run 17:
Highest Train: 100.00
Highest Valid: 56.00
  Final Train: 100.00
   Final Test: 57.20
Split: 06, Run: 03
None time:  2.518653635168448
None Run 18:
Highest Train: 100.00
Highest Valid: 59.80
  Final Train: 100.00
   Final Test: 61.20
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.6700924229808152
None Run 19:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.90
Split: 07, Run: 02
None time:  1.6032567098736763
None Run 20:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 72.70
Split: 07, Run: 03
None time:  1.4653149680234492
None Run 21:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 72.30
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  3.1735788728110492
None Run 22:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 75.80
Split: 08, Run: 02
None time:  1.5057680530007929
None Run 23:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 74.20
Split: 08, Run: 03
None time:  1.6934696780517697
None Run 24:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 75.60
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.559622132917866
None Run 25:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 61.00
Split: 09, Run: 02
None time:  2.3013948551379144
None Run 26:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 62.30
Split: 09, Run: 03
None time:  1.4268757989630103
None Run 27:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 62.00
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.8776883981190622
None Run 28:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 72.50
Split: 10, Run: 02
None time:  2.136927626794204
None Run 29:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 71.60
Split: 10, Run: 03
None time:  1.6503383370582014
None Run 30:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 69.80
run time now: 5.688788652420044
total time:  57.17322018998675
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.53 ± 5.79
  Final Train: 100.00 ± 0.00
   Final Test: 67.37 ± 5.84
best run test_acc: 68.79000091552734
[I 2023-06-12 00:51:21,256] Trial 41 finished with value: 67.53333282470703 and parameters: {'Fwd': 4.1028626997159095e-05, 'K': 1, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.299300490738577, 'loop': 1, 'loss': 'MSE', 'lr': 0.0023431328590214177, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0980700358943086e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.55
lr:  0.00153227568268993
weight_decay:  2.240461682461216e-06
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.3001894659828395
None Run 01:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 02
None time:  1.3073771360795945
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.30
Split: 01, Run: 03
None time:  3.351681142114103
None Run 03:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 72.50
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.285256490111351
None Run 04:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 62.30
Split: 02, Run: 02
None time:  1.2175556069705635
None Run 05:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 58.20
Split: 02, Run: 03
None time:  1.246959940996021
None Run 06:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 63.10
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.649372029816732
None Run 07:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.20
Split: 03, Run: 02
None time:  1.9036178849637508
None Run 08:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.10
Split: 03, Run: 03
None time:  3.1391283858101815
None Run 09:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.90
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.4964444099459797
None Run 10:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 65.00
Split: 04, Run: 02
None time:  1.5663851010613143
None Run 11:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 66.90
Split: 04, Run: 03
None time:  2.0054946599993855
None Run 12:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 67.40
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.8469551040325314
None Run 13:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.40
Split: 05, Run: 02
None time:  1.4462153480853885
None Run 14:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 64.70
Split: 05, Run: 03
None time:  1.751058897934854
None Run 15:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 64.60
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.1758, Train: 100.00%, Valid: 55.00% Test: 56.30%
Split: 06, Run: 01
None time:  4.012987978057936
None Run 16:
Highest Train: 100.00
Highest Valid: 55.00
  Final Train: 100.00
   Final Test: 55.90
Split: 06, Run: 02
None time:  1.5471472558565438
None Run 17:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 53.00
Split: 06, Run: 03, Epoch: 100, Loss: 0.1723, Train: 100.00%, Valid: 54.20% Test: 55.90%
Split: 06, Run: 03
None time:  4.054943369003013
None Run 18:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 55.70
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.7510306481271982
None Run 19:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.60
Split: 07, Run: 02
None time:  1.2788094549905509
None Run 20:
Highest Train: 100.00
Highest Valid: 73.40
  Final Train: 100.00
   Final Test: 73.30
Split: 07, Run: 03
None time:  1.596452526981011
None Run 21:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 73.60
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.1966838350053877
None Run 22:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.00
Split: 08, Run: 02
None time:  2.685587610118091
None Run 23:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 76.70
Split: 08, Run: 03
None time:  1.2627321968320757
None Run 24:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 74.80
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.6056706851813942
None Run 25:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 59.30
Split: 09, Run: 02
None time:  1.488075983012095
None Run 26:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 59.80
Split: 09, Run: 03
None time:  1.8440440380945802
None Run 27:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 67.00
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2319604309741408
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 70.60
Split: 10, Run: 02
None time:  2.212062447099015
None Run 29:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 71.10
Split: 10, Run: 03
None time:  1.3955746630672365
None Run 30:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 70.10
run time now: 4.8658246994018555
total time:  64.33284226688556
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.24 ± 6.32
  Final Train: 100.00 ± 0.00
   Final Test: 66.82 ± 6.15
best run test_acc: 68.37999725341797
[I 2023-06-12 00:52:26,049] Trial 42 finished with value: 67.23999786376953 and parameters: {'Fwd': 0.00010562076689798862, 'K': 2, 'alpha': 0.55, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 6.342388632543938, 'loop': 1, 'loss': 'MSE', 'lr': 0.00153227568268993, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.240461682461216e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.45
lr:  0.002189871345654818
weight_decay:  3.7551327720600446e-06
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.3223, Train: 100.00%, Valid: 70.80% Test: 68.60%
Split: 01, Run: 01
None time:  3.4012958989478648
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 68.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.2847, Train: 100.00%, Valid: 73.80% Test: 68.70%
Split: 01, Run: 02
None time:  3.537212199997157
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 69.00
Split: 01, Run: 03
None time:  2.269602162996307
None Run 03:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 73.60
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  2.0800289779435843
None Run 04:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 61.20
Split: 02, Run: 02
None time:  1.5115629450883716
None Run 05:
Highest Train: 100.00
Highest Valid: 62.40
  Final Train: 100.00
   Final Test: 60.90
Split: 02, Run: 03
None time:  2.859012207016349
None Run 06:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 64.50
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9340734682045877
None Run 07:
Highest Train: 100.00
Highest Valid: 58.00
  Final Train: 100.00
   Final Test: 56.30
Split: 03, Run: 02
None time:  2.327705816132948
None Run 08:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 69.10
Split: 03, Run: 03
None time:  1.0092715139035136
None Run 09:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 56.60
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01, Epoch: 100, Loss: 0.3238, Train: 100.00%, Valid: 62.60% Test: 60.00%
Split: 04, Run: 01
None time:  3.520081006921828
None Run 10:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 60.30
Split: 04, Run: 02, Epoch: 100, Loss: 0.3194, Train: 100.00%, Valid: 64.80% Test: 61.80%
Split: 04, Run: 02
None time:  3.465657618129626
None Run 11:
Highest Train: 100.00
Highest Valid: 65.00
  Final Train: 100.00
   Final Test: 61.00
Split: 04, Run: 03
None time:  3.0700498670339584
None Run 12:
Highest Train: 100.00
Highest Valid: 60.00
  Final Train: 100.00
   Final Test: 59.40
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.9989390519913286
None Run 13:
Highest Train: 100.00
Highest Valid: 60.60
  Final Train: 100.00
   Final Test: 56.70
Split: 05, Run: 02
None time:  1.999351535923779
None Run 14:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 66.20
Split: 05, Run: 03
None time:  0.8761849068105221
None Run 15:
Highest Train: 100.00
Highest Valid: 57.40
  Final Train: 100.00
   Final Test: 57.10
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01, Epoch: 100, Loss: 0.3844, Train: 100.00%, Valid: 64.60% Test: 60.20%
Split: 06, Run: 01
None time:  3.494868842884898
None Run 16:
Highest Train: 100.00
Highest Valid: 64.60
  Final Train: 100.00
   Final Test: 60.20
Split: 06, Run: 02
None time:  2.7225053959991783
None Run 17:
Highest Train: 100.00
Highest Valid: 56.40
  Final Train: 100.00
   Final Test: 54.60
Split: 06, Run: 03, Epoch: 100, Loss: 0.3939, Train: 100.00%, Valid: 47.60% Test: 47.60%
Split: 06, Run: 03
None time:  3.479344730032608
None Run 18:
Highest Train: 100.00
Highest Valid: 48.00
  Final Train: 100.00
   Final Test: 46.90
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01, Epoch: 100, Loss: 0.3386, Train: 100.00%, Valid: 66.00% Test: 68.90%
Split: 07, Run: 01
None time:  3.5092082270421088
None Run 19:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 68.90
Split: 07, Run: 02, Epoch: 100, Loss: 0.3535, Train: 100.00%, Valid: 67.00% Test: 68.80%
Split: 07, Run: 02
None time:  3.0010243367869407
None Run 20:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 68.60
Split: 07, Run: 03
None time:  2.4696871140040457
None Run 21:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 71.20
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0801847209222615
None Run 22:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 63.80
Split: 08, Run: 02
None time:  1.015681479126215
None Run 23:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.40
Split: 08, Run: 03
None time:  1.2510856490116566
None Run 24:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.40
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  2.445175000000745
None Run 25:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 73.80
Split: 09, Run: 02
None time:  2.5703381658531725
None Run 26:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.40
Split: 09, Run: 03
None time:  2.7937274160794914
None Run 27:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 66.70
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2260207058861852
None Run 28:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 73.40
Split: 10, Run: 02
None time:  1.7926651739981025
None Run 29:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 68.90
Split: 10, Run: 03
None time:  1.589533224934712
None Run 30:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 71.20
run time now: 4.644796133041382
total time:  69.97166923992336
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.06 ± 6.22
  Final Train: 100.00 ± 0.00
   Final Test: 64.36 ± 6.62
best run test_acc: 68.54000091552734
[I 2023-06-12 00:53:36,587] Trial 43 finished with value: 65.06000518798828 and parameters: {'Fwd': 7.604669308595946e-05, 'K': 1, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 30, 'lambda1': 0.65, 'lambda2': 6.047349270838716, 'loop': 1, 'loss': 'MSE', 'lr': 0.002189871345654818, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.7551327720600446e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.30000000000000004
lr:  0.0015820793535886658
weight_decay:  8.835937030533667e-06
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.305470594903454
None Run 01:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 72.70
Split: 01, Run: 02, Epoch: 100, Loss: 0.0760, Train: 100.00%, Valid: 78.60% Test: 74.40%
Split: 01, Run: 02
None time:  4.300005706958473
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 73.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0915, Train: 100.00%, Valid: 76.00% Test: 72.50%
Split: 01, Run: 03
None time:  4.256598882144317
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 72.60
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.4066208119038492
None Run 04:
Highest Train: 100.00
Highest Valid: 61.80
  Final Train: 100.00
   Final Test: 63.60
Split: 02, Run: 02
None time:  1.3850786730181426
None Run 05:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 61.60
Split: 02, Run: 03
None time:  1.898513093125075
None Run 06:
Highest Train: 100.00
Highest Valid: 61.40
  Final Train: 100.00
   Final Test: 63.70
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  2.6361888819374144
None Run 07:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 67.20
Split: 03, Run: 02
None time:  1.9015447129495442
None Run 08:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 69.60
Split: 03, Run: 03
None time:  1.9089825758710504
None Run 09:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 68.60
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.3694338409695774
None Run 10:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 70.00
Split: 04, Run: 02
None time:  1.8632148569449782
None Run 11:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 65.90
Split: 04, Run: 03
None time:  1.371446680976078
None Run 12:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 63.20
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.3066733840387315
None Run 13:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 66.10
Split: 05, Run: 02
None time:  3.169243973912671
None Run 14:
Highest Train: 100.00
Highest Valid: 70.20
  Final Train: 100.00
   Final Test: 68.30
Split: 05, Run: 03
None time:  1.526638497132808
None Run 15:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 66.40
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.447370626963675
None Run 16:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 54.80
Split: 06, Run: 02
None time:  2.5264329111669213
None Run 17:
Highest Train: 100.00
Highest Valid: 53.00
  Final Train: 100.00
   Final Test: 54.00
Split: 06, Run: 03
None time:  1.6819260190241039
None Run 18:
Highest Train: 100.00
Highest Valid: 54.60
  Final Train: 100.00
   Final Test: 54.60
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.0778412881772965
None Run 19:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.90
Split: 07, Run: 02
None time:  1.9518891961779445
None Run 20:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 70.40
Split: 07, Run: 03
None time:  1.5181618928909302
None Run 21:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 74.70
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.833713529165834
None Run 22:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 69.40
Split: 08, Run: 02
None time:  3.8913533759769052
None Run 23:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 76.60
Split: 08, Run: 03
None time:  1.5363718490116298
None Run 24:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.00
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01, Epoch: 100, Loss: 0.0976, Train: 100.00%, Valid: 66.60% Test: 66.60%
Split: 09, Run: 01
None time:  4.4972821900155395
None Run 25:
Highest Train: 100.00
Highest Valid: 66.60
  Final Train: 100.00
   Final Test: 65.80
Split: 09, Run: 02
None time:  1.435007605003193
None Run 26:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 64.80
Split: 09, Run: 03
None time:  1.4753170059993863
None Run 27:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 67.80
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.6283699760679156
None Run 28:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 73.00
Split: 10, Run: 02
None time:  2.8869167719967663
None Run 29:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 71.80
Split: 10, Run: 03
None time:  3.286461218027398
None Run 30:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 71.70
run time now: 7.823032379150391
total time:  72.78413000400178
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.70 ± 6.57
  Final Train: 100.00 ± 0.00
   Final Test: 67.62 ± 5.83
best run test_acc: 69.22999572753906
[I 2023-06-12 00:54:49,779] Trial 44 finished with value: 67.69999694824219 and parameters: {'Fwd': 0.0001477544843330741, 'K': 3, 'alpha': 0.30000000000000004, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 7.638399732165305, 'loop': 1, 'loss': 'MSE', 'lr': 0.0015820793535886658, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.835937030533667e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.6000000000000001
lr:  0.0031679644904676293
weight_decay:  2.0131769756858494e-06
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.819406013004482
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 71.70
Split: 01, Run: 02
None time:  3.2028459031134844
None Run 02:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 73.90
Split: 01, Run: 03
None time:  1.1047871189657599
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 67.10
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.3336389809846878
None Run 04:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 69.90
Split: 02, Run: 02
None time:  2.7828870830126107
None Run 05:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 65.20
Split: 02, Run: 03
None time:  1.5115924389101565
None Run 06:
Highest Train: 100.00
Highest Valid: 62.00
  Final Train: 100.00
   Final Test: 62.40
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.8822769080288708
None Run 07:
Highest Train: 100.00
Highest Valid: 64.80
  Final Train: 100.00
   Final Test: 65.30
Split: 03, Run: 02
None time:  1.0878468859009445
None Run 08:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 65.00
Split: 03, Run: 03
None time:  0.9990021609701216
None Run 09:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.80
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.9069760499987751
None Run 10:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 69.40
Split: 04, Run: 02
None time:  2.381998220924288
None Run 11:
Highest Train: 100.00
Highest Valid: 61.00
  Final Train: 100.00
   Final Test: 58.10
Split: 04, Run: 03
None time:  2.09818394202739
None Run 12:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 61.80
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.120948040857911
None Run 13:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.60
Split: 05, Run: 02
None time:  1.4474615780636668
None Run 14:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 64.50
Split: 05, Run: 03, Epoch: 100, Loss: 0.1129, Train: 100.00%, Valid: 69.00% Test: 68.20%
Split: 05, Run: 03
None time:  5.474070142023265
None Run 15:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 67.80
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.8512703569140285
None Run 16:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 57.60
Split: 06, Run: 02
None time:  3.0112752479035407
None Run 17:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 57.40
Split: 06, Run: 03
None time:  1.3323827059939504
None Run 18:
Highest Train: 100.00
Highest Valid: 60.80
  Final Train: 100.00
   Final Test: 59.20
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.0719994129613042
None Run 19:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 73.30
Split: 07, Run: 02
None time:  1.3905504439026117
None Run 20:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 72.70
Split: 07, Run: 03
None time:  3.424815985839814
None Run 21:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 70.70
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.0555828681681305
None Run 22:
Highest Train: 100.00
Highest Valid: 67.60
  Final Train: 100.00
   Final Test: 68.40
Split: 08, Run: 02
None time:  1.0267225028946996
None Run 23:
Highest Train: 100.00
Highest Valid: 74.20
  Final Train: 100.00
   Final Test: 74.60
Split: 08, Run: 03
None time:  1.0517917058896273
None Run 24:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 68.60
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.3473027399741113
None Run 25:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 70.70
Split: 09, Run: 02
None time:  1.0922851748764515
None Run 26:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 63.10
Split: 09, Run: 03
None time:  0.9712662380188704
None Run 27:
Highest Train: 100.00
Highest Valid: 66.20
  Final Train: 100.00
   Final Test: 61.70
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  3.803737856214866
None Run 28:
Highest Train: 100.00
Highest Valid: 71.00
  Final Train: 100.00
   Final Test: 73.50
Split: 10, Run: 02
None time:  1.8191105660516769
None Run 29:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 71.90
Split: 10, Run: 03
None time:  1.1016356309410185
None Run 30:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 68.90
run time now: 6.748688220977783
total time:  58.157948046922684
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.79 ± 5.27
  Final Train: 100.00 ± 0.00
   Final Test: 66.69 ± 5.28
best run test_acc: 69.75999450683594
[I 2023-06-12 00:55:48,432] Trial 45 finished with value: 67.79332733154297 and parameters: {'Fwd': 5.1576085185324075e-05, 'K': 2, 'alpha': 0.6000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 20, 'lambda1': 0.75, 'lambda2': 6.749408353454381, 'loop': 2, 'loss': 'MSE', 'lr': 0.0031679644904676293, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.0131769756858494e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.004884937905506563
weight_decay:  1.0316317513721046e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.4303763259667903
None Run 01:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 02, Epoch: 100, Loss: 0.0955, Train: 100.00%, Valid: 79.40% Test: 75.40%
Split: 01, Run: 02
None time:  4.827445766888559
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 03
None time:  4.812128671910614
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 74.00
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.5047814671415836
None Run 04:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 66.30
Split: 02, Run: 02
None time:  1.5835201072040945
None Run 05:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 64.30
Split: 02, Run: 03
None time:  1.074986943975091
None Run 06:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 59.10
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  0.9531859860289842
None Run 07:
Highest Train: 100.00
Highest Valid: 63.00
  Final Train: 100.00
   Final Test: 63.80
Split: 03, Run: 02
None time:  0.9771189459133893
None Run 08:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 62.60
Split: 03, Run: 03
None time:  0.927354654064402
None Run 09:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 50.50
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  1.5874316170811653
None Run 10:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.00
Split: 04, Run: 02
None time:  0.9281004490330815
None Run 11:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 61.30
Split: 04, Run: 03
None time:  1.039836377138272
None Run 12:
Highest Train: 100.00
Highest Valid: 63.20
  Final Train: 100.00
   Final Test: 60.90
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.9180606508161873
None Run 13:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 66.00
Split: 05, Run: 02
None time:  2.078380976105109
None Run 14:
Highest Train: 100.00
Highest Valid: 65.20
  Final Train: 100.00
   Final Test: 62.50
Split: 05, Run: 03
None time:  2.1652002709452063
None Run 15:
Highest Train: 100.00
Highest Valid: 71.60
  Final Train: 100.00
   Final Test: 69.20
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.1795533790718764
None Run 16:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 57.80
Split: 06, Run: 02
None time:  2.0616690029855818
None Run 17:
Highest Train: 100.00
Highest Valid: 54.00
  Final Train: 100.00
   Final Test: 53.50
Split: 06, Run: 03
None time:  0.8187369771767408
None Run 18:
Highest Train: 100.00
Highest Valid: 48.80
  Final Train: 100.00
   Final Test: 46.90
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.6604125888552517
None Run 19:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 71.10
Split: 07, Run: 02
None time:  1.6338694361038506
None Run 20:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 72.20
Split: 07, Run: 03
None time:  2.762821082957089
None Run 21:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 70.80
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.8651084201410413
None Run 22:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 72.20
Split: 08, Run: 02
None time:  1.6792451611254364
None Run 23:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.90
Split: 08, Run: 03
None time:  1.0916524790227413
None Run 24:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 76.10
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  0.9365945479366928
None Run 25:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 64.40
Split: 09, Run: 02
None time:  0.9054456849116832
None Run 26:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 67.00
Split: 09, Run: 03
None time:  0.8839358689729124
None Run 27:
Highest Train: 100.00
Highest Valid: 57.60
  Final Train: 100.00
   Final Test: 58.30
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.2228425778448582
None Run 28:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 74.20
Split: 10, Run: 02
None time:  0.9335222281515598
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.80
Split: 10, Run: 03
None time:  2.1332330238074064
None Run 30:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 72.30
run time now: 4.332536935806274
total time:  52.193079858087
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.42 ± 7.70
  Final Train: 100.00 ± 0.00
   Final Test: 66.00 ± 7.60
best run test_acc: 69.1199951171875
[I 2023-06-12 00:56:41,205] Trial 46 finished with value: 66.42000579833984 and parameters: {'Fwd': 9.332560025050412e-06, 'K': 9, 'alpha': 0.45, 'dropout': 0.8, 'gnnepoch': 20, 'lambda1': 0.65, 'lambda2': 8.111132847007159, 'loop': 1, 'loss': 'MSE', 'lr': 0.004884937905506563, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0316317513721046e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.0
lr:  0.0020405676462640675
weight_decay:  5.0256046057870625e-06
dropout:  0.7000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9893659900408238
None Run 01:
Highest Train: 100.00
Highest Valid: 43.80
  Final Train: 100.00
   Final Test: 41.60
Split: 01, Run: 02
None time:  0.8482262708712369
None Run 02:
Highest Train: 100.00
Highest Valid: 40.00
  Final Train: 100.00
   Final Test: 38.20
Split: 01, Run: 03
None time:  1.350817342987284
None Run 03:
Highest Train: 100.00
Highest Valid: 47.80
  Final Train: 100.00
   Final Test: 46.50
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0446773499716073
None Run 04:
Highest Train: 100.00
Highest Valid: 44.20
  Final Train: 100.00
   Final Test: 46.80
Split: 02, Run: 02
None time:  0.8239969140850008
None Run 05:
Highest Train: 100.00
Highest Valid: 41.20
  Final Train: 100.00
   Final Test: 42.00
Split: 02, Run: 03
None time:  1.2917265901342034
None Run 06:
Highest Train: 100.00
Highest Valid: 51.80
  Final Train: 100.00
   Final Test: 57.60
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.3352260699030012
None Run 07:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 40.60
Split: 03, Run: 02
None time:  0.9396579950116575
None Run 08:
Highest Train: 100.00
Highest Valid: 40.60
  Final Train: 100.00
   Final Test: 40.00
Split: 03, Run: 03
None time:  0.9113317017909139
None Run 09:
Highest Train: 100.00
Highest Valid: 45.20
  Final Train: 100.00
   Final Test: 46.80
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  0.8631465781945735
None Run 10:
Highest Train: 100.00
Highest Valid: 41.80
  Final Train: 100.00
   Final Test: 41.30
Split: 04, Run: 02
None time:  0.8300955628510565
None Run 11:
Highest Train: 100.00
Highest Valid: 30.20
  Final Train: 100.00
   Final Test: 27.40
Split: 04, Run: 03
None time:  0.9228654701728374
None Run 12:
Highest Train: 100.00
Highest Valid: 42.40
  Final Train: 100.00
   Final Test: 38.40
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1994121719617397
None Run 13:
Highest Train: 100.00
Highest Valid: 41.60
  Final Train: 100.00
   Final Test: 34.60
Split: 05, Run: 02
None time:  1.5083450339734554
None Run 14:
Highest Train: 100.00
Highest Valid: 49.00
  Final Train: 100.00
   Final Test: 44.50
Split: 05, Run: 03
None time:  1.3394114109687507
None Run 15:
Highest Train: 100.00
Highest Valid: 52.20
  Final Train: 100.00
   Final Test: 48.30
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  0.9748341129161417
None Run 16:
Highest Train: 100.00
Highest Valid: 29.20
  Final Train: 100.00
   Final Test: 27.50
Split: 06, Run: 02
None time:  0.8605859340168536
None Run 17:
Highest Train: 100.00
Highest Valid: 20.40
  Final Train: 100.00
   Final Test: 17.10
Split: 06, Run: 03
None time:  1.4132389519363642
None Run 18:
Highest Train: 100.00
Highest Valid: 33.80
  Final Train: 100.00
   Final Test: 34.40
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.1650454150512815
None Run 19:
Highest Train: 100.00
Highest Valid: 37.80
  Final Train: 100.00
   Final Test: 39.00
Split: 07, Run: 02
None time:  0.8677834160625935
None Run 20:
Highest Train: 100.00
Highest Valid: 47.40
  Final Train: 100.00
   Final Test: 49.90
Split: 07, Run: 03
None time:  1.433385306969285
None Run 21:
Highest Train: 100.00
Highest Valid: 49.20
  Final Train: 100.00
   Final Test: 46.00
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  0.949534583138302
None Run 22:
Highest Train: 100.00
Highest Valid: 51.20
  Final Train: 100.00
   Final Test: 52.90
Split: 08, Run: 02
None time:  1.763847335940227
None Run 23:
Highest Train: 100.00
Highest Valid: 54.80
  Final Train: 100.00
   Final Test: 57.10
Split: 08, Run: 03
None time:  1.1989238860551268
None Run 24:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 63.60
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.2932004760950804
None Run 25:
Highest Train: 100.00
Highest Valid: 42.80
  Final Train: 100.00
   Final Test: 38.90
Split: 09, Run: 02
None time:  1.6778309438377619
None Run 26:
Highest Train: 100.00
Highest Valid: 52.60
  Final Train: 100.00
   Final Test: 49.40
Split: 09, Run: 03
None time:  1.2743784140329808
None Run 27:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 51.10
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  0.9380654830019921
None Run 28:
Highest Train: 100.00
Highest Valid: 33.40
  Final Train: 100.00
   Final Test: 37.10
Split: 10, Run: 02
None time:  0.8280722841154784
None Run 29:
Highest Train: 100.00
Highest Valid: 31.80
  Final Train: 100.00
   Final Test: 35.40
Split: 10, Run: 03
None time:  0.8986065129283816
None Run 30:
Highest Train: 100.00
Highest Valid: 38.60
  Final Train: 100.00
   Final Test: 41.20
run time now: 2.6920337677001953
total time:  34.28288595797494
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 42.96 ± 8.76
  Final Train: 100.00 ± 0.00
   Final Test: 42.51 ± 9.57
best run test_acc: 48.06999969482422
[I 2023-06-12 00:57:16,085] Trial 47 finished with value: 42.96000289916992 and parameters: {'Fwd': 9.453360004554628e-05, 'K': 1, 'alpha': 0.0, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 7.442277517788061, 'loop': 1, 'loss': 'MSE', 'lr': 0.0020405676462640675, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.0256046057870625e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.35000000000000003
lr:  0.0012751218492875723
weight_decay:  1.8764124941022002e-06
dropout:  0.6000000000000001
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1460, Train: 100.00%, Valid: 75.60% Test: 71.60%
Split: 01, Run: 01
None time:  3.9847556459717453
None Run 01:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 71.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.1315, Train: 100.00%, Valid: 74.60% Test: 71.70%
Split: 01, Run: 02
None time:  4.005138411885127
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 71.20
Split: 01, Run: 03
None time:  2.8594117870088667
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 73.30
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  3.390269701136276
None Run 04:
Highest Train: 100.00
Highest Valid: 59.20
  Final Train: 100.00
   Final Test: 63.90
Split: 02, Run: 02
None time:  2.8300327998586
None Run 05:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 65.50
Split: 02, Run: 03, Epoch: 100, Loss: 0.1531, Train: 100.00%, Valid: 57.80% Test: 61.30%
Split: 02, Run: 03
None time:  4.095106404973194
None Run 06:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 61.20
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  3.388072354020551
None Run 07:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 69.70
Split: 03, Run: 02
None time:  1.786091207060963
None Run 08:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 64.50
Split: 03, Run: 03, Epoch: 100, Loss: 0.1718, Train: 100.00%, Valid: 66.40% Test: 66.10%
Split: 03, Run: 03
None time:  3.7862221230752766
None Run 09:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 65.90
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.5614924288820475
None Run 10:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 64.30
Split: 04, Run: 02
None time:  1.2685541801620275
None Run 11:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 59.10
Split: 04, Run: 03
None time:  2.5522641111165285
None Run 12:
Highest Train: 100.00
Highest Valid: 63.60
  Final Train: 100.00
   Final Test: 62.20
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  3.806173278018832
None Run 13:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 65.60
Split: 05, Run: 02, Epoch: 100, Loss: 0.2039, Train: 100.00%, Valid: 63.40% Test: 61.40%
Split: 05, Run: 02
None time:  3.9992330260574818
None Run 14:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 61.40
Split: 05, Run: 03
None time:  3.399288750020787
None Run 15:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 62.20
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.9895277309697121
None Run 16:
Highest Train: 100.00
Highest Valid: 52.00
  Final Train: 100.00
   Final Test: 51.80
Split: 06, Run: 02
None time:  2.5836381730623543
None Run 17:
Highest Train: 100.00
Highest Valid: 57.80
  Final Train: 100.00
   Final Test: 57.10
Split: 06, Run: 03, Epoch: 100, Loss: 0.2084, Train: 100.00%, Valid: 56.20% Test: 57.90%
Split: 06, Run: 03
None time:  4.041417672997341
None Run 18:
Highest Train: 100.00
Highest Valid: 57.00
  Final Train: 100.00
   Final Test: 57.60
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  1.6912053499836475
None Run 19:
Highest Train: 100.00
Highest Valid: 71.80
  Final Train: 100.00
   Final Test: 72.70
Split: 07, Run: 02
None time:  1.7665525150950998
None Run 20:
Highest Train: 100.00
Highest Valid: 75.00
  Final Train: 100.00
   Final Test: 74.50
Split: 07, Run: 03
None time:  1.632551590912044
None Run 21:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 73.30
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  2.7848347229883075
None Run 22:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 73.90
Split: 08, Run: 02
None time:  1.4067792231217027
None Run 23:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 74.00
Split: 08, Run: 03
None time:  1.5175109000410885
None Run 24:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.30
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.5613418729044497
None Run 25:
Highest Train: 100.00
Highest Valid: 68.40
  Final Train: 100.00
   Final Test: 68.90
Split: 09, Run: 02
None time:  2.683542141923681
None Run 26:
Highest Train: 100.00
Highest Valid: 67.00
  Final Train: 100.00
   Final Test: 67.50
Split: 09, Run: 03
None time:  1.3917791119311005
None Run 27:
Highest Train: 100.00
Highest Valid: 70.00
  Final Train: 100.00
   Final Test: 69.70
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.4276444409042597
None Run 28:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 71.80
Split: 10, Run: 02
None time:  1.3454267499037087
None Run 29:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 70.70
Split: 10, Run: 03
None time:  2.546191926812753
None Run 30:
Highest Train: 100.00
Highest Valid: 69.60
  Final Train: 100.00
   Final Test: 72.40
run time now: 5.3456244468688965
total time:  78.59993040096015
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 67.08 ± 6.26
  Final Train: 100.00 ± 0.00
   Final Test: 66.96 ± 5.95
best run test_acc: 68.66000366210938
[I 2023-06-12 00:58:35,117] Trial 48 finished with value: 67.08000183105469 and parameters: {'Fwd': 2.690744065517314e-05, 'K': 2, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 6.8766756798322435, 'loop': 1, 'loss': 'MSE', 'lr': 0.0012751218492875723, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8764124941022002e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.55
lr:  0.0025110194540791516
weight_decay:  9.387365715259273e-06
dropout:  0.9
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.766256745904684
None Run 01:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 72.60
Split: 01, Run: 02
None time:  2.366891738958657
None Run 02:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 72.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.2013, Train: 100.00%, Valid: 78.40% Test: 72.80%
Split: 01, Run: 03
None time:  4.006292294943705
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 72.20
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.0782310240902007
None Run 04:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 61.00
Split: 02, Run: 02
None time:  1.4329226871486753
None Run 05:
Highest Train: 100.00
Highest Valid: 57.20
  Final Train: 100.00
   Final Test: 61.50
Split: 02, Run: 03
None time:  1.5423052080441266
None Run 06:
Highest Train: 100.00
Highest Valid: 66.00
  Final Train: 100.00
   Final Test: 66.10
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01
None time:  1.100284214131534
None Run 07:
Highest Train: 100.00
Highest Valid: 67.20
  Final Train: 100.00
   Final Test: 68.20
Split: 03, Run: 02
None time:  1.1390141339506954
None Run 08:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 58.40
Split: 03, Run: 03
None time:  1.3188095779623836
None Run 09:
Highest Train: 100.00
Highest Valid: 71.40
  Final Train: 100.00
   Final Test: 71.00
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  2.3429522609803826
None Run 10:
Highest Train: 100.00
Highest Valid: 69.40
  Final Train: 100.00
   Final Test: 69.40
Split: 04, Run: 02
None time:  1.179858909221366
None Run 11:
Highest Train: 100.00
Highest Valid: 62.20
  Final Train: 100.00
   Final Test: 60.00
Split: 04, Run: 03
None time:  1.1108909130562097
None Run 12:
Highest Train: 100.00
Highest Valid: 60.40
  Final Train: 100.00
   Final Test: 56.90
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  1.1263394430279732
None Run 13:
Highest Train: 100.00
Highest Valid: 53.40
  Final Train: 100.00
   Final Test: 53.40
Split: 05, Run: 02
None time:  1.0710738929919899
None Run 14:
Highest Train: 100.00
Highest Valid: 59.40
  Final Train: 100.00
   Final Test: 55.10
Split: 05, Run: 03, Epoch: 100, Loss: 0.2944, Train: 100.00%, Valid: 63.80% Test: 60.70%
Split: 05, Run: 03
None time:  3.927986677037552
None Run 15:
Highest Train: 100.00
Highest Valid: 64.00
  Final Train: 100.00
   Final Test: 60.60
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.06529908394441
None Run 16:
Highest Train: 100.00
Highest Valid: 61.60
  Final Train: 100.00
   Final Test: 61.20
Split: 06, Run: 02
None time:  1.176498348126188
None Run 17:
Highest Train: 100.00
Highest Valid: 53.60
  Final Train: 100.00
   Final Test: 53.60
Split: 06, Run: 03
None time:  1.810975210973993
None Run 18:
Highest Train: 100.00
Highest Valid: 50.60
  Final Train: 100.00
   Final Test: 49.60
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  3.481203925097361
None Run 19:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 71.70
Split: 07, Run: 02
None time:  1.1563502810895443
None Run 20:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.60
Split: 07, Run: 03, Epoch: 100, Loss: 0.2624, Train: 100.00%, Valid: 75.20% Test: 75.00%
Split: 07, Run: 03
None time:  3.8849452829454094
None Run 21:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 75.00
len(train) 35
random split Cora split 7
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 08, Run: 01
None time:  1.5511447521857917
None Run 22:
Highest Train: 100.00
Highest Valid: 72.00
  Final Train: 100.00
   Final Test: 74.40
Split: 08, Run: 02
None time:  1.2394894799217582
None Run 23:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.60
Split: 08, Run: 03
None time:  1.885544537100941
None Run 24:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 73.20
len(train) 35
random split Cora split 8
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 09, Run: 01
None time:  1.1607879009097815
None Run 25:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 72.80
Split: 09, Run: 02
None time:  1.1080005320254713
None Run 26:
Highest Train: 100.00
Highest Valid: 69.00
  Final Train: 100.00
   Final Test: 67.20
Split: 09, Run: 03
None time:  1.0818782190326601
None Run 27:
Highest Train: 100.00
Highest Valid: 60.20
  Final Train: 100.00
   Final Test: 55.80
len(train) 35
random split Cora split 9
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 10, Run: 01
None time:  1.1672718399204314
None Run 28:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 70.70
Split: 10, Run: 02
None time:  1.994063048856333
None Run 29:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 71.90
Split: 10, Run: 03
None time:  1.0607584898825735
None Run 30:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 64.80
run time now: 4.2497780323028564
total time:  52.83375767292455
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.23 ± 7.61
  Final Train: 100.00 ± 0.00
   Final Test: 65.57 ± 7.61
best run test_acc: 69.5
[I 2023-06-12 00:59:28,400] Trial 49 finished with value: 66.22666931152344 and parameters: {'Fwd': 4.470544627134258e-05, 'K': 3, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 40, 'lambda1': 0.45, 'lambda2': 5.415058450785298, 'loop': 1, 'loss': 'MSE', 'lr': 0.0025110194540791516, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.387365715259273e-06, 'weightedloss': True}. Best is trial 35 with value: 68.52666473388672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.6000000000000001
lr:  0.0019053515460892658
weight_decay:  1.7313733154541138e-06
dropout:  0.8
random split 10 times and each for 3 runs
len(train) 35
random split Cora split 0
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.743916980922222
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 02
None time:  1.2764299281407148
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  2.219354891916737
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 72.50
len(train) 35
random split Cora split 1
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 02, Run: 01
None time:  1.2193831328768283
None Run 04:
Highest Train: 100.00
Highest Valid: 58.80
  Final Train: 100.00
   Final Test: 61.80
Split: 02, Run: 02
None time:  1.2608298740815371
None Run 05:
Highest Train: 100.00
Highest Valid: 55.40
  Final Train: 100.00
   Final Test: 58.60
Split: 02, Run: 03
None time:  1.234619062859565
None Run 06:
Highest Train: 100.00
Highest Valid: 56.20
  Final Train: 100.00
   Final Test: 58.70
len(train) 35
random split Cora split 2
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 03, Run: 01, Epoch: 100, Loss: 0.1502, Train: 100.00%, Valid: 67.20% Test: 67.60%
Split: 03, Run: 01
None time:  3.760673973010853
None Run 07:
Highest Train: 100.00
Highest Valid: 67.80
  Final Train: 100.00
   Final Test: 67.70
Split: 03, Run: 02
None time:  1.2143684171605855
None Run 08:
Highest Train: 100.00
Highest Valid: 62.60
  Final Train: 100.00
   Final Test: 60.10
Split: 03, Run: 03
None time:  1.5856022201478481
None Run 09:
Highest Train: 100.00
Highest Valid: 68.60
  Final Train: 100.00
   Final Test: 69.10
len(train) 35
random split Cora split 3
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 04, Run: 01
None time:  3.523063214030117
None Run 10:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 63.70
Split: 04, Run: 02
None time:  1.3410717851947993
None Run 11:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 62.40
Split: 04, Run: 03
None time:  2.4384171990677714
None Run 12:
Highest Train: 100.00
Highest Valid: 62.80
  Final Train: 100.00
   Final Test: 58.10
len(train) 35
random split Cora split 4
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 05, Run: 01
None time:  2.31104849698022
None Run 13:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 64.50
Split: 05, Run: 02
None time:  2.532000902108848
None Run 14:
Highest Train: 100.00
Highest Valid: 65.60
  Final Train: 100.00
   Final Test: 61.90
Split: 05, Run: 03
None time:  1.3343099870253354
None Run 15:
Highest Train: 100.00
Highest Valid: 65.40
  Final Train: 100.00
   Final Test: 61.30
len(train) 35
random split Cora split 5
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 06, Run: 01
None time:  1.5409484691917896
None Run 16:
Highest Train: 100.00
Highest Valid: 63.40
  Final Train: 100.00
   Final Test: 59.10
Split: 06, Run: 02
None time:  1.9617409640923142
None Run 17:
Highest Train: 100.00
Highest Valid: 53.80
  Final Train: 100.00
   Final Test: 54.20
Split: 06, Run: 03
None time:  1.7168174521066248
None Run 18:
Highest Train: 100.00
Highest Valid: 53.20
  Final Train: 100.00
   Final Test: 52.20
len(train) 35
random split Cora split 6
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(35, device='cuda:0')
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 07, Run: 01
None time:  2.696602868149057
None Run 19:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 66.40
Split: 07, Run: 02
None time:  1.4247670050244778
None Run 20:
Highest Train: 100.00
Highest Valid: 72.20
  Final Train: 100.00
   Final Test: 71.90
