[I 2023-06-12 00:12:20,426] A new study created in RDB with name: Cora_ALTOPT
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.15000000000000002
lr:  0.0005641130232810538
weight_decay:  1.5157192410327001e-05
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2817432368174195
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 02
None time:  1.1460212802048773
None Run 02:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.60% Test: 78.70%
Split: 01, Run: 03
None time:  4.0730769000947475
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.80
run time now: 7.5276243686676025
total time:  9.268166882917285
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 78.43 ± 0.64
[I 2023-06-12 00:12:30,408] Trial 0 finished with value: 78.20000457763672 and parameters: {'Fwd': 0.003242215488953444, 'K': 10, 'alpha': 0.15000000000000002, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 1.0, 'lambda2': 6.4625375272157015, 'loop': 0, 'loss': 'CE', 'lr': 0.0005641130232810538, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.5157192410327001e-05, 'weightedloss': False}. Best is trial 0 with value: 78.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.15000000000000002
lr:  0.00010334386356539129
weight_decay:  0.0030641825665396315
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.594500879989937
None Run 01:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 73.00
Split: 01, Run: 02
None time:  0.5299097830429673
None Run 02:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 73.00
Split: 01, Run: 03
None time:  0.5935447087977082
None Run 03:
Highest Train: 100.00
Highest Valid: 72.40
  Final Train: 100.00
   Final Test: 73.00
run time now: 1.7414193153381348
total time:  1.766035865060985
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 73.00 ± 0.00
[I 2023-06-12 00:12:32,726] Trial 1 finished with value: 72.39999389648438 and parameters: {'Fwd': 2.1733443573136583e-06, 'K': 2, 'alpha': 0.15000000000000002, 'dropout': 0.2, 'gnnepoch': 10, 'lambda1': 0.0, 'lambda2': 9.731837095573022, 'loop': 0, 'loss': 'MSE', 'lr': 0.00010334386356539129, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0030641825665396315, 'weightedloss': False}. Best is trial 0 with value: 78.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.6000000000000001
lr:  0.00029557494619203445
weight_decay:  1.93527790029059e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5972522171214223
None Run 01:
Highest Train: 100.00
Highest Valid: 66.40
  Final Train: 100.00
   Final Test: 68.10
Split: 01, Run: 02
None time:  0.756099039921537
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  0.8544256018940359
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 98.57
   Final Test: 79.20
run time now: 2.2329962253570557
total time:  2.246706746984273
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.00 ± 7.46
  Final Train: 99.52 ± 0.82
   Final Test: 75.90 ± 6.78
[I 2023-06-12 00:12:35,446] Trial 2 finished with value: 74.99999237060547 and parameters: {'Fwd': 0.001623690929324474, 'K': 6, 'alpha': 0.6000000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 30, 'lambda1': 0.6000000000000001, 'lambda2': 3.3461085525513323, 'loop': 2, 'loss': 'CE', 'lr': 0.00029557494619203445, 'softmaxF': False, 'useGCN': False, 'weight_decay': 1.93527790029059e-05, 'weightedloss': False}. Best is trial 0 with value: 78.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.15000000000000002
lr:  0.0009733041995323159
weight_decay:  4.9590200221000706e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9378184461966157
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 97.86
   Final Test: 80.20
Split: 01, Run: 02
None time:  2.174165643984452
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 97.86
   Final Test: 78.00
Split: 01, Run: 03
None time:  2.0499510690569878
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 97.86
   Final Test: 74.50
run time now: 6.196595191955566
total time:  6.244604740990326
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.67 ± 2.58
  Final Train: 97.86 ± 0.00
   Final Test: 77.57 ± 2.87
[I 2023-06-12 00:12:42,138] Trial 3 finished with value: 77.66666412353516 and parameters: {'Fwd': 0.00241545564501405, 'K': 6, 'alpha': 0.15000000000000002, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8500000000000001, 'lambda2': 0.2514446324048403, 'loop': 1, 'loss': 'CE', 'lr': 0.0009733041995323159, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.9590200221000706e-05, 'weightedloss': True}. Best is trial 0 with value: 78.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.05
lr:  0.0002626264834047168
weight_decay:  0.0006326062480911402
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 70.80% Test: 70.10%
Split: 01, Run: 01
None time:  1.3582667100708932
None Run 01:
Highest Train: 100.00
Highest Valid: 70.80
  Final Train: 100.00
   Final Test: 70.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 71.20% Test: 71.90%
Split: 01, Run: 02
None time:  1.0126685111317784
None Run 02:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 71.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.20% Test: 76.70%
Split: 01, Run: 03
None time:  1.3053925621788949
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 76.70
run time now: 3.702666997909546
total time:  3.7310672600287944
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.07 ± 3.59
  Final Train: 100.00 ± 0.00
   Final Test: 72.90 ± 3.41
[I 2023-06-12 00:12:46,187] Trial 4 finished with value: 73.0666732788086 and parameters: {'Fwd': 0.02682516663018761, 'K': 3, 'alpha': 0.05, 'dropout': 0.2, 'gnnepoch': 20, 'lambda1': 0.05, 'lambda2': 5.46661989944142, 'loop': 0, 'loss': 'CE', 'lr': 0.0002626264834047168, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0006326062480911402, 'weightedloss': False}. Best is trial 0 with value: 78.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.0050692193900782325
weight_decay:  0.00039773654110796517
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5952877369709313
None Run 01:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 74.20
Split: 01, Run: 02
None time:  0.6073597299400717
None Run 02:
Highest Train: 100.00
Highest Valid: 69.20
  Final Train: 100.00
   Final Test: 72.80
Split: 01, Run: 03
None time:  0.5695046610198915
None Run 03:
Highest Train: 100.00
Highest Valid: 67.40
  Final Train: 100.00
   Final Test: 68.90
run time now: 1.8007514476776123
total time:  1.825080615002662
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 1.25
  Final Train: 100.00 ± 0.00
   Final Test: 71.97 ± 2.75
[I 2023-06-12 00:12:48,356] Trial 5 finished with value: 68.79999542236328 and parameters: {'Fwd': 0.002752748196582699, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 0, 'lambda1': 0.5, 'lambda2': 2.2162694957320506, 'loop': 1, 'loss': 'CE', 'lr': 0.0050692193900782325, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00039773654110796517, 'weightedloss': False}. Best is trial 0 with value: 78.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.15000000000000002
lr:  0.0005559415389434975
weight_decay:  3.0324696550235855e-06
dropout:  0.0
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.5190135361626744
None Run 01:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 02
None time:  0.4910703038331121
None Run 02:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.70
Split: 01, Run: 03
None time:  0.548884998075664
None Run 03:
Highest Train: 100.00
Highest Valid: 65.80
  Final Train: 100.00
   Final Test: 67.70
run time now: 1.585428237915039
total time:  1.6068464629352093
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 65.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 67.70 ± 0.00
[I 2023-06-12 00:12:50,327] Trial 6 finished with value: 65.80000305175781 and parameters: {'Fwd': 0.00044696329638764943, 'K': 7, 'alpha': 0.15000000000000002, 'dropout': 0.0, 'gnnepoch': 10, 'lambda1': 0.5, 'lambda2': 6.97595221261674, 'loop': 2, 'loss': 'MSE', 'lr': 0.0005559415389434975, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.0324696550235855e-06, 'weightedloss': True}. Best is trial 0 with value: 78.20000457763672.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.0009431200994321406
weight_decay:  4.0708602506451635e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0665242339018732
None Run 01:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  0.9977770049590617
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.087668715044856
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.80
run time now: 3.181626081466675
total time:  3.210539791965857
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 79.87 ± 1.45
[I 2023-06-12 00:12:53,920] Trial 7 finished with value: 78.9333267211914 and parameters: {'Fwd': 0.000995068937537282, 'K': 9, 'alpha': 0.55, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.25, 'lambda2': 7.5644523251095706, 'loop': 2, 'loss': 'CE', 'lr': 0.0009431200994321406, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.0708602506451635e-05, 'weightedloss': True}. Best is trial 7 with value: 78.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.0007970507597534947
weight_decay:  3.9659046191106466e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.450107195880264
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  2.3837228128686547
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 03
None time:  1.997615208150819
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 76.30
run time now: 5.852769136428833
total time:  5.876139726955444
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 76.77 ± 0.42
[I 2023-06-12 00:13:00,264] Trial 8 finished with value: 78.33333587646484 and parameters: {'Fwd': 0.02362150837126448, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.8415348134826237, 'loop': 2, 'loss': 'MSE', 'lr': 0.0007970507597534947, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.9659046191106466e-06, 'weightedloss': False}. Best is trial 7 with value: 78.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.8500000000000001
lr:  0.0007114004267274486
weight_decay:  0.00025954559540319167
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8663801550865173
None Run 01:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 76.80
Split: 01, Run: 02
None time:  1.1504715310875326
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 75.90
Split: 01, Run: 03, Epoch: 100, Loss: 0.1089, Train: 100.00%, Valid: 77.60% Test: 78.30%
Split: 01, Run: 03
None time:  2.63012111117132
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.90
run time now: 4.672596216201782
total time:  4.702721308916807
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.47 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 77.20 ± 1.54
[I 2023-06-12 00:13:05,300] Trial 9 finished with value: 77.46666717529297 and parameters: {'Fwd': 0.0001295071796393754, 'K': 2, 'alpha': 0.8500000000000001, 'dropout': 0.2, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 9.459353704917222, 'loop': 1, 'loss': 'MSE', 'lr': 0.0007114004267274486, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00025954559540319167, 'weightedloss': True}. Best is trial 7 with value: 78.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.002651721856923424
weight_decay:  0.08994194134914757
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8925193750765175
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 02
None time:  1.7849420281127095
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.7485283510759473
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 79.20
run time now: 5.450912952423096
total time:  5.477105554193258
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 79.60 ± 1.15
[I 2023-06-12 00:13:11,205] Trial 10 finished with value: 78.9333267211914 and parameters: {'Fwd': 3.3568772426800454e-05, 'K': 10, 'alpha': 0.45, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 7.795413112811409, 'loop': 2, 'loss': 'CE', 'lr': 0.002651721856923424, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.08994194134914757, 'weightedloss': True}. Best is trial 7 with value: 78.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0026753660821477302
weight_decay:  0.08468448768469158
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8989321428816766
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 02
None time:  1.7820060451049358
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.7319599429611117
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 79.50
run time now: 5.44001579284668
total time:  5.458487113006413
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 79.73 ± 1.17
[I 2023-06-12 00:13:17,187] Trial 11 finished with value: 78.9333267211914 and parameters: {'Fwd': 5.170680827969147e-05, 'K': 10, 'alpha': 0.4, 'dropout': 0.9, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 7.649043557050067, 'loop': 2, 'loss': 'CE', 'lr': 0.0026753660821477302, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.08468448768469158, 'weightedloss': True}. Best is trial 7 with value: 78.9333267211914.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.002288280718874187
weight_decay:  0.08508211456845609
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.099466506158933
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 02
None time:  2.023658350808546
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.8059361660853028
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.80
run time now: 5.956495761871338
total time:  5.982454532990232
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 80.07 ± 0.64
[I 2023-06-12 00:13:23,606] Trial 12 finished with value: 79.26666259765625 and parameters: {'Fwd': 2.5540472969460064e-05, 'K': 9, 'alpha': 0.4, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.123063880422347, 'loop': 2, 'loss': 'CE', 'lr': 0.002288280718874187, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.08508211456845609, 'weightedloss': True}. Best is trial 12 with value: 79.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.4
lr:  0.001941083134380361
weight_decay:  0.0095959819049298
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.171454151859507
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 02
None time:  2.013328932924196
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  2.1582946290727705
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 6.368106126785278
total time:  6.3955275469925255
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.73 ± 1.33
  Final Train: 100.00 ± 0.00
   Final Test: 79.70 ± 1.41
[I 2023-06-12 00:13:30,472] Trial 13 finished with value: 78.73333740234375 and parameters: {'Fwd': 9.541966400976271e-06, 'K': 8, 'alpha': 0.4, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.25, 'lambda2': 8.578666810804997, 'loop': 2, 'loss': 'CE', 'lr': 0.001941083134380361, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0095959819049298, 'weightedloss': True}. Best is trial 12 with value: 79.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.6000000000000001
lr:  0.008509880898413518
weight_decay:  7.785530720387934e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.69743955694139
None Run 01:
Highest Train: 100.00
Highest Valid: 68.00
  Final Train: 100.00
   Final Test: 69.50
Split: 01, Run: 02
None time:  0.7039375780150294
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 75.80
Split: 01, Run: 03
None time:  0.7756369300186634
None Run 03:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 75.50
run time now: 2.204113721847534
total time:  2.22804105700925
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.53 ± 4.82
  Final Train: 100.00 ± 0.00
   Final Test: 73.60 ± 3.55
[I 2023-06-12 00:13:33,125] Trial 14 finished with value: 73.53333282470703 and parameters: {'Fwd': 1.023487478480429e-06, 'K': 8, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 40, 'lambda1': 0.15000000000000002, 'lambda2': 5.752815494485354, 'loop': 1, 'loss': 'CE', 'lr': 0.008509880898413518, 'softmaxF': False, 'useGCN': False, 'weight_decay': 7.785530720387934e-05, 'weightedloss': True}. Best is trial 12 with value: 79.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.35000000000000003
lr:  0.0017926246788926496
weight_decay:  0.010139065767836151
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.019657213939354
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 02
None time:  1.5364006177987903
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  2.034078281139955
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 77.80
run time now: 5.615306615829468
total time:  5.6346457751933485
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.60 ± 1.60
  Final Train: 100.00 ± 0.00
   Final Test: 79.43 ± 1.52
[I 2023-06-12 00:13:39,216] Trial 15 finished with value: 78.5999984741211 and parameters: {'Fwd': 0.00029110180176484163, 'K': 4, 'alpha': 0.35000000000000003, 'dropout': 0.7000000000000001, 'gnnepoch': 80, 'lambda1': 0.4, 'lambda2': 8.416868378747663, 'loop': 2, 'loss': 'CE', 'lr': 0.0017926246788926496, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.010139065767836151, 'weightedloss': True}. Best is trial 12 with value: 79.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.30000000000000004
lr:  0.0016552232708709719
weight_decay:  1.0842156440137096e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5762364699039608
None Run 01:
Highest Train: 100.00
Highest Valid: 74.40
  Final Train: 100.00
   Final Test: 73.30
Split: 01, Run: 02
None time:  1.5921655429992825
None Run 02:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.4846815878991038
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.50
run time now: 4.68160343170166
total time:  4.709953560028225
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.40 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 76.03 ± 2.53
[I 2023-06-12 00:13:44,382] Trial 16 finished with value: 75.4000015258789 and parameters: {'Fwd': 1.159087281148968e-05, 'K': 9, 'alpha': 0.30000000000000004, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.65, 'lambda2': 6.752063313349325, 'loop': 1, 'loss': 'CE', 'lr': 0.0016552232708709719, 'softmaxF': True, 'useGCN': False, 'weight_decay': 1.0842156440137096e-06, 'weightedloss': True}. Best is trial 12 with value: 79.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.0040860551931358085
weight_decay:  0.002491410702465506
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9785754659678787
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.883380874991417
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.7845812330488116
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.80
run time now: 5.6728057861328125
total time:  5.73003876907751
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 80.87 ± 1.05
[I 2023-06-12 00:13:50,675] Trial 17 finished with value: 79.5999984741211 and parameters: {'Fwd': 0.08059608375164927, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.1, 'lambda2': 9.843115888237566, 'loop': 2, 'loss': 'CE', 'lr': 0.0040860551931358085, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002491410702465506, 'weightedloss': True}. Best is trial 17 with value: 79.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.004122112129074228
weight_decay:  0.024098331961989686
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3775270979385823
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  3.6631861010100693
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 03
None time:  1.3147898120805621
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.00
run time now: 7.383740186691284
total time:  7.401145511073992
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 80.93 ± 1.62
[I 2023-06-12 00:13:58,621] Trial 18 finished with value: 80.0 and parameters: {'Fwd': 0.061861981757085835, 'K': 8, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 80, 'lambda1': 0.1, 'lambda2': 9.547807356123998, 'loop': 1, 'loss': 'MSE', 'lr': 0.004122112129074228, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.024098331961989686, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.75
lr:  0.004981896933255861
weight_decay:  0.0019112170504015796
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6613855171017349
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 02
None time:  2.102658992866054
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  2.743333112914115
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.40
run time now: 6.533331632614136
total time:  6.560381466988474
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 80.07 ± 0.58
[I 2023-06-12 00:14:05,746] Trial 19 finished with value: 79.99999237060547 and parameters: {'Fwd': 0.04392146848057891, 'K': 4, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.1, 'lambda2': 9.82886908597373, 'loop': 1, 'loss': 'MSE', 'lr': 0.004981896933255861, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0019112170504015796, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  1.0
lr:  0.007344251556911888
weight_decay:  0.023061042040638104
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1551, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 01
None time:  4.971466238843277
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.1591, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 02
None time:  5.02408313495107
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.1629, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 03
None time:  4.880301327910274
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
run time now: 14.900028944015503
total time:  14.928459024988115
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 73.20 ± 0.00
[I 2023-06-12 00:14:21,133] Trial 20 finished with value: 72.5999984741211 and parameters: {'Fwd': 0.09354602821307596, 'K': 4, 'alpha': 1.0, 'dropout': 0.8, 'gnnepoch': 100, 'lambda1': 0.0, 'lambda2': 9.757724066330166, 'loop': 1, 'loss': 'MSE', 'lr': 0.007344251556911888, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.023061042040638104, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.75
lr:  0.004374203004754441
weight_decay:  0.0018953434849108904
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0485788439400494
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 02
None time:  1.793287588050589
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.734334760112688
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.599426507949829
total time:  5.621456522960216
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 79.57 ± 1.27
[I 2023-06-12 00:14:27,216] Trial 21 finished with value: 79.13333129882812 and parameters: {'Fwd': 0.09878889410907046, 'K': 4, 'alpha': 0.75, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.1, 'lambda2': 9.94940708859267, 'loop': 1, 'loss': 'MSE', 'lr': 0.004374203004754441, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0018953434849108904, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8
lr:  0.004705558515445022
weight_decay:  0.0011708560981867912
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.651206969982013
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  3.9322058288380504
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  3.104379286058247
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.60
run time now: 8.713324069976807
total time:  8.733215742046013
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 80.83 ± 0.68
[I 2023-06-12 00:14:36,426] Trial 22 finished with value: 79.86666107177734 and parameters: {'Fwd': 0.012011677032433143, 'K': 5, 'alpha': 0.8, 'dropout': 0.8, 'gnnepoch': 70, 'lambda1': 0.1, 'lambda2': 8.930219803139915, 'loop': 1, 'loss': 'MSE', 'lr': 0.004705558515445022, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0011708560981867912, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.8500000000000001
lr:  0.008949881902058879
weight_decay:  0.000889659503336198
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2322472240775824
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 02
None time:  2.5310608549043536
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  2.1704953440930694
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.50
run time now: 6.961454629898071
total time:  6.989048861898482
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 79.03 ± 0.50
[I 2023-06-12 00:14:43,947] Trial 23 finished with value: 79.26666259765625 and parameters: {'Fwd': 0.010344347418332733, 'K': 5, 'alpha': 0.8500000000000001, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 8.863311596870576, 'loop': 1, 'loss': 'MSE', 'lr': 0.008949881902058879, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000889659503336198, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.8500000000000001
lr:  0.006081318796857736
weight_decay:  0.004367813657018277
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9802161490079015
None Run 01:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 02
None time:  1.566369203850627
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.5043554578442127
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 79.90
run time now: 5.074992418289185
total time:  5.102999889990315
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 1.83
  Final Train: 100.00 ± 0.00
   Final Test: 79.70 ± 0.17
[I 2023-06-12 00:14:49,473] Trial 24 finished with value: 79.5999984741211 and parameters: {'Fwd': 0.010021256717254158, 'K': 1, 'alpha': 0.8500000000000001, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.4, 'lambda2': 9.134763334511357, 'loop': 1, 'loss': 'MSE', 'lr': 0.006081318796857736, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.004367813657018277, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.7000000000000001
lr:  0.0033517209497927573
weight_decay:  0.0015466525985814283
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.00% Test: 79.40%
Split: 01, Run: 01
None time:  2.773493078071624
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.80% Test: 80.10%
Split: 01, Run: 02
None time:  3.0671842370647937
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.20% Test: 81.50%
Split: 01, Run: 03
None time:  2.3171706979628652
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 81.50
run time now: 8.18464183807373
total time:  8.21162823610939
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 80.30 ± 1.08
[I 2023-06-12 00:14:58,156] Trial 25 finished with value: 78.66666412353516 and parameters: {'Fwd': 0.03648357382043641, 'K': 5, 'alpha': 0.7000000000000001, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.4, 'lambda2': 8.832235841718296, 'loop': 0, 'loss': 'MSE', 'lr': 0.0033517209497927573, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0015466525985814283, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9
lr:  0.005470092171174219
weight_decay:  0.0002219793174723349
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.1479, Train: 100.00%, Valid: 78.40% Test: 79.70%
Split: 01, Run: 01
None time:  4.810107914963737
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  2.1769377710297704
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  3.470981378108263
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.00
run time now: 10.484734058380127
total time:  10.50429095607251
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 79.17 ± 0.47
[I 2023-06-12 00:15:09,168] Trial 26 finished with value: 78.66666412353516 and parameters: {'Fwd': 0.009524139010647538, 'K': 3, 'alpha': 0.9, 'dropout': 0.8, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 8.888183807522843, 'loop': 1, 'loss': 'MSE', 'lr': 0.005470092171174219, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0002219793174723349, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.65
lr:  0.009321535058271052
weight_decay:  0.0009165988813407688
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4240617949981242
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 02
None time:  1.4802816950250417
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.7027297888416797
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.30
run time now: 4.633464336395264
total time:  4.662790103117004
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 79.50 ± 0.82
[I 2023-06-12 00:15:14,393] Trial 27 finished with value: 78.9333267211914 and parameters: {'Fwd': 0.03589314306956134, 'K': 5, 'alpha': 0.65, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.1, 'lambda2': 8.21611157789311, 'loop': 1, 'loss': 'MSE', 'lr': 0.009321535058271052, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0009165988813407688, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.8
lr:  0.0035895781810534218
weight_decay:  0.0057312997906919065
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.80% Test: 79.90%
Split: 01, Run: 01
None time:  2.214274909114465
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 02
None time:  0.927738729165867
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  0.6797498359810561
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.30
run time now: 3.8464696407318115
total time:  3.867889877874404
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 79.43 ± 0.42
[I 2023-06-12 00:15:18,847] Trial 28 finished with value: 78.5999984741211 and parameters: {'Fwd': 0.0062386899131802965, 'K': 3, 'alpha': 0.8, 'dropout': 0.7000000000000001, 'gnnepoch': 40, 'lambda1': 0.75, 'lambda2': 9.319707178084265, 'loop': 0, 'loss': 'MSE', 'lr': 0.0035895781810534218, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0057312997906919065, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  1.0
lr:  0.0064507806026364535
weight_decay:  0.022983753190601176
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.40% Test: 82.20%
Split: 01, Run: 01
None time:  3.9446454669814557
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.00% Test: 80.00%
Split: 01, Run: 02
None time:  3.8710955299902707
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.20% Test: 80.90%
Split: 01, Run: 03
None time:  3.822037070058286
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.90
run time now: 11.674805402755737
total time:  11.729665682883933
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 80.60 ± 0.89
[I 2023-06-12 00:15:31,075] Trial 29 finished with value: 79.19999694824219 and parameters: {'Fwd': 0.004703439271523021, 'K': 7, 'alpha': 1.0, 'dropout': 0.9, 'gnnepoch': 100, 'lambda1': 0.35000000000000003, 'lambda2': 7.1688580000687505, 'loop': 0, 'loss': 'MSE', 'lr': 0.0064507806026364535, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.022983753190601176, 'weightedloss': False}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.00486067922070782
weight_decay:  0.0013733615458254647
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8594390219077468
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  1.6884769150055945
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  1.4054956948384643
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.30
run time now: 4.979680061340332
total time:  5.003473505144939
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 79.77 ± 0.40
[I 2023-06-12 00:15:36,566] Trial 30 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.014980060070577828, 'K': 4, 'alpha': 0.55, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.15000000000000002, 'lambda2': 8.08909875106204, 'loop': 1, 'loss': 'MSE', 'lr': 0.00486067922070782, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0013733615458254647, 'weightedloss': True}. Best is trial 18 with value: 80.0.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.5
lr:  0.004649060625438121
weight_decay:  0.001375598520572717
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9174437311012298
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 02
None time:  2.071241762023419
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.525602402864024
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.10
run time now: 5.563336133956909
total time:  5.580261254915968
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 80.13 ± 0.35
[I 2023-06-12 00:15:42,682] Trial 31 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.016684094636973727, 'K': 4, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.15000000000000002, 'lambda2': 6.313851107255334, 'loop': 1, 'loss': 'MSE', 'lr': 0.004649060625438121, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001375598520572717, 'weightedloss': True}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.5
lr:  0.00316312189023025
weight_decay:  0.002938414856352678
dropout:  0.0
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0798, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 01
None time:  4.483139849035069
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0843, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 02
None time:  4.145672036102042
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0825, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 03
None time:  4.451255560154095
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
run time now: 13.156989812850952
total time:  13.17601071903482
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 73.20 ± 0.00
[I 2023-06-12 00:15:56,372] Trial 32 finished with value: 72.5999984741211 and parameters: {'Fwd': 0.04920621536062976, 'K': 5, 'alpha': 0.5, 'dropout': 0.0, 'gnnepoch': 50, 'lambda1': 0.0, 'lambda2': 6.474623688133938, 'loop': 1, 'loss': 'MSE', 'lr': 0.00316312189023025, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.002938414856352678, 'weightedloss': True}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.65
lr:  0.007100490756434099
weight_decay:  0.0006588261876526263
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9565743969287723
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  2.2306593500543386
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.8779450540896505
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 6.089049816131592
total time:  6.114930031821132
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.47 ± 1.63
  Final Train: 100.00 ± 0.00
   Final Test: 78.27 ± 0.06
[I 2023-06-12 00:16:03,011] Trial 33 finished with value: 79.46666717529297 and parameters: {'Fwd': 0.018472107946628288, 'K': 2, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 9.888059938726569, 'loop': 1, 'loss': 'MSE', 'lr': 0.007100490756434099, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0006588261876526263, 'weightedloss': True}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.25
lr:  0.004547538693886174
weight_decay:  0.000164854047994937
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.2449978759977967
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02
None time:  1.7948432511184365
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.654751606984064
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.720288276672363
total time:  6.7393906489014626
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.30 ± 0.26
[I 2023-06-12 00:16:10,293] Trial 34 finished with value: 78.93333435058594 and parameters: {'Fwd': 0.05090911208527778, 'K': 6, 'alpha': 0.25, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.05, 'lambda2': 9.206291048353435, 'loop': 1, 'loss': 'MSE', 'lr': 0.004547538693886174, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.000164854047994937, 'weightedloss': False}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.75
lr:  0.009871690091029933
weight_decay:  0.0005061521351028191
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0691, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 01
None time:  3.997598585905507
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 02, Epoch: 100, Loss: 0.0700, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 02
None time:  3.9101105539593846
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0818, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 03
None time:  3.9559919969178736
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
run time now: 11.88460397720337
total time:  11.918189845979214
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 73.20 ± 0.00
[I 2023-06-12 00:16:22,798] Trial 35 finished with value: 72.5999984741211 and parameters: {'Fwd': 0.004809483732644334, 'K': 3, 'alpha': 0.75, 'dropout': 0.2, 'gnnepoch': 40, 'lambda1': 0.0, 'lambda2': 6.128298632982876, 'loop': 1, 'loss': 'MSE', 'lr': 0.009871690091029933, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0005061521351028191, 'weightedloss': True}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.65
lr:  0.005864649973087782
weight_decay:  0.00112931526732048
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.80% Test: 79.40%
Split: 01, Run: 01
None time:  3.338575383881107
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 02
None time:  1.8761060698889196
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.80% Test: 79.40%
Split: 01, Run: 03
None time:  3.171648055082187
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.40
run time now: 8.40669298171997
total time:  8.423340117093176
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 79.70 ± 0.70
[I 2023-06-12 00:16:31,826] Trial 36 finished with value: 80.0 and parameters: {'Fwd': 0.01984331910937991, 'K': 4, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.2, 'lambda2': 4.349883017256095, 'loop': 0, 'loss': 'MSE', 'lr': 0.005864649973087782, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00112931526732048, 'weightedloss': False}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.65
lr:  0.006814166844873412
weight_decay:  0.0003852522509761057
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.80% Test: 78.60%
Split: 01, Run: 01
None time:  3.3322673321235925
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.60% Test: 78.80%
Split: 01, Run: 02
None time:  3.1037773790303618
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.40% Test: 78.40%
Split: 01, Run: 03
None time:  3.076035693055019
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.10
run time now: 9.53416395187378
total time:  9.560388612095267
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 0.32
[I 2023-06-12 00:16:41,901] Trial 37 finished with value: 79.26666259765625 and parameters: {'Fwd': 0.02210758287912289, 'K': 2, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.2, 'lambda2': 4.698920631544495, 'loop': 0, 'loss': 'MSE', 'lr': 0.006814166844873412, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0003852522509761057, 'weightedloss': False}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.0033993317824266606
weight_decay:  0.0027060218139833853
dropout:  0.1
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.40% Test: 79.30%
Split: 01, Run: 01
None time:  2.8054203728679568
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 80.20% Test: 79.20%
Split: 01, Run: 02
None time:  3.106595109915361
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.60% Test: 78.70%
Split: 01, Run: 03
None time:  2.976278297835961
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.60
run time now: 8.912968635559082
total time:  8.932120203971863
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 79.03 ± 0.38
[I 2023-06-12 00:16:51,319] Trial 38 finished with value: 79.73333740234375 and parameters: {'Fwd': 0.0021314231667682866, 'K': 4, 'alpha': 0.55, 'dropout': 0.1, 'gnnepoch': 90, 'lambda1': 0.6000000000000001, 'lambda2': 4.759158181739015, 'loop': 0, 'loss': 'MSE', 'lr': 0.0033993317824266606, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0027060218139833853, 'weightedloss': False}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.0
lr:  0.0013878026352155527
weight_decay:  0.005105238989765077
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.40% Test: 80.70%
Split: 01, Run: 01
None time:  3.3825018079951406
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.40% Test: 81.40%
Split: 01, Run: 02
None time:  3.046275335829705
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.00% Test: 81.10%
Split: 01, Run: 03
None time:  3.2602955638431013
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 9.749881505966187
total time:  9.783421250991523
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 80.93 ± 0.29
[I 2023-06-12 00:17:01,629] Trial 39 finished with value: 79.26667022705078 and parameters: {'Fwd': 0.0558604077535767, 'K': 3, 'alpha': 0.0, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.30000000000000004, 'lambda2': 4.370068410831479, 'loop': 0, 'loss': 'MSE', 'lr': 0.0013878026352155527, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.005105238989765077, 'weightedloss': False}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.5
lr:  0.005597385684473243
weight_decay:  0.0005072704043142196
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 73.00% Test: 75.10%
Split: 01, Run: 01
None time:  1.197469212114811
None Run 01:
Highest Train: 100.00
Highest Valid: 73.00
  Final Train: 100.00
   Final Test: 75.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 76.00% Test: 77.50%
Split: 01, Run: 02
None time:  1.5057545730378479
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 77.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 74.00% Test: 76.90%
Split: 01, Run: 03
None time:  1.504443434998393
None Run 03:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 76.30
run time now: 4.2301976680755615
total time:  4.254099414916709
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.33 ± 1.53
  Final Train: 100.00 ± 0.00
   Final Test: 76.30 ± 1.20
[I 2023-06-12 00:17:06,383] Trial 40 finished with value: 74.33333587646484 and parameters: {'Fwd': 0.029994876412995426, 'K': 1, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.45, 'lambda2': 5.288506987377546, 'loop': 0, 'loss': 'MSE', 'lr': 0.005597385684473243, 'softmaxF': False, 'useGCN': False, 'weight_decay': 0.0005072704043142196, 'weightedloss': False}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.7000000000000001
lr:  0.004069419018463031
weight_decay:  0.001182849112995525
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9549794669728726
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02
None time:  2.179922765120864
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.8046136940829456
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.30
run time now: 6.966523885726929
total time:  6.992924500955269
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.53 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 79.93 ± 0.81
[I 2023-06-12 00:17:13,902] Trial 41 finished with value: 79.53333282470703 and parameters: {'Fwd': 0.01569256642619218, 'K': 5, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.1, 'lambda2': 7.421607322603961, 'loop': 1, 'loss': 'MSE', 'lr': 0.004069419018463031, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.001182849112995525, 'weightedloss': False}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8
lr:  0.005458423959289021
weight_decay:  0.0015152070498072878
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9466556790284812
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 02
None time:  2.7529498550575227
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  2.122788071865216
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.20
run time now: 6.859798908233643
total time:  6.880697576794773
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 80.03 ± 0.29
[I 2023-06-12 00:17:21,370] Trial 42 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.02826704103539328, 'K': 6, 'alpha': 0.8, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.15000000000000002, 'lambda2': 9.509681627058846, 'loop': 1, 'loss': 'MSE', 'lr': 0.005458423959289021, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0015152070498072878, 'weightedloss': False}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.004771297032897276
weight_decay:  0.0007697649444636374
dropout:  0.1
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8679939091671258
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 02
None time:  1.52211380796507
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  2.8206283741164953
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.60
run time now: 6.2363879680633545
total time:  6.264210688183084
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 79.63 ± 0.91
[I 2023-06-12 00:17:28,122] Trial 43 finished with value: 78.79999542236328 and parameters: {'Fwd': 0.003719387247729223, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.1, 'gnnepoch': 60, 'lambda1': 0.05, 'lambda2': 7.0010777048156045, 'loop': 1, 'loss': 'MSE', 'lr': 0.004771297032897276, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0007697649444636374, 'weightedloss': True}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.0029431624598387353
weight_decay:  0.00030552335796661786
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0193218691274524
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 02
None time:  1.9928574978839606
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  1.7522959529887885
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.790924549102783
total time:  5.824409681139514
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.63 ± 0.55
[I 2023-06-12 00:17:34,458] Trial 44 finished with value: 79.9333267211914 and parameters: {'Fwd': 0.008491291367841481, 'K': 6, 'alpha': 0.9, 'dropout': 0.5, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 4.003470268826169, 'loop': 1, 'loss': 'MSE', 'lr': 0.0029431624598387353, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00030552335796661786, 'weightedloss': True}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9
lr:  0.0029007472486060897
weight_decay:  0.00029125633818752317
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8264561160467565
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.40% Test: 81.70%
Split: 01, Run: 02
None time:  3.342934186803177
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 79.80% Test: 80.70%
Split: 01, Run: 03
None time:  3.774675684981048
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.70
run time now: 8.971490144729614
total time:  8.989357847021893
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.07 ± 0.47
[I 2023-06-12 00:17:43,889] Trial 45 finished with value: 79.86666870117188 and parameters: {'Fwd': 0.0073819880302618, 'K': 7, 'alpha': 0.9, 'dropout': 0.5, 'gnnepoch': 90, 'lambda1': 0.25, 'lambda2': 3.9456046951084573, 'loop': 0, 'loss': 'MSE', 'lr': 0.0029007472486060897, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00029125633818752317, 'weightedloss': False}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.002414996960832458
weight_decay:  0.00012184896969613897
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0892411270178854
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  3.4914683680981398
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03, Epoch: 100, Loss: 0.0771, Train: 100.00%, Valid: 80.00% Test: 80.70%
Split: 01, Run: 03
None time:  4.901584197068587
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.80
run time now: 10.507185220718384
total time:  10.529062452027574
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.53 ± 0.25
[I 2023-06-12 00:17:54,926] Trial 46 finished with value: 80.13333129882812 and parameters: {'Fwd': 0.021582964921109296, 'K': 6, 'alpha': 0.9, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 3.676169793152593, 'loop': 1, 'loss': 'MSE', 'lr': 0.002414996960832458, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012184896969613897, 'weightedloss': True}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.0022815188336940163
weight_decay:  0.00011750703339645701
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2950315449852496
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.7443430009298027
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  1.3182841709349304
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.38327693939209
total time:  4.404881889000535
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 79.53 ± 1.26
[I 2023-06-12 00:17:59,755] Trial 47 finished with value: 79.20000457763672 and parameters: {'Fwd': 0.0013150456086694084, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.2, 'gnnepoch': 100, 'lambda1': 0.30000000000000004, 'lambda2': 3.1602834313783985, 'loop': 1, 'loss': 'MSE', 'lr': 0.0022815188336940163, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00011750703339645701, 'weightedloss': True}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.9500000000000001
lr:  0.003691203883591762
weight_decay:  2.786997076763642e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8550740899518132
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  1.6761167428921908
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  2.7584837439935654
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.40
run time now: 6.314002275466919
total time:  6.334478090982884
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 80.77 ± 0.71
[I 2023-06-12 00:18:06,544] Trial 48 finished with value: 79.86666870117188 and parameters: {'Fwd': 0.017586720851628802, 'K': 3, 'alpha': 0.9500000000000001, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 5.702726621696998, 'loop': 1, 'loss': 'MSE', 'lr': 0.003691203883591762, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.786997076763642e-05, 'weightedloss': True}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.0023537650116958477
weight_decay:  0.0001226506563958736
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.3473681949544698
None Run 01:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 02
None time:  0.24312358302995563
None Run 02:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.20
Split: 01, Run: 03
None time:  0.2210461930371821
None Run 03:
Highest Train: 100.00
Highest Valid: 66.80
  Final Train: 100.00
   Final Test: 68.20
run time now: 0.8650379180908203
total time:  0.8893820401281118
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 66.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 68.20 ± 0.00
[I 2023-06-12 00:18:07,913] Trial 49 finished with value: 66.79999542236328 and parameters: {'Fwd': 0.049834129512506896, 'K': 8, 'alpha': 0.45, 'dropout': 0.30000000000000004, 'gnnepoch': 0, 'lambda1': 0.35000000000000003, 'lambda2': 5.285187262626859, 'loop': 0, 'loss': 'MSE', 'lr': 0.0023537650116958477, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001226506563958736, 'weightedloss': False}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.6000000000000001
lr:  0.007724321580969404
weight_decay:  6.0161713381668695e-05
dropout:  0.1
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5072248270735145
None Run 01:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 02
None time:  1.7298537760507315
None Run 02:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  2.2117500589229167
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.475750684738159
total time:  5.494803857058287
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.27 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 78.00 ± 1.05
[I 2023-06-12 00:18:13,915] Trial 50 finished with value: 76.26667022705078 and parameters: {'Fwd': 0.003247962136425007, 'K': 4, 'alpha': 0.6000000000000001, 'dropout': 0.1, 'gnnepoch': 120, 'lambda1': 1.0, 'lambda2': 2.387546770826605, 'loop': 2, 'loss': 'MSE', 'lr': 0.007724321580969404, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.0161713381668695e-05, 'weightedloss': True}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9
lr:  0.002682123183134981
weight_decay:  0.00029911505321239464
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0683599528856575
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 02
None time:  1.5407281580846757
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  2.1118865511380136
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.80
run time now: 5.7467732429504395
total time:  5.769970003981143
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 80.33 ± 0.45
[I 2023-06-12 00:18:20,132] Trial 51 finished with value: 79.53333282470703 and parameters: {'Fwd': 0.022804580487113767, 'K': 6, 'alpha': 0.9, 'dropout': 0.2, 'gnnepoch': 80, 'lambda1': 0.2, 'lambda2': 3.825922634097364, 'loop': 1, 'loss': 'MSE', 'lr': 0.002682123183134981, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00029911505321239464, 'weightedloss': True}. Best is trial 31 with value: 80.26666259765625.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.9500000000000001
lr:  0.003974451003145635
weight_decay:  0.0004004241875748034
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.2401458469685167
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02
None time:  2.0402822319883853
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  2.08783513517119
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.40
run time now: 6.396048307418823
total time:  6.419986434048042
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 80.13 ± 0.25
[I 2023-06-12 00:18:26,979] Trial 52 finished with value: 80.33332824707031 and parameters: {'Fwd': 0.007454766158451968, 'K': 6, 'alpha': 0.9500000000000001, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 3.677926463223373, 'loop': 1, 'loss': 'MSE', 'lr': 0.003974451003145635, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0004004241875748034, 'weightedloss': True}. Best is trial 52 with value: 80.33332824707031.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.9500000000000001
lr:  0.003914085393288612
weight_decay:  0.00045805181585326294
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 0.0835, Train: 100.00%, Valid: 79.20% Test: 79.70%
Split: 01, Run: 01
None time:  5.50366611010395
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 02
None time:  5.320442265132442
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.4735352050047368
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.80
run time now: 12.40198278427124
total time:  12.429570412961766
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 79.43 ± 0.57
[I 2023-06-12 00:18:39,886] Trial 53 finished with value: 79.33333587646484 and parameters: {'Fwd': 0.06632231429607849, 'K': 7, 'alpha': 0.9500000000000001, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.05, 'lambda2': 3.4810232311410436, 'loop': 1, 'loss': 'MSE', 'lr': 0.003914085393288612, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00045805181585326294, 'weightedloss': True}. Best is trial 52 with value: 80.33332824707031.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.8
lr:  0.0063447533663596335
weight_decay:  0.0019550665817475946
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.121452837018296
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  2.099156812997535
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  2.09453545906581
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 78.80
run time now: 6.351573705673218
total time:  6.375725022051483
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 78.50 ± 0.30
[I 2023-06-12 00:18:46,805] Trial 54 finished with value: 79.13333129882812 and parameters: {'Fwd': 0.03388122336468861, 'K': 6, 'alpha': 0.8, 'dropout': 0.30000000000000004, 'gnnepoch': 90, 'lambda1': 0.15000000000000002, 'lambda2': 7.815558225220965, 'loop': 1, 'loss': 'MSE', 'lr': 0.0063447533663596335, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0019550665817475946, 'weightedloss': True}. Best is trial 52 with value: 80.33332824707031.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.005618294118561946
weight_decay:  0.00016738992764632102
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.765659400029108
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 02
None time:  2.1554729950148612
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  3.009727647062391
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 78.70
run time now: 6.953943729400635
total time:  6.981561067979783
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 79.47 ± 0.75
[I 2023-06-12 00:18:54,314] Trial 55 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.013583139153914393, 'K': 10, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.25, 'lambda2': 4.425957384611478, 'loop': 1, 'loss': 'MSE', 'lr': 0.005618294118561946, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016738992764632102, 'weightedloss': True}. Best is trial 55 with value: 80.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.9500000000000001
lr:  0.00401516228330542
weight_decay:  0.00018515541698285685
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.9500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.975581184029579
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02
None time:  1.591434941161424
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.982137423940003
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.00
run time now: 7.572978258132935
total time:  7.5911305288318545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 80.57 ± 0.45
[I 2023-06-12 00:19:02,393] Trial 56 finished with value: 80.0 and parameters: {'Fwd': 0.013950901291703783, 'K': 10, 'alpha': 0.9500000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.25, 'lambda2': 4.878690985352948, 'loop': 1, 'loss': 'MSE', 'lr': 0.00401516228330542, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00018515541698285685, 'weightedloss': True}. Best is trial 55 with value: 80.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8500000000000001
lr:  0.008042440206771764
weight_decay:  9.579806075604583e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8615118400193751
None Run 01:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  0.7439361091237515
None Run 02:
Highest Train: 100.00
Highest Valid: 70.40
  Final Train: 100.00
   Final Test: 71.30
Split: 01, Run: 03
None time:  0.3844248210079968
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 77.20
run time now: 2.0173239707946777
total time:  2.0373056018725038
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.27 ± 3.40
  Final Train: 100.00 ± 0.00
   Final Test: 75.43 ± 3.59
[I 2023-06-12 00:19:04,858] Trial 57 finished with value: 74.26667022705078 and parameters: {'Fwd': 0.06859483625193925, 'K': 9, 'alpha': 0.8500000000000001, 'dropout': 0.4, 'gnnepoch': 10, 'lambda1': 0.25, 'lambda2': 4.279917460307582, 'loop': 1, 'loss': 'CE', 'lr': 0.008042440206771764, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.579806075604583e-05, 'weightedloss': True}. Best is trial 55 with value: 80.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  1.0
lr:  0.006136574119290255
weight_decay:  4.415255756156707e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3038199869915843
None Run 01:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.6990445267874748
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  2.4266443920787424
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 76.20
run time now: 7.461054086685181
total time:  7.488354498986155
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.40 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 77.47 ± 1.10
[I 2023-06-12 00:19:12,815] Trial 58 finished with value: 78.4000015258789 and parameters: {'Fwd': 0.006807219309006757, 'K': 9, 'alpha': 1.0, 'dropout': 0.30000000000000004, 'gnnepoch': 100, 'lambda1': 0.9, 'lambda2': 2.869344712847715, 'loop': 1, 'loss': 'MSE', 'lr': 0.006136574119290255, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.415255756156707e-05, 'weightedloss': True}. Best is trial 55 with value: 80.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.75
lr:  0.005216840277861581
weight_decay:  6.830842539713853e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4201924179214984
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 02
None time:  1.5230344340670854
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.6334310218226165
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.60077166557312
total time:  4.627400303957984
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.67 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 80.47 ± 1.12
[I 2023-06-12 00:19:17,928] Trial 59 finished with value: 79.66666412353516 and parameters: {'Fwd': 0.021884233292262145, 'K': 8, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.35000000000000003, 'lambda2': 6.174199742475033, 'loop': 2, 'loss': 'MSE', 'lr': 0.005216840277861581, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.830842539713853e-05, 'weightedloss': True}. Best is trial 55 with value: 80.5999984741211.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0033958672826060604
weight_decay:  0.0001285101704101432
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5300661800429225
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  2.7546648918651044
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  2.2570559170562774
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
run time now: 6.567544460296631
total time:  6.594694751081988
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.21
[I 2023-06-12 00:19:24,999] Trial 60 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.012144119671806964, 'K': 10, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.086012203037407, 'loop': 1, 'loss': 'CE', 'lr': 0.0033958672826060604, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001285101704101432, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00328884575735386
weight_decay:  0.00017865586492576803
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7440178291872144
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 02
None time:  2.7235824649687856
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  2.31799002783373
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.40
run time now: 6.820678234100342
total time:  6.855693168006837
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.07 ± 0.58
[I 2023-06-12 00:19:32,291] Trial 61 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.012464634012660583, 'K': 10, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.088247940358712, 'loop': 1, 'loss': 'CE', 'lr': 0.00328884575735386, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017865586492576803, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.003303513621564397
weight_decay:  0.00014732412390555327
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5896845820825547
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  2.547990360064432
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.672295501921326
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.837104558944702
total time:  5.85670710215345
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.36
[I 2023-06-12 00:19:38,670] Trial 62 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.01094763959177329, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.6000000000000001, 'lambda2': 5.04595459091451, 'loop': 1, 'loss': 'CE', 'lr': 0.003303513621564397, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014732412390555327, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.0035046693928264187
weight_decay:  0.00014225875978587097
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.3932193729560822
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  1.87355956598185
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  2.2899563701357692
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.50
run time now: 6.588334560394287
total time:  6.626090950099751
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.53 ± 1.15
  Final Train: 100.00 ± 0.00
   Final Test: 80.03 ± 2.50
[I 2023-06-12 00:19:45,753] Trial 63 finished with value: 79.53333282470703 and parameters: {'Fwd': 0.011952204451046432, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 5.235045339274492, 'loop': 1, 'loss': 'CE', 'lr': 0.0035046693928264187, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014225875978587097, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.25
lr:  0.003065564501424174
weight_decay:  0.00021580753348067003
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8292706219945103
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  1.7368788528256118
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.8178434420842677
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.50
run time now: 5.410165309906006
total time:  5.43719996092841
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.00 ± 0.62
[I 2023-06-12 00:19:51,734] Trial 64 finished with value: 80.33332824707031 and parameters: {'Fwd': 0.005845219687474326, 'K': 10, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 4.8669207300249635, 'loop': 1, 'loss': 'CE', 'lr': 0.003065564501424174, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021580753348067003, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.2
lr:  0.003077165066088968
weight_decay:  0.00018786029358644577
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.478827720042318
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  1.7665369198657572
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.8010275780688971
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.50
run time now: 5.074968099594116
total time:  5.093217499088496
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.03 ± 0.57
[I 2023-06-12 00:19:57,338] Trial 65 finished with value: 80.26667022705078 and parameters: {'Fwd': 0.0024281581745937944, 'K': 10, 'alpha': 0.2, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.60816787166895, 'loop': 1, 'loss': 'CE', 'lr': 0.003077165066088968, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00018786029358644577, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.25
lr:  0.0020200066048184813
weight_decay:  8.435617150268757e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.25)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.511763557093218
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 02
None time:  1.9730986829381436
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.7344655969645828
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.30
run time now: 5.243535041809082
total time:  5.268405543873087
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.53 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 79.80 ± 1.23
[I 2023-06-12 00:20:03,071] Trial 66 finished with value: 79.5333251953125 and parameters: {'Fwd': 0.0023252548641165753, 'K': 10, 'alpha': 0.25, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.55, 'lambda2': 5.650533932979505, 'loop': 1, 'loss': 'CE', 'lr': 0.0020200066048184813, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.435617150268757e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.15000000000000002
lr:  0.0030366084319056004
weight_decay:  0.00021032594216563284
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.141911264974624
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  2.5659002671018243
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.8492570200469345
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.00
run time now: 5.580540895462036
total time:  5.607288046972826
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.13 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 80.83 ± 0.85
[I 2023-06-12 00:20:09,311] Trial 67 finished with value: 80.13333129882812 and parameters: {'Fwd': 0.0055473020537092155, 'K': 10, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 70, 'lambda1': 0.55, 'lambda2': 5.0109007184236845, 'loop': 1, 'loss': 'CE', 'lr': 0.0030366084319056004, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021032594216563284, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.2
lr:  0.0026562172244832564
weight_decay:  0.00019072132356604503
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.669934110948816
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 02
None time:  1.8820102158933878
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  1.421463827136904
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.40
run time now: 5.001996040344238
total time:  5.021641734056175
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 79.07 ± 1.76
[I 2023-06-12 00:20:14,852] Trial 68 finished with value: 79.39999389648438 and parameters: {'Fwd': 0.0039008341860264925, 'K': 9, 'alpha': 0.2, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 5.952651890927488, 'loop': 1, 'loss': 'CE', 'lr': 0.0026562172244832564, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00019072132356604503, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.0033343003088393735
weight_decay:  0.0002509094682437975
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3254611040465534
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  2.178099437151104
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.6664608279243112
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.80
run time now: 5.202834606170654
total time:  5.225694179069251
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 80.70 ± 0.90
[I 2023-06-12 00:20:20,662] Trial 69 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.008069278628048938, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 5.522251403976448, 'loop': 1, 'loss': 'CE', 'lr': 0.0033343003088393735, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002509094682437975, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.0015314850830917682
weight_decay:  0.00026253057892381776
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1755182538181543
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 02
None time:  1.0289009250700474
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.2974066259339452
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
run time now: 3.525113105773926
total time:  3.5436014330480248
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.00 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 79.90 ± 1.84
[I 2023-06-12 00:20:24,738] Trial 70 finished with value: 80.0 and parameters: {'Fwd': 0.008492192163092556, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.5, 'gnnepoch': 40, 'lambda1': 0.7000000000000001, 'lambda2': 4.631590177003391, 'loop': 1, 'loss': 'CE', 'lr': 0.0015314850830917682, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00026253057892381776, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.003264457779700057
weight_decay:  9.219087251597461e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7864871539641172
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 02
None time:  1.5750418109819293
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  2.1117444618139416
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.10
run time now: 5.499704360961914
total time:  5.521553063066676
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 80.80 ± 0.62
[I 2023-06-12 00:20:30,718] Trial 71 finished with value: 80.33333587646484 and parameters: {'Fwd': 0.005399846887675347, 'K': 10, 'alpha': 0.1, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.5, 'lambda2': 5.480375843858734, 'loop': 1, 'loss': 'CE', 'lr': 0.003264457779700057, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.219087251597461e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.0036599837271170665
weight_decay:  8.46488409271379e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.413968272972852
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  2.1098301459569484
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.8486021659336984
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.80
run time now: 5.398247480392456
total time:  5.419709810987115
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.00 ± 0.62
[I 2023-06-12 00:20:36,610] Trial 72 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.0058205502255513275, 'K': 10, 'alpha': 0.1, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.5, 'lambda2': 5.042917475878109, 'loop': 1, 'loss': 'CE', 'lr': 0.0036599837271170665, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.46488409271379e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.0036222901846768756
weight_decay:  5.943754577210104e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.63242396293208
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.8518263960722834
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.6682110710535198
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.70
run time now: 5.180312156677246
total time:  5.199092583032325
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 80.97 ± 0.64
[I 2023-06-12 00:20:42,255] Trial 73 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.010885784037400918, 'K': 10, 'alpha': 0.1, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 5.1796399663649435, 'loop': 1, 'loss': 'CE', 'lr': 0.0036222901846768756, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.943754577210104e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.1
lr:  0.004407294372934428
weight_decay:  5.652383887507646e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3832232609856874
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6217789419461042
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.5937590880785137
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.626110553741455
total time:  4.646326084854081
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.75
[I 2023-06-12 00:20:47,363] Trial 74 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.012590887729249938, 'K': 10, 'alpha': 0.1, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 5.448111597482266, 'loop': 1, 'loss': 'CE', 'lr': 0.004407294372934428, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.652383887507646e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.004526173532006074
weight_decay:  5.222021499733668e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6406860640272498
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.6184726140927523
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  2.0285327250603586
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.314815044403076
total time:  5.334275115048513
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.55
[I 2023-06-12 00:20:53,237] Trial 75 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.011852271290826392, 'K': 9, 'alpha': 0.1, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 5.886181875204481, 'loop': 1, 'loss': 'CE', 'lr': 0.004526173532006074, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.222021499733668e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004257177320565541
weight_decay:  3.2614143286931666e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2697499098721892
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.5323570200707763
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.9272431021090597
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.757969617843628
total time:  4.785380280809477
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.66
[I 2023-06-12 00:20:58,664] Trial 76 finished with value: 80.73333740234375 and parameters: {'Fwd': 0.012457758017112953, 'K': 9, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 5.917410446278809, 'loop': 1, 'loss': 'CE', 'lr': 0.004257177320565541, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.2614143286931666e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.004565886990654486
weight_decay:  3.202255421446018e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.674415847985074
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.985728404019028
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.5159642130602151
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.204092264175415
total time:  5.223309224005789
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.50
[I 2023-06-12 00:21:04,320] Trial 77 finished with value: 81.0 and parameters: {'Fwd': 0.00408908432624093, 'K': 9, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.45, 'lambda2': 5.986802178473962, 'loop': 1, 'loss': 'CE', 'lr': 0.004565886990654486, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.202255421446018e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.003888311481674307
weight_decay:  2.7103578194808388e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7243811700027436
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.8222453980706632
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  1.4089540077839047
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 98.57
   Final Test: 75.50
run time now: 2.9856388568878174
total time:  3.012330763041973
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 71.07 ± 3.93
  Final Train: 99.52 ± 0.82
   Final Test: 71.83 ± 3.18
[I 2023-06-12 00:21:07,809] Trial 78 finished with value: 71.0666732788086 and parameters: {'Fwd': 0.0039580303336246405, 'K': 9, 'alpha': 0.0, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.6000000000000001, 'lambda2': 6.542330875904561, 'loop': 1, 'loss': 'CE', 'lr': 0.003888311481674307, 'softmaxF': True, 'useGCN': False, 'weight_decay': 2.7103578194808388e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.05
lr:  0.004427644634650626
weight_decay:  3.458850024212269e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.227012149989605
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 02
None time:  0.9081378008704633
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.4413782330229878
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 79.00
run time now: 3.6039600372314453
total time:  3.622314261039719
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.13 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 0.44
[I 2023-06-12 00:21:11,929] Trial 79 finished with value: 79.13333129882812 and parameters: {'Fwd': 0.003003359133549789, 'K': 10, 'alpha': 0.05, 'dropout': 0.7000000000000001, 'gnnepoch': 30, 'lambda1': 0.45, 'lambda2': 5.083620722998586, 'loop': 1, 'loss': 'CE', 'lr': 0.004427644634650626, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.458850024212269e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0048862174133565105
weight_decay:  1.7058821436207823e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4746122849173844
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.6043497798964381
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  1.2651713681407273
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 4.378994703292847
total time:  4.399067038903013
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.81
[I 2023-06-12 00:21:16,791] Trial 80 finished with value: 81.0 and parameters: {'Fwd': 0.010903991007748554, 'K': 9, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.45, 'lambda2': 6.009657490232007, 'loop': 1, 'loss': 'CE', 'lr': 0.0048862174133565105, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.7058821436207823e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.005021507966195523
weight_decay:  1.5606966791347438e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4718357590027153
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.802547027124092
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 03
None time:  1.4633967359550297
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.7649946212768555
total time:  4.789728943025693
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.97
[I 2023-06-12 00:21:22,101] Trial 81 finished with value: 81.0 and parameters: {'Fwd': 0.011559738202838427, 'K': 9, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.45, 'lambda2': 5.951556864139292, 'loop': 1, 'loss': 'CE', 'lr': 0.005021507966195523, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.5606966791347438e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.005197549357863539
weight_decay:  1.5196952004941916e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.372832708992064
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.6491749279666692
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  1.449075856944546
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.49855375289917
total time:  4.524146392010152
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.98
[I 2023-06-12 00:21:27,179] Trial 82 finished with value: 80.9333267211914 and parameters: {'Fwd': 0.010263440996947162, 'K': 9, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 6.033942984006932, 'loop': 1, 'loss': 'CE', 'lr': 0.005197549357863539, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.5196952004941916e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0049856787449352276
weight_decay:  1.1562317549706022e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.973123705945909
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.4795887358486652
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.4859994100406766
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.70
run time now: 3.9601633548736572
total time:  3.9827411151491106
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.06
[I 2023-06-12 00:21:31,718] Trial 83 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.02896530535197473, 'K': 9, 'alpha': 0.05, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 6.06769442439326, 'loop': 1, 'loss': 'CE', 'lr': 0.0049856787449352276, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.1562317549706022e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.007370538791837362
weight_decay:  1.4334233381602623e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5145894158631563
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 02
None time:  1.3273930810391903
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.497228167951107
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.367613792419434
total time:  4.3869847531896085
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.97 ± 0.23
[I 2023-06-12 00:21:36,549] Trial 84 finished with value: 80.26666259765625 and parameters: {'Fwd': 0.0045110531776715035, 'K': 8, 'alpha': 0.0, 'dropout': 0.6000000000000001, 'gnnepoch': 30, 'lambda1': 0.6000000000000001, 'lambda2': 6.360827611084806, 'loop': 1, 'loss': 'CE', 'lr': 0.007370538791837362, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4334233381602623e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.05
lr:  0.0065496742611271
weight_decay:  1.818946051971741e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.977662389865145
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  1.5376234131399542
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.1010377949569374
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.70
run time now: 4.643376350402832
total time:  4.666146719828248
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.86
[I 2023-06-12 00:21:41,788] Trial 85 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.009316725165894232, 'K': 9, 'alpha': 0.05, 'dropout': 0.7000000000000001, 'gnnepoch': 40, 'lambda1': 0.4, 'lambda2': 5.821303399213785, 'loop': 1, 'loss': 'CE', 'lr': 0.0065496742611271, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.818946051971741e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.00522388233034574
weight_decay:  1.0337218033901429e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4187709661200643
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.7625656200107187
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 03
None time:  1.3317344191018492
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.541965484619141
total time:  4.568736387882382
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 1.07
[I 2023-06-12 00:21:46,875] Trial 86 finished with value: 80.86666107177734 and parameters: {'Fwd': 0.006282280235753748, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 5.92853209611747, 'loop': 1, 'loss': 'CE', 'lr': 0.00522388233034574, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0337218033901429e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.45
lr:  0.005006555705700685
weight_decay:  7.620870130499539e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.157957597868517
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  1.5759872100315988
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.4119568311143667
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.168936729431152
total time:  4.1966566811315715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.85
[I 2023-06-12 00:21:51,555] Trial 87 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.016816406046589297, 'K': 8, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 6.662939017537526, 'loop': 1, 'loss': 'CE', 'lr': 0.005006555705700685, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.620870130499539e-06, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.008385985770651746
weight_decay:  3.737693547836208e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4115144689567387
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  0.8484303329605609
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.26492797001265
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.60
run time now: 3.553070068359375
total time:  3.5750362570397556
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 82.03 ± 0.51
[I 2023-06-12 00:21:55,592] Trial 88 finished with value: 81.26666259765625 and parameters: {'Fwd': 0.036794498929931224, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.4, 'lambda2': 6.802396552522639, 'loop': 1, 'loss': 'CE', 'lr': 0.008385985770651746, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.737693547836208e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.009006219435232873
weight_decay:  2.311660699365624e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2798005510121584
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.2860794779844582
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.2893749920185655
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.30
run time now: 3.8835668563842773
total time:  3.9086192611139268
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.46
[I 2023-06-12 00:21:59,965] Trial 89 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.03748625863610942, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.5, 'gnnepoch': 40, 'lambda1': 0.4, 'lambda2': 6.80465866869101, 'loop': 1, 'loss': 'CE', 'lr': 0.009006219435232873, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.311660699365624e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.0
lr:  0.00834257411342016
weight_decay:  3.8178891513660434e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1954864750150591
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 02
None time:  1.585507684852928
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.0895443581975996
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 3.899423122406006
total time:  3.9227419688832015
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 80.93 ± 0.50
[I 2023-06-12 00:22:04,436] Trial 90 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.026395650248319455, 'K': 9, 'alpha': 0.0, 'dropout': 0.5, 'gnnepoch': 30, 'lambda1': 0.4, 'lambda2': 6.413879879040819, 'loop': 1, 'loss': 'CE', 'lr': 0.00834257411342016, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.8178891513660434e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.005831905026024819
weight_decay:  3.502032252645555e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4436704760883003
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.7668851630296558
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.2675969530828297
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.90
run time now: 4.505693435668945
total time:  4.53163606999442
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.56
[I 2023-06-12 00:22:09,460] Trial 91 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.009798619566014227, 'K': 8, 'alpha': 0.05, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 6.24992369229208, 'loop': 1, 'loss': 'CE', 'lr': 0.005831905026024819, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.502032252645555e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.05
lr:  0.006906987872304511
weight_decay:  1.850649484393071e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.05)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4416081940289587
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.5457200850360096
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 03
None time:  1.3592543550767004
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.391847610473633
total time:  4.414611744927242
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.97 ± 0.65
[I 2023-06-12 00:22:14,404] Trial 92 finished with value: 80.80000305175781 and parameters: {'Fwd': 0.007091427241323754, 'K': 8, 'alpha': 0.05, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 6.196622977611006, 'loop': 1, 'loss': 'CE', 'lr': 0.006906987872304511, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.850649484393071e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.006791252094986616
weight_decay:  1.016862251353151e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4086444489657879
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.7777799319010228
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 03
None time:  1.1414419009815902
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.355898857116699
total time:  4.383567490847781
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.60
[I 2023-06-12 00:22:19,336] Trial 93 finished with value: 80.86666107177734 and parameters: {'Fwd': 0.006538202304609314, 'K': 8, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 6.241570220941119, 'loop': 1, 'loss': 'CE', 'lr': 0.006791252094986616, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.016862251353151e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.006989890264922479
weight_decay:  9.348251040236214e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5763323940336704
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 02
None time:  1.2914803160820156
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.588276892900467
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.488298177719116
total time:  4.524553894996643
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.90 ± 0.46
[I 2023-06-12 00:22:24,275] Trial 94 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.0019210487950838907, 'K': 8, 'alpha': 0.2, 'dropout': 0.7000000000000001, 'gnnepoch': 40, 'lambda1': 0.35000000000000003, 'lambda2': 6.085187927620487, 'loop': 1, 'loss': 'CE', 'lr': 0.006989890264922479, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.348251040236214e-06, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.00743392780028791
weight_decay:  1.9345649358454203e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9539090869948268
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.1968667039182037
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.4545832769945264
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
run time now: 3.6342082023620605
total time:  3.6603557281196117
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.15
[I 2023-06-12 00:22:28,464] Trial 95 finished with value: 81.06666564941406 and parameters: {'Fwd': 0.0029409393776173437, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.4, 'lambda2': 6.8290975242267935, 'loop': 1, 'loss': 'CE', 'lr': 0.00743392780028791, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.9345649358454203e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.15000000000000002
lr:  0.00977119030174371
weight_decay:  6.217214645242523e-06
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8553555579856038
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.7371433491352946
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  0.9047533399425447
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
run time now: 2.5236656665802
total time:  2.54904513200745
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.27 ± 6.22
  Final Train: 100.00 ± 0.00
   Final Test: 76.83 ± 6.17
[I 2023-06-12 00:22:31,455] Trial 96 finished with value: 75.26667022705078 and parameters: {'Fwd': 0.0030922031165872468, 'K': 9, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.4, 'lambda2': 6.7893543908008045, 'loop': 1, 'loss': 'CE', 'lr': 0.00977119030174371, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.217214645242523e-06, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.2
lr:  0.00785447805538578
weight_decay:  1.478713832925985e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.2)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2802097178064287
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.433634788962081
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.3001323048956692
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.040440559387207
total time:  4.0617912649177015
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.78
[I 2023-06-12 00:22:36,082] Trial 97 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.001638833431855222, 'K': 8, 'alpha': 0.2, 'dropout': 0.6000000000000001, 'gnnepoch': 40, 'lambda1': 0.45, 'lambda2': 7.048144271997295, 'loop': 1, 'loss': 'CE', 'lr': 0.00785447805538578, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.478713832925985e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.15000000000000002
lr:  0.0053643524618362335
weight_decay:  2.3970893983781916e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3355002698954195
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.4610770200379193
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.4575853531714529
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.278784513473511
total time:  4.306463999906555
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.42
[I 2023-06-12 00:22:40,891] Trial 98 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.017039453629267422, 'K': 7, 'alpha': 0.15000000000000002, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 7.224335640080138, 'loop': 1, 'loss': 'CE', 'lr': 0.0053643524618362335, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.3970893983781916e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.006180314602556683
weight_decay:  1.2171330492073562e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4574313540942967
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.6119112269952893
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.4856478839647025
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.58412766456604
total time:  4.6119737471453846
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.80
[I 2023-06-12 00:22:45,973] Trial 99 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.004858183144164983, 'K': 9, 'alpha': 0.1, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.35000000000000003, 'lambda2': 5.767671453484122, 'loop': 1, 'loss': 'CE', 'lr': 0.006180314602556683, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.2171330492073562e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.15000000000000002
lr:  0.008306533467100332
weight_decay:  5.591598446026762e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.15000000000000002)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0467535299248993
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.1919592679478228
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.5455789098050445
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.80
run time now: 3.8074264526367188
total time:  3.832126140827313
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.10 ± 0.79
[I 2023-06-12 00:22:50,396] Trial 100 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.00690549625612198, 'K': 8, 'alpha': 0.15000000000000002, 'dropout': 0.6000000000000001, 'gnnepoch': 40, 'lambda1': 0.45, 'lambda2': 6.61315697943306, 'loop': 1, 'loss': 'CE', 'lr': 0.008306533467100332, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.591598446026762e-06, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.007035973808520262
weight_decay:  1.760204600182178e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.39092505001463
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.525856874883175
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 03
None time:  1.0527379219420254
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.30
run time now: 3.9940783977508545
total time:  4.012565741082653
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.93 ± 0.60
[I 2023-06-12 00:22:54,842] Trial 101 finished with value: 80.86666107177734 and parameters: {'Fwd': 0.006804057754326129, 'K': 8, 'alpha': 0.0, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.5, 'lambda2': 6.2937749200839574, 'loop': 1, 'loss': 'CE', 'lr': 0.007035973808520262, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.760204600182178e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.0
lr:  0.006634738216090488
weight_decay:  1.9172027591048995e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2574522229842842
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.770996920997277
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.6712433700449765
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.10
run time now: 4.726577520370483
total time:  4.747785493033007
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.21
[I 2023-06-12 00:23:00,047] Trial 102 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.0037387027944793295, 'K': 8, 'alpha': 0.0, 'dropout': 0.7000000000000001, 'gnnepoch': 40, 'lambda1': 0.5, 'lambda2': 6.397114188215078, 'loop': 1, 'loss': 'CE', 'lr': 0.006634738216090488, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.9172027591048995e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.0
lr:  0.005757202266181107
weight_decay:  9.861262308951875e-06
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.410259481985122
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.90
Split: 01, Run: 02
None time:  1.8365718021523207
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 03
None time:  1.4172890291083604
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.60
run time now: 4.689270734786987
total time:  4.709916946012527
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 82.10 ± 1.30
[I 2023-06-12 00:23:05,344] Trial 103 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.015430615816316095, 'K': 7, 'alpha': 0.0, 'dropout': 0.8, 'gnnepoch': 50, 'lambda1': 0.4, 'lambda2': 6.861254561968873, 'loop': 1, 'loss': 'CE', 'lr': 0.005757202266181107, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.861262308951875e-06, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.1
lr:  0.00746434699683464
weight_decay:  1.8351720325555382e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.1)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4513422020245343
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.4811583440750837
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.6979110788088292
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.20
run time now: 4.699656009674072
total time:  4.731820857152343
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 82.13 ± 0.31
[I 2023-06-12 00:23:10,660] Trial 104 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.008407665730066226, 'K': 9, 'alpha': 0.1, 'dropout': 0.7000000000000001, 'gnnepoch': 50, 'lambda1': 0.55, 'lambda2': 6.582158322374272, 'loop': 1, 'loss': 'CE', 'lr': 0.00746434699683464, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.8351720325555382e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.008689715442487608
weight_decay:  1.4275020601797904e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0390099710784853
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  1.8951791059225798
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.7498137529473752
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.704524993896484
total time:  4.723484985064715
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.75
[I 2023-06-12 00:23:15,929] Trial 105 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.02092084118753465, 'K': 9, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 6.0254141380722555, 'loop': 1, 'loss': 'CE', 'lr': 0.008689715442487608, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4275020601797904e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.008622518575148706
weight_decay:  2.276718415220109e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6112598369363695
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  1.3913632109761238
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.696772496914491
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.726248025894165
total time:  4.760536674177274
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.75
[I 2023-06-12 00:23:21,106] Trial 106 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.020484089562865532, 'K': 9, 'alpha': 0.4, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.6000000000000001, 'lambda2': 5.929610856988894, 'loop': 1, 'loss': 'CE', 'lr': 0.008622518575148706, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.276718415220109e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.008888490738082688
weight_decay:  4.444428678817617e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5824617689941078
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  1.5468421219848096
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.5381514551118016
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
run time now: 4.696334362030029
total time:  4.726164686027914
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 82.03 ± 0.45
[I 2023-06-12 00:23:26,249] Trial 107 finished with value: 81.33332824707031 and parameters: {'Fwd': 0.04126880732195809, 'K': 9, 'alpha': 0.4, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 5.356067768604784, 'loop': 1, 'loss': 'CE', 'lr': 0.008888490738082688, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.444428678817617e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.008698802670838848
weight_decay:  4.0849931510531994e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6667610069271177
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.6730454959906638
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.1746363320853561
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
run time now: 4.542253017425537
total time:  4.563306394964457
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 82.10 ± 0.50
[I 2023-06-12 00:23:31,251] Trial 108 finished with value: 81.33332824707031 and parameters: {'Fwd': 0.04441802676817254, 'K': 9, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.34726479250776, 'loop': 1, 'loss': 'CE', 'lr': 0.008698802670838848, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.0849931510531994e-05, 'weightedloss': True}. Best is trial 60 with value: 81.33333587646484.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.009989511933710947
weight_decay:  4.244769111383501e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6858605709858239
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  1.9856723279226571
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.8685009069740772
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 83.10
run time now: 5.56565523147583
total time:  5.583665585145354
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 82.60 ± 0.62
[I 2023-06-12 00:23:37,324] Trial 109 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.08254027725911933, 'K': 9, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.50233378231305, 'loop': 1, 'loss': 'CE', 'lr': 0.009989511933710947, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.244769111383501e-05, 'weightedloss': True}. Best is trial 109 with value: 81.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.009788956432500532
weight_decay:  4.496459826366308e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9350102171301842
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 02
None time:  1.0434825019910932
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 03
None time:  0.99371597613208
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 78.90
run time now: 2.9951884746551514
total time:  3.0215723619330674
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.53 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 2.35
[I 2023-06-12 00:23:40,932] Trial 110 finished with value: 78.53333282470703 and parameters: {'Fwd': 0.04413717183533517, 'K': 9, 'alpha': 0.55, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.53112525078041, 'loop': 1, 'loss': 'CE', 'lr': 0.009788956432500532, 'softmaxF': True, 'useGCN': False, 'weight_decay': 4.496459826366308e-05, 'weightedloss': True}. Best is trial 109 with value: 81.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.008815789896973437
weight_decay:  2.86069117090096e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5957975347992033
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  1.4769034029450268
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.3763626678846776
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
run time now: 4.478001117706299
total time:  4.504906575893983
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 82.10 ± 0.40
[I 2023-06-12 00:23:45,920] Trial 111 finished with value: 81.19999694824219 and parameters: {'Fwd': 0.038365396123831955, 'K': 9, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.361692287829507, 'loop': 1, 'loss': 'CE', 'lr': 0.008815789896973437, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.86069117090096e-05, 'weightedloss': True}. Best is trial 109 with value: 81.4000015258789.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.009255702180365703
weight_decay:  4.156211312521541e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6179520569276065
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.7020283320453018
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.7802001228556037
None Run 03:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.90
run time now: 5.141613245010376
total time:  5.178649859968573
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 82.47 ± 0.51
[I 2023-06-12 00:23:51,560] Trial 112 finished with value: 81.66667175292969 and parameters: {'Fwd': 0.08730550166861663, 'K': 9, 'alpha': 0.4, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.406675930084522, 'loop': 1, 'loss': 'CE', 'lr': 0.009255702180365703, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.156211312521541e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.009416720772219533
weight_decay:  4.046497771975774e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0932681658305228
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.2772450749762356
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 03
None time:  2.0250928380992264
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.80
run time now: 6.4197938442230225
total time:  6.441920187091455
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 82.43 ± 0.40
[I 2023-06-12 00:23:58,496] Trial 113 finished with value: 81.06665802001953 and parameters: {'Fwd': 0.0838167255227278, 'K': 9, 'alpha': 0.4, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.3544318630070755, 'loop': 1, 'loss': 'CE', 'lr': 0.009416720772219533, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.046497771975774e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.009102366045795677
weight_decay:  4.647063288083822e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5292771488893777
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.9549717199988663
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 03
None time:  1.8942165409680456
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.40
run time now: 5.408610820770264
total time:  5.43309857416898
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 82.13 ± 0.64
[I 2023-06-12 00:24:04,502] Trial 114 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.07835401789804317, 'K': 9, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.34724237607448, 'loop': 1, 'loss': 'CE', 'lr': 0.009102366045795677, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.647063288083822e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.008024973644460373
weight_decay:  2.968536121095511e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6721883090212941
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.5451484280638397
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 03
None time:  1.6931355681736022
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.93943977355957
total time:  4.966582268010825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 82.20 ± 0.53
[I 2023-06-12 00:24:09,991] Trial 115 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.09923243217856093, 'K': 10, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.248325838148042, 'loop': 1, 'loss': 'CE', 'lr': 0.008024973644460373, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.968536121095511e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00973992056909721
weight_decay:  7.162493707023494e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.294262956827879
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 83.50
Split: 01, Run: 02
None time:  2.328744155121967
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 83.70
Split: 01, Run: 03
None time:  1.8848967999219894
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.539646148681641
total time:  6.558962458977476
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 82.77 ± 1.45
[I 2023-06-12 00:24:17,089] Trial 116 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.09928831413019795, 'K': 10, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 5.321085257352176, 'loop': 1, 'loss': 'CE', 'lr': 0.00973992056909721, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.162493707023494e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00999579269870759
weight_decay:  4.7443572536572425e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7423935460392386
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.90
Split: 01, Run: 02
None time:  1.9135322507936507
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 83.10
Split: 01, Run: 03
None time:  1.9479130969848484
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.60
run time now: 6.629805564880371
total time:  6.654338313033804
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 82.87 ± 0.25
[I 2023-06-12 00:24:24,231] Trial 117 finished with value: 81.0666732788086 and parameters: {'Fwd': 0.0843082745500414, 'K': 10, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 5.287957230749865, 'loop': 1, 'loss': 'CE', 'lr': 0.00999579269870759, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.7443572536572425e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.009983621971408983
weight_decay:  6.936902521266745e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.7824432889465243
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 83.00
Split: 01, Run: 02
None time:  1.9160575200803578
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.70
Split: 01, Run: 03
None time:  1.8455254889559
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
run time now: 6.566220760345459
total time:  6.589760118164122
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 82.57 ± 0.51
[I 2023-06-12 00:24:31,373] Trial 118 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.09190220082659384, 'K': 10, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 4.766082713992227, 'loop': 1, 'loss': 'CE', 'lr': 0.009983621971408983, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.936902521266745e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.00976377406113128
weight_decay:  6.612519754971507e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7970510108862072
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.70
Split: 01, Run: 02
None time:  1.7802278641611338
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.9870580970309675
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.70
run time now: 5.592378854751587
total time:  5.614209913881496
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 82.20 ± 0.87
[I 2023-06-12 00:24:37,590] Trial 119 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.09998709129392708, 'K': 10, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 4.685673398251509, 'loop': 1, 'loss': 'CE', 'lr': 0.00976377406113128, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.612519754971507e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.008042899407689682
weight_decay:  7.112021146255947e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3602005110587925
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 83.40
Split: 01, Run: 02
None time:  2.650318233994767
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.8426382360048592
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
run time now: 5.87908411026001
total time:  5.907584307016805
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 82.30 ± 0.95
[I 2023-06-12 00:24:43,954] Trial 120 finished with value: 81.19999694824219 and parameters: {'Fwd': 0.059891083708075374, 'K': 10, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 4.9422022990163565, 'loop': 1, 'loss': 'CE', 'lr': 0.008042899407689682, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.112021146255947e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.008237437859957992
weight_decay:  7.55640417535552e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6672725300304592
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 83.40
Split: 01, Run: 02
None time:  2.2059239679947495
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 03
None time:  2.081380994990468
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 83.10
run time now: 5.982813358306885
total time:  6.007209529168904
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 82.93 ± 0.57
[I 2023-06-12 00:24:50,407] Trial 121 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.06957656172958716, 'K': 10, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 4.890367099603723, 'loop': 1, 'loss': 'CE', 'lr': 0.008237437859957992, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.55640417535552e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.008902089209249285
weight_decay:  5.4053164677083316e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9179807959590107
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 83.40
Split: 01, Run: 02
None time:  1.961001246003434
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.7559970819856972
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.80
run time now: 5.6772778034210205
total time:  5.719616116955876
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 82.67 ± 0.81
[I 2023-06-12 00:24:56,565] Trial 122 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.055855094635824235, 'K': 10, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 5.193401538980489, 'loop': 1, 'loss': 'CE', 'lr': 0.008902089209249285, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.4053164677083316e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00808906666501886
weight_decay:  0.00010638153898809372
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7711501028388739
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.234020072966814
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 03
None time:  1.824624486034736
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.50
run time now: 5.859798908233643
total time:  5.887002147035673
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 82.20 ± 0.26
[I 2023-06-12 00:25:02,869] Trial 123 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.05783225844640866, 'K': 10, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 4.5844927363721375, 'loop': 1, 'loss': 'CE', 'lr': 0.00808906666501886, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010638153898809372, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.007945426495517396
weight_decay:  0.00010694835116689181
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8563682781532407
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.197559447027743
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 03
None time:  1.950933723943308
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
run time now: 6.0296852588653564
total time:  6.053557701874524
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 82.13 ± 0.15
[I 2023-06-12 00:25:09,431] Trial 124 finished with value: 81.0 and parameters: {'Fwd': 0.06204610902084328, 'K': 10, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 80, 'lambda1': 0.7000000000000001, 'lambda2': 4.830585150610842, 'loop': 1, 'loss': 'CE', 'lr': 0.007945426495517396, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010694835116689181, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.007788880520535495
weight_decay:  7.474740797787702e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.432002877118066
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.6537124558817595
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.207898586988449
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.40
run time now: 5.3214991092681885
total time:  5.3397761199157685
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 82.23 ± 0.47
[I 2023-06-12 00:25:15,227] Trial 125 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.042596020362982115, 'K': 10, 'alpha': 0.4, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 4.6404970814739235, 'loop': 1, 'loss': 'CE', 'lr': 0.007788880520535495, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.474740797787702e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0074398526518674015
weight_decay:  7.786749916756272e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5066342349164188
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  1.5213067340664566
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.499826967017725
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.559872627258301
total time:  4.5868605899158865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.90 ± 0.52
[I 2023-06-12 00:25:20,394] Trial 126 finished with value: 81.06666564941406 and parameters: {'Fwd': 0.046332560045161876, 'K': 10, 'alpha': 0.4, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 4.934453872902029, 'loop': 1, 'loss': 'CE', 'lr': 0.0074398526518674015, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.786749916756272e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00892768109354688
weight_decay:  6.352001990824305e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.70381711400114
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  1.6831654098350555
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 03
None time:  2.049410309875384
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 83.10
run time now: 5.463019609451294
total time:  5.485821978189051
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 82.83 ± 0.25
[I 2023-06-12 00:25:26,291] Trial 127 finished with value: 81.66666412353516 and parameters: {'Fwd': 0.09748700406344613, 'K': 10, 'alpha': 0.55, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.677500424206035, 'loop': 1, 'loss': 'CE', 'lr': 0.00892768109354688, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.352001990824305e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.008824326499955114
weight_decay:  6.192277582718899e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6973689859732985
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.780602022074163
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.90
Split: 01, Run: 03
None time:  1.8417397518642247
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 83.60
run time now: 5.35136866569519
total time:  5.3683791579678655
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 83.03 ± 0.51
[I 2023-06-12 00:25:32,125] Trial 128 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.09974862192378933, 'K': 10, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.619808206168952, 'loop': 1, 'loss': 'CE', 'lr': 0.008824326499955114, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.192277582718899e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00890220940723181
weight_decay:  2.9138860025703544e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.681907573947683
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.8573078501503915
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 83.10
Split: 01, Run: 03
None time:  2.424122212920338
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 83.60
run time now: 5.992384433746338
total time:  6.016151778167114
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 83.10 ± 0.50
[I 2023-06-12 00:25:38,640] Trial 129 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.09622555144972131, 'K': 10, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.664761861361732, 'loop': 1, 'loss': 'CE', 'lr': 0.00890220940723181, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.9138860025703544e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.009054955847117433
weight_decay:  6.0785429972468364e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0343369368929416
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.90
Split: 01, Run: 02
None time:  1.7402778679970652
None Run 02:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  1.7261885479092598
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.70
run time now: 4.525593042373657
total time:  4.552156060002744
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 82.60 ± 0.36
[I 2023-06-12 00:25:43,655] Trial 130 finished with value: 81.66666412353516 and parameters: {'Fwd': 0.09671799489248863, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.7545917633734405, 'loop': 1, 'loss': 'CE', 'lr': 0.009054955847117433, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.0785429972468364e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.009958359061690103
weight_decay:  6.100937221374097e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6567954369820654
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 83.20
Split: 01, Run: 02
None time:  1.6820017260033637
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.70
Split: 01, Run: 03
None time:  1.9593997390475124
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.20
run time now: 5.327913761138916
total time:  5.354748016223311
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 82.70 ± 0.50
[I 2023-06-12 00:25:49,529] Trial 131 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.0964866910189038, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.672323187344706, 'loop': 1, 'loss': 'CE', 'lr': 0.009958359061690103, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.100937221374097e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00920440630189676
weight_decay:  6.0082579435969724e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4298289709258825
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.90
Split: 01, Run: 02
None time:  1.675546367885545
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  1.7498066099360585
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.90
run time now: 4.884681701660156
total time:  4.903271063929424
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 82.67 ± 0.40
[I 2023-06-12 00:25:54,972] Trial 132 finished with value: 81.60000610351562 and parameters: {'Fwd': 0.09935457474452564, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.650566098273276, 'loop': 1, 'loss': 'CE', 'lr': 0.00920440630189676, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.0082579435969724e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.009736227607792901
weight_decay:  5.88519507273077e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1264325350057334
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  2.151691645151004
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 03
None time:  1.964846626855433
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.70
run time now: 6.273823976516724
total time:  6.295884773135185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 82.33 ± 0.35
[I 2023-06-12 00:26:01,773] Trial 133 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.09821336601005447, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.623314132874847, 'loop': 1, 'loss': 'CE', 'lr': 0.009736227607792901, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.88519507273077e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.009746329044013548
weight_decay:  6.123552100912051e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5717714380007237
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 83.30
Split: 01, Run: 02
None time:  1.533807918895036
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.70
Split: 01, Run: 03
None time:  1.9827327670063823
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
run time now: 5.115227937698364
total time:  5.14054435887374
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 82.77 ± 0.50
[I 2023-06-12 00:26:07,462] Trial 134 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.09078329375675759, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.712163013841903, 'loop': 1, 'loss': 'CE', 'lr': 0.009746329044013548, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.123552100912051e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.009721644525256843
weight_decay:  9.924972178885385e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.776335627073422
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 83.20
Split: 01, Run: 02
None time:  1.3437507210765034
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 83.40
Split: 01, Run: 03
None time:  1.5849700779654086
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.734960556030273
total time:  4.764342399081215
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 82.70 ± 1.04
[I 2023-06-12 00:26:12,758] Trial 135 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.07655916543836798, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.6881945409378805, 'loop': 1, 'loss': 'CE', 'lr': 0.009721644525256843, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.924972178885385e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.007687931746671002
weight_decay:  0.00012728366262968634
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6620892998762429
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  1.6095294179394841
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 03
None time:  1.6248202288988978
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
run time now: 5.042147874832153
total time:  5.062699695117772
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 82.40 ± 0.46
[I 2023-06-12 00:26:18,385] Trial 136 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.09381073235915316, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.097537883259267, 'loop': 1, 'loss': 'CE', 'lr': 0.007687931746671002, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012728366262968634, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.009117095556357478
weight_decay:  0.00014684632041125258
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2766091879457235
None Run 01:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 02
None time:  1.0421450741123408
None Run 02:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.592381990980357
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 77.30
run time now: 3.939467191696167
total time:  3.9587221019901335
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.93 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 77.97 ± 0.61
[I 2023-06-12 00:26:22,878] Trial 137 finished with value: 77.93333435058594 and parameters: {'Fwd': 0.09929484740927255, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.59799151510001, 'loop': 1, 'loss': 'CE', 'lr': 0.009117095556357478, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.00014684632041125258, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007278212363086579
weight_decay:  6.194575766831309e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5216493560001254
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.2022346090525389
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.750072100199759
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.516132831573486
total time:  4.536197524052113
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.95
[I 2023-06-12 00:26:27,895] Trial 138 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.07477796244758693, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.770107233628673, 'loop': 1, 'loss': 'CE', 'lr': 0.007278212363086579, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.194575766831309e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0075351799578131425
weight_decay:  6.981839036965068e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.654002082068473
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.7173803229816258
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.6059441519901156
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.007863521575928
total time:  5.028936018934473
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.60
[I 2023-06-12 00:26:33,451] Trial 139 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.07433413427981252, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.751463616247547, 'loop': 1, 'loss': 'CE', 'lr': 0.0075351799578131425, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.981839036965068e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006366012262138085
weight_decay:  5.847628641096197e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5726824270095676
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6634916430339217
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.5727758519351482
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
run time now: 4.834414005279541
total time:  4.852172682061791
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.26
[I 2023-06-12 00:26:38,862] Trial 140 finished with value: 81.19999694824219 and parameters: {'Fwd': 0.07177722972933248, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.773667626664082, 'loop': 1, 'loss': 'CE', 'lr': 0.006366012262138085, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.847628641096197e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.00742139658210346
weight_decay:  8.662314828817166e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6873075389303267
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.1941004311665893
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.6487052040174603
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.557340383529663
total time:  4.5706409639678895
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.86
[I 2023-06-12 00:26:43,991] Trial 141 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.08158845887340742, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.542243659095884, 'loop': 1, 'loss': 'CE', 'lr': 0.00742139658210346, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.662314828817166e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006992883530500438
weight_decay:  9.355599054748886e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6426588268950582
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.681776992045343
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.7212060480378568
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.088782787322998
total time:  5.114374037832022
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.46
[I 2023-06-12 00:26:49,648] Trial 142 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.07272351204912147, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.656338834684677, 'loop': 1, 'loss': 'CE', 'lr': 0.006992883530500438, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.355599054748886e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.007053346544141004
weight_decay:  8.181170956408732e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.308390944963321
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6492614950984716
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.7038607699796557
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.68384313583374
total time:  4.702821562997997
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.55
[I 2023-06-12 00:26:54,931] Trial 143 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.06056458553673224, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.510717874621637, 'loop': 1, 'loss': 'CE', 'lr': 0.007053346544141004, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.181170956408732e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.007055859516321674
weight_decay:  9.087862716573979e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.48283635196276
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.399453273974359
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.6276241489686072
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.542910575866699
total time:  4.560064202174544
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.96
[I 2023-06-12 00:27:00,036] Trial 144 finished with value: 81.66666412353516 and parameters: {'Fwd': 0.0673693744704567, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.508365416520126, 'loop': 1, 'loss': 'CE', 'lr': 0.007055859516321674, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.087862716573979e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006996642929368858
weight_decay:  9.186044232779304e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2820060250815004
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6351860919967294
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.429907684912905
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.3738062381744385
total time:  4.387793675996363
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.91
[I 2023-06-12 00:27:04,932] Trial 145 finished with value: 81.66666412353516 and parameters: {'Fwd': 0.06781971363503603, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.570706122977733, 'loop': 1, 'loss': 'CE', 'lr': 0.006996642929368858, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.186044232779304e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006263296312236625
weight_decay:  9.110879975720895e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5038268289063126
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.6915630588773638
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.6818669438362122
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.906120777130127
total time:  4.921891285805032
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.45
[I 2023-06-12 00:27:10,346] Trial 146 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.06316374504476227, 'K': 10, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.759760609189751, 'loop': 1, 'loss': 'CE', 'lr': 0.006263296312236625, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.110879975720895e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006972990879425063
weight_decay:  0.00010111677363175409
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2469029668718576
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6378274329472333
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.6765594431199133
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.585461139678955
total time:  4.605760689126328
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.50
[I 2023-06-12 00:27:15,455] Trial 147 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.05763167436870864, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.539529184590404, 'loop': 1, 'loss': 'CE', 'lr': 0.006972990879425063, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010111677363175409, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.006572587436095822
weight_decay:  0.0001103490237189322
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4025677591562271
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.280995577108115
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.724468223983422
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.439415693283081
total time:  4.460024279076606
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.31
[I 2023-06-12 00:27:20,401] Trial 148 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.05225073016530441, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.807709659757953, 'loop': 1, 'loss': 'CE', 'lr': 0.006572587436095822, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001103490237189322, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0069517262735733715
weight_decay:  0.00014707431595507148
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.656980698928237
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.443266161950305
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.3815639449749142
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.583129167556763
total time:  4.605851794825867
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.51
[I 2023-06-12 00:27:25,452] Trial 149 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.06504708135505366, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.439979913364207, 'loop': 1, 'loss': 'CE', 'lr': 0.0069517262735733715, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014707431595507148, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.005953482371071452
weight_decay:  0.0001471442167217119
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.664928943151608
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.442776792915538
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.6629126039333642
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.799378871917725
total time:  4.815557986032218
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.35
[I 2023-06-12 00:27:30,700] Trial 150 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.05439517482955438, 'K': 10, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.5315537129891625, 'loop': 1, 'loss': 'CE', 'lr': 0.005953482371071452, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001471442167217119, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0069404394070968845
weight_decay:  8.818014307870805e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5410380840767175
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.2802261030301452
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.6547989610116929
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.509693384170532
total time:  4.524845473002642
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.85
[I 2023-06-12 00:27:35,668] Trial 151 finished with value: 81.66666412353516 and parameters: {'Fwd': 0.06881571738511069, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.678812563017919, 'loop': 1, 'loss': 'CE', 'lr': 0.0069404394070968845, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.818014307870805e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0069261812023376996
weight_decay:  9.640907052629585e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6557898551691324
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6637643061112612
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.549394248984754
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.895040035247803
total time:  4.9148023661691695
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.46
[I 2023-06-12 00:27:41,083] Trial 152 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.06926982681368163, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.439481475008481, 'loop': 1, 'loss': 'CE', 'lr': 0.0069261812023376996, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.640907052629585e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006967079453083724
weight_decay:  9.374649451177119e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6594816539436579
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.3911839509382844
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.723359805997461
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.83479118347168
total time:  4.868331179022789
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.51
[I 2023-06-12 00:27:46,528] Trial 153 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.06534973409661708, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.451576125565667, 'loop': 1, 'loss': 'CE', 'lr': 0.006967079453083724, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.374649451177119e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.007078489237699559
weight_decay:  0.00011066541336897127
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.478139994898811
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.484939418034628
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.6290427218191326
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.621596336364746
total time:  4.638773638987914
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.53
[I 2023-06-12 00:27:51,596] Trial 154 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.06340373105720569, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.1628398162211955, 'loop': 1, 'loss': 'CE', 'lr': 0.007078489237699559, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011066541336897127, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006890162745820948
weight_decay:  0.0001296989676724455
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7547190100885928
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.5199511661194265
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.7860012520104647
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.60
run time now: 5.089803457260132
total time:  5.108010954922065
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 81.30 ± 0.75
[I 2023-06-12 00:27:57,171] Trial 155 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.030647889487708312, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.509285264959386, 'loop': 1, 'loss': 'CE', 'lr': 0.006890162745820948, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001296989676724455, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.005762020960707835
weight_decay:  8.912291758250658e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6397530101239681
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  1.6949290661141276
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.7004431509412825
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.062517881393433
total time:  5.075311413034797
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.12
[I 2023-06-12 00:28:02,766] Trial 156 finished with value: 81.0 and parameters: {'Fwd': 0.05083242305350595, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.425736076974105, 'loop': 1, 'loss': 'CE', 'lr': 0.005762020960707835, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.912291758250658e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.006496472070559373
weight_decay:  9.064235598821581e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3314939090050757
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.4291366671677679
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.676725239958614
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.465799570083618
total time:  4.4824339910410345
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.57
[I 2023-06-12 00:28:07,656] Trial 157 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.07136413980937181, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.178158236015405, 'loop': 1, 'loss': 'CE', 'lr': 0.006496472070559373, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.064235598821581e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.007179311930203751
weight_decay:  0.00016498202764669365
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6431690759491175
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.7783909810241312
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.3736515240743756
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.826021909713745
total time:  4.846378490095958
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 81.30 ± 0.85
[I 2023-06-12 00:28:13,079] Trial 158 finished with value: 81.00000762939453 and parameters: {'Fwd': 0.03530214651239139, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 6.19359327079016, 'loop': 1, 'loss': 'CE', 'lr': 0.007179311930203751, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016498202764669365, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0062450013468352316
weight_decay:  0.00011873889432521982
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6166511848568916
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.455656056990847
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.6761521270964295
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.774882555007935
total time:  4.789439712185413
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.38
[I 2023-06-12 00:28:18,367] Trial 159 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.06302069692338538, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.846189678422283, 'loop': 1, 'loss': 'CE', 'lr': 0.0062450013468352316, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011873889432521982, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.00591128328206095
weight_decay:  5.09023450342379e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2014535190537572
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  1.0356167529243976
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.0357928599696606
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 80.00
run time now: 3.3038151264190674
total time:  3.3234174069948494
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 2.12
  Final Train: 100.00 ± 0.00
   Final Test: 79.47 ± 1.19
[I 2023-06-12 00:28:22,174] Trial 160 finished with value: 78.20000457763672 and parameters: {'Fwd': 0.04470343322158403, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.416304360743256, 'loop': 1, 'loss': 'CE', 'lr': 0.00591128328206095, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.09023450342379e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0070871534371548745
weight_decay:  0.00010900659619711023
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4483026950620115
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.4415614381432533
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.6935835198964924
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.61009669303894
total time:  4.6293021098244935
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.96
[I 2023-06-12 00:28:27,266] Trial 161 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.06630095424751621, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.168318947821434, 'loop': 1, 'loss': 'CE', 'lr': 0.0070871534371548745, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010900659619711023, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006915491074460062
weight_decay:  8.44710034657261e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6879583930131048
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.4032780611887574
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.6120768000837415
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.7322070598602295
total time:  4.750215122010559
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.46
[I 2023-06-12 00:28:32,488] Trial 162 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.06959834535106603, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.244138273142684, 'loop': 1, 'loss': 'CE', 'lr': 0.006915491074460062, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.44710034657261e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.008326569238569214
weight_decay:  0.00015587220002130037
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.958152640145272
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.9091674629598856
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.7429285200778395
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 5.641528129577637
total time:  5.661166332894936
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 80.77 ± 1.06
[I 2023-06-12 00:28:38,683] Trial 163 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.05181683322003849, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.006441618915535, 'loop': 1, 'loss': 'CE', 'lr': 0.008326569238569214, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015587220002130037, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.007587984421331843
weight_decay:  9.815787930802193e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5918364231474698
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.611112432088703
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.722614635946229
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.955596208572388
total time:  4.974768306827173
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.67
[I 2023-06-12 00:28:44,215] Trial 164 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.06934660512375182, 'K': 10, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.510736042217878, 'loop': 1, 'loss': 'CE', 'lr': 0.007587984421331843, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.815787930802193e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.005508981954497849
weight_decay:  7.395965818177553e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2114845039322972
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6292239108588547
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.6861890689469874
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.555920839309692
total time:  4.576913251075894
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.25
[I 2023-06-12 00:28:49,367] Trial 165 finished with value: 81.20000457763672 and parameters: {'Fwd': 0.02994866709797043, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.039896056219989, 'loop': 1, 'loss': 'CE', 'lr': 0.005508981954497849, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.395965818177553e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.00667900235335245
weight_decay:  0.00021762740432084045
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6350584209430963
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.5108317320700735
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.4953912741038948
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.40
run time now: 3.665168523788452
total time:  3.679209497058764
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.23
[I 2023-06-12 00:28:53,521] Trial 166 finished with value: 81.0 and parameters: {'Fwd': 0.052987211359305515, 'K': 10, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 5.285651193801917, 'loop': 1, 'loss': 'CE', 'lr': 0.00667900235335245, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021762740432084045, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.008487632623294751
weight_decay:  5.387729759315562e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6404307698830962
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.7156935459934175
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.2374339988455176
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.621049880981445
total time:  4.638397624948993
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.45
[I 2023-06-12 00:28:58,612] Trial 167 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.07368127201846378, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.832616457178178, 'loop': 1, 'loss': 'CE', 'lr': 0.008487632623294751, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.387729759315562e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007630567219826651
weight_decay:  0.00011873361399227
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8021369280759245
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.9550838959403336
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.8647869110573083
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 5.65320611000061
total time:  5.67559667583555
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.68
[I 2023-06-12 00:29:04,740] Trial 168 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.03593455362110749, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.445377519031248, 'loop': 1, 'loss': 'CE', 'lr': 0.007630567219826651, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011873361399227, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0060829534333027
weight_decay:  7.755905407461289e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4858342839870602
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.373656352981925
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.5727266741450876
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.457974672317505
total time:  4.477457378990948
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.47
[I 2023-06-12 00:29:09,694] Trial 169 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.054450672481803415, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 1.0, 'lambda2': 6.181869625895474, 'loop': 1, 'loss': 'CE', 'lr': 0.0060829534333027, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.755905407461289e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007171769962645684
weight_decay:  0.00017531356805654803
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6580304589588195
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.618944824906066
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.102736596018076
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.407644510269165
total time:  4.422727431869134
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.98
[I 2023-06-12 00:29:14,706] Trial 170 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.07718985307454501, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.079560849871017, 'loop': 1, 'loss': 'CE', 'lr': 0.007171769962645684, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017531356805654803, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0070565756944283515
weight_decay:  0.00017712722534149193
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6696603510063142
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.6496096199844033
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.5742228969465941
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.961018323898315
total time:  5.022020248929039
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.91
[I 2023-06-12 00:29:20,328] Trial 171 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.07227542905619962, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.063532793444858, 'loop': 1, 'loss': 'CE', 'lr': 0.0070565756944283515, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017712722534149193, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.008224608065019899
weight_decay:  0.00019266293712464472
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.453011306002736
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.4434975690674037
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.4584400989115238
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.20
run time now: 4.3802268505096436
total time:  4.394153069937602
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.10 ± 0.90
[I 2023-06-12 00:29:25,226] Trial 172 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.07886207329407167, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.062709923825144, 'loop': 1, 'loss': 'CE', 'lr': 0.008224608065019899, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00019266293712464472, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0072171795628314574
weight_decay:  0.0001518636174492386
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4778319359757006
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.5955518570262939
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.6802062939386815
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.784504652023315
total time:  4.799909198889509
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.60
[I 2023-06-12 00:29:30,527] Trial 173 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.043848572428560544, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.200147050640127, 'loop': 1, 'loss': 'CE', 'lr': 0.0072171795628314574, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001518636174492386, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.008803667130928786
weight_decay:  0.0002471208623054099
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.710954065900296
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.6673713109921664
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  1.8904475951567292
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.306606292724609
total time:  5.375384723069146
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.20 ± 1.15
[I 2023-06-12 00:29:36,384] Trial 174 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.05942158530775175, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 4.875065603210754, 'loop': 1, 'loss': 'CE', 'lr': 0.008803667130928786, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002471208623054099, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.005504262162265428
weight_decay:  0.00013036454824666047
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.504085490014404
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.5144239908549935
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.2911119589116424
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.40
run time now: 4.338520288467407
total time:  4.35423437692225
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.30
[I 2023-06-12 00:29:41,187] Trial 175 finished with value: 80.80000305175781 and parameters: {'Fwd': 0.07884279755197016, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 5.6418691285583495, 'loop': 1, 'loss': 'CE', 'lr': 0.005504262162265428, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013036454824666047, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.006473479961437974
weight_decay:  6.554677935224966e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5801559679675847
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.6779583820607513
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.4131332009565085
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.699091672897339
total time:  4.718818531837314
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.32
[I 2023-06-12 00:29:46,531] Trial 176 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.04608357870441662, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.0284378687866855, 'loop': 1, 'loss': 'CE', 'lr': 0.006473479961437974, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.554677935224966e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.007778575454022026
weight_decay:  0.00018248253679311585
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5955339749343693
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.444880115101114
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.5571362609043717
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.625577926635742
total time:  4.640261941123754
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.96
[I 2023-06-12 00:29:51,718] Trial 177 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.0794119546688651, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.935140537328203, 'loop': 1, 'loss': 'CE', 'lr': 0.007778575454022026, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00018248253679311585, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.008647043186261145
weight_decay:  0.0003311254719227267
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.646794632077217
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.6868510751519352
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.775678938953206
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.70
run time now: 5.137353420257568
total time:  5.155304274056107
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.71
[I 2023-06-12 00:29:57,457] Trial 178 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.0999221099048836, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.312959533628305, 'loop': 1, 'loss': 'CE', 'lr': 0.008647043186261145, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003311254719227267, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.007167927721799556
weight_decay:  0.00011211781635076486
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0014474280178547
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.5634057740680873
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.4803156058769673
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.70
run time now: 4.072375774383545
total time:  4.0923147930298
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.06
[I 2023-06-12 00:30:02,101] Trial 179 finished with value: 80.86666107177734 and parameters: {'Fwd': 0.05579442598136889, 'K': 10, 'alpha': 0.55, 'dropout': 0.30000000000000004, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 5.598507690722227, 'loop': 1, 'loss': 'CE', 'lr': 0.007167927721799556, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011211781635076486, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006097765203321831
weight_decay:  6.239860294868192e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6389344059862196
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.8207239490002394
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.8043552341405302
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.40
run time now: 5.294345378875732
total time:  5.3157052849419415
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.96
[I 2023-06-12 00:30:07,927] Trial 180 finished with value: 81.0 and parameters: {'Fwd': 0.02739434573516678, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 5.906189372969873, 'loop': 1, 'loss': 'CE', 'lr': 0.006097765203321831, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.239860294868192e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.006822239967910496
weight_decay:  9.344058201258602e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4168872660957277
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6594467679969966
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.4964852510020137
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.6018946170806885
total time:  4.617006431799382
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.45
[I 2023-06-12 00:30:13,001] Trial 181 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.06551323354851059, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.390346887166908, 'loop': 1, 'loss': 'CE', 'lr': 0.006822239967910496, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.344058201258602e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.00802490659336426
weight_decay:  8.080494910888168e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4899695399217308
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.5687140498775989
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.7466395350638777
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.8330299854278564
total time:  4.8460142409894615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.20 ± 0.80
[I 2023-06-12 00:30:18,365] Trial 182 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.07059854401496725, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.603635330155103, 'loop': 1, 'loss': 'CE', 'lr': 0.00802490659336426, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.080494910888168e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.009000216709465329
weight_decay:  5.4039433988203626e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3881494970992208
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.4705594840925187
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.7715758809354156
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 4.658228158950806
total time:  4.674604133935645
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.67
[I 2023-06-12 00:30:23,621] Trial 183 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.0378432272616789, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.152883348068598, 'loop': 1, 'loss': 'CE', 'lr': 0.009000216709465329, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.4039433988203626e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0011656185692782736
weight_decay:  0.00010054318319316492
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7671572479885072
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 02
None time:  1.5850537861697376
None Run 02:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 76.00
Split: 01, Run: 03
None time:  1.2234727919567376
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 76.80
run time now: 4.60713267326355
total time:  4.627554971957579
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.80 ± 2.42
  Final Train: 100.00 ± 0.00
   Final Test: 77.40 ± 1.78
[I 2023-06-12 00:30:28,830] Trial 184 finished with value: 76.79999542236328 and parameters: {'Fwd': 0.06355349293255387, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.427228120146009, 'loop': 1, 'loss': 'CE', 'lr': 0.0011656185692782736, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010054318319316492, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.007112806282789784
weight_decay:  4.904967433987394e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.65076536196284
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.650760558899492
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.4929459909908473
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.824574708938599
total time:  4.845049232011661
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.93
[I 2023-06-12 00:30:34,120] Trial 185 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.07904401161208513, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.74048707835048, 'loop': 1, 'loss': 'CE', 'lr': 0.007112806282789784, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.904967433987394e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.007648261824759848
weight_decay:  4.579768377959935e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4060356519185007
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.6504784310236573
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.7675481191836298
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.851193189620972
total time:  4.864681167062372
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.70
[I 2023-06-12 00:30:39,566] Trial 186 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.09801442587813958, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.778649799218555, 'loop': 1, 'loss': 'CE', 'lr': 0.007648261824759848, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.579768377959935e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.000577973078877323
weight_decay:  3.5616309046121924e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8524321308359504
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 02
None time:  1.616430088179186
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 03
None time:  1.757028104038909
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.70
run time now: 5.251360654830933
total time:  5.2653729328885674
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.90 ± 0.26
[I 2023-06-12 00:30:45,312] Trial 187 finished with value: 78.79999542236328 and parameters: {'Fwd': 0.04793020633707951, 'K': 10, 'alpha': 0.55, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 6.057737411605951, 'loop': 1, 'loss': 'CE', 'lr': 0.000577973078877323, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.5616309046121924e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0065005807388287705
weight_decay:  0.00013825924320453654
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4942894880659878
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.4644383729901165
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.3162842309102416
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.302889108657837
total time:  4.318829200929031
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.17
[I 2023-06-12 00:30:50,158] Trial 188 finished with value: 81.0666732788086 and parameters: {'Fwd': 0.08170761677904355, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.720496501804258, 'loop': 1, 'loss': 'CE', 'lr': 0.0065005807388287705, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013825924320453654, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.005566578424905352
weight_decay:  6.902819255847286e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.634009923087433
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.7095455259550363
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.788076409138739
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.40
run time now: 5.163847208023071
total time:  5.1876521981321275
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.26
[I 2023-06-12 00:30:55,816] Trial 189 finished with value: 81.0 and parameters: {'Fwd': 0.08091530878832273, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.800709842248709, 'loop': 1, 'loss': 'CE', 'lr': 0.005566578424905352, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.902819255847286e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.008298231328285683
weight_decay:  5.000801988531321e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0174265410751104
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 02
None time:  1.226208225125447
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 99.29
   Final Test: 80.70
Split: 01, Run: 03
None time:  0.994227654999122
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
run time now: 3.2611050605773926
total time:  3.2845317719038576
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.80
  Final Train: 99.76 ± 0.41
   Final Test: 81.03 ± 0.76
[I 2023-06-12 00:30:59,614] Trial 190 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.05640806881360752, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.228125351013021, 'loop': 1, 'loss': 'CE', 'lr': 0.008298231328285683, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.000801988531321e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007082167765205281
weight_decay:  8.765789698961758e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6823914980050176
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.3107030850369483
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.6405391998123378
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.811519384384155
total time:  4.899961998919025
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.95
[I 2023-06-12 00:31:05,126] Trial 191 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.06712741034942579, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.500706275259317, 'loop': 1, 'loss': 'CE', 'lr': 0.007082167765205281, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.765789698961758e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007383350386729689
weight_decay:  7.134141942470491e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6584004331380129
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.6418903628364205
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.7092888120096177
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.040262937545776
total time:  5.075826738029718
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.91
[I 2023-06-12 00:31:10,795] Trial 192 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.0986447472446272, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.588276001684296, 'loop': 1, 'loss': 'CE', 'lr': 0.007383350386729689, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.134141942470491e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.009000146826426173
weight_decay:  0.00011650319195696463
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2097280248999596
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.6170018389821053
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.7209649081341922
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
run time now: 4.57967472076416
total time:  4.596185031812638
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.85
[I 2023-06-12 00:31:15,808] Trial 193 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.07628823326498568, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.748417727362242, 'loop': 1, 'loss': 'CE', 'lr': 0.009000146826426173, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011650319195696463, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.006799373222252902
weight_decay:  0.00016124846732217102
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4467848108615726
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.5692949660588056
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.5691303531639278
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.6122448444366455
total time:  4.6265462869778275
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.40
[I 2023-06-12 00:31:20,891] Trial 194 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.04310108088432371, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.371198599596962, 'loop': 1, 'loss': 'CE', 'lr': 0.006799373222252902, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016124846732217102, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0059069935628445515
weight_decay:  5.162235686829621e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.423534442903474
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.6700841549318284
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.6501185200177133
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.772249937057495
total time:  4.7916453529614955
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.17
[I 2023-06-12 00:31:26,122] Trial 195 finished with value: 81.0 and parameters: {'Fwd': 0.0009572332551546343, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.048713687011225, 'loop': 1, 'loss': 'CE', 'lr': 0.0059069935628445515, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.162235686829621e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007809475701743617
weight_decay:  7.907268949057205e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4938408669549972
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.2207019999623299
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.7916713550221175
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.531117677688599
total time:  4.5518612819723785
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.70
[I 2023-06-12 00:31:31,152] Trial 196 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.05966678800032745, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.959539011692384, 'loop': 1, 'loss': 'CE', 'lr': 0.007809475701743617, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.907268949057205e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006382872418192147
weight_decay:  0.0001021547566557766
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6345788950566202
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.9312728599179536
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.5980694270692766
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.193629026412964
total time:  5.218121243873611
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.56
[I 2023-06-12 00:31:36,791] Trial 197 finished with value: 81.06666564941406 and parameters: {'Fwd': 0.07707273148010804, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 5.5171316329073115, 'loop': 1, 'loss': 'CE', 'lr': 0.006382872418192147, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001021547566557766, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.009065796879676393
weight_decay:  3.782504262719924e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5110376731026918
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.7834277239162475
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.84981643804349
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.174193620681763
total time:  5.204808895010501
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.57
[I 2023-06-12 00:31:42,445] Trial 198 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.034927224969951695, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.169582198792475, 'loop': 1, 'loss': 'CE', 'lr': 0.009065796879676393, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.782504262719924e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.007107490465904248
weight_decay:  6.10660667629936e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.290489035891369
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6042027240619063
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.197511144913733
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.1221923828125
total time:  4.143735037883744
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.23
[I 2023-06-12 00:31:47,102] Trial 199 finished with value: 81.0666732788086 and parameters: {'Fwd': 0.04795362918605618, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 5.849138925197456, 'loop': 1, 'loss': 'CE', 'lr': 0.007107490465904248, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.10660667629936e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.008137577179833693
weight_decay:  0.00021457237524686508
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6561198020353913
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6528858100064099
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.475109055172652
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 4.8100011348724365
total time:  4.828271553153172
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.70
[I 2023-06-12 00:31:52,427] Trial 200 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.06139495667777305, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 4.529034865960415, 'loop': 1, 'loss': 'CE', 'lr': 0.008137577179833693, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021457237524686508, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.007028694242304323
weight_decay:  9.259088117184447e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4816442849114537
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6705363360233605
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.6726598769892007
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.8529980182647705
total time:  4.871562764979899
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.47
[I 2023-06-12 00:31:57,806] Trial 201 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.06663923538959027, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.395290052155654, 'loop': 1, 'loss': 'CE', 'lr': 0.007028694242304323, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.259088117184447e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.007282886853791641
weight_decay:  0.00012981074715198452
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3118771410081536
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.4341245761606842
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.7072461410425603
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.47817587852478
total time:  4.5126835578121245
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.93
[I 2023-06-12 00:32:02,795] Trial 202 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.07730241997214979, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.540952970186813, 'loop': 1, 'loss': 'CE', 'lr': 0.007282886853791641, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012981074715198452, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.0019053287624612126
weight_decay:  7.925276649323792e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.639432196971029
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  1.3109522119630128
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 03
None time:  1.417597338091582
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 78.00
run time now: 4.39471173286438
total time:  4.414190866984427
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 78.73 ± 1.36
[I 2023-06-12 00:32:07,703] Trial 203 finished with value: 78.20000457763672 and parameters: {'Fwd': 0.09971696461526978, 'K': 10, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.197273000972881, 'loop': 1, 'loss': 'CE', 'lr': 0.0019053287624612126, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.925276649323792e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006358940060793302
weight_decay:  9.98523142012663e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5868496671319008
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.5430828819517046
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.6609593899920583
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.8188769817352295
total time:  4.836683804169297
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.35
[I 2023-06-12 00:32:13,024] Trial 204 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.05246409405596037, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.640371757948807, 'loop': 1, 'loss': 'CE', 'lr': 0.006358940060793302, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.98523142012663e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.00030286034669139544
weight_decay:  5.699494810714203e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.041280389064923
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  1.6330836040433496
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.7577170999720693
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.4606544971466064
total time:  5.479270581854507
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.87 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 77.93 ± 0.21
[I 2023-06-12 00:32:18,938] Trial 205 finished with value: 77.86666870117188 and parameters: {'Fwd': 0.06487977148309629, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.358709277643242, 'loop': 1, 'loss': 'CE', 'lr': 0.00030286034669139544, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.699494810714203e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.008161936707608557
weight_decay:  0.00013454572443127516
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.671905922004953
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.695104273967445
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.4588270538952202
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.8546833992004395
total time:  4.872630514902994
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.70
[I 2023-06-12 00:32:24,382] Trial 206 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.08080396375772124, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.932561186142936, 'loop': 1, 'loss': 'CE', 'lr': 0.008161936707608557, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013454572443127516, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.005076493287602177
weight_decay:  8.38866219213218e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7201493640895933
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.884333882946521
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.3571374411694705
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.987014055252075
total time:  5.012147203087807
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.44
[I 2023-06-12 00:32:29,930] Trial 207 finished with value: 80.80000305175781 and parameters: {'Fwd': 0.04228561011205939, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.831242181008983, 'loop': 1, 'loss': 'CE', 'lr': 0.005076493287602177, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.38866219213218e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.00888591734545168
weight_decay:  6.53293200455127e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5187242859974504
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.5983092770911753
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.5359758860431612
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.682203054428101
total time:  4.7006742029916495
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 1.00
[I 2023-06-12 00:32:35,108] Trial 208 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.06393045690546688, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.498693446011158, 'loop': 1, 'loss': 'CE', 'lr': 0.00888591734545168, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.53293200455127e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.005751926455353639
weight_decay:  4.244393974536441e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5203060668427497
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6412711290176958
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.6428283639252186
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.853722333908081
total time:  4.8674644969869405
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.50
[I 2023-06-12 00:32:40,517] Trial 209 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.09970563092594101, 'K': 10, 'alpha': 0.75, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.17546836023677, 'loop': 1, 'loss': 'CE', 'lr': 0.005751926455353639, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.244393974536441e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.006786889548342046
weight_decay:  0.0001797398908823001
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8165037950966507
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.558942232048139
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.6909532931167632
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.80
run time now: 5.09348201751709
total time:  5.108038970036432
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.74
[I 2023-06-12 00:32:46,034] Trial 210 finished with value: 81.0 and parameters: {'Fwd': 0.05211205542398836, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.651215166423337, 'loop': 1, 'loss': 'CE', 'lr': 0.006786889548342046, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001797398908823001, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.007218273688636466
weight_decay:  0.00011299010264759764
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6463986949529499
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.6325440360233188
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 03
None time:  1.1537269251421094
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.458337068557739
total time:  4.473337328992784
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 1.02
[I 2023-06-12 00:32:51,062] Trial 211 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.07067921859142859, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.119371816477001, 'loop': 1, 'loss': 'CE', 'lr': 0.007218273688636466, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011299010264759764, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.007625992248436689
weight_decay:  9.831705661523319e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.036269397009164
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 02
None time:  0.9822665920946747
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  0.8835808481089771
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 2.927028179168701
total time:  2.9426856758072972
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 0.80
  Final Train: 100.00 ± 0.00
   Final Test: 80.40 ± 0.62
[I 2023-06-12 00:32:54,536] Trial 212 finished with value: 79.5999984741211 and parameters: {'Fwd': 0.06167085854547846, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 20, 'lambda1': 0.8, 'lambda2': 5.310922471031128, 'loop': 1, 'loss': 'CE', 'lr': 0.007625992248436689, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.831705661523319e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.006768120638808272
weight_decay:  7.748296130816922e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.612751569133252
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6684547408949584
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.527358649065718
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.841706275939941
total time:  4.860605577006936
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.61
[I 2023-06-12 00:32:59,887] Trial 213 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.07872474793363106, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.749497937431928, 'loop': 1, 'loss': 'CE', 'lr': 0.006768120638808272, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.748296130816922e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.008266894973031198
weight_decay:  0.00011835140220364892
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4521502549760044
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6461748951114714
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.69127178308554
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.822612762451172
total time:  4.854510090081021
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.64
[I 2023-06-12 00:33:05,190] Trial 214 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.05220492865291853, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.0118633196760065, 'loop': 1, 'loss': 'CE', 'lr': 0.008266894973031198, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011835140220364892, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0061983139189149385
weight_decay:  0.00016013216140488631
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2590196901001036
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.408632674952969
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.6799549080897123
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.3771913051605225
total time:  4.393421196844429
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.25
[I 2023-06-12 00:33:10,028] Trial 215 finished with value: 81.13333892822266 and parameters: {'Fwd': 0.03251752995663927, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.460454732065465, 'loop': 1, 'loss': 'CE', 'lr': 0.0061983139189149385, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016013216140488631, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.009214825141110921
weight_decay:  0.00010183606723895325
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6628929530270398
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.6357023119926453
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.1582153351046145
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.485558271408081
total time:  4.5015209200792015
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 1.00
[I 2023-06-12 00:33:14,954] Trial 216 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.08263040619601489, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.239157510566949, 'loop': 1, 'loss': 'CE', 'lr': 0.009214825141110921, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010183606723895325, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007297270635712468
weight_decay:  4.9322399651907684e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4248116870876402
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.718108895001933
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.7248562809545547
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.8967132568359375
total time:  4.913224181858823
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.40
[I 2023-06-12 00:33:20,414] Trial 217 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.09988380767314736, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.801908562103427, 'loop': 1, 'loss': 'CE', 'lr': 0.007297270635712468, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.9322399651907684e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007696862687714449
weight_decay:  5.2531199650878914e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.060840736841783
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.6116155539639294
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.6865135240368545
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
run time now: 4.385437250137329
total time:  4.404933262849227
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 81.83 ± 0.42
[I 2023-06-12 00:33:25,306] Trial 218 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.09994930605366166, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 6.057677626943616, 'loop': 1, 'loss': 'CE', 'lr': 0.007696862687714449, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.2531199650878914e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.008322131849573713
weight_decay:  4.026492784804867e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.675517522962764
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.7023284430615604
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.7248141020536423
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.131691217422485
total time:  5.150315623963252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.64
[I 2023-06-12 00:33:30,977] Trial 219 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.00017031821458058762, 'K': 10, 'alpha': 0.5, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.819456638005959, 'loop': 1, 'loss': 'CE', 'lr': 0.008322131849573713, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.026492784804867e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.001522993938651927
weight_decay:  6.592998496251255e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3994489181786776
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02
None time:  1.4721290240995586
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  1.179338354850188
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.076959609985352
total time:  4.098677140893415
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 80.27 ± 0.21
[I 2023-06-12 00:33:35,588] Trial 220 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.08060591087925022, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.9500000000000001, 'lambda2': 5.665726865379116, 'loop': 1, 'loss': 'CE', 'lr': 0.001522993938651927, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.592998496251255e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.007055500036771771
weight_decay:  8.100508461739789e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6511023079510778
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.4688859081361443
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.70452408795245
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.856487035751343
total time:  4.877126517007127
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.93
[I 2023-06-12 00:33:41,039] Trial 221 finished with value: 81.66666412353516 and parameters: {'Fwd': 0.06603192599752335, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.482595516141926, 'loop': 1, 'loss': 'CE', 'lr': 0.007055500036771771, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.100508461739789e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006637785121736966
weight_decay:  8.506209411998117e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3871899889782071
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.6776063970755786
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.4876904638949782
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.581216335296631
total time:  4.597736805910245
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.35
[I 2023-06-12 00:33:46,097] Trial 222 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.06241176225490523, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.46581918360116, 'loop': 1, 'loss': 'CE', 'lr': 0.006637785121736966, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.506209411998117e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.007345579503402726
weight_decay:  5.063939514084764e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6451871520839632
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.190623752772808
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.3900698819197714
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.255345344543457
total time:  4.273787464015186
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.86
[I 2023-06-12 00:33:50,862] Trial 223 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.08020985209612715, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.89984206659666, 'loop': 1, 'loss': 'CE', 'lr': 0.007345579503402726, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.063939514084764e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.55
lr:  0.006017167716072702
weight_decay:  7.134640479189021e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.529772432986647
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.5278356350027025
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.3888145762030035
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.60
run time now: 4.469808578491211
total time:  4.484297015005723
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.03 ± 0.75
[I 2023-06-12 00:33:55,809] Trial 224 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.09845619868452786, 'K': 1, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.684456996670946, 'loop': 1, 'loss': 'CE', 'lr': 0.006017167716072702, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.134640479189021e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.009983634862230938
weight_decay:  6.111581664327538e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4037546848412603
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.7745142800267786
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.4578245370648801
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.40
run time now: 4.698891878128052
total time:  4.7180377680342644
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.60
[I 2023-06-12 00:34:01,054] Trial 225 finished with value: 81.26666259765625 and parameters: {'Fwd': 0.04642558977082223, 'K': 10, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.500944256722635, 'loop': 1, 'loss': 'CE', 'lr': 0.009983634862230938, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.111581664327538e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0008226364901538562
weight_decay:  8.857836422886486e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8331178878434002
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02
None time:  1.4401803030632436
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  1.6144445380195975
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.917186260223389
total time:  4.933768384857103
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.67 ± 6.01
  Final Train: 100.00 ± 0.00
   Final Test: 76.40 ± 5.65
[I 2023-06-12 00:34:06,464] Trial 226 finished with value: 75.66666412353516 and parameters: {'Fwd': 0.06958563515866278, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.745535730018451, 'loop': 1, 'loss': 'CE', 'lr': 0.0008226364901538562, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.857836422886486e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006912642332851673
weight_decay:  4.577063657965449e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6174761808943003
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.4110208249185234
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.4671496688388288
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.523618698120117
total time:  4.538096338044852
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.40
[I 2023-06-12 00:34:11,428] Trial 227 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.05657397113536654, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.066075713011416, 'loop': 1, 'loss': 'CE', 'lr': 0.006912642332851673, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.577063657965449e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0054193378447373
weight_decay:  0.00014152941869556684
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8696203387808055
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.8665258279070258
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 99.29
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.677763634128496
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 99.29
   Final Test: 81.30
run time now: 5.443615674972534
total time:  5.466460212133825
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.50
  Final Train: 99.29 ± 0.00
   Final Test: 81.33 ± 0.45
[I 2023-06-12 00:34:17,355] Trial 228 finished with value: 80.86666870117188 and parameters: {'Fwd': 3.675028775449517e-05, 'K': 10, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 1.3819379825101228, 'loop': 1, 'loss': 'CE', 'lr': 0.0054193378447373, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014152941869556684, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.007653401075023516
weight_decay:  3.3109019578295315e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.428472536150366
None Run 01:
Highest Train: 100.00
Highest Valid: 82.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.542513927910477
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.3288263538852334
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.3253490924835205
total time:  4.343988290056586
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 1.06
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.49
[I 2023-06-12 00:34:22,270] Trial 229 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.04037825854333961, 'K': 10, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.32354640291028, 'loop': 1, 'loss': 'CE', 'lr': 0.007653401075023516, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.3109019578295315e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.00902985440067001
weight_decay:  6.892147475714999e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9301907420158386
None Run 01:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 02
None time:  1.0391989587806165
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.0664473129436374
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 79.50
run time now: 3.0622737407684326
total time:  3.077138069085777
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.47 ± 1.30
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 1.88
[I 2023-06-12 00:34:25,803] Trial 230 finished with value: 76.46666717529297 and parameters: {'Fwd': 0.07976397679290945, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.599053871055894, 'loop': 1, 'loss': 'CE', 'lr': 0.00902985440067001, 'softmaxF': True, 'useGCN': False, 'weight_decay': 6.892147475714999e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.006890008415652722
weight_decay:  0.00011256003069570282
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.470596675062552
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.675162296043709
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.4203411280177534
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.594662666320801
total time:  4.609772783936933
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.45
[I 2023-06-12 00:34:30,856] Trial 231 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.0635202467650533, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.12072085276553, 'loop': 1, 'loss': 'CE', 'lr': 0.006890008415652722, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011256003069570282, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.006232510739740094
weight_decay:  9.472496763433553e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.442897534929216
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.6420909110456705
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.6500501970294863
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.765918254852295
total time:  4.783209851011634
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.29
[I 2023-06-12 00:34:36,148] Trial 232 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.06427286305779052, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.339108494315594, 'loop': 1, 'loss': 'CE', 'lr': 0.006232510739740094, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.472496763433553e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.007373625575093303
weight_decay:  0.00024794085066081543
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3604598408564925
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.4701445060782135
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.6963867768645287
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.559602737426758
total time:  4.585410695988685
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.75
[I 2023-06-12 00:34:41,188] Trial 233 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.08565610209484506, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.884432028231103, 'loop': 1, 'loss': 'CE', 'lr': 0.007373625575093303, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00024794085066081543, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.00820128856551024
weight_decay:  0.00012097040328808648
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4692122940905392
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.5377562469802797
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.4807765427976847
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.513383626937866
total time:  4.533205167856067
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 0.75
[I 2023-06-12 00:34:46,183] Trial 234 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.09934953845249091, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.936944327233365, 'loop': 1, 'loss': 'CE', 'lr': 0.00820128856551024, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012097040328808648, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.008158452936933432
weight_decay:  0.0001288047159429529
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4490233149845153
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.5953595319297165
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.7642467860132456
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.839879989624023
total time:  4.8620613540988415
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 0.75
[I 2023-06-12 00:34:51,510] Trial 235 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.09896302635660403, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.8697469803008016, 'loop': 1, 'loss': 'CE', 'lr': 0.008158452936933432, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001288047159429529, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.00845060710024089
weight_decay:  0.00018560557957781983
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.292509312974289
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.460553513141349
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.6141520491801202
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.394985675811768
total time:  4.413924653083086
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.93
[I 2023-06-12 00:34:56,473] Trial 236 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.09462407279205448, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 4.861361035053839, 'loop': 1, 'loss': 'CE', 'lr': 0.00845060710024089, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00018560557957781983, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0022360945888743496
weight_decay:  0.00013123465399451437
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6552822978701442
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  1.3239577480126172
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  1.5119643560610712
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 77.50
run time now: 4.521559238433838
total time:  4.5425672121346
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.60 ± 1.91
  Final Train: 100.00 ± 0.00
   Final Test: 78.90 ± 1.28
[I 2023-06-12 00:35:01,472] Trial 237 finished with value: 78.5999984741211 and parameters: {'Fwd': 0.08144894614801916, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.584795415233605, 'loop': 1, 'loss': 'CE', 'lr': 0.0022360945888743496, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013123465399451437, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.008116874267682414
weight_decay:  0.0003008620906303358
dropout:  0.0
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.667985568055883
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 02
None time:  1.6551840777974576
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  1.6643958741333336
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.50
run time now: 5.020238399505615
total time:  5.040076799923554
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 80.23 ± 0.75
[I 2023-06-12 00:35:06,980] Trial 238 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.0983020131783541, 'K': 10, 'alpha': 0.5, 'dropout': 0.0, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.938037108742855, 'loop': 1, 'loss': 'CE', 'lr': 0.008116874267682414, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003008620906303358, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00937980025804344
weight_decay:  0.0001572571236446245
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.818361486075446
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  1.8032016570214182
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  1.5599189950153232
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 5.209342002868652
total time:  5.2255315980874
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 1.14
[I 2023-06-12 00:35:12,713] Trial 239 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.05197760435809071, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 4.3460394881837745, 'loop': 1, 'loss': 'CE', 'lr': 0.00937980025804344, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0001572571236446245, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.008603144339234757
weight_decay:  7.379875562743152e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6622568920720369
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.7743398661259562
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.6675174050033092
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.128847599029541
total time:  5.145103103015572
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.79
[I 2023-06-12 00:35:18,453] Trial 240 finished with value: 81.26666259765625 and parameters: {'Fwd': 0.07366952703920791, 'K': 10, 'alpha': 0.5, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.7205058077862665, 'loop': 1, 'loss': 'CE', 'lr': 0.008603144339234757, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.379875562743152e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.007808832272828655
weight_decay:  8.737105291887713e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3124469679314643
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.717000009957701
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.723965578014031
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.773340702056885
total time:  4.797015895834193
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.49
[I 2023-06-12 00:35:23,717] Trial 241 finished with value: 81.0 and parameters: {'Fwd': 0.0005818345867157533, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.535573362976525, 'loop': 1, 'loss': 'CE', 'lr': 0.007808832272828655, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.737105291887713e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007332443602463815
weight_decay:  0.00011524004312789211
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5016163249965757
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.4814373729750514
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.7324751319829375
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.745835542678833
total time:  4.765404079807922
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.80
[I 2023-06-12 00:35:28,950] Trial 242 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.09911552955025037, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.3018068929132145, 'loop': 1, 'loss': 'CE', 'lr': 0.007332443602463815, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011524004312789211, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006534154858764253
weight_decay:  5.626926937453636e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4282306178938597
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.6592003018595278
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.4118736539967358
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.527328252792358
total time:  4.547731935046613
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.25
[I 2023-06-12 00:35:34,107] Trial 243 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.0687052376282388, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.628095485495184, 'loop': 1, 'loss': 'CE', 'lr': 0.006534154858764253, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.626926937453636e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0027629557788282537
weight_decay:  7.627297529251707e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7357999829109758
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 02
None time:  1.486711286008358
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  1.8791448411066085
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 79.50
run time now: 5.131162643432617
total time:  5.149653817992657
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.47 ± 1.14
  Final Train: 100.00 ± 0.00
   Final Test: 79.97 ± 0.64
[I 2023-06-12 00:35:39,830] Trial 244 finished with value: 79.46666717529297 and parameters: {'Fwd': 0.07623573367660182, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.1857389917144365, 'loop': 1, 'loss': 'CE', 'lr': 0.0027629557788282537, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.627297529251707e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007927798941630705
weight_decay:  0.0001034179888260377
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4705449261236936
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.7743995080236346
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.5106798668857664
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
run time now: 4.796451091766357
total time:  4.8099411288276315
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.44
[I 2023-06-12 00:35:45,058] Trial 245 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.05241822716719577, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.449475821882068, 'loop': 1, 'loss': 'CE', 'lr': 0.007927798941630705, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001034179888260377, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0018081532054529282
weight_decay:  5.9011377182318495e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7144971110392362
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 02
None time:  1.7139913840219378
None Run 02:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 77.70
Split: 01, Run: 03
None time:  1.653787022922188
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 77.90
run time now: 5.1098716259002686
total time:  5.124061607057229
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.00 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 78.40 ± 1.04
[I 2023-06-12 00:35:50,617] Trial 246 finished with value: 78.0 and parameters: {'Fwd': 0.06274233368315922, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.769108686444296, 'loop': 1, 'loss': 'CE', 'lr': 0.0018081532054529282, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.9011377182318495e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.009195010664900813
weight_decay:  0.00014500567181963164
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0229503398295492
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.6835442681331187
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.6522371489554644
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.387516736984253
total time:  4.412501982180402
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.00 ± 0.95
[I 2023-06-12 00:35:55,483] Trial 247 finished with value: 81.0 and parameters: {'Fwd': 0.09957424731971155, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.323804928430098, 'loop': 1, 'loss': 'CE', 'lr': 0.009195010664900813, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014500567181963164, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006960374765606614
weight_decay:  0.00021623133640578574
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3159996001049876
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.5186207571532577
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.1601136091630906
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.019744157791138
total time:  4.0424306509085
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.21
[I 2023-06-12 00:36:00,087] Trial 248 finished with value: 80.9333267211914 and parameters: {'Fwd': 0.07494037125271757, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.440695545369433, 'loop': 1, 'loss': 'CE', 'lr': 0.006960374765606614, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021623133640578574, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0025617586143967443
weight_decay:  8.875438400016241e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.439258512109518
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02
None time:  1.6895178379490972
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.7331253648735583
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.60
run time now: 4.900753974914551
total time:  4.920791439013556
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.20 ± 1.39
  Final Train: 100.00 ± 0.00
   Final Test: 79.50 ± 0.79
[I 2023-06-12 00:36:05,501] Trial 249 finished with value: 79.20000457763672 and parameters: {'Fwd': 0.047911530784453385, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.000872906185252, 'loop': 1, 'loss': 'CE', 'lr': 0.0025617586143967443, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.875438400016241e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.008434850166612553
weight_decay:  4.5862713174850964e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4054349600337446
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6775246928445995
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.6802814709953964
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.7930824756622314
total time:  4.806213018018752
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 0.59
[I 2023-06-12 00:36:10,825] Trial 250 finished with value: 81.19999694824219 and parameters: {'Fwd': 2.4661612382403172e-06, 'K': 10, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.93558839783017, 'loop': 1, 'loss': 'CE', 'lr': 0.008434850166612553, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.5862713174850964e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.005979842915518326
weight_decay:  0.0001149820773096006
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6234954809769988
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.6615720679983497
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.40374293201603
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.716487407684326
total time:  4.730890995822847
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.46
[I 2023-06-12 00:36:16,157] Trial 251 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.06629800844167681, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.63587155735633, 'loop': 1, 'loss': 'CE', 'lr': 0.005979842915518326, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001149820773096006, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.007420938768682291
weight_decay:  6.712383567889804e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6642837240360677
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.774450798984617
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.8599667558446527
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.334021329879761
total time:  5.356046122964472
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.95
[I 2023-06-12 00:36:22,004] Trial 252 finished with value: 81.0 and parameters: {'Fwd': 0.08396858384940149, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 4.187855895903794, 'loop': 1, 'loss': 'CE', 'lr': 0.007420938768682291, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.712383567889804e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.00999580152646387
weight_decay:  8.576310751790532e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.316620809957385
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.5857165239285678
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 03
None time:  1.6729909020941705
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.6043126583099365
total time:  4.622765969019383
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 80.83 ± 1.01
[I 2023-06-12 00:36:27,125] Trial 253 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.04002396010174569, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.12279824445927, 'loop': 1, 'loss': 'CE', 'lr': 0.00999580152646387, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.576310751790532e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006596609214882212
weight_decay:  0.00013633589191412206
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6656593249645084
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.6831937020178884
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.3341077910736203
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.710984945297241
total time:  4.725343342870474
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.31
[I 2023-06-12 00:36:32,413] Trial 254 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.05702344656463378, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.317819495443307, 'loop': 1, 'loss': 'CE', 'lr': 0.006596609214882212, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013633589191412206, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.00791842178703061
weight_decay:  3.687009964684008e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4789917289745063
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.6015235928352922
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.5125537640415132
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.634716272354126
total time:  4.6641619491856545
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.21
[I 2023-06-12 00:36:37,620] Trial 255 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.09934759715657805, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.709250250959826, 'loop': 1, 'loss': 'CE', 'lr': 0.00791842178703061, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.687009964684008e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.002081908082600027
weight_decay:  5.306249498339687e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8505109690595418
None Run 01:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 77.30
Split: 01, Run: 02
None time:  0.7801517809275538
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 03
None time:  1.0061831888742745
None Run 03:
Highest Train: 100.00
Highest Valid: 69.80
  Final Train: 100.00
   Final Test: 71.00
run time now: 2.685061454772949
total time:  2.7000365150161088
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 70.80 ± 2.65
  Final Train: 100.00 ± 0.00
   Final Test: 72.73 ± 3.99
[I 2023-06-12 00:36:40,934] Trial 256 finished with value: 70.80000305175781 and parameters: {'Fwd': 0.07678718725570333, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.454507547976542, 'loop': 1, 'loss': 'CE', 'lr': 0.002081908082600027, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.306249498339687e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.008902442550446883
weight_decay:  0.0001757256604982646
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8058806310873479
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.7090756751131266
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.8801388358697295
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.424816131591797
total time:  5.443380721146241
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.76
[I 2023-06-12 00:36:46,989] Trial 257 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.022525872808140956, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 4.964980092278569, 'loop': 1, 'loss': 'CE', 'lr': 0.008902442550446883, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001757256604982646, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0057376956445698325
weight_decay:  0.00010115283759848803
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3911816971376538
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.37704040389508
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.6625544640701264
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.459991216659546
total time:  4.478977099992335
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.23
[I 2023-06-12 00:36:51,998] Trial 258 finished with value: 80.93334197998047 and parameters: {'Fwd': 0.058326642514539145, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 6.121135998225091, 'loop': 1, 'loss': 'CE', 'lr': 0.0057376956445698325, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010115283759848803, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0070991241093297346
weight_decay:  7.027212003390809e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.722814731998369
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.7075477309990674
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.534434145083651
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.993526220321655
total time:  5.008617888903245
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.87
[I 2023-06-12 00:36:57,553] Trial 259 finished with value: 81.66666412353516 and parameters: {'Fwd': 0.08059910941195424, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.91015474482695, 'loop': 1, 'loss': 'CE', 'lr': 0.0070991241093297346, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.027212003390809e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.45
lr:  0.008341097071868529
weight_decay:  6.285741144879929e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5745750810019672
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.685366728110239
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.6655492789577693
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.9515979290008545
total time:  4.970834097126499
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.95
[I 2023-06-12 00:37:02,999] Trial 260 finished with value: 81.06666564941406 and parameters: {'Fwd': 0.09977727793911967, 'K': 9, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.866681653388024, 'loop': 1, 'loss': 'CE', 'lr': 0.008341097071868529, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.285741144879929e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.007403704679508535
weight_decay:  7.284106430376663e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4006955130025744
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.236506599932909
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 03
None time:  1.1578078609891236
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
run time now: 3.82352352142334
total time:  3.842974692117423
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 82.13 ± 0.15
[I 2023-06-12 00:37:07,390] Trial 261 finished with value: 81.26666259765625 and parameters: {'Fwd': 0.07911602840183418, 'K': 10, 'alpha': 0.4, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.958165257343968, 'loop': 1, 'loss': 'CE', 'lr': 0.007403704679508535, 'softmaxF': False, 'useGCN': True, 'weight_decay': 7.284106430376663e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0063629761507023016
weight_decay:  1.4977145781170811e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6404068358242512
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.627894300967455
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.6479690379928797
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.94677996635437
total time:  4.970433737151325
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.30
[I 2023-06-12 00:37:12,886] Trial 262 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.04679985645906063, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.7150819768044325, 'loop': 1, 'loss': 'CE', 'lr': 0.0063629761507023016, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.4977145781170811e-06, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0012314963455432788
weight_decay:  0.0005158340493188168
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6549440389499068
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 02
None time:  1.8508990209084004
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  1.7946532061323524
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.325514078140259
total time:  5.343862114939839
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.87 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 79.07 ± 1.83
[I 2023-06-12 00:37:18,828] Trial 263 finished with value: 78.86666107177734 and parameters: {'Fwd': 0.033242641366464064, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 6.236355586312921, 'loop': 1, 'loss': 'CE', 'lr': 0.0012314963455432788, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0005158340493188168, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.009142307830187157
weight_decay:  4.519931877722177e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3199386079795659
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.7073667391669005
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.5051502648275346
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.561384201049805
total time:  4.5773077150806785
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.70
[I 2023-06-12 00:37:23,827] Trial 264 finished with value: 81.00000762939453 and parameters: {'Fwd': 0.025687605624709814, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 9.979301197299916, 'loop': 1, 'loss': 'CE', 'lr': 0.009142307830187157, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.519931877722177e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00393958968228246
weight_decay:  3.015992479565004e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.662911695893854
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6081490048673004
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.6538308020681143
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.9532246589660645
total time:  4.975816871970892
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.55
[I 2023-06-12 00:37:29,301] Trial 265 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.08039077022611069, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.7993855773521865, 'loop': 1, 'loss': 'CE', 'lr': 0.00393958968228246, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.015992479565004e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0077071051335207445
weight_decay:  5.4193881660672415e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2845906091388315
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.7433905738871545
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.738044073106721
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.786069631576538
total time:  4.815030476776883
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.58
[I 2023-06-12 00:37:34,664] Trial 266 finished with value: 81.0666732788086 and parameters: {'Fwd': 0.001017777925593404, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.193372496838106, 'loop': 1, 'loss': 'CE', 'lr': 0.0077071051335207445, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.4193881660672415e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.006894060309642131
weight_decay:  0.00012672395118103362
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3475919771008193
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  1.3369617918506265
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.4210489250253886
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.134443998336792
total time:  4.148915804922581
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.10
[I 2023-06-12 00:37:39,230] Trial 267 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.06098401393482457, 'K': 10, 'alpha': 0.4, 'dropout': 0.30000000000000004, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.569246805620218, 'loop': 1, 'loss': 'CE', 'lr': 0.006894060309642131, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012672395118103362, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.005197227401741741
weight_decay:  7.734833901893253e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6858903800603002
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 02
None time:  1.84839041903615
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.9037259449250996
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 5.466376781463623
total time:  5.480203639017418
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 80.97 ± 0.51
[I 2023-06-12 00:37:45,209] Trial 268 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.07010813001657826, 'K': 9, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 8.835675957922472, 'loop': 2, 'loss': 'CE', 'lr': 0.005197227401741741, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.734833901893253e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.008476869063335675
weight_decay:  4.044348631159039e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6797521621920168
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.7244223761372268
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.5918498190585524
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.021611928939819
total time:  5.03991934703663
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.79
[I 2023-06-12 00:37:50,847] Trial 269 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.08192351302228724, 'K': 10, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 6.469621088405592, 'loop': 1, 'loss': 'CE', 'lr': 0.008476869063335675, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.044348631159039e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0029112082165106065
weight_decay:  0.00036421019298093826
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4250520148780197
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  1.7415400429163128
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  1.7967853320296854
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.9949376583099365
total time:  5.014547039987519
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 80.57 ± 0.55
[I 2023-06-12 00:37:56,354] Trial 270 finished with value: 79.86666870117188 and parameters: {'Fwd': 0.09947248130528219, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 6.022249085047444, 'loop': 1, 'loss': 'CE', 'lr': 0.0029112082165106065, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00036421019298093826, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006300904900487691
weight_decay:  0.030473031391829126
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3642088728956878
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.3722191569395363
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.682906999019906
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.444895505905151
total time:  4.461361799854785
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.35
[I 2023-06-12 00:38:01,264] Trial 271 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.05194354614802645, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 7.4984937450326274, 'loop': 1, 'loss': 'CE', 'lr': 0.006300904900487691, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.030473031391829126, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.5
lr:  0.007248751728129826
weight_decay:  6.441119846521494e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5264855050481856
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.6430534948594868
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  1.4060362200252712
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
run time now: 4.6020917892456055
total time:  4.62058094702661
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 0.96
[I 2023-06-12 00:38:06,313] Trial 272 finished with value: 81.0 and parameters: {'Fwd': 0.037711041567235086, 'K': 5, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.801641198879497, 'loop': 1, 'loss': 'CE', 'lr': 0.007248751728129826, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.441119846521494e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.009306500941909922
weight_decay:  0.00025330094910863606
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6171910371631384
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.5547223170287907
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.7601293271873146
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.962031126022339
total time:  4.978619397850707
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 0.61
[I 2023-06-12 00:38:11,756] Trial 273 finished with value: 81.26667022705078 and parameters: {'Fwd': 9.619837827279989e-05, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.294742433897268, 'loop': 1, 'loss': 'CE', 'lr': 0.009306500941909922, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00025330094910863606, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0009276285793338644
weight_decay:  0.00010746416170896352
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.689449202036485
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 02
None time:  1.5717515589203686
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  1.410725292051211
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.6982691287994385
total time:  4.717922742012888
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.73 ± 6.06
  Final Train: 100.00 ± 0.00
   Final Test: 76.53 ± 5.77
[I 2023-06-12 00:38:16,943] Trial 274 finished with value: 75.73332977294922 and parameters: {'Fwd': 0.07040643157790444, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.564174383723113, 'loop': 1, 'loss': 'CE', 'lr': 0.0009276285793338644, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010746416170896352, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0015677940780749633
weight_decay:  0.00017458662378960795
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.753125528106466
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 02
None time:  2.1914694129955024
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.7166670139413327
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.30
run time now: 5.694380760192871
total time:  5.743685729103163
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.47 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 79.50 ± 0.62
[I 2023-06-12 00:38:23,238] Trial 275 finished with value: 79.46666717529297 and parameters: {'Fwd': 0.05438710425964825, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 4.520855261742485, 'loop': 1, 'loss': 'CE', 'lr': 0.0015677940780749633, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017458662378960795, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.007942193001502165
weight_decay:  8.303276697615486e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8436223501339555
None Run 01:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  1.1403314049821347
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  0.9283890530932695
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 80.90
run time now: 2.937310218811035
total time:  2.953268909128383
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.40 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 80.40 ± 0.46
[I 2023-06-12 00:38:26,816] Trial 276 finished with value: 78.4000015258789 and parameters: {'Fwd': 0.07872773095377615, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 5.087400893509791, 'loop': 1, 'loss': 'CE', 'lr': 0.007942193001502165, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.303276697615486e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.005715722563502596
weight_decay:  5.298775030949031e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6192978818435222
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.133897024905309
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.399801068007946
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.185044527053833
total time:  4.198369132820517
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.31
[I 2023-06-12 00:38:31,518] Trial 277 finished with value: 81.20000457763672 and parameters: {'Fwd': 0.06512328386029752, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.825638991118461, 'loop': 1, 'loss': 'CE', 'lr': 0.005715722563502596, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.298775030949031e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.00475854958436011
weight_decay:  0.0008475754061468741
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6054138680920005
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.546619747998193
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.6685479199513793
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
run time now: 4.846357107162476
total time:  4.860856292070821
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.45
[I 2023-06-12 00:38:36,948] Trial 278 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.0003918060344633201, 'K': 10, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 1.0, 'lambda2': 8.68468730867735, 'loop': 1, 'loss': 'CE', 'lr': 0.00475854958436011, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0008475754061468741, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006661998851962435
weight_decay:  0.00012896042721298755
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7594681810587645
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.90
Split: 01, Run: 02
None time:  1.7069059780333191
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 03
None time:  1.6295114171225578
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.174331903457642
total time:  5.196156152058393
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.97 ± 0.95
[I 2023-06-12 00:38:42,747] Trial 279 finished with value: 80.73333740234375 and parameters: {'Fwd': 0.0022122401809749693, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.347511356777298, 'loop': 1, 'loss': 'CE', 'lr': 0.006661998851962435, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012896042721298755, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.00012132736661698877
weight_decay:  2.377679778674054e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.164417042862624
None Run 01:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 02
None time:  1.9204859919846058
None Run 02:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 03
None time:  1.2721643410623074
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 5.397514820098877
total time:  5.411140477051958
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.67 ± 4.31
  Final Train: 100.00 ± 0.00
   Final Test: 75.17 ± 4.69
[I 2023-06-12 00:38:48,729] Trial 280 finished with value: 73.66666412353516 and parameters: {'Fwd': 0.09830231490959039, 'K': 10, 'alpha': 0.5, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 6.086964580499787, 'loop': 1, 'loss': 'CE', 'lr': 0.00012132736661698877, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.377679778674054e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.009996865400628016
weight_decay:  9.505055751693173e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3554759330581874
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  1.6360269871074706
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.6773670371621847
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.691492080688477
total time:  4.70523593807593
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.90 ± 0.90
[I 2023-06-12 00:38:54,027] Trial 281 finished with value: 80.80000305175781 and parameters: {'Fwd': 0.04521511460430457, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.613891617371568, 'loop': 1, 'loss': 'CE', 'lr': 0.009996865400628016, 'softmaxF': False, 'useGCN': True, 'weight_decay': 9.505055751693173e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.008604549058837558
weight_decay:  7.050031601712747e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.6042914248537272
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.4514085138216615
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.5599029250442982
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 1.641470193862915
total time:  1.6560534029267728
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.00
[I 2023-06-12 00:38:56,135] Trial 282 finished with value: 68.80000305175781 and parameters: {'Fwd': 0.0031822294051693225, 'K': 10, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 0, 'lambda1': 0.75, 'lambda2': 4.975247249675635, 'loop': 1, 'loss': 'CE', 'lr': 0.008604549058837558, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.050031601712747e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.004253692449491806
weight_decay:  0.00020191560232104365
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6911168089136481
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.5688051769975573
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.841613463126123
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.00
run time now: 5.131129741668701
total time:  5.14931237208657
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 81.07 ± 0.93
[I 2023-06-12 00:39:01,762] Trial 283 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.0819454880575232, 'K': 10, 'alpha': 0.55, 'dropout': 0.9, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.43178608199222, 'loop': 1, 'loss': 'CE', 'lr': 0.004253692449491806, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00020191560232104365, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.007338522166370978
weight_decay:  0.00015199471001435183
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5696951241698116
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.5961012369953096
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.539866500068456
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.730704069137573
total time:  4.751318793045357
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.96
[I 2023-06-12 00:39:07,118] Trial 284 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.05986418449128687, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 8.276843172378051, 'loop': 1, 'loss': 'CE', 'lr': 0.007338522166370978, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015199471001435183, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.45
lr:  0.007974219665765472
weight_decay:  4.644919272882212e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4700586718972772
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.5362409290391952
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.511458605993539
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.40
run time now: 4.539473056793213
total time:  4.559834328945726
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.65
[I 2023-06-12 00:39:12,260] Trial 285 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.0017348894475513416, 'K': 2, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.752213303375771, 'loop': 1, 'loss': 'CE', 'lr': 0.007974219665765472, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.644919272882212e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00642947803500507
weight_decay:  0.0036374008058741134
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.281712522963062
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  3.4679353560786694
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  3.6398771631065756
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.30
run time now: 9.418225526809692
total time:  9.43662590207532
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 82.43 ± 0.32
[I 2023-06-12 00:39:22,259] Trial 286 finished with value: 81.13333892822266 and parameters: {'Fwd': 0.0997267847754255, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 120, 'lambda1': 0.8500000000000001, 'lambda2': 5.197226764521837, 'loop': 1, 'loss': 'CE', 'lr': 0.00642947803500507, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0036374008058741134, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0070580231603041745
weight_decay:  8.369474236204841e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6618301409762353
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.7346964529715478
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.6439115589018911
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.06670618057251
total time:  5.085492034908384
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.55
[I 2023-06-12 00:39:27,936] Trial 287 finished with value: 81.33333587646484 and parameters: {'Fwd': 1.2300466732186807e-05, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.797501074171809, 'loop': 1, 'loss': 'CE', 'lr': 0.0070580231603041745, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.369474236204841e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.003380513914232117
weight_decay:  0.0001120469678775141
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.292317399987951
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 02
None time:  1.7320539308711886
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.9331530530471355
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.985358238220215
total time:  5.005606120917946
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 80.67 ± 0.40
[I 2023-06-12 00:39:33,478] Trial 288 finished with value: 80.06666564941406 and parameters: {'Fwd': 0.017251875778641353, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.658402050186587, 'loop': 1, 'loss': 'CE', 'lr': 0.003380513914232117, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001120469678775141, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.001724753730292075
weight_decay:  3.723581291796172e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6780590200796723
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 02
None time:  1.7450303309597075
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.30
Split: 01, Run: 03
None time:  2.4643058890942484
None Run 03:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 81.60
run time now: 5.925305366516113
total time:  5.938833269989118
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 80.23 ± 1.21
[I 2023-06-12 00:39:40,009] Trial 289 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.04079720784176363, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.426463530740282, 'loop': 1, 'loss': 'CE', 'lr': 0.001724753730292075, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.723581291796172e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.009003756225153453
weight_decay:  6.882151865243363e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6231127050705254
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.6940465129446238
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.9157103830948472
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 5.31174111366272
total time:  5.330279380083084
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.07 ± 1.25
[I 2023-06-12 00:39:46,005] Trial 290 finished with value: 80.9333267211914 and parameters: {'Fwd': 0.07109317992859125, 'K': 10, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 6.354573330963284, 'loop': 1, 'loss': 'CE', 'lr': 0.009003756225153453, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.882151865243363e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.005442513664778078
weight_decay:  6.087498876868557e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4394331949297339
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 02
None time:  3.859588294988498
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.4607873340137303
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.790329694747925
total time:  6.813608924858272
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 80.90 ± 0.36
[I 2023-06-12 00:39:53,429] Trial 291 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.00021975197766467482, 'K': 10, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.977682777535701, 'loop': 1, 'loss': 'MSE', 'lr': 0.005442513664778078, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.087498876868557e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.006019774787298809
weight_decay:  9.883498308374489e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5820133881643414
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.5077782559674233
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.2224671700969338
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.337939023971558
total time:  4.35143814701587
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.23
[I 2023-06-12 00:39:58,281] Trial 292 finished with value: 80.93333435058594 and parameters: {'Fwd': 9.457314243612486e-05, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 9.234931878035523, 'loop': 1, 'loss': 'CE', 'lr': 0.006019774787298809, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.883498308374489e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.007934953893041531
weight_decay:  0.00014016064194555787
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6194595140405
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  1.6960586190689355
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.8277082538697869
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
run time now: 5.170140504837036
total time:  5.184221903095022
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 82.33 ± 0.45
[I 2023-06-12 00:40:03,941] Trial 293 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.052714296434339135, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.192962156607435, 'loop': 1, 'loss': 'CE', 'lr': 0.007934953893041531, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014016064194555787, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006912963863687197
weight_decay:  5.1456335339228665e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9388406870421022
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.0219341199845076
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.0548799550160766
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.40
run time now: 3.0418038368225098
total time:  3.0585463491734117
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 80.00 ± 1.06
[I 2023-06-12 00:40:07,578] Trial 294 finished with value: 79.4000015258789 and parameters: {'Fwd': 0.07786326939045529, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.4992937796568855, 'loop': 1, 'loss': 'CE', 'lr': 0.006912963863687197, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.1456335339228665e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.008561027304682754
weight_decay:  8.254985211103994e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4574349711183459
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.5289882679935545
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.5079664690420032
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
run time now: 4.5217437744140625
total time:  4.540204655844718
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.29
[I 2023-06-12 00:40:12,645] Trial 295 finished with value: 81.20000457763672 and parameters: {'Fwd': 0.0023912490954437963, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 4.884074939872291, 'loop': 1, 'loss': 'CE', 'lr': 0.008561027304682754, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.254985211103994e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.007548268471214411
weight_decay:  0.00011483888840543407
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4627010310068727
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.90
Split: 01, Run: 02
None time:  1.626686102943495
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.70
Split: 01, Run: 03
None time:  1.72283049300313
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 4.8427910804748535
total time:  4.858241513138637
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 82.17 ± 1.10
[I 2023-06-12 00:40:18,011] Trial 296 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.06321632225557004, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.752657330635435, 'loop': 1, 'loss': 'CE', 'lr': 0.007548268471214411, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011483888840543407, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0007030796722961036
weight_decay:  6.12191792299806e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5778046501800418
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 02
None time:  1.3709064091090113
None Run 02:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 74.20
Split: 01, Run: 03
None time:  1.5196471069939435
None Run 03:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 78.00
run time now: 4.499655485153198
total time:  4.514302680967376
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.07 ± 2.41
  Final Train: 100.00 ± 0.00
   Final Test: 77.23 ± 2.73
[I 2023-06-12 00:40:23,135] Trial 297 finished with value: 77.06666564941406 and parameters: {'Fwd': 0.029398084924497872, 'K': 10, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.293215384007016, 'loop': 1, 'loss': 'CE', 'lr': 0.0007030796722961036, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.12191792299806e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.002437863566057263
weight_decay:  3.363260409365714e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7572591609787196
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 02
None time:  1.6382533740252256
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 03
None time:  1.5076556308194995
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 77.40
run time now: 4.93211030960083
total time:  4.957359974971041
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 1.68
  Final Train: 100.00 ± 0.00
   Final Test: 79.10 ± 1.57
[I 2023-06-12 00:40:28,564] Trial 298 finished with value: 78.9333267211914 and parameters: {'Fwd': 0.08472308929075971, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 6.187910489554294, 'loop': 1, 'loss': 'CE', 'lr': 0.002437863566057263, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.363260409365714e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00921843315319546
weight_decay:  0.00020097230276590588
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6408999760169536
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.584309137891978
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.7680595379788429
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.018686771392822
total time:  5.032121768919751
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.64
[I 2023-06-12 00:40:34,061] Trial 299 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.04736126683274377, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.6202083223398684, 'loop': 1, 'loss': 'CE', 'lr': 0.00921843315319546, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00020097230276590588, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0037942512845100204
weight_decay:  8.399088621839286e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3472970880102366
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.6267218869179487
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.5305798570625484
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.529817342758179
total time:  4.551229999167845
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.74
[I 2023-06-12 00:40:39,130] Trial 300 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.06620197707755955, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.937339930192282, 'loop': 1, 'loss': 'CE', 'lr': 0.0037942512845100204, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.399088621839286e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0062906666057922925
weight_decay:  0.00015605908439822705
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6564986780285835
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.6587069751694798
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.553228094941005
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.897186517715454
total time:  4.911371756810695
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.35
[I 2023-06-12 00:40:44,509] Trial 301 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.05576660656227452, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.041273957768391, 'loop': 1, 'loss': 'CE', 'lr': 0.0062906666057922925, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015605908439822705, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0019608737360306593
weight_decay:  0.00030608639261658525
dropout:  0.1
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8203777689486742
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 02
None time:  1.73854000098072
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.8004871560260653
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.70
run time now: 5.382930040359497
total time:  5.397143797017634
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.07 ± 1.01
  Final Train: 100.00 ± 0.00
   Final Test: 79.73 ± 0.65
[I 2023-06-12 00:40:50,440] Trial 302 finished with value: 79.06666564941406 and parameters: {'Fwd': 0.0006153375373239287, 'K': 10, 'alpha': 0.5, 'dropout': 0.1, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 4.652483793212509, 'loop': 1, 'loss': 'CE', 'lr': 0.0019608737360306593, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00030608639261658525, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.008241546648375436
weight_decay:  4.744588809024132e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.640455910935998
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6876643779687583
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.4249550991225988
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.784223794937134
total time:  4.803114770911634
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.75
[I 2023-06-12 00:40:55,705] Trial 303 finished with value: 81.66666412353516 and parameters: {'Fwd': 0.09960367152727903, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.463030304065593, 'loop': 1, 'loss': 'CE', 'lr': 0.008241546648375436, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.744588809024132e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.75
lr:  0.008181533456061155
weight_decay:  4.17128077382697e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7126358121167868
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 83.20
Split: 01, Run: 02
None time:  1.4953344180248678
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.4277255539782345
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
run time now: 4.664188623428345
total time:  4.6869397449772805
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 82.33 ± 0.75
[I 2023-06-12 00:41:00,849] Trial 304 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.08320629847228075, 'K': 9, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.587434480814984, 'loop': 1, 'loss': 'CE', 'lr': 0.008181533456061155, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.17128077382697e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.009208621067606787
weight_decay:  2.9775912586648463e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3845222310628742
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.5859527562279254
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  1.714060345897451
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.711689472198486
total time:  4.7252136510796845
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.10 ± 1.15
[I 2023-06-12 00:41:06,127] Trial 305 finished with value: 81.13333892822266 and parameters: {'Fwd': 0.08541817975470695, 'K': 10, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.287420163987639, 'loop': 1, 'loss': 'CE', 'lr': 0.009208621067606787, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.9775912586648463e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.00783989038404382
weight_decay:  5.256810891067785e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5780766049865633
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.1092459801584482
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.7511617748532444
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 4.469613552093506
total time:  4.5203850930556655
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.85
[I 2023-06-12 00:41:11,183] Trial 306 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.09977332655998528, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.797415238396782, 'loop': 1, 'loss': 'CE', 'lr': 0.00783989038404382, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.256810891067785e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0014204431715839731
weight_decay:  6.581126702104277e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5911954680923373
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 02
None time:  1.9458933537825942
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.619146766141057
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.60
run time now: 5.1837263107299805
total time:  5.202684220159426
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.00 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 79.10 ± 0.78
[I 2023-06-12 00:41:16,865] Trial 307 finished with value: 79.0 and parameters: {'Fwd': 0.0713595547760346, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 6.0537202309810985, 'loop': 1, 'loss': 'CE', 'lr': 0.0014204431715839731, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.581126702104277e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0022378824639877693
weight_decay:  4.341755241389731e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.483248624019325
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 02
None time:  3.802363079972565
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  3.6445038858801126
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.80
run time now: 9.95615029335022
total time:  9.971407043049112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 80.77 ± 0.15
[I 2023-06-12 00:41:27,282] Trial 308 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.09885164479754595, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.07583853141134, 'loop': 1, 'loss': 'MSE', 'lr': 0.0022378824639877693, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.341755241389731e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.008669392436935049
weight_decay:  7.019366545724868e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7004072780255228
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.7755546800326556
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.4393383469432592
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.941033124923706
total time:  4.9551674500107765
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.52
[I 2023-06-12 00:41:32,723] Trial 309 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.03767352063939488, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 3.0012523781954172, 'loop': 1, 'loss': 'CE', 'lr': 0.008669392436935049, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.019366545724868e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.007225871011157576
weight_decay:  2.6653768312812962e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.592954077059403
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.600510778138414
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.590648751007393
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.60
run time now: 4.808405876159668
total time:  4.827975091058761
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.89
[I 2023-06-12 00:41:38,127] Trial 310 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.07914837610256709, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.461374440870858, 'loop': 1, 'loss': 'CE', 'lr': 0.007225871011157576, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.6653768312812962e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00961118531025267
weight_decay:  5.284252435510624e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3415580110158771
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 99.29
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.4803446589503437
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 99.29
   Final Test: 82.20
Split: 01, Run: 03
None time:  1.522877051960677
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 99.29
   Final Test: 81.20
run time now: 4.372174501419067
total time:  4.390111701097339
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.46
  Final Train: 99.29 ± 0.00
   Final Test: 81.80 ± 0.53
[I 2023-06-12 00:41:42,985] Trial 311 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.06033873435867379, 'K': 10, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 1.0101931356425808, 'loop': 1, 'loss': 'CE', 'lr': 0.00961118531025267, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.284252435510624e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.009938886841158597
weight_decay:  9.869962042846298e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4750541469547898
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.90
Split: 01, Run: 02
None time:  1.7185575210023671
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.3686784871388227
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.10
run time now: 4.590558052062988
total time:  4.60929337493144
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 82.27 ± 0.57
[I 2023-06-12 00:41:48,030] Trial 312 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.048317564362767865, 'K': 9, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.460078776960139, 'loop': 1, 'loss': 'CE', 'lr': 0.009938886841158597, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.869962042846298e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.004757175760897719
weight_decay:  8.153054065005013e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.450034397887066
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.6706048001069576
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.647847895976156
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.795966148376465
total time:  4.8160501040983945
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.50
[I 2023-06-12 00:41:53,299] Trial 313 finished with value: 81.0 and parameters: {'Fwd': 0.023114514632268043, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.721305564703493, 'loop': 1, 'loss': 'CE', 'lr': 0.004757175760897719, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.153054065005013e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.007895418819298481
weight_decay:  3.505734845723603e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.204565871041268
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.6498217058833688
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.7811248360667378
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.20
run time now: 4.661138534545898
total time:  4.680431792978197
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 1.00
[I 2023-06-12 00:41:58,450] Trial 314 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.07974459044307967, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.260050341054186, 'loop': 1, 'loss': 'CE', 'lr': 0.007895418819298481, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.505734845723603e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0012276569370996626
weight_decay:  5.8865290368908144e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0978218580130488
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 02
None time:  1.3534738649614155
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.1489180251955986
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 78.80
run time now: 3.6241719722747803
total time:  3.6487845219671726
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.07 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 1.42
[I 2023-06-12 00:42:02,583] Trial 315 finished with value: 79.06666564941406 and parameters: {'Fwd': 0.06344225800879262, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 4.837366283290293, 'loop': 1, 'loss': 'CE', 'lr': 0.0012276569370996626, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.8865290368908144e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.006707689731729407
weight_decay:  0.00010590570809416946
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.000392350135371
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.5464910201262683
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 03
None time:  1.5178346710745245
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.087533712387085
total time:  4.102367534069344
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.40
[I 2023-06-12 00:42:07,215] Trial 316 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.09957449098996111, 'K': 10, 'alpha': 0.8, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.5798704871081215, 'loop': 1, 'loss': 'CE', 'lr': 0.006707689731729407, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010590570809416946, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.008384845023639552
weight_decay:  0.0004338405742144413
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6191700419876724
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.478153983131051
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.7660686010494828
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.889507055282593
total time:  4.910033316118643
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.61
[I 2023-06-12 00:42:12,668] Trial 317 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.05284686507242181, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 9.028581033328846, 'loop': 1, 'loss': 'CE', 'lr': 0.008384845023639552, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0004338405742144413, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.005876023981707108
weight_decay:  0.007548221117594622
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2374008500482887
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.5895615310873836
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.6159999249503016
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.467898845672607
total time:  4.481294174911454
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.20
[I 2023-06-12 00:42:17,773] Trial 318 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.0723091563325097, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.844500542014889, 'loop': 1, 'loss': 'CE', 'lr': 0.005876023981707108, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.007548221117594622, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.007462459349966262
weight_decay:  4.007088508990595e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6014640321955085
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.5232331780716777
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.4175679630134255
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.567844390869141
total time:  4.582665445050225
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.93 ± 0.65
[I 2023-06-12 00:42:22,832] Trial 319 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.03402590607395188, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.524243728841834, 'loop': 1, 'loss': 'CE', 'lr': 0.007462459349966262, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.007088508990595e-06, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.00653219788881772
weight_decay:  4.6266386045027204e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.646246552001685
None Run 01:
Highest Train: 99.29
Highest Valid: 81.40
  Final Train: 97.86
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.6002676282078028
None Run 02:
Highest Train: 99.29
Highest Valid: 80.80
  Final Train: 97.86
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.4568895439151675
None Run 03:
Highest Train: 99.29
Highest Valid: 80.80
  Final Train: 96.43
   Final Test: 80.60
run time now: 4.727928876876831
total time:  4.742021345067769
None All runs:
Highest Train: 99.29 ± 0.00
Highest Valid: 81.00 ± 0.35
  Final Train: 97.38 ± 0.82
   Final Test: 81.10 ± 0.56
[I 2023-06-12 00:42:28,060] Trial 320 finished with value: 81.00000762939453 and parameters: {'Fwd': 0.08061966931559113, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 0.003659792573742493, 'loop': 1, 'loss': 'CE', 'lr': 0.00653219788881772, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.6266386045027204e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.008614240881563704
weight_decay:  7.343176122664192e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8517253049649298
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.4720122620929033
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 03
None time:  1.6555592929944396
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 5.011452913284302
total time:  5.026744021102786
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.00 ± 1.22
[I 2023-06-12 00:42:33,538] Trial 321 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.04526515958602397, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 7.25958028070162, 'loop': 1, 'loss': 'CE', 'lr': 0.008614240881563704, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.343176122664192e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.002854783149338956
weight_decay:  0.00012069828986754139
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5528530511073768
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 02
None time:  1.379843742121011
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  1.4318125189747661
None Run 03:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.70
run time now: 4.394428968429565
total time:  4.4137148121371865
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.67 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 79.97 ± 0.46
[I 2023-06-12 00:42:38,439] Trial 322 finished with value: 79.66666412353516 and parameters: {'Fwd': 0.013232179735040154, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.356062279148897, 'loop': 1, 'loss': 'CE', 'lr': 0.002854783149338956, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012069828986754139, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.005245797852907166
weight_decay:  8.58523564654418e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5203533279709518
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.452063384000212
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 03
None time:  1.490391386905685
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.50
run time now: 4.492369890213013
total time:  4.517333043040708
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.90
[I 2023-06-12 00:42:43,390] Trial 323 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.06567832246428343, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 3.7635152327305015, 'loop': 1, 'loss': 'CE', 'lr': 0.005245797852907166, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.58523564654418e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007326430328009463
weight_decay:  5.5704538299645446e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.184982927981764
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.4706275828648359
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.5899094040505588
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.271815776824951
total time:  4.291928763967007
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.60
[I 2023-06-12 00:42:48,158] Trial 324 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.001133454224342175, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 6.20926203178194, 'loop': 1, 'loss': 'CE', 'lr': 0.007326430328009463, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.5704538299645446e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006168970502985755
weight_decay:  3.9285558767774645e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.604952716967091
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.5007281459402293
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.679597137030214
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.812395334243774
total time:  4.826016861014068
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.25
[I 2023-06-12 00:42:53,471] Trial 325 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.09907991784485284, 'K': 10, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.65, 'lambda2': 5.095164365013063, 'loop': 1, 'loss': 'CE', 'lr': 0.006168970502985755, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.9285558767774645e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.001727851045559403
weight_decay:  7.034052418568614e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6558743759524077
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 02
None time:  1.3363827508874238
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.5759846358560026
None Run 03:
Highest Train: 100.00
Highest Valid: 74.80
  Final Train: 100.00
   Final Test: 76.00
run time now: 4.5967066287994385
total time:  4.613682439085096
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.60 ± 2.50
  Final Train: 100.00 ± 0.00
   Final Test: 78.10 ± 1.90
[I 2023-06-12 00:42:58,646] Trial 326 finished with value: 77.5999984741211 and parameters: {'Fwd': 0.05351063455837752, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 2.6237498687633174, 'loop': 1, 'loss': 'CE', 'lr': 0.001727851045559403, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.034052418568614e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.55
lr:  0.0010104795146294388
weight_decay:  0.00010060259883105871
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.380900542018935
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 78.20% Test: 79.90%
Split: 01, Run: 02
None time:  3.039593645837158
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03, Epoch: 100, Loss: 0.0000, Train: 100.00%, Valid: 77.60% Test: 79.20%
Split: 01, Run: 03
None time:  3.091079944977537
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 79.30
run time now: 7.536602735519409
total time:  7.5522964091505855
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 79.30 ± 0.50
[I 2023-06-12 00:43:06,842] Trial 327 finished with value: 78.0666732788086 and parameters: {'Fwd': 0.08293945353526025, 'K': 6, 'alpha': 0.55, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.92136077543638, 'loop': 0, 'loss': 'MSE', 'lr': 0.0010104795146294388, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010060259883105871, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.007864641088329807
weight_decay:  0.000245711457795133
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6320299778599292
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.9512697209138423
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.7881852469872683
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.39912486076355
total time:  5.420356225920841
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.55
[I 2023-06-12 00:43:12,736] Trial 328 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.007475507779628213, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 4.14047207425325, 'loop': 1, 'loss': 'CE', 'lr': 0.007864641088329807, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.000245711457795133, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.00432390379390951
weight_decay:  0.00012595602681354873
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6473668890539557
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.335998552152887
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.6505757418926805
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.6639463901519775
total time:  4.679004832869396
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.66
[I 2023-06-12 00:43:17,919] Trial 329 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.07003155868378351, 'K': 10, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.51344795380444, 'loop': 1, 'loss': 'CE', 'lr': 0.00432390379390951, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012595602681354873, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006922036711189188
weight_decay:  6.366342863534594e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.383598230080679
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  2.745558393886313
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.2918244011234492
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
run time now: 6.446208238601685
total time:  6.461326600983739
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 82.00 ± 0.35
[I 2023-06-12 00:43:24,860] Trial 330 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.03871568051116336, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.696434184281742, 'loop': 1, 'loss': 'CE', 'lr': 0.006922036711189188, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.366342863534594e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.009140916201138905
weight_decay:  0.000743012539269445
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6410752299707383
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.482815588125959
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  1.5431368038989604
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.695802927017212
total time:  4.718601731117815
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 80.77 ± 1.00
[I 2023-06-12 00:43:30,040] Trial 331 finished with value: 81.06666564941406 and parameters: {'Fwd': 0.059737001039672395, 'K': 9, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.362515065426803, 'loop': 1, 'loss': 'CE', 'lr': 0.009140916201138905, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.000743012539269445, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.008475668760769127
weight_decay:  0.0011511341132580707
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.597584102069959
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6416676179505885
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.4910961561836302
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.758244752883911
total time:  4.77618271112442
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.64
[I 2023-06-12 00:43:35,331] Trial 332 finished with value: 81.20000457763672 and parameters: {'Fwd': 0.028651962973058977, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.925695176708457, 'loop': 1, 'loss': 'CE', 'lr': 0.008475668760769127, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0011511341132580707, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.5
lr:  0.0073902526951033255
weight_decay:  8.551477132965497e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8457060409709811
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  0.763989354018122
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  0.765716457972303
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 80.90
run time now: 2.405763626098633
total time:  2.4255195951554924
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.73 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 80.33 ± 0.55
[I 2023-06-12 00:43:38,283] Trial 333 finished with value: 77.73332977294922 and parameters: {'Fwd': 0.0020261639598937523, 'K': 3, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 6.011603661190049, 'loop': 1, 'loss': 'CE', 'lr': 0.0073902526951033255, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.551477132965497e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.00565432009982821
weight_decay:  4.833458885578982e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7112711151130497
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 83.00
Split: 01, Run: 02
None time:  1.419518749928102
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  1.7087450451217592
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.872962713241577
total time:  4.887958652107045
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 1.53
[I 2023-06-12 00:43:43,626] Trial 334 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.09896902095558047, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 4.674725106936695, 'loop': 1, 'loss': 'CE', 'lr': 0.00565432009982821, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.833458885578982e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006536277377338899
weight_decay:  0.00014217086763261715
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.61948027391918
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.9293895980808884
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.798512727022171
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 5.374017238616943
total time:  5.3982838310766965
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.68
[I 2023-06-12 00:43:49,561] Trial 335 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.09982492406686706, 'K': 10, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.171890179702432, 'loop': 1, 'loss': 'CE', 'lr': 0.006536277377338899, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014217086763261715, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0004543477609934458
weight_decay:  0.004530909414064809
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.948275342816487
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02
None time:  1.8612475208938122
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 03
None time:  1.4241426538210362
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.90
run time now: 5.263511896133423
total time:  5.281705243047327
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.47 ± 2.50
  Final Train: 100.00 ± 0.00
   Final Test: 77.40 ± 2.19
[I 2023-06-12 00:43:55,299] Trial 336 finished with value: 77.46666717529297 and parameters: {'Fwd': 0.06848533282832465, 'K': 10, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.580408486824439, 'loop': 1, 'loss': 'CE', 'lr': 0.0004543477609934458, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.004530909414064809, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.009258412899311777
weight_decay:  0.000543286090856646
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6262168770190328
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.6791148271877319
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.7181828208267689
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.054346323013306
total time:  5.070702438941225
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.65
[I 2023-06-12 00:44:00,923] Trial 337 finished with value: 81.26667022705078 and parameters: {'Fwd': 2.3257293798349874e-05, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 3.519908417220636, 'loop': 1, 'loss': 'CE', 'lr': 0.009258412899311777, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.000543286090856646, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  2
alpha:  0.7000000000000001
lr:  0.007794385987225017
weight_decay:  0.00010125675626430572
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=2, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3873519860208035
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.70
Split: 01, Run: 02
None time:  1.7192933179903775
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.6320746860001236
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.40
run time now: 4.766080379486084
total time:  4.784867430105805
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 82.33 ± 0.40
[I 2023-06-12 00:44:06,295] Trial 338 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.006133631051114958, 'K': 2, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.42819613949007, 'loop': 1, 'loss': 'CE', 'lr': 0.007794385987225017, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010125675626430572, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.007177595761467103
weight_decay:  0.00017641627568370098
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4492090800777078
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.5997851379215717
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.699874275131151
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.776088714599609
total time:  4.794866246869788
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.65
[I 2023-06-12 00:44:11,571] Trial 339 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.020202497794231302, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 7.958500856296836, 'loop': 1, 'loss': 'CE', 'lr': 0.007177595761467103, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00017641627568370098, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.008307467350520336
weight_decay:  3.18830276966184e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.330883617978543
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.5923200289253145
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.707712291041389
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 4.6544623374938965
total time:  4.670540313003585
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.60
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.74
[I 2023-06-12 00:44:16,750] Trial 340 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.04584143847217365, 'K': 10, 'alpha': 0.5, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.773617100015668, 'loop': 1, 'loss': 'CE', 'lr': 0.008307467350520336, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.18830276966184e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.009927657021917313
weight_decay:  2.41283079787143e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5356226658914238
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.6299707440193743
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.6995321460999548
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.950993537902832
total time:  4.964237957959995
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.17 ± 0.57
[I 2023-06-12 00:44:22,339] Trial 341 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.0005116248638442258, 'K': 9, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.320207685864315, 'loop': 1, 'loss': 'CE', 'lr': 0.009927657021917313, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.41283079787143e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006035321174169857
weight_decay:  7.587163089575426e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4761141559574753
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.420201672008261
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.6477670660242438
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.578032732009888
total time:  4.5979708910454065
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.51
[I 2023-06-12 00:44:27,408] Trial 342 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.001491999606998488, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 9.780985708912247, 'loop': 1, 'loss': 'CE', 'lr': 0.006035321174169857, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.587163089575426e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0021627876379070148
weight_decay:  6.238116008318435e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4207840480376035
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 02
None time:  1.3550999739672989
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.4686227780766785
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.276293039321899
total time:  4.29866505600512
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 80.57 ± 0.21
[I 2023-06-12 00:44:32,127] Trial 343 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.00021026261088871433, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.7000000000000001, 'lambda2': 5.016776859725818, 'loop': 1, 'loss': 'CE', 'lr': 0.0021627876379070148, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.238116008318435e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.7000000000000001
lr:  0.006677248813685582
weight_decay:  4.406149647768248e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.354223256930709
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 02
None time:  2.426809045020491
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  2.318257945822552
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 7.273881912231445
total time:  7.290125498082489
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 80.63 ± 0.31
[I 2023-06-12 00:44:39,954] Trial 344 finished with value: 80.80000305175781 and parameters: {'Fwd': 0.08181741426801917, 'K': 7, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 110, 'lambda1': 0.8500000000000001, 'lambda2': 6.315418865052975, 'loop': 1, 'loss': 'CE', 'lr': 0.006677248813685582, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.406149647768248e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.002464894718647663
weight_decay:  0.00011640816409410683
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6829292981419712
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 02
None time:  1.7309472928754985
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  2.3962188989389688
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.90
run time now: 5.836270570755005
total time:  5.8502869619987905
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.73 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 79.77 ± 0.90
[I 2023-06-12 00:44:46,406] Trial 345 finished with value: 79.73332977294922 and parameters: {'Fwd': 0.0013882680110068515, 'K': 10, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.245573232156184, 'loop': 1, 'loss': 'CE', 'lr': 0.002464894718647663, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011640816409410683, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0037102685053924437
weight_decay:  8.706880384483514e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.5743604069575667
None Run 01:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 02
None time:  1.5457964288070798
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.9849469331093132
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 7.132416486740112
total time:  7.151735437102616
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.00 ± 0.30
[I 2023-06-12 00:44:54,082] Trial 346 finished with value: 79.79999542236328 and parameters: {'Fwd': 0.05771563591161283, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 8.52071225894531, 'loop': 1, 'loss': 'MSE', 'lr': 0.0037102685053924437, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.706880384483514e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0031183111442542387
weight_decay:  5.623637844904267e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6677384828217328
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 02
None time:  1.8402549671009183
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.5302946839947253
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 5.066386938095093
total time:  5.087556715821847
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.07 ± 0.32
[I 2023-06-12 00:44:59,633] Trial 347 finished with value: 80.26667022705078 and parameters: {'Fwd': 5.931489019898739e-05, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 5.633299089749629, 'loop': 1, 'loss': 'CE', 'lr': 0.0031183111442542387, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.623637844904267e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00870023490355159
weight_decay:  7.452634712525352e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.4795390719082206
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 02
None time:  2.3926397140603513
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  2.3228877999354154
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.90
run time now: 7.223079442977905
total time:  7.2418371790554374
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 79.53 ± 0.47
[I 2023-06-12 00:45:07,441] Trial 348 finished with value: 79.86666107177734 and parameters: {'Fwd': 0.07926823562488278, 'K': 10, 'alpha': 0.55, 'dropout': 0.30000000000000004, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 5.902110698457927, 'loop': 2, 'loss': 'CE', 'lr': 0.00870023490355159, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.452634712525352e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.007317829565354911
weight_decay:  0.00021344065130702054
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6138385930098593
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.5768391450401396
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 03
None time:  1.7085277759470046
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.80
run time now: 4.9323790073394775
total time:  4.951997890835628
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.85
[I 2023-06-12 00:45:12,957] Trial 349 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.06945183564007766, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.481389334453629, 'loop': 1, 'loss': 'CE', 'lr': 0.007317829565354911, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00021344065130702054, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.007981034859487274
weight_decay:  3.816350304691993e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2653692760504782
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.7547628849279135
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.3882554590236396
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.43905782699585
total time:  4.453941397136077
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.74
[I 2023-06-12 00:45:17,954] Trial 350 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.04953080894789635, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.754455259112803, 'loop': 1, 'loss': 'CE', 'lr': 0.007981034859487274, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.816350304691993e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0018812158364282963
weight_decay:  0.00038833441085129575
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.602292348863557
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.20
Split: 01, Run: 02
None time:  1.2409160491079092
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.347973397001624
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.30
run time now: 4.222463369369507
total time:  4.242438587825745
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.00 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 79.07 ± 1.00
[I 2023-06-12 00:45:22,731] Trial 351 finished with value: 78.99999237060547 and parameters: {'Fwd': 0.09968379975351435, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 6.054306708104066, 'loop': 1, 'loss': 'CE', 'lr': 0.0018812158364282963, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00038833441085129575, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.005348974762773629
weight_decay:  0.0001498689182352347
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7147102309390903
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.6258903790730983
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.5965094028506428
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.964331388473511
total time:  4.982391508994624
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.83
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.50
[I 2023-06-12 00:45:28,272] Trial 352 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.06091621748169201, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 4.799659016273664, 'loop': 1, 'loss': 'CE', 'lr': 0.005348974762773629, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001498689182352347, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0067843461585349
weight_decay:  9.717476981864248e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.0820563789457083
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.102655675029382
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  0.9144354811869562
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.20
run time now: 3.135108232498169
total time:  3.153793322155252
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 80.30 ± 1.25
[I 2023-06-12 00:45:31,966] Trial 353 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.0007960819306026845, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 7.794383802561127, 'loop': 1, 'loss': 'CE', 'lr': 0.0067843461585349, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.717476981864248e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0015960440288937303
weight_decay:  5.0292311165215616e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.802564081037417
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 02
None time:  1.7072220661211759
None Run 02:
Highest Train: 100.00
Highest Valid: 76.60
  Final Train: 100.00
   Final Test: 77.20
Split: 01, Run: 03
None time:  1.5955730217974633
None Run 03:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.80
run time now: 5.131238222122192
total time:  5.146221098024398
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.33 ± 1.81
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 1.57
[I 2023-06-12 00:45:37,623] Trial 354 finished with value: 77.33333587646484 and parameters: {'Fwd': 0.07910292278515942, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.266134120003537, 'loop': 1, 'loss': 'CE', 'lr': 0.0015960440288937303, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.0292311165215616e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.009005005909896299
weight_decay:  0.00012346634086306073
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4164775509852916
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.4759579750243574
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.60
Split: 01, Run: 03
None time:  1.6058325781486928
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.528194189071655
total time:  4.5421313820406795
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.20 ± 0.66
[I 2023-06-12 00:45:42,638] Trial 355 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.0012504498360477374, 'K': 10, 'alpha': 0.5, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 1.0, 'lambda2': 5.498866076772439, 'loop': 1, 'loss': 'CE', 'lr': 0.009005005909896299, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012346634086306073, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0013454618324926007
weight_decay:  0.03122294363811809
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5663508458528668
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 02
None time:  1.61523740994744
None Run 02:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  1.6222886070609093
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 74.10
run time now: 4.8298234939575195
total time:  4.851772055961192
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.60 ± 3.30
  Final Train: 100.00 ± 0.00
   Final Test: 77.20 ± 3.20
[I 2023-06-12 00:45:47,998] Trial 356 finished with value: 76.5999984741211 and parameters: {'Fwd': 0.04259683417903729, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 4.020421550139693, 'loop': 1, 'loss': 'CE', 'lr': 0.0013454618324926007, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.03122294363811809, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.004598179227891673
weight_decay:  6.45848138301688e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.414495271164924
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.66822097892873
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.6216589729301631
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.732968330383301
total time:  4.752314464189112
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.62
[I 2023-06-12 00:45:53,278] Trial 357 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.003636209051710016, 'K': 9, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.085711483960338, 'loop': 1, 'loss': 'CE', 'lr': 0.004598179227891673, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.45848138301688e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.006212314612665729
weight_decay:  8.448674786301857e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5182912908494473
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.2441782660316676
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.2823950902093202
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.078192472457886
total time:  4.099685597931966
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.38
[I 2023-06-12 00:45:57,874] Trial 358 finished with value: 81.0 and parameters: {'Fwd': 0.0786486399850455, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.7371813702788925, 'loop': 1, 'loss': 'CE', 'lr': 0.006212314612665729, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.448674786301857e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0077987215942302195
weight_decay:  0.00010406675048612808
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7921761039178818
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.8731125500053167
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.3357123259920627
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.70
run time now: 5.028398275375366
total time:  5.043849283829331
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.74
[I 2023-06-12 00:46:03,589] Trial 359 finished with value: 81.06666564941406 and parameters: {'Fwd': 0.002970106869461366, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 5.436605742023694, 'loop': 1, 'loss': 'CE', 'lr': 0.0077987215942302195, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010406675048612808, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.002007904145884216
weight_decay:  4.6931200379390816e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8616310870274901
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 02
None time:  2.621946176048368
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  2.2897313500288874
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.20
run time now: 6.800124168395996
total time:  6.815799598116428
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 80.80 ± 0.36
[I 2023-06-12 00:46:10,955] Trial 360 finished with value: 80.20000457763672 and parameters: {'Fwd': 0.05535057763995519, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 3.162256661161966, 'loop': 1, 'loss': 'CE', 'lr': 0.002007904145884216, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.6931200379390816e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.65
lr:  0.007054009897367816
weight_decay:  0.00017440953262170522
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2007788389455527
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.507669802987948
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.579997291089967
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.311517000198364
total time:  4.326592699857429
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.27 ± 0.74
[I 2023-06-12 00:46:15,840] Trial 361 finished with value: 81.0666732788086 and parameters: {'Fwd': 2.22664036372826e-06, 'K': 4, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 6.141757157993579, 'loop': 1, 'loss': 'CE', 'lr': 0.007054009897367816, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017440953262170522, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.008271558791157265
weight_decay:  0.00025973034581833215
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.348453663988039
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.5022537850309163
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.467672117985785
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.348735094070435
total time:  4.366940127918497
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.07 ± 0.76
[I 2023-06-12 00:46:20,686] Trial 362 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.008841682218550409, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.930370940134776, 'loop': 1, 'loss': 'CE', 'lr': 0.008271558791157265, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00025973034581833215, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.009279600720754459
weight_decay:  0.05259441021034662
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4187680301256478
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.717437552055344
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.7574275829829276
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.60
run time now: 4.925895690917969
total time:  4.945960893994197
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 0.71
[I 2023-06-12 00:46:26,195] Trial 363 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.002434992510514717, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.271320015809672, 'loop': 1, 'loss': 'CE', 'lr': 0.009279600720754459, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.05259441021034662, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.005781527476313226
weight_decay:  6.229265157964391e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.656563150929287
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  0.9126161551102996
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.6055241560097784
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.210924386978149
total time:  4.227610077010468
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.56
[I 2023-06-12 00:46:30,875] Trial 364 finished with value: 81.0 and parameters: {'Fwd': 0.01778752190451688, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 9.379883196881789, 'loop': 1, 'loss': 'CE', 'lr': 0.005781527476313226, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.229265157964391e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.007333005581049419
weight_decay:  0.0010249892018832543
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.680893081938848
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.3983342368155718
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.6589773739688098
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.40
run time now: 4.768753528594971
total time:  4.788326340960339
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.43 ± 0.96
[I 2023-06-12 00:46:36,144] Trial 365 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.06574158868986069, 'K': 9, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.682638686638422, 'loop': 1, 'loss': 'CE', 'lr': 0.007333005581049419, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0010249892018832543, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.003048545363641304
weight_decay:  3.176457488678862e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1638660540338606
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02, Epoch: 100, Loss: 0.0600, Train: 100.00%, Valid: 79.20% Test: 80.30%
Split: 01, Run: 02
None time:  5.531758629949763
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  4.024455907056108
None Run 03:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.80
run time now: 11.74797773361206
total time:  11.764022269984707
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 80.07 ± 0.25
[I 2023-06-12 00:46:48,398] Trial 366 finished with value: 79.4000015258789 and parameters: {'Fwd': 0.08429681181734514, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 7.02294472306942, 'loop': 1, 'loss': 'MSE', 'lr': 0.003048545363641304, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.176457488678862e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.006563856803355245
weight_decay:  0.0001309348757201878
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.208455587970093
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.19134790613316
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.5000710871536285
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
run time now: 3.978454113006592
total time:  4.0383397289551795
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.25
[I 2023-06-12 00:46:53,027] Trial 367 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.0018730510846553651, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 4.450631735138491, 'loop': 1, 'loss': 'CE', 'lr': 0.006563856803355245, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001309348757201878, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.008542726496901912
weight_decay:  0.001859456961486732
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6212407080456614
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.4928389401175082
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.72865414689295
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.869720935821533
total time:  4.883788652019575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.38
[I 2023-06-12 00:46:58,493] Trial 368 finished with value: 81.13333892822266 and parameters: {'Fwd': 0.03252240272550546, 'K': 10, 'alpha': 0.5, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 4.986998330511598, 'loop': 1, 'loss': 'CE', 'lr': 0.008542726496901912, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.001859456961486732, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.009981072693545175
weight_decay:  7.66094745437098e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7352601359598339
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.686066007008776
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.3255532421171665
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.60
run time now: 4.769911527633667
total time:  4.784643780905753
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 80.97 ± 1.23
[I 2023-06-12 00:47:03,707] Trial 369 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.09972397121981182, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.650004196294009, 'loop': 1, 'loss': 'CE', 'lr': 0.009981072693545175, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.66094745437098e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.0023229610812394424
weight_decay:  9.64470218571773e-05
dropout:  0.2
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.2, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7036020790692419
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 02
None time:  1.416287394007668
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.0818070890381932
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 77.90
run time now: 4.228008031845093
total time:  4.24555839295499
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.93 ± 1.51
  Final Train: 100.00 ± 0.00
   Final Test: 78.93 ± 0.96
[I 2023-06-12 00:47:08,416] Trial 370 finished with value: 78.93334197998047 and parameters: {'Fwd': 0.005135146916847572, 'K': 10, 'alpha': 0.75, 'dropout': 0.2, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.386904289496458, 'loop': 1, 'loss': 'CE', 'lr': 0.0023229610812394424, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.64470218571773e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.007792960179531579
weight_decay:  2.1295802778567067e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5140000691171736
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 02
None time:  1.565563949989155
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.5252446488011628
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
run time now: 4.6438422203063965
total time:  4.659506926080212
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.15
[I 2023-06-12 00:47:13,570] Trial 371 finished with value: 81.20000457763672 and parameters: {'Fwd': 0.05441305920602525, 'K': 9, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.845070253058499, 'loop': 1, 'loss': 'CE', 'lr': 0.007792960179531579, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.1295802778567067e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.004813789959144903
weight_decay:  5.7973094076241374e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7692252169363201
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 02
None time:  0.8883621629793197
None Run 02:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 76.30
Split: 01, Run: 03
None time:  1.16636219387874
None Run 03:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 78.50
run time now: 2.851766347885132
total time:  2.8702508478891104
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.93 ± 2.32
  Final Train: 100.00 ± 0.00
   Final Test: 78.57 ± 2.30
[I 2023-06-12 00:47:17,020] Trial 372 finished with value: 77.9333267211914 and parameters: {'Fwd': 0.004511128587809397, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 4.632799727053076, 'loop': 1, 'loss': 'CE', 'lr': 0.004813789959144903, 'softmaxF': True, 'useGCN': False, 'weight_decay': 5.7973094076241374e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.003413157583878306
weight_decay:  1.9590788675211337e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8241082790773362
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.8885146158281714
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.708975617075339
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.20
run time now: 5.455977439880371
total time:  5.475658556213602
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.47
[I 2023-06-12 00:47:23,023] Trial 373 finished with value: 80.26667022705078 and parameters: {'Fwd': 0.07055745244205877, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.596942458406459, 'loop': 1, 'loss': 'CE', 'lr': 0.003413157583878306, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.9590788675211337e-06, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006191960435057273
weight_decay:  3.837708136397142e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.7876630930695683
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 02
None time:  0.8334799080621451
None Run 02:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 77.00
Split: 01, Run: 03
None time:  0.8733977528754622
None Run 03:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 77.70
run time now: 2.525271415710449
total time:  2.540239815134555
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.80 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 77.43 ± 0.38
[I 2023-06-12 00:47:26,142] Trial 374 finished with value: 76.80000305175781 and parameters: {'Fwd': 1.3915449880446048e-06, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 10, 'lambda1': 0.9, 'lambda2': 4.897853171042235, 'loop': 1, 'loss': 'CE', 'lr': 0.006191960435057273, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.837708136397142e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.007218098057904572
weight_decay:  7.116915719494973e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3023696038872004
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.70
Split: 01, Run: 02
None time:  1.6639324410352856
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.0131335959304124
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.999866008758545
total time:  5.012546293903142
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.90 ± 0.72
[I 2023-06-12 00:47:31,782] Trial 375 finished with value: 80.80000305175781 and parameters: {'Fwd': 0.04019842303478303, 'K': 10, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.154685577021765, 'loop': 1, 'loss': 'CE', 'lr': 0.007218098057904572, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.116915719494973e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0087423363010977
weight_decay:  0.00012475454510850378
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.671024170005694
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.7612883469555527
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.6431800050195307
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.105170249938965
total time:  5.121063042199239
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.61
[I 2023-06-12 00:47:37,460] Trial 376 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.08145601849412151, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.302806599178782, 'loop': 1, 'loss': 'CE', 'lr': 0.0087423363010977, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00012475454510850378, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.007785019786387413
weight_decay:  4.869197617650519e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3963817269541323
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  1.5780602770391852
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.3825382329523563
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.70
run time now: 4.387516975402832
total time:  4.4058457592036575
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.61
  Final Train: 100.00 ± 0.00
   Final Test: 81.93 ± 0.49
[I 2023-06-12 00:47:42,390] Trial 377 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.06386184643595665, 'K': 10, 'alpha': 0.5, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.584454047701074, 'loop': 1, 'loss': 'CE', 'lr': 0.007785019786387413, 'softmaxF': False, 'useGCN': True, 'weight_decay': 4.869197617650519e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0055523090474004
weight_decay:  0.00016817443993400675
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4580617700703442
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.2920563779771328
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.6617863809224218
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.439611196517944
total time:  4.468027669005096
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.47 ± 0.29
[I 2023-06-12 00:47:47,432] Trial 378 finished with value: 81.13333892822266 and parameters: {'Fwd': 0.09928605630815976, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.325202328585184, 'loop': 1, 'loss': 'CE', 'lr': 0.0055523090474004, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00016817443993400675, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006745024146587626
weight_decay:  8.96072858753315e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.792553620878607
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  1.6543179000727832
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 03
None time:  1.5310264590661973
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.00
run time now: 5.004407167434692
total time:  5.019078345969319
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.97 ± 0.91
[I 2023-06-12 00:47:53,003] Trial 379 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.012112101901593566, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 6.002153879973697, 'loop': 1, 'loss': 'CE', 'lr': 0.006745024146587626, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.96072858753315e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00923828263010662
weight_decay:  7.379887822003652e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5059837389271706
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.4340091119520366
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.6820477941073477
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.66057014465332
total time:  4.680382869904861
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.64
[I 2023-06-12 00:47:58,155] Trial 380 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.0484285522678397, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.815265794650826, 'loop': 1, 'loss': 'CE', 'lr': 0.00923828263010662, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.379887822003652e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.35000000000000003
lr:  0.008150562525953213
weight_decay:  2.641292804521514e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.342346103163436
None Run 01:
Highest Train: 100.00
Highest Valid: 82.40
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.616616687970236
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.6885767420753837
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.674493074417114
total time:  4.698596623027697
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.76
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.78
[I 2023-06-12 00:48:03,379] Trial 381 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.07877455657163336, 'K': 10, 'alpha': 0.35000000000000003, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.136414153487724, 'loop': 1, 'loss': 'CE', 'lr': 0.008150562525953213, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.641292804521514e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006858871517778136
weight_decay:  0.019699920543702804
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.407658803043887
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  1.0429812700022012
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.4738413179293275
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.40
run time now: 3.9562828540802
total time:  3.979809907032177
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.10
[I 2023-06-12 00:48:07,840] Trial 382 finished with value: 81.19999694824219 and parameters: {'Fwd': 0.0004179210948133004, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.41198775336579, 'loop': 1, 'loss': 'CE', 'lr': 0.006858871517778136, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.019699920543702804, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.55
lr:  0.009962175842966221
weight_decay:  0.0006699353615039714
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5727416530717164
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.90
Split: 01, Run: 02
None time:  1.534422712866217
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 99.29
   Final Test: 80.50
Split: 01, Run: 03
None time:  1.240039920900017
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 99.29
   Final Test: 82.20
run time now: 4.373760938644409
total time:  4.387322677997872
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.53
  Final Train: 99.52 ± 0.41
   Final Test: 81.87 ± 1.23
[I 2023-06-12 00:48:12,754] Trial 383 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.00025418886286816714, 'K': 5, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 1.5933008573500063, 'loop': 1, 'loss': 'CE', 'lr': 0.009962175842966221, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0006699353615039714, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.0073381266496067975
weight_decay:  0.0001097498339847602
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6347051330376416
None Run 01:
Highest Train: 100.00
Highest Valid: 82.20
  Final Train: 99.29
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.6267133648507297
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 99.29
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.644994179951027
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 98.57
   Final Test: 81.50
run time now: 4.936269521713257
total time:  4.960735474945977
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.70
  Final Train: 99.05 ± 0.41
   Final Test: 81.37 ± 0.32
[I 2023-06-12 00:48:18,328] Trial 384 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.06106309193005317, 'K': 10, 'alpha': 0.75, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 0.5212924799790315, 'loop': 1, 'loss': 'CE', 'lr': 0.0073381266496067975, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001097498339847602, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.006307819158372166
weight_decay:  0.008070613560281072
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.53321294602938
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 02
None time:  1.8272853640373796
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.20
Split: 01, Run: 03
None time:  1.4996912269853055
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 78.40
run time now: 5.885054111480713
total time:  5.9023067250382155
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.87 ± 1.03
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 0.64
[I 2023-06-12 00:48:24,851] Trial 385 finished with value: 78.86666870117188 and parameters: {'Fwd': 0.07988430486382302, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 5.656013528380432, 'loop': 1, 'loss': 'MSE', 'lr': 0.006307819158372166, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.008070613560281072, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.008352246181293608
weight_decay:  5.8992663949363256e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6680244531016797
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.7268165070563555
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.4664242730941623
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.889404296875
total time:  4.90570768318139
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.72
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.49
[I 2023-06-12 00:48:30,322] Trial 386 finished with value: 80.99999237060547 and parameters: {'Fwd': 0.009810493784277311, 'K': 10, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 6.115617490382622, 'loop': 1, 'loss': 'CE', 'lr': 0.008352246181293608, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.8992663949363256e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.003791063481700466
weight_decay:  0.0002081819657969988
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8968843859620392
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.7050661710090935
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 03
None time:  0.960625003091991
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.5912230014801025
total time:  4.6058227240573615
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.68
[I 2023-06-12 00:48:35,437] Trial 387 finished with value: 81.19999694824219 and parameters: {'Fwd': 0.09971456021729146, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 4.817115158331738, 'loop': 1, 'loss': 'CE', 'lr': 0.003791063481700466, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002081819657969988, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.007607950267047113
weight_decay:  4.1339362319536934e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6500191008672118
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6565450860653073
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.524674422107637
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.873728275299072
total time:  4.894176797941327
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 0.58
[I 2023-06-12 00:48:40,990] Trial 388 finished with value: 81.0666732788086 and parameters: {'Fwd': 5.3873693761940325e-06, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.4977516476465205, 'loop': 1, 'loss': 'CE', 'lr': 0.007607950267047113, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.1339362319536934e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0025677661133580404
weight_decay:  0.00014583341936344208
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6763527009170502
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 02
None time:  1.3551750199403614
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  1.8593543202150613
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.90
run time now: 4.941143035888672
total time:  4.961232113884762
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.20 ± 1.39
  Final Train: 100.00 ± 0.00
   Final Test: 79.60 ± 0.62
[I 2023-06-12 00:48:46,493] Trial 389 finished with value: 79.20000457763672 and parameters: {'Fwd': 0.043099764727193124, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.799233929385265, 'loop': 1, 'loss': 'CE', 'lr': 0.0025677661133580404, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014583341936344208, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0009577962305592896
weight_decay:  0.0003162190978986799
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6539109710138291
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 02
None time:  1.6515476771164685
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.423825410893187
None Run 03:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 78.60
run time now: 4.756817579269409
total time:  4.773903358960524
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.53 ± 1.62
  Final Train: 100.00 ± 0.00
   Final Test: 79.57 ± 0.95
[I 2023-06-12 00:48:51,857] Trial 390 finished with value: 78.53333282470703 and parameters: {'Fwd': 0.024209966763861893, 'K': 10, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.24436680089857, 'loop': 1, 'loss': 'CE', 'lr': 0.0009577962305592896, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0003162190978986799, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0006178316502180179
weight_decay:  8.845141997932605e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.869794201105833
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
Split: 01, Run: 02
None time:  1.39907912700437
None Run 02:
Highest Train: 100.00
Highest Valid: 77.00
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  0.8346855079289526
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 79.70
run time now: 3.1309776306152344
total time:  3.1480304109863937
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.40 ± 4.85
  Final Train: 100.00 ± 0.00
   Final Test: 76.43 ± 5.66
[I 2023-06-12 00:48:55,497] Trial 391 finished with value: 74.4000015258789 and parameters: {'Fwd': 0.06596864950699359, 'K': 10, 'alpha': 0.45, 'dropout': 0.6000000000000001, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 6.503193852273832, 'loop': 1, 'loss': 'CE', 'lr': 0.0006178316502180179, 'softmaxF': True, 'useGCN': False, 'weight_decay': 8.845141997932605e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.009011504875623244
weight_decay:  5.629097592412662e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8418977609835565
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.5779178289230913
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.70
Split: 01, Run: 03
None time:  1.7809219150803983
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.40
run time now: 5.229205369949341
total time:  5.245199012104422
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 80.77 ± 1.29
[I 2023-06-12 00:49:01,229] Trial 392 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.030892243968566643, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.9, 'lambda2': 5.0330534942514005, 'loop': 1, 'loss': 'CE', 'lr': 0.009011504875623244, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.629097592412662e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.005058911665747997
weight_decay:  0.00010722986323228023
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7220320098567754
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.428015052108094
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.6339054179843515
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.812803030014038
total time:  4.8360767418053
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.42
[I 2023-06-12 00:49:06,727] Trial 393 finished with value: 81.0666732788086 and parameters: {'Fwd': 0.05291823670548073, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.648475212835295, 'loop': 1, 'loss': 'CE', 'lr': 0.005058911665747997, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010722986323228023, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.006070103114377228
weight_decay:  7.223791877588692e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.638233128003776
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.6134287470486015
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.418200861895457
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.695879697799683
total time:  4.713267480954528
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.42
[I 2023-06-12 00:49:11,977] Trial 394 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.0001433038933927479, 'K': 10, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.933054573321118, 'loop': 1, 'loss': 'CE', 'lr': 0.006070103114377228, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.223791877588692e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.00693544229102651
weight_decay:  8.480765875786151e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7114109061658382
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.6378536359407008
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.643812014022842
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.03242564201355
total time:  5.09046307601966
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.47 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.85
[I 2023-06-12 00:49:17,685] Trial 395 finished with value: 81.46666717529297 and parameters: {'Fwd': 0.08163563617602078, 'K': 9, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.38426552988825, 'loop': 1, 'loss': 'CE', 'lr': 0.00693544229102651, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.480765875786151e-06, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.00016015382667846799
weight_decay:  0.0019055271376961786
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.343535624910146
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  2.3276038081385195
None Run 02:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 75.60
Split: 01, Run: 03
None time:  1.6770606031641364
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 73.10
run time now: 5.382868766784668
total time:  5.410630309954286
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 74.73 ± 3.14
  Final Train: 100.00 ± 0.00
   Final Test: 75.27 ± 2.02
[I 2023-06-12 00:49:23,643] Trial 396 finished with value: 74.73333740234375 and parameters: {'Fwd': 0.015936881286563957, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.30000000000000004, 'lambda2': 4.722869221325617, 'loop': 1, 'loss': 'CE', 'lr': 0.00016015382667846799, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0019055271376961786, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.00027663044068982175
weight_decay:  4.8561218843508126e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9809816300403327
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.90
Split: 01, Run: 02
None time:  2.178414954105392
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.5916358281392604
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 74.60
run time now: 5.789798736572266
total time:  5.8032762059010565
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.60 ± 3.29
  Final Train: 100.00 ± 0.00
   Final Test: 77.50 ± 2.51
[I 2023-06-12 00:49:29,903] Trial 397 finished with value: 76.5999984741211 and parameters: {'Fwd': 0.09986578549798544, 'K': 10, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 3.72703214916683, 'loop': 1, 'loss': 'CE', 'lr': 0.00027663044068982175, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.8561218843508126e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0003512827474667973
weight_decay:  3.6485874709565486e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5843729269690812
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.7669054688885808
None Run 02:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 74.00
Split: 01, Run: 03
None time:  1.5303860281128436
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 77.50
run time now: 4.9075422286987305
total time:  4.928726608864963
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.87 ± 2.91
  Final Train: 100.00 ± 0.00
   Final Test: 76.73 ± 2.44
[I 2023-06-12 00:49:35,413] Trial 398 finished with value: 76.86666107177734 and parameters: {'Fwd': 0.0008433159969284435, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 2.39834805190954, 'loop': 1, 'loss': 'CE', 'lr': 0.0003512827474667973, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.6485874709565486e-06, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.008238278242360071
weight_decay:  0.0001240308299557153
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7840340330731124
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  1.6452925100456923
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  2.1342644880060107
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.10
run time now: 5.588449001312256
total time:  5.607649791054428
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 80.73 ± 0.57
[I 2023-06-12 00:49:41,564] Trial 399 finished with value: 80.93334197998047 and parameters: {'Fwd': 0.06961882017888697, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.8500000000000001, 'lambda2': 5.481941776965184, 'loop': 1, 'loss': 'CE', 'lr': 0.008238278242360071, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001240308299557153, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.0004962736127095695
weight_decay:  3.39594354052107e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9014785361941904
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 02
None time:  1.5235924001317471
None Run 02:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.7366464640945196
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.10
run time now: 5.209537982940674
total time:  5.232643587980419
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 1.40
  Final Train: 100.00 ± 0.00
   Final Test: 78.37 ± 0.93
[I 2023-06-12 00:49:47,309] Trial 400 finished with value: 78.19999694824219 and parameters: {'Fwd': 0.053938033731154265, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.19648573595651, 'loop': 1, 'loss': 'CE', 'lr': 0.0004962736127095695, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.39594354052107e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.005841381541170957
weight_decay:  8.588424140395095e-05
dropout:  0.8
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.8, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6519390409812331
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.70
Split: 01, Run: 02
None time:  1.70100307604298
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.5519825830124319
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.929784774780273
total time:  4.944082269910723
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.96
[I 2023-06-12 00:49:52,787] Trial 401 finished with value: 80.73332977294922 and parameters: {'Fwd': 0.03916016089485131, 'K': 10, 'alpha': 0.55, 'dropout': 0.8, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.703308890507515, 'loop': 1, 'loss': 'CE', 'lr': 0.005841381541170957, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.588424140395095e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.007693790196981301
weight_decay:  6.403125393489225e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6166870340239257
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.5429504809435457
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.4797173228580505
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.668798208236694
total time:  4.682795142987743
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.70
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.70
[I 2023-06-12 00:49:58,001] Trial 402 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.06907861615125206, 'K': 9, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 6.1023206720743435, 'loop': 1, 'loss': 'CE', 'lr': 0.007693790196981301, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.403125393489225e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.004353097590861045
weight_decay:  0.00014637303441236097
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5463893651030958
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 02
None time:  1.2958445369731635
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.496885976055637
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.366015672683716
total time:  4.3811805041041225
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.13 ± 0.12
[I 2023-06-12 00:50:02,982] Trial 403 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.0002928867005262346, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 5.008553608352309, 'loop': 1, 'loss': 'CE', 'lr': 0.004353097590861045, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00014637303441236097, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0016786278576045221
weight_decay:  9.670352041900395e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  3.3486567181535065
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  4.470555176027119
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 03
None time:  5.39517798088491
None Run 03:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.30
run time now: 13.239025831222534
total time:  13.257622209843248
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.27 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.03 ± 0.64
[I 2023-06-12 00:50:16,831] Trial 404 finished with value: 79.26667022705078 and parameters: {'Fwd': 0.08208035015127767, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 5.8376350706669085, 'loop': 1, 'loss': 'MSE', 'lr': 0.0016786278576045221, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.670352041900395e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0010861263077596996
weight_decay:  4.384272721151847e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8043962339870632
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  1.5465330670122057
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 75.80
Split: 01, Run: 03
None time:  1.5834008341189474
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 77.60
run time now: 4.962566375732422
total time:  4.9762570220045745
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.33 ± 2.14
  Final Train: 100.00 ± 0.00
   Final Test: 77.90 ± 2.26
[I 2023-06-12 00:50:22,333] Trial 405 finished with value: 77.33333587646484 and parameters: {'Fwd': 0.006081168915436364, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 7.96623706651658, 'loop': 1, 'loss': 'CE', 'lr': 0.0010861263077596996, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.384272721151847e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  3
alpha:  0.65
lr:  0.008878920265420531
weight_decay:  7.674935633498491e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=3, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5165391119662672
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.3370617979671806
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 03
None time:  1.6240234561264515
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.70
run time now: 4.503870725631714
total time:  4.520608601858839
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 80.93 ± 1.12
[I 2023-06-12 00:50:27,424] Trial 406 finished with value: 81.06666564941406 and parameters: {'Fwd': 0.003184620075336014, 'K': 3, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 3.9048677443454345, 'loop': 1, 'loss': 'CE', 'lr': 0.008878920265420531, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.674935633498491e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.006671563964130485
weight_decay:  0.00017021168473035372
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.265595376957208
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  0.8780812111217529
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.5349752930924296
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 3.7055985927581787
total time:  3.7208265350200236
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.00 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.23
[I 2023-06-12 00:50:31,708] Trial 407 finished with value: 81.0 and parameters: {'Fwd': 0.05666111493614612, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.565879627592996, 'loop': 0, 'loss': 'CE', 'lr': 0.006671563964130485, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00017021168473035372, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.007518553548049585
weight_decay:  1.051538198326009e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5294945139903575
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.2379186188336462
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.4847440801095217
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.282680988311768
total time:  4.30068259104155
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.26
[I 2023-06-12 00:50:36,520] Trial 408 finished with value: 81.26667022705078 and parameters: {'Fwd': 6.226603987733356e-05, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.65, 'lambda2': 5.2958110951181805, 'loop': 1, 'loss': 'CE', 'lr': 0.007518553548049585, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.051538198326009e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.009376480111999505
weight_decay:  0.00023374846006450734
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4409443829208612
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.90
Split: 01, Run: 02
None time:  1.5011613920796663
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  1.509058655006811
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.90
run time now: 4.475775718688965
total time:  4.492389087099582
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 82.67 ± 0.40
[I 2023-06-12 00:50:41,576] Trial 409 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.09957898748796962, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.427710494876735, 'loop': 1, 'loss': 'CE', 'lr': 0.009376480111999505, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00023374846006450734, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.009312391701017816
weight_decay:  0.0002617231511658086
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.1670921118929982
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 02
None time:  1.011034375987947
None Run 02:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.18772768904455
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.00
run time now: 3.4007561206817627
total time:  3.414505288004875
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 79.87 ± 0.90
[I 2023-06-12 00:50:45,527] Trial 410 finished with value: 79.9333267211914 and parameters: {'Fwd': 0.0991791114048633, 'K': 10, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 4.315623170303441, 'loop': 1, 'loss': 'CE', 'lr': 0.009312391701017816, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.0002617231511658086, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.009715154122925953
weight_decay:  0.0002981228951287238
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6866304958239198
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  1.3187106258701533
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  1.7505470318719745
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.20
run time now: 4.784332752227783
total time:  4.799515692982823
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 82.40 ± 0.35
[I 2023-06-12 00:50:50,860] Trial 411 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.0012946350889204347, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.4932157949963685, 'loop': 1, 'loss': 'CE', 'lr': 0.009715154122925953, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002981228951287238, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.0007784078975168969
weight_decay:  2.914568849621758e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.1500192421954125
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 02
None time:  2.0315419791731983
None Run 02:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 03
None time:  1.1949336950201541
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 78.20
run time now: 5.405550241470337
total time:  5.426781596848741
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.53 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 78.67 ± 0.50
[I 2023-06-12 00:50:56,890] Trial 412 finished with value: 78.53333282470703 and parameters: {'Fwd': 0.0821778745529184, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.9500000000000001, 'lambda2': 3.2706932192765352, 'loop': 1, 'loss': 'CE', 'lr': 0.0007784078975168969, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.914568849621758e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.00852320747719124
weight_decay:  0.00018140057358487192
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7021998099517077
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.7268948601558805
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.7562777660787106
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.80
run time now: 5.213304042816162
total time:  5.229339543031529
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.93 ± 0.32
[I 2023-06-12 00:51:02,630] Trial 413 finished with value: 80.9333267211914 and parameters: {'Fwd': 0.004548777255111314, 'K': 10, 'alpha': 0.75, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.610388007260656, 'loop': 1, 'loss': 'CE', 'lr': 0.00852320747719124, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00018140057358487192, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.00269056886177147
weight_decay:  0.00022311216897495247
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8232047650963068
None Run 01:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 78.30
Split: 01, Run: 02
None time:  0.5779864289797843
None Run 02:
Highest Train: 100.00
Highest Valid: 74.00
  Final Train: 100.00
   Final Test: 75.00
Split: 01, Run: 03
None time:  0.9351507199462503
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 2.3635404109954834
total time:  2.3788122918922454
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.33 ± 4.24
  Final Train: 100.00 ± 0.00
   Final Test: 74.40 ± 4.23
[I 2023-06-12 00:51:05,464] Trial 414 finished with value: 73.33333587646484 and parameters: {'Fwd': 0.07496624275139435, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 20, 'lambda1': 0.9, 'lambda2': 8.455464232853444, 'loop': 1, 'loss': 'CE', 'lr': 0.00269056886177147, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00022311216897495247, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0020822131594856797
weight_decay:  0.09775474695015582
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.661940417950973
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  2.34194919699803
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.322459941962734
None Run 03:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.70
run time now: 7.358285903930664
total time:  7.376948029035702
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 82.13 ± 0.51
[I 2023-06-12 00:51:13,305] Trial 415 finished with value: 80.9333267211914 and parameters: {'Fwd': 0.08251474462888868, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 90, 'lambda1': 0.9500000000000001, 'lambda2': 4.407815849316523, 'loop': 1, 'loss': 'CE', 'lr': 0.0020822131594856797, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.09775474695015582, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.008497151038420503
weight_decay:  5.3097829317126985e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6462771820370108
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.6594940591603518
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.3261877498589456
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.30
run time now: 4.666623592376709
total time:  4.681702526984736
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.90 ± 0.66
[I 2023-06-12 00:51:18,523] Trial 416 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.01439405341747688, 'K': 10, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 8.34164057135678, 'loop': 1, 'loss': 'CE', 'lr': 0.008497151038420503, 'softmaxF': False, 'useGCN': True, 'weight_decay': 5.3097829317126985e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.009983697898093167
weight_decay:  0.00040702200393959875
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8423633181955665
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.8400479468982667
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 03
None time:  1.827935985988006
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.60
run time now: 5.533176422119141
total time:  5.549688776023686
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.90 ± 1.13
[I 2023-06-12 00:51:24,619] Trial 417 finished with value: 80.46666717529297 and parameters: {'Fwd': 0.06423739859047643, 'K': 10, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 4.839799804494743, 'loop': 1, 'loss': 'CE', 'lr': 0.009983697898093167, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00040702200393959875, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0009135744446301052
weight_decay:  0.00019828036699125212
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4793119728565216
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 02
None time:  1.6108155669644475
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 75.10
Split: 01, Run: 03
None time:  1.7230673108715564
None Run 03:
Highest Train: 100.00
Highest Valid: 75.60
  Final Train: 100.00
   Final Test: 76.80
run time now: 4.836744785308838
total time:  4.855334243969992
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.40 ± 3.08
  Final Train: 100.00 ± 0.00
   Final Test: 77.10 ± 2.17
[I 2023-06-12 00:51:30,045] Trial 418 finished with value: 76.39999389648438 and parameters: {'Fwd': 0.09981961255623165, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.24368467729796, 'loop': 1, 'loss': 'CE', 'lr': 0.0009135744446301052, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00019828036699125212, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.8
lr:  0.0011183514508135218
weight_decay:  0.0035410035453954107
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.589220677036792
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  1.6367793439421803
None Run 02:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.5749313009437174
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 69.90
run time now: 4.8303139209747314
total time:  4.843837291933596
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 75.60 ± 5.92
  Final Train: 100.00 ± 0.00
   Final Test: 76.40 ± 5.67
[I 2023-06-12 00:51:35,392] Trial 419 finished with value: 75.5999984741211 and parameters: {'Fwd': 0.04683996367790755, 'K': 9, 'alpha': 0.8, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.95884070252809, 'loop': 1, 'loss': 'CE', 'lr': 0.0011183514508135218, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0035410035453954107, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.003351684880509601
weight_decay:  3.778671653007616e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9693386040162295
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  1.8515443939249963
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.8451075239572674
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.689809083938599
total time:  5.709662504028529
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 80.67 ± 0.47
[I 2023-06-12 00:51:41,786] Trial 420 finished with value: 79.9333267211914 and parameters: {'Fwd': 0.0006512825865473667, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 6.306412746859551, 'loop': 1, 'loss': 'CE', 'lr': 0.003351684880509601, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.778671653007616e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0013726483068342143
weight_decay:  7.081245960722974e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.452212065923959
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 02
None time:  1.693587000016123
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 76.70
Split: 01, Run: 03
None time:  1.607218910008669
None Run 03:
Highest Train: 100.00
Highest Valid: 73.20
  Final Train: 100.00
   Final Test: 74.40
run time now: 4.780048608779907
total time:  4.7943156061228365
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.27 ± 3.00
  Final Train: 100.00 ± 0.00
   Final Test: 76.97 ± 2.71
[I 2023-06-12 00:51:47,186] Trial 421 finished with value: 76.26667022705078 and parameters: {'Fwd': 0.000823727802941683, 'K': 10, 'alpha': 0.4, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 4.534522617418883, 'loop': 1, 'loss': 'CE', 'lr': 0.0013726483068342143, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.081245960722974e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.008002045131942087
weight_decay:  5.311080227948411e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5308835140895098
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  1.2307199148926884
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  1.5037252740003169
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 83.00
run time now: 4.300246477127075
total time:  4.317283089039847
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 82.57 ± 0.40
[I 2023-06-12 00:51:52,092] Trial 422 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.06565816253648082, 'K': 10, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.138261557462138, 'loop': 1, 'loss': 'CE', 'lr': 0.008002045131942087, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.311080227948411e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.009009721252962203
weight_decay:  0.00013880602801305102
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.845548169920221
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  1.9642143240198493
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.20
Split: 01, Run: 03
None time:  1.6521102068945765
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 79.40
run time now: 5.491875171661377
total time:  5.511278753867373
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 79.53 ± 0.42
[I 2023-06-12 00:51:58,159] Trial 423 finished with value: 80.0666732788086 and parameters: {'Fwd': 0.08086496015649558, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.038815794125971, 'loop': 1, 'loss': 'MSE', 'lr': 0.009009721252962203, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013880602801305102, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.00750587840157069
weight_decay:  1.0170912540102531e-06
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8443692829459906
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  1.766644753050059
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.3003092431463301
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.940639019012451
total time:  4.960092991124839
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.90
  Final Train: 100.00 ± 0.00
   Final Test: 81.73 ± 0.93
[I 2023-06-12 00:52:03,619] Trial 424 finished with value: 81.06666564941406 and parameters: {'Fwd': 0.05328134792830552, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 70, 'lambda1': 1.0, 'lambda2': 4.132600925118556, 'loop': 1, 'loss': 'CE', 'lr': 0.00750587840157069, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.0170912540102531e-06, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  1.0
lr:  0.0002175896133940915
weight_decay:  0.00011743105246664073
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=1.0)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0704993959516287
None Run 01:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 77.80
Split: 01, Run: 02
None time:  1.6445996779948473
None Run 02:
Highest Train: 100.00
Highest Valid: 70.60
  Final Train: 100.00
   Final Test: 72.60
Split: 01, Run: 03
None time:  1.5054367680568248
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 72.60
run time now: 5.248880863189697
total time:  5.268151360098273
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.87 ± 4.05
  Final Train: 100.00 ± 0.00
   Final Test: 74.33 ± 3.00
[I 2023-06-12 00:52:09,386] Trial 425 finished with value: 73.86666870117188 and parameters: {'Fwd': 0.0005583278936322952, 'K': 10, 'alpha': 1.0, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 3.5712836144791527, 'loop': 1, 'loss': 'CE', 'lr': 0.0002175896133940915, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011743105246664073, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.006502845847142705
weight_decay:  7.322290012218918e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4543641349300742
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.4308448620140553
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 03
None time:  1.7399703599512577
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.90
run time now: 4.649357080459595
total time:  4.662477288860828
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.46
[I 2023-06-12 00:52:14,575] Trial 426 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.08251206137536349, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.347330592619276, 'loop': 1, 'loss': 'CE', 'lr': 0.006502845847142705, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.322290012218918e-06, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.75
lr:  0.005446287323298683
weight_decay:  5.994013842475182e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5643953869584948
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.0512583979871124
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.3413709942251444
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.50
run time now: 3.9856784343719482
total time:  4.0057515350636095
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.36
[I 2023-06-12 00:52:19,154] Trial 427 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.035088962060109814, 'K': 7, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.975925461177267, 'loop': 1, 'loss': 'CE', 'lr': 0.005446287323298683, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.994013842475182e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.55
lr:  0.0012261728438413982
weight_decay:  1.435304124488889e-06
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7508158250711858
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 02
None time:  1.4558325139805675
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 75.80
Split: 01, Run: 03
None time:  1.2836905389558524
None Run 03:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 76.80
run time now: 4.520232439041138
total time:  4.539235537871718
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.87 ± 2.23
  Final Train: 100.00 ± 0.00
   Final Test: 77.40 ± 1.97
[I 2023-06-12 00:52:24,187] Trial 428 finished with value: 76.86666107177734 and parameters: {'Fwd': 0.06782325461680302, 'K': 9, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 3.843037061922777, 'loop': 1, 'loss': 'CE', 'lr': 0.0012261728438413982, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.435304124488889e-06, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.008263675761866943
weight_decay:  0.0015023231437244259
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8170435710344464
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 83.10
Split: 01, Run: 02
None time:  1.6438015399035066
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 03
None time:  1.899641013937071
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.390631675720215
total time:  5.407999183051288
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.40 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 82.13 ± 1.42
[I 2023-06-12 00:52:30,087] Trial 429 finished with value: 80.4000015258789 and parameters: {'Fwd': 0.00025813110152775017, 'K': 10, 'alpha': 0.45, 'dropout': 0.5, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.714988859646695, 'loop': 1, 'loss': 'CE', 'lr': 0.008263675761866943, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0015023231437244259, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.009090384362292706
weight_decay:  9.076657299856945e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9203596080187708
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 02
None time:  1.524357205023989
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 99.29
   Final Test: 79.00
Split: 01, Run: 03
None time:  0.8493767201434821
None Run 03:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.50
run time now: 3.325239658355713
total time:  3.3566857089754194
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.93 ± 0.23
  Final Train: 99.76 ± 0.41
   Final Test: 79.30 ± 0.26
[I 2023-06-12 00:52:34,039] Trial 430 finished with value: 79.9333267211914 and parameters: {'Fwd': 0.09985248840606772, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 4.79909906490502, 'loop': 1, 'loss': 'CE', 'lr': 0.009090384362292706, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.076657299856945e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.007258235243737311
weight_decay:  4.352643632339685e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.648474141024053
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.6905034892261028
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.4113180339336395
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.7784905433654785
total time:  4.792103979969397
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.79
[I 2023-06-12 00:52:39,348] Trial 431 finished with value: 81.5999984741211 and parameters: {'Fwd': 0.06621012200954177, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.4865107473289845, 'loop': 1, 'loss': 'CE', 'lr': 0.007258235243737311, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.352643632339685e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0014509163189069287
weight_decay:  3.939188029628909e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6286316069308668
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.50
Split: 01, Run: 02
None time:  1.7920664970297366
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  1.6959941869135946
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.90
run time now: 5.141999006271362
total time:  5.158479760866612
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.27 ± 2.52
  Final Train: 100.00 ± 0.00
   Final Test: 78.13 ± 2.90
[I 2023-06-12 00:52:45,039] Trial 432 finished with value: 77.26667022705078 and parameters: {'Fwd': 0.04639779866471726, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 7.241066371547971, 'loop': 2, 'loss': 'CE', 'lr': 0.0014509163189069287, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.939188029628909e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  1
alpha:  0.65
lr:  0.007326587005626041
weight_decay:  0.0008419658933167799
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=1, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5828231391496956
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.8869772220496088
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 03
None time:  1.9144615719560534
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.80
run time now: 5.416671276092529
total time:  5.449959432007745
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.12
[I 2023-06-12 00:52:51,137] Trial 433 finished with value: 81.20000457763672 and parameters: {'Fwd': 0.00428158876926832, 'K': 1, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.143553046687859, 'loop': 1, 'loss': 'CE', 'lr': 0.007326587005626041, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0008419658933167799, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0008614240615739013
weight_decay:  4.404549246853247e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6328628740739077
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 02
None time:  1.3977380760479718
None Run 02:
Highest Train: 100.00
Highest Valid: 76.80
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 03
None time:  1.679310373030603
None Run 03:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 73.20
run time now: 4.743204355239868
total time:  4.755613502813503
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.40 ± 3.42
  Final Train: 100.00 ± 0.00
   Final Test: 76.40 ± 3.15
[I 2023-06-12 00:52:56,416] Trial 434 finished with value: 76.39999389648438 and parameters: {'Fwd': 0.0003794249302211291, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.425503653370686, 'loop': 1, 'loss': 'CE', 'lr': 0.0008614240615739013, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.404549246853247e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.008153671113105665
weight_decay:  2.1286219740283463e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2025889959186316
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.2055984491016716
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.6349189470056444
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.073031902313232
total time:  4.091483799973503
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.87 ± 0.70
[I 2023-06-12 00:53:01,007] Trial 435 finished with value: 81.06666564941406 and parameters: {'Fwd': 0.0256702275942957, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.806784488039129, 'loop': 1, 'loss': 'CE', 'lr': 0.008153671113105665, 'softmaxF': False, 'useGCN': True, 'weight_decay': 2.1286219740283463e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.009231454979843137
weight_decay:  3.0372159417300016e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5774912459310144
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  2.6478221940342337
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 83.20
Split: 01, Run: 03
None time:  1.5778873548842967
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.10
run time now: 5.82994270324707
total time:  5.845484807156026
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 82.70 ± 0.56
[I 2023-06-12 00:53:07,330] Trial 436 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.09889190577699211, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.548237681321682, 'loop': 1, 'loss': 'CE', 'lr': 0.009231454979843137, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.0372159417300016e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0006646192571564273
weight_decay:  0.0002467845771862229
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6916437800973654
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.40
Split: 01, Run: 02
None time:  1.1930534990970045
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 74.40
Split: 01, Run: 03
None time:  1.668729550903663
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 78.20
run time now: 4.580356121063232
total time:  4.603069182951003
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.60 ± 2.31
  Final Train: 100.00 ± 0.00
   Final Test: 77.33 ± 2.61
[I 2023-06-12 00:53:12,434] Trial 437 finished with value: 77.5999984741211 and parameters: {'Fwd': 0.001773119492325082, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.147633314787866, 'loop': 1, 'loss': 'CE', 'lr': 0.0006646192571564273, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002467845771862229, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.00994425145365285
weight_decay:  1.503316934290214e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6233779359608889
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.5122522118035704
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 03
None time:  1.75246049487032
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.924533843994141
total time:  4.943240044871345
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.20 ± 0.85
[I 2023-06-12 00:53:17,873] Trial 438 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.06808266577767676, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 4.949596947484804, 'loop': 1, 'loss': 'CE', 'lr': 0.00994425145365285, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.503316934290214e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  5
alpha:  0.7000000000000001
lr:  0.006269313730071467
weight_decay:  0.0014105326829066856
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=5, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2331145210191607
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 02
None time:  1.5432176620233804
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.564644284080714
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
run time now: 4.360619306564331
total time:  4.375496210996062
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.40
  Final Train: 100.00 ± 0.00
   Final Test: 81.20 ± 0.36
[I 2023-06-12 00:53:22,903] Trial 439 finished with value: 81.19999694824219 and parameters: {'Fwd': 0.0820052566305344, 'K': 5, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.268659855633464, 'loop': 1, 'loss': 'CE', 'lr': 0.006269313730071467, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0014105326829066856, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.35000000000000003
lr:  0.007747789460437374
weight_decay:  6.246527062356296e-06
dropout:  0.0
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.0, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.35000000000000003)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4494286349508911
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.2200490080285817
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.4340351182036102
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.126605987548828
total time:  4.1460732109844685
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.38
[I 2023-06-12 00:53:27,698] Trial 440 finished with value: 81.20000457763672 and parameters: {'Fwd': 0.00031978266670273806, 'K': 9, 'alpha': 0.35000000000000003, 'dropout': 0.0, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.93129095539253, 'loop': 1, 'loss': 'CE', 'lr': 0.007747789460437374, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.246527062356296e-06, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0018084287865904125
weight_decay:  2.606704581750674e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8561395620927215
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  1.8979619881138206
None Run 02:
Highest Train: 100.00
Highest Valid: 79.00
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 03
None time:  1.446726034861058
None Run 03:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.60
run time now: 5.229956865310669
total time:  5.243791023036465
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.03 ± 0.55
[I 2023-06-12 00:53:33,476] Trial 441 finished with value: 79.33333587646484 and parameters: {'Fwd': 0.05616287908103181, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 7.779761584760677, 'loop': 1, 'loss': 'CE', 'lr': 0.0018084287865904125, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.606704581750674e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  6
alpha:  0.5
lr:  0.002332488247306823
weight_decay:  5.445683491882845e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=6, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.203567228047177
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.9914429190102965
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.8694673089776188
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.10
run time now: 6.113818645477295
total time:  6.153111438034102
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.27 ± 0.46
  Final Train: 100.00 ± 0.00
   Final Test: 81.37 ± 0.64
[I 2023-06-12 00:53:40,250] Trial 442 finished with value: 80.26667022705078 and parameters: {'Fwd': 0.0001978014776284405, 'K': 6, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 100, 'lambda1': 0.8, 'lambda2': 6.462495199680762, 'loop': 1, 'loss': 'CE', 'lr': 0.002332488247306823, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.445683491882845e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.30000000000000004
lr:  0.007000560577112239
weight_decay:  6.547526544400417e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.30000000000000004)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.0640470900107175
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 02
None time:  1.6033185638953
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.10
Split: 01, Run: 03
None time:  1.7682956119533628
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.463945388793945
total time:  5.483829281060025
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 1.22
  Final Train: 100.00 ± 0.00
   Final Test: 79.53 ± 0.81
[I 2023-06-12 00:53:46,330] Trial 443 finished with value: 79.5999984741211 and parameters: {'Fwd': 0.00015266288339345344, 'K': 10, 'alpha': 0.30000000000000004, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.680418283277371, 'loop': 1, 'loss': 'MSE', 'lr': 0.007000560577112239, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.547526544400417e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8500000000000001
lr:  0.004978832224033239
weight_decay:  0.00035009866414153893
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8500000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9608203279785812
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 02
None time:  1.3800134968478233
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.469751153839752
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
run time now: 3.83420991897583
total time:  3.8506709951907396
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.67 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.30 ± 0.17
[I 2023-06-12 00:53:50,832] Trial 444 finished with value: 80.66666412353516 and parameters: {'Fwd': 0.0005022797405708372, 'K': 10, 'alpha': 0.8500000000000001, 'dropout': 0.5, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 4.655814189525472, 'loop': 1, 'loss': 'CE', 'lr': 0.004978832224033239, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00035009866414153893, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0026903028817861765
weight_decay:  3.960577917797306e-05
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3908904241397977
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 02
None time:  1.6668918619398028
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  1.438118610996753
None Run 03:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 79.20
run time now: 4.521516799926758
total time:  4.544990339083597
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.33 ± 1.15
  Final Train: 100.00 ± 0.00
   Final Test: 80.07 ± 1.17
[I 2023-06-12 00:53:55,895] Trial 445 finished with value: 79.33333587646484 and parameters: {'Fwd': 0.0003310324987603263, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 9.683447758088002, 'loop': 1, 'loss': 'CE', 'lr': 0.0026903028817861765, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.960577917797306e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.7000000000000001
lr:  0.0005397142640172127
weight_decay:  4.830412091784113e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9297569619957358
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.50
Split: 01, Run: 02
None time:  1.8610060119535774
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.10
Split: 01, Run: 03
None time:  1.713303522206843
None Run 03:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.10
run time now: 5.531037330627441
total time:  5.548362253932282
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.73 ± 2.76
  Final Train: 100.00 ± 0.00
   Final Test: 77.57 ± 3.01
[I 2023-06-12 00:54:01,958] Trial 446 finished with value: 77.73332977294922 and parameters: {'Fwd': 0.07047651017436529, 'K': 9, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.430401773947224, 'loop': 1, 'loss': 'CE', 'lr': 0.0005397142640172127, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.830412091784113e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  7
alpha:  0.65
lr:  0.008479708558618185
weight_decay:  0.00015328488667905142
dropout:  0.1
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=7, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5598621000535786
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.68680793303065
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.6233089310117066
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.894554615020752
total time:  4.916614999063313
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.47 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.57 ± 0.35
[I 2023-06-12 00:54:07,470] Trial 447 finished with value: 80.46666717529297 and parameters: {'Fwd': 4.4700143108805136e-05, 'K': 7, 'alpha': 0.65, 'dropout': 0.1, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 2.846594164883412, 'loop': 1, 'loss': 'CE', 'lr': 0.008479708558618185, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015328488667905142, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00041943435467666336
weight_decay:  7.621790630312755e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4826826381031424
None Run 01:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.60
Split: 01, Run: 02
None time:  1.7917394549585879
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 03
None time:  1.5138746940065175
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 77.50
run time now: 4.814049959182739
total time:  4.829442393034697
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 77.53 ± 1.05
[I 2023-06-12 00:54:12,849] Trial 448 finished with value: 78.20000457763672 and parameters: {'Fwd': 8.66089743898618e-06, 'K': 10, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.1450397447845235, 'loop': 1, 'loss': 'CE', 'lr': 0.00041943435467666336, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.621790630312755e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.003589074093305585
weight_decay:  1.2001371492393722e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01, Epoch: 100, Loss: 1.5176, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 01
None time:  5.651039119809866
None Run 01:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 02, Epoch: 100, Loss: 1.5173, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 02
None time:  6.3419075009878725
None Run 02:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
Split: 01, Run: 03, Epoch: 100, Loss: 1.5163, Train: 100.00%, Valid: 72.60% Test: 73.20%
Split: 01, Run: 03
None time:  5.293383525218815
None Run 03:
Highest Train: 100.00
Highest Valid: 72.60
  Final Train: 100.00
   Final Test: 73.20
run time now: 17.315205574035645
total time:  17.32958811498247
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 72.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 73.20 ± 0.00
[I 2023-06-12 00:54:30,665] Trial 449 finished with value: 72.5999984741211 and parameters: {'Fwd': 1.7996016538514616e-05, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.0, 'lambda2': 5.601985038376289, 'loop': 1, 'loss': 'CE', 'lr': 0.003589074093305585, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.2001371492393722e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.006885041130969879
weight_decay:  3.471057978297755e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8246857810299844
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 02
None time:  1.0446941358968616
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 76.90
Split: 01, Run: 03
None time:  1.1636408460326493
None Run 03:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 79.80
run time now: 3.064336061477661
total time:  3.0791865659411997
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.67 ± 3.56
  Final Train: 100.00 ± 0.00
   Final Test: 78.83 ± 1.67
[I 2023-06-12 00:54:34,237] Trial 450 finished with value: 76.66666412353516 and parameters: {'Fwd': 0.09988454783224666, 'K': 10, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.913756436534478, 'loop': 1, 'loss': 'CE', 'lr': 0.006885041130969879, 'softmaxF': True, 'useGCN': False, 'weight_decay': 3.471057978297755e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0031381421120344507
weight_decay:  0.00011182358519672661
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.33917695004493
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 02
None time:  1.511311155045405
None Run 02:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.3672978540416807
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.2449729442596436
total time:  4.260234765009955
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.07 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.03 ± 0.35
[I 2023-06-12 00:54:38,992] Trial 451 finished with value: 80.06666564941406 and parameters: {'Fwd': 0.040720180619924315, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 5.313042887908125, 'loop': 1, 'loss': 'CE', 'lr': 0.0031381421120344507, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011182358519672661, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0002378790024375686
weight_decay:  0.00019835934645028898
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.9408875941298902
None Run 01:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.90
Split: 01, Run: 02
None time:  1.9620357339736074
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.40
Split: 01, Run: 03
None time:  1.8087669231463224
None Run 03:
Highest Train: 100.00
Highest Valid: 73.60
  Final Train: 100.00
   Final Test: 73.30
run time now: 5.74373459815979
total time:  5.769395102048293
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.00 ± 2.95
  Final Train: 100.00 ± 0.00
   Final Test: 76.53 ± 2.81
[I 2023-06-12 00:54:45,419] Trial 452 finished with value: 77.0 and parameters: {'Fwd': 9.566310417324044e-05, 'K': 10, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 4.96098734633497, 'loop': 1, 'loss': 'CE', 'lr': 0.0002378790024375686, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00019835934645028898, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0015294647858763843
weight_decay:  0.05942212281951164
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.467218088917434
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  2.3112338341306895
None Run 02:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 03
None time:  2.1945300900842994
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.60
run time now: 7.004389762878418
total time:  7.021366856992245
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.87 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 80.47 ± 1.40
[I 2023-06-12 00:54:53,016] Trial 453 finished with value: 79.86666870117188 and parameters: {'Fwd': 0.058724618084855594, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 8.964700875136302, 'loop': 1, 'loss': 'CE', 'lr': 0.0015294647858763843, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.05942212281951164, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.005884289205391472
weight_decay:  0.00967723685723957
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5870496530551463
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.6770210328977555
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.653401092858985
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
run time now: 4.944231748580933
total time:  4.9571205580141395
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.60 ± 0.17
[I 2023-06-12 00:54:58,626] Trial 454 finished with value: 80.93333435058594 and parameters: {'Fwd': 0.0029255630087169095, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 6.185642771250528, 'loop': 1, 'loss': 'CE', 'lr': 0.005884289205391472, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00967723685723957, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007548306313338359
weight_decay:  0.0033735931714329354
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5490241528023034
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.40
Split: 01, Run: 02
None time:  1.5118096561636776
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  1.6122014918364584
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.20
run time now: 4.707803964614868
total time:  4.737937729107216
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.60
[I 2023-06-12 00:55:03,959] Trial 455 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.00011821804281104987, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 5.721162100537693, 'loop': 1, 'loss': 'CE', 'lr': 0.007548306313338359, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.0033735931714329354, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.008929230413008079
weight_decay:  6.320989201606894e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6245848729740828
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.3356150130275637
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 99.29
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.6457409299910069
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 99.29
   Final Test: 80.70
run time now: 4.631744384765625
total time:  4.644477126887068
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.60
  Final Train: 99.52 ± 0.41
   Final Test: 81.17 ± 0.72
[I 2023-06-12 00:55:09,203] Trial 456 finished with value: 81.20000457763672 and parameters: {'Fwd': 3.6770970380264114e-05, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 2.2002041671942463, 'loop': 1, 'loss': 'CE', 'lr': 0.008929230413008079, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.320989201606894e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.007984938656189091
weight_decay:  8.994381044233153e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.486824827035889
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.8015253101475537
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 03
None time:  1.818677990930155
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 83.00
run time now: 5.13629937171936
total time:  5.151310905814171
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.53 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 82.47 ± 0.61
[I 2023-06-12 00:55:14,836] Trial 457 finished with value: 81.53333282470703 and parameters: {'Fwd': 0.07923784622551125, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 3.398621044026226, 'loop': 1, 'loss': 'CE', 'lr': 0.007984938656189091, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.994381044233153e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.006531238941969071
weight_decay:  4.66376030102163e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7166433709207922
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.50
Split: 01, Run: 02
None time:  1.7131213410757482
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.5231526440475136
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.90
run time now: 4.980317115783691
total time:  5.014594457112253
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.93 ± 0.95
  Final Train: 100.00 ± 0.00
   Final Test: 81.67 ± 0.80
[I 2023-06-12 00:55:20,422] Trial 458 finished with value: 80.9333267211914 and parameters: {'Fwd': 0.0503813293300912, 'K': 9, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.530068692836534, 'loop': 1, 'loss': 'CE', 'lr': 0.006531238941969071, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.66376030102163e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.00912259164322938
weight_decay:  0.00011388975500301098
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.319884867174551
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.6050140971783549
None Run 02:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.5569999879226089
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.30
run time now: 4.510784387588501
total time:  4.527670719893649
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.35
  Final Train: 100.00 ± 0.00
   Final Test: 81.33 ± 1.00
[I 2023-06-12 00:55:25,548] Trial 459 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.07029800401816108, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 4.191785443562381, 'loop': 1, 'loss': 'CE', 'lr': 0.00912259164322938, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011388975500301098, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0029161304300397094
weight_decay:  7.005505816561048e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5495376749895513
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.20
Split: 01, Run: 02
None time:  1.5042178488802165
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.70
Split: 01, Run: 03
None time:  2.137838206021115
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.20
run time now: 5.217496395111084
total time:  5.23179592192173
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.80 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.50
[I 2023-06-12 00:55:31,266] Trial 460 finished with value: 80.79999542236328 and parameters: {'Fwd': 0.08094386819316021, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 9.09475183842882, 'loop': 1, 'loss': 'CE', 'lr': 0.0029161304300397094, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.005505816561048e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.009928576602690972
weight_decay:  0.0001348632718739859
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5036074130330235
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.7293762539047748
None Run 02:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.6938614808022976
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.70
run time now: 4.957212209701538
total time:  4.97363390494138
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 81.40 ± 0.61
[I 2023-06-12 00:55:36,757] Trial 461 finished with value: 81.06666564941406 and parameters: {'Fwd': 0.012692019010987092, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.200275474873885, 'loop': 1, 'loss': 'CE', 'lr': 0.009928576602690972, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001348632718739859, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.4
lr:  0.0007412418842587382
weight_decay:  0.0010215119651938687
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2461886149831116
None Run 01:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 77.10
Split: 01, Run: 02
None time:  1.3980208109132946
None Run 02:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 78.50
Split: 01, Run: 03
None time:  1.4683394951280206
None Run 03:
Highest Train: 100.00
Highest Valid: 77.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.142944812774658
total time:  4.162118480075151
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 78.87 ± 1.98
[I 2023-06-12 00:55:41,436] Trial 462 finished with value: 77.80000305175781 and parameters: {'Fwd': 0.02891737508692346, 'K': 10, 'alpha': 0.4, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.75, 'lambda2': 4.741853486914768, 'loop': 1, 'loss': 'MSE', 'lr': 0.0007412418842587382, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0010215119651938687, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.00395309312436868
weight_decay:  5.3913806608443283e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4804143190849572
None Run 01:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.4033136391080916
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.724302080925554
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.639460563659668
total time:  4.659737868933007
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.12
  Final Train: 100.00 ± 0.00
   Final Test: 81.30 ± 0.72
[I 2023-06-12 00:55:46,569] Trial 463 finished with value: 80.73333740234375 and parameters: {'Fwd': 0.05944506700568954, 'K': 10, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.80747807849835, 'loop': 1, 'loss': 'CE', 'lr': 0.00395309312436868, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.3913806608443283e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.007171829332303435
weight_decay:  8.25199044517992e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7941042599268258
None Run 01:
Highest Train: 100.00
Highest Valid: 81.60
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.8315436909906566
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.5759759729262441
None Run 03:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.30
run time now: 5.231551647186279
total time:  5.247195368167013
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.64
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.85
[I 2023-06-12 00:55:52,282] Trial 464 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.0990402912790926, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 4.407801636944932, 'loop': 1, 'loss': 'CE', 'lr': 0.007171829332303435, 'softmaxF': True, 'useGCN': True, 'weight_decay': 8.25199044517992e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.005423350068572528
weight_decay:  0.0002731934448049754
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.683058749185875
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.6495122550986707
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.4361026920378208
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.60
run time now: 4.796330213546753
total time:  4.816136508015916
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 81.63 ± 0.35
[I 2023-06-12 00:55:57,662] Trial 465 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.042148295587838135, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 6.716043457964545, 'loop': 1, 'loss': 'CE', 'lr': 0.005423350068572528, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0002731934448049754, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.008376467793611026
weight_decay:  3.39530028104281e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.766550384927541
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.70
Split: 01, Run: 02
None time:  1.3814218351617455
None Run 02:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.70
Split: 01, Run: 03
None time:  2.1776942398864776
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.90
run time now: 5.354854583740234
total time:  5.376704972004518
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.23
  Final Train: 100.00 ± 0.00
   Final Test: 82.77 ± 0.12
[I 2023-06-12 00:56:03,618] Trial 466 finished with value: 81.13333129882812 and parameters: {'Fwd': 0.07933991200977147, 'K': 10, 'alpha': 0.75, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.419693805810243, 'loop': 1, 'loss': 'CE', 'lr': 0.008376467793611026, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.39530028104281e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0006545346578643836
weight_decay:  0.0006425199730688294
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8207419770769775
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.90
Split: 01, Run: 02
None time:  1.8801491670310497
None Run 02:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 03
None time:  1.4823718920815736
None Run 03:
Highest Train: 100.00
Highest Valid: 78.40
  Final Train: 100.00
   Final Test: 78.60
run time now: 5.205821752548218
total time:  5.2277673908974975
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.20 ± 0.69
  Final Train: 100.00 ± 0.00
   Final Test: 80.13 ± 1.66
[I 2023-06-12 00:56:09,426] Trial 467 finished with value: 79.20000457763672 and parameters: {'Fwd': 0.0654299137367738, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 6.007272630639207, 'loop': 1, 'loss': 'CE', 'lr': 0.0006545346578643836, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0006425199730688294, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.004047801956083547
weight_decay:  0.0001705671801899787
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.738363130018115
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.6909333809744567
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.513765114126727
None Run 03:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.90
run time now: 4.96988320350647
total time:  4.9904683970380574
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 0.58
[I 2023-06-12 00:56:15,017] Trial 468 finished with value: 80.86666870117188 and parameters: {'Fwd': 0.007077202674533793, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 6.9036071118147575, 'loop': 1, 'loss': 'CE', 'lr': 0.004047801956083547, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001705671801899787, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.8
lr:  0.006294529001965744
weight_decay:  9.270645469387868e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.8)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.8530995619948953
None Run 01:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 02
None time:  0.8567502810619771
None Run 02:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
Split: 01, Run: 03
None time:  0.8624456089455634
None Run 03:
Highest Train: 100.00
Highest Valid: 68.80
  Final Train: 100.00
   Final Test: 70.00
run time now: 2.5976626873016357
total time:  2.612517128000036
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 68.80 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 70.00 ± 0.00
[I 2023-06-12 00:56:18,221] Trial 469 finished with value: 68.80000305175781 and parameters: {'Fwd': 0.051075992191258794, 'K': 10, 'alpha': 0.8, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 4.975585464806847, 'loop': 0, 'loss': 'CE', 'lr': 0.006294529001965744, 'softmaxF': True, 'useGCN': False, 'weight_decay': 9.270645469387868e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.5
lr:  0.0076933455904053955
weight_decay:  6.114321184597556e-05
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6365719849709421
None Run 01:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 82.80
Split: 01, Run: 02
None time:  1.6527638379484415
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 03
None time:  1.722209425875917
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.70
run time now: 5.117562770843506
total time:  5.141561302123591
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.53 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.90 ± 1.08
[I 2023-06-12 00:56:23,976] Trial 470 finished with value: 80.53333282470703 and parameters: {'Fwd': 0.0011329933990481221, 'K': 9, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.624570542818204, 'loop': 1, 'loss': 'CE', 'lr': 0.0076933455904053955, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.114321184597556e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.007062555606258173
weight_decay:  0.00010826777199480734
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7493239031173289
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.50
Split: 01, Run: 02
None time:  1.933377506909892
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 03
None time:  1.7934105810709298
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 79.90
run time now: 5.503307342529297
total time:  5.520863331854343
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.87 ± 0.31
  Final Train: 100.00 ± 0.00
   Final Test: 80.57 ± 0.83
[I 2023-06-12 00:56:30,051] Trial 471 finished with value: 80.86666107177734 and parameters: {'Fwd': 0.009137369210925866, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 80, 'lambda1': 0.9, 'lambda2': 5.2810898274342755, 'loop': 1, 'loss': 'CE', 'lr': 0.007062555606258173, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00010826777199480734, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.008594134975105845
weight_decay:  4.561051821633063e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6227978949900717
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  1.4425707929767668
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.80
Split: 01, Run: 03
None time:  1.6738580809906125
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 81.00
run time now: 4.769140243530273
total time:  4.787273830967024
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.13 ± 0.58
  Final Train: 100.00 ± 0.00
   Final Test: 81.23 ± 0.59
[I 2023-06-12 00:56:35,409] Trial 472 finished with value: 81.13333892822266 and parameters: {'Fwd': 0.00017618530452830408, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.762885872710088, 'loop': 1, 'loss': 'CE', 'lr': 0.008594134975105845, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.561051821633063e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.007820280759968158
weight_decay:  0.00020911371798212512
dropout:  0.9
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.9, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.3073352829087526
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.60
Split: 01, Run: 02
None time:  1.491734507959336
None Run 02:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.42582070780918
None Run 03:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.40
run time now: 4.269376277923584
total time:  4.295548382913694
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 1.04
  Final Train: 100.00 ± 0.00
   Final Test: 81.70 ± 0.79
[I 2023-06-12 00:56:40,202] Trial 473 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.0018849865244595033, 'K': 10, 'alpha': 0.65, 'dropout': 0.9, 'gnnepoch': 50, 'lambda1': 0.8, 'lambda2': 6.261818283701647, 'loop': 1, 'loss': 'CE', 'lr': 0.007820280759968158, 'softmaxF': False, 'useGCN': True, 'weight_decay': 0.00020911371798212512, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.005725555135794286
weight_decay:  7.400021053102437e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4413453149609268
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 98.57
   Final Test: 81.70
Split: 01, Run: 02
None time:  1.6450955800246447
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 97.14
   Final Test: 81.30
Split: 01, Run: 03
None time:  1.716108141001314
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 97.86
   Final Test: 80.90
run time now: 4.831305742263794
total time:  4.849201619857922
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.60
  Final Train: 97.86 ± 0.71
   Final Test: 81.30 ± 0.40
[I 2023-06-12 00:56:45,651] Trial 474 finished with value: 81.20000457763672 and parameters: {'Fwd': 0.022689360225889982, 'K': 10, 'alpha': 0.5, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 0.6171254253386067, 'loop': 1, 'loss': 'CE', 'lr': 0.005725555135794286, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.400021053102437e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  4
alpha:  0.55
lr:  0.0045988583764933555
weight_decay:  2.503149300920981e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=4, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2144201560877264
None Run 01:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.2035567751154304
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.40
Split: 01, Run: 03
None time:  1.5813050831202418
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.030919551849365
total time:  4.04798081307672
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.42
  Final Train: 100.00 ± 0.00
   Final Test: 81.53 ± 0.51
[I 2023-06-12 00:56:50,212] Trial 475 finished with value: 81.0666732788086 and parameters: {'Fwd': 0.09961246652355728, 'K': 4, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.468607936971741, 'loop': 1, 'loss': 'CE', 'lr': 0.0045988583764933555, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.503149300920981e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0005580405896255053
weight_decay:  1.708508810428651e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4250704341102391
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 78.80
Split: 01, Run: 02
None time:  1.841947415145114
None Run 02:
Highest Train: 100.00
Highest Valid: 74.60
  Final Train: 100.00
   Final Test: 74.80
Split: 01, Run: 03
None time:  1.6771746641024947
None Run 03:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 77.80
run time now: 4.974245071411133
total time:  4.993793225148693
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.53 ± 2.57
  Final Train: 100.00 ± 0.00
   Final Test: 77.13 ± 2.08
[I 2023-06-12 00:56:55,738] Trial 476 finished with value: 77.53333282470703 and parameters: {'Fwd': 4.801880873924543e-06, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.7000000000000001, 'lambda2': 5.07779633065192, 'loop': 1, 'loss': 'CE', 'lr': 0.0005580405896255053, 'softmaxF': True, 'useGCN': True, 'weight_decay': 1.708508810428651e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0004094872204461879
weight_decay:  0.00013317420388221193
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4483399849850684
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 02
None time:  1.592798839090392
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 74.20
Split: 01, Run: 03
None time:  1.7547255929093808
None Run 03:
Highest Train: 100.00
Highest Valid: 78.20
  Final Train: 100.00
   Final Test: 78.60
run time now: 4.818181753158569
total time:  4.833903972990811
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.20 ± 3.03
  Final Train: 100.00 ± 0.00
   Final Test: 77.17 ± 2.57
[I 2023-06-12 00:57:01,116] Trial 477 finished with value: 77.19999694824219 and parameters: {'Fwd': 0.000886242828771195, 'K': 10, 'alpha': 0.65, 'dropout': 0.30000000000000004, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 4.60038067716391, 'loop': 1, 'loss': 'CE', 'lr': 0.0004094872204461879, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00013317420388221193, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.006677919991191364
weight_decay:  5.4704259496120816e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7071931790560484
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.4641392449848354
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.00
Split: 01, Run: 03
None time:  1.8586127508897334
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.50
run time now: 5.057347536087036
total time:  5.07495981012471
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.07 ± 0.81
  Final Train: 100.00 ± 0.00
   Final Test: 81.20 ± 0.82
[I 2023-06-12 00:57:06,733] Trial 478 finished with value: 81.0666732788086 and parameters: {'Fwd': 0.016443345882078166, 'K': 10, 'alpha': 0.45, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.75, 'lambda2': 5.929543714826393, 'loop': 1, 'loss': 'CE', 'lr': 0.006677919991191364, 'softmaxF': True, 'useGCN': True, 'weight_decay': 5.4704259496120816e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.4
lr:  0.009224123309237523
weight_decay:  0.0004834703892851982
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.4)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5181194529868662
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.715740012936294
None Run 02:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 03
None time:  1.3262775060720742
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 80.90
run time now: 4.586449861526489
total time:  4.60111822700128
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.20 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.03 ± 1.11
[I 2023-06-12 00:57:11,826] Trial 479 finished with value: 81.20000457763672 and parameters: {'Fwd': 0.08099059754096868, 'K': 9, 'alpha': 0.4, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.6034472419333845, 'loop': 1, 'loss': 'CE', 'lr': 0.009224123309237523, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0004834703892851982, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.000678376319084904
weight_decay:  9.902054533484706e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.7044548159465194
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 79.00
Split: 01, Run: 02
None time:  1.5674318810924888
None Run 02:
Highest Train: 100.00
Highest Valid: 75.20
  Final Train: 100.00
   Final Test: 74.70
Split: 01, Run: 03
None time:  1.681137328967452
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.00
run time now: 4.980729579925537
total time:  4.9950995210092515
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 77.40 ± 2.11
  Final Train: 100.00 ± 0.00
   Final Test: 77.23 ± 2.25
[I 2023-06-12 00:57:17,316] Trial 480 finished with value: 77.4000015258789 and parameters: {'Fwd': 0.002352388132117054, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.333284790821891, 'loop': 1, 'loss': 'CE', 'lr': 0.000678376319084904, 'softmaxF': True, 'useGCN': True, 'weight_decay': 9.902054533484706e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.007315622150531277
weight_decay:  3.753171837525114e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): Identity()
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): Identity()
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4383369921706617
None Run 01:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  1.4536892450414598
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 03
None time:  3.243104469962418
None Run 03:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 81.30
run time now: 6.160455226898193
total time:  6.175516226794571
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.20 ± 0.20
  Final Train: 100.00 ± 0.00
   Final Test: 80.40 ± 0.85
[I 2023-06-12 00:57:24,099] Trial 481 finished with value: 80.20000457763672 and parameters: {'Fwd': 0.06529427500691524, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.9, 'lambda2': 4.788708409854873, 'loop': 1, 'loss': 'MSE', 'lr': 0.007315622150531277, 'softmaxF': True, 'useGCN': True, 'weight_decay': 3.753171837525114e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.0007762668483113382
weight_decay:  0.001972768629615365
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.8055972459260374
None Run 01:
Highest Train: 100.00
Highest Valid: 79.40
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  1.8066094820387661
None Run 02:
Highest Train: 100.00
Highest Valid: 78.00
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  1.6264033110346645
None Run 03:
Highest Train: 100.00
Highest Valid: 77.20
  Final Train: 100.00
   Final Test: 77.10
run time now: 5.304696798324585
total time:  5.3427264471538365
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.20 ± 1.11
  Final Train: 100.00 ± 0.00
   Final Test: 78.17 ± 1.59
[I 2023-06-12 00:57:29,997] Trial 482 finished with value: 78.20000457763672 and parameters: {'Fwd': 0.03327240054613089, 'K': 10, 'alpha': 0.5, 'dropout': 0.4, 'gnnepoch': 70, 'lambda1': 0.8, 'lambda2': 6.086990206187258, 'loop': 1, 'loss': 'CE', 'lr': 0.0007762668483113382, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.001972768629615365, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0012333261218322867
weight_decay:  7.592787529401295e-05
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.841256279964
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 02
None time:  1.3607579628005624
None Run 02:
Highest Train: 100.00
Highest Valid: 76.00
  Final Train: 100.00
   Final Test: 76.10
Split: 01, Run: 03
None time:  1.6340688068885356
None Run 03:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 78.50
run time now: 4.865448951721191
total time:  4.879948902875185
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.27 ± 2.05
  Final Train: 100.00 ± 0.00
   Final Test: 78.33 ± 2.15
[I 2023-06-12 00:57:35,374] Trial 483 finished with value: 78.26666259765625 and parameters: {'Fwd': 0.08141798100029989, 'K': 10, 'alpha': 0.55, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 9.403478489799292, 'loop': 1, 'loss': 'CE', 'lr': 0.0012333261218322867, 'softmaxF': True, 'useGCN': True, 'weight_decay': 7.592787529401295e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  8
alpha:  0.65
lr:  0.0020442045566124037
weight_decay:  0.00015066463602267992
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=8, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4678147451486439
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.40
Split: 01, Run: 02
None time:  1.65076995594427
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 78.10
Split: 01, Run: 03
None time:  1.4365644068457186
None Run 03:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 78.20
run time now: 4.668248891830444
total time:  4.7566212981473655
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.73 ± 1.21
  Final Train: 100.00 ± 0.00
   Final Test: 78.90 ± 1.30
[I 2023-06-12 00:57:40,707] Trial 484 finished with value: 78.73333740234375 and parameters: {'Fwd': 0.04909624995805621, 'K': 8, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 1.8590723930388786, 'loop': 1, 'loss': 'CE', 'lr': 0.0020442045566124037, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00015066463602267992, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.008473399727640895
weight_decay:  6.374779360496634e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.2533276989124715
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 99.29
   Final Test: 81.80
Split: 01, Run: 02
None time:  1.5543934078887105
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 99.29
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.5026510830502957
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 99.29
   Final Test: 81.50
run time now: 4.33465313911438
total time:  4.349925870075822
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.27 ± 0.50
  Final Train: 99.29 ± 0.00
   Final Test: 81.63 ± 0.15
[I 2023-06-12 00:57:45,621] Trial 485 finished with value: 81.26667022705078 and parameters: {'Fwd': 0.06622675777059535, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.8500000000000001, 'lambda2': 1.3080014362529724, 'loop': 1, 'loss': 'CE', 'lr': 0.008473399727640895, 'softmaxF': True, 'useGCN': True, 'weight_decay': 6.374779360496634e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.0008705451778040182
weight_decay:  4.402938096582139e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6418809038586915
None Run 01:
Highest Train: 100.00
Highest Valid: 79.60
  Final Train: 100.00
   Final Test: 79.60
Split: 01, Run: 02
None time:  1.3594904178753495
None Run 02:
Highest Train: 100.00
Highest Valid: 73.80
  Final Train: 100.00
   Final Test: 75.00
Split: 01, Run: 03
None time:  1.6245314879342914
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 77.70
run time now: 4.65405535697937
total time:  4.668676000088453
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.53 ± 2.91
  Final Train: 100.00 ± 0.00
   Final Test: 77.43 ± 2.31
[I 2023-06-12 00:57:50,831] Trial 486 finished with value: 76.53333282470703 and parameters: {'Fwd': 0.08561962160982725, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 1.0, 'lambda2': 8.530555802037586, 'loop': 1, 'loss': 'CE', 'lr': 0.0008705451778040182, 'softmaxF': True, 'useGCN': True, 'weight_decay': 4.402938096582139e-05, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.0007819591043806109
weight_decay:  0.002223345096679481
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  0.9000609428621829
None Run 01:
Highest Train: 100.00
Highest Valid: 78.80
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 02
None time:  0.706068207975477
None Run 02:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 77.40
Split: 01, Run: 03
None time:  0.8477281089872122
None Run 03:
Highest Train: 100.00
Highest Valid: 75.40
  Final Train: 100.00
   Final Test: 76.80
run time now: 2.4806621074676514
total time:  2.4957799550611526
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.87 ± 1.75
  Final Train: 100.00 ± 0.00
   Final Test: 77.20 ± 0.35
[I 2023-06-12 00:57:53,849] Trial 487 finished with value: 76.86666870117188 and parameters: {'Fwd': 0.019323662097433397, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 7.703309307908267, 'loop': 1, 'loss': 'CE', 'lr': 0.0007819591043806109, 'softmaxF': True, 'useGCN': False, 'weight_decay': 0.002223345096679481, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.65
lr:  0.006268564742884421
weight_decay:  0.0005598074206426748
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.56943266489543
None Run 01:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 81.90
Split: 01, Run: 02
None time:  2.4811300090514123
None Run 02:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  2.2551306961104274
None Run 03:
Highest Train: 100.00
Highest Valid: 80.60
  Final Train: 100.00
   Final Test: 80.20
run time now: 7.376272201538086
total time:  7.396112781018019
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.00
  Final Train: 100.00 ± 0.00
   Final Test: 80.93 ± 0.87
[I 2023-06-12 00:58:01,868] Trial 488 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.00922577609629366, 'K': 9, 'alpha': 0.65, 'dropout': 0.5, 'gnnepoch': 110, 'lambda1': 0.9, 'lambda2': 5.124301402486695, 'loop': 1, 'loss': 'CE', 'lr': 0.006268564742884421, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0005598074206426748, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.6000000000000001
lr:  0.0017680021358419844
weight_decay:  0.012250153592337666
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.5971073468681425
None Run 01:
Highest Train: 100.00
Highest Valid: 80.00
  Final Train: 100.00
   Final Test: 80.30
Split: 01, Run: 02
None time:  2.2190194881986827
None Run 02:
Highest Train: 100.00
Highest Valid: 78.60
  Final Train: 100.00
   Final Test: 79.80
Split: 01, Run: 03
None time:  2.1935221429448575
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.30
run time now: 6.0338134765625
total time:  6.046361010055989
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 79.60 ± 0.87
  Final Train: 100.00 ± 0.00
   Final Test: 80.13 ± 0.29
[I 2023-06-12 00:58:08,484] Trial 489 finished with value: 79.5999984741211 and parameters: {'Fwd': 0.0579500251324771, 'K': 10, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 7.624608585562155, 'loop': 1, 'loss': 'CE', 'lr': 0.0017680021358419844, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.012250153592337666, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.5
lr:  0.007917746349930171
weight_decay:  0.07577509327916267
dropout:  0.30000000000000004
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.30000000000000004, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.5)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.4776414681691676
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.10
Split: 01, Run: 02
None time:  1.853317195083946
None Run 02:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 80.70
Split: 01, Run: 03
None time:  1.6631357301957905
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 79.90
run time now: 5.022618055343628
total time:  5.037265013903379
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.73 ± 0.92
  Final Train: 100.00 ± 0.00
   Final Test: 80.90 ± 1.11
[I 2023-06-12 00:58:14,039] Trial 490 finished with value: 80.73332977294922 and parameters: {'Fwd': 6.537574163611381e-05, 'K': 10, 'alpha': 0.5, 'dropout': 0.30000000000000004, 'gnnepoch': 70, 'lambda1': 0.8500000000000001, 'lambda2': 5.830172262085346, 'loop': 1, 'loss': 'CE', 'lr': 0.007917746349930171, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.07577509327916267, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.55
lr:  0.009935585982827065
weight_decay:  2.9998916604745758e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.55)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6673528118990362
None Run 01:
Highest Train: 100.00
Highest Valid: 81.80
  Final Train: 100.00
   Final Test: 82.00
Split: 01, Run: 02
None time:  1.3235600909683853
None Run 02:
Highest Train: 100.00
Highest Valid: 81.40
  Final Train: 100.00
   Final Test: 80.90
Split: 01, Run: 03
None time:  1.7703878488391638
None Run 03:
Highest Train: 100.00
Highest Valid: 80.80
  Final Train: 100.00
   Final Test: 80.70
run time now: 4.789829730987549
total time:  4.805088839028031
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.33 ± 0.50
  Final Train: 100.00 ± 0.00
   Final Test: 81.20 ± 0.70
[I 2023-06-12 00:58:19,448] Trial 491 finished with value: 81.33333587646484 and parameters: {'Fwd': 0.03777835039872736, 'K': 10, 'alpha': 0.55, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9500000000000001, 'lambda2': 5.621877427982762, 'loop': 1, 'loss': 'CE', 'lr': 0.009935585982827065, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.9998916604745758e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.005138064649734693
weight_decay:  8.832982847529408e-05
dropout:  0.7000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.7000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6895381070207804
None Run 01:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 82.30
Split: 01, Run: 02
None time:  1.6285382730420679
None Run 02:
Highest Train: 100.00
Highest Valid: 80.40
  Final Train: 100.00
   Final Test: 81.10
Split: 01, Run: 03
None time:  1.135378107894212
None Run 03:
Highest Train: 100.00
Highest Valid: 80.20
  Final Train: 100.00
   Final Test: 81.10
run time now: 4.4795472621917725
total time:  4.494113035965711
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 80.60 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.50 ± 0.69
[I 2023-06-12 00:58:24,540] Trial 492 finished with value: 80.5999984741211 and parameters: {'Fwd': 0.07821563103960294, 'K': 10, 'alpha': 0.45, 'dropout': 0.7000000000000001, 'gnnepoch': 60, 'lambda1': 0.8, 'lambda2': 5.32814559717888, 'loop': 1, 'loss': 'CE', 'lr': 0.005138064649734693, 'softmaxF': False, 'useGCN': True, 'weight_decay': 8.832982847529408e-05, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.65
lr:  0.0009866516461506652
weight_decay:  0.000301800245403025
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.65)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.007565750973299
None Run 01:
Highest Train: 100.00
Highest Valid: 79.80
  Final Train: 100.00
   Final Test: 80.00
Split: 01, Run: 02
None time:  2.0224527339451015
None Run 02:
Highest Train: 100.00
Highest Valid: 79.20
  Final Train: 100.00
   Final Test: 78.70
Split: 01, Run: 03
None time:  1.715451671043411
None Run 03:
Highest Train: 100.00
Highest Valid: 76.20
  Final Train: 100.00
   Final Test: 76.70
run time now: 5.847077369689941
total time:  5.913665489992127
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 78.40 ± 1.93
  Final Train: 100.00 ± 0.00
   Final Test: 78.47 ± 1.66
[I 2023-06-12 00:58:31,132] Trial 493 finished with value: 78.4000015258789 and parameters: {'Fwd': 0.00745924805571504, 'K': 10, 'alpha': 0.65, 'dropout': 0.4, 'gnnepoch': 60, 'lambda1': 0.9, 'lambda2': 5.518419280569259, 'loop': 2, 'loss': 'CE', 'lr': 0.0009866516461506652, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.000301800245403025, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.75
lr:  0.0001242056140850736
weight_decay:  2.992346605289771e-06
dropout:  0.5
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.5, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.75)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.5993112029973418
None Run 01:
Highest Train: 100.00
Highest Valid: 76.40
  Final Train: 100.00
   Final Test: 78.00
Split: 01, Run: 02
None time:  2.3630310071166605
None Run 02:
Highest Train: 100.00
Highest Valid: 72.80
  Final Train: 100.00
   Final Test: 74.90
Split: 01, Run: 03
None time:  1.6116054689045995
None Run 03:
Highest Train: 100.00
Highest Valid: 71.20
  Final Train: 100.00
   Final Test: 72.60
run time now: 6.601663589477539
total time:  6.616369279101491
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 73.47 ± 2.66
  Final Train: 100.00 ± 0.00
   Final Test: 75.17 ± 2.71
[I 2023-06-12 00:58:38,308] Trial 494 finished with value: 73.46666717529297 and parameters: {'Fwd': 0.06416617299312562, 'K': 10, 'alpha': 0.75, 'dropout': 0.5, 'gnnepoch': 60, 'lambda1': 0.75, 'lambda2': 7.095986674114618, 'loop': 1, 'loss': 'CE', 'lr': 0.0001242056140850736, 'softmaxF': True, 'useGCN': True, 'weight_decay': 2.992346605289771e-06, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  9
alpha:  0.6000000000000001
lr:  0.000322151737833954
weight_decay:  0.00011020556006662103
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=9, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.6000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  2.9463027520105243
None Run 01:
Highest Train: 100.00
Highest Valid: 77.40
  Final Train: 100.00
   Final Test: 76.50
Split: 01, Run: 02
None time:  2.409982251934707
None Run 02:
Highest Train: 100.00
Highest Valid: 77.60
  Final Train: 100.00
   Final Test: 77.60
Split: 01, Run: 03
None time:  1.7410469299647957
None Run 03:
Highest Train: 100.00
Highest Valid: 75.80
  Final Train: 100.00
   Final Test: 75.30
run time now: 7.1262900829315186
total time:  7.142345872009173
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 76.93 ± 0.99
  Final Train: 100.00 ± 0.00
   Final Test: 76.47 ± 1.15
[I 2023-06-12 00:58:45,966] Trial 495 finished with value: 76.93333435058594 and parameters: {'Fwd': 3.2579106007563595e-05, 'K': 9, 'alpha': 0.6000000000000001, 'dropout': 0.4, 'gnnepoch': 50, 'lambda1': 0.05, 'lambda2': 4.996783137788898, 'loop': 1, 'loss': 'CE', 'lr': 0.000322151737833954, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.00011020556006662103, 'weightedloss': False}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.7000000000000001
lr:  0.006967444539438656
weight_decay:  0.0001740303985479233
dropout:  0.6000000000000001
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.6000000000000001, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.7000000000000001)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
init label
Split: 01, Run: 01
None time:  1.6541635668836534
None Run 01:
Highest Train: 100.00
Highest Valid: 82.00
  Final Train: 100.00
   Final Test: 82.20
Split: 01, Run: 02
None time:  1.7287759790197015
None Run 02:
Highest Train: 100.00
Highest Valid: 81.20
  Final Train: 100.00
   Final Test: 81.60
Split: 01, Run: 03
None time:  1.3826659668702632
None Run 03:
Highest Train: 100.00
Highest Valid: 81.00
  Final Train: 100.00
   Final Test: 81.50
run time now: 4.794651031494141
total time:  4.813346436014399
None All runs:
Highest Train: 100.00 ± 0.00
Highest Valid: 81.40 ± 0.53
  Final Train: 100.00 ± 0.00
   Final Test: 81.77 ± 0.38
[I 2023-06-12 00:58:51,279] Trial 496 finished with value: 81.4000015258789 and parameters: {'Fwd': 0.0468023461344406, 'K': 10, 'alpha': 0.7000000000000001, 'dropout': 0.6000000000000001, 'gnnepoch': 60, 'lambda1': 0.8500000000000001, 'lambda2': 5.734157486996309, 'loop': 1, 'loss': 'CE', 'lr': 0.006967444539438656, 'softmaxF': True, 'useGCN': True, 'weight_decay': 0.0001740303985479233, 'weightedloss': True}. Best is trial 112 with value: 81.66667175292969.
/home/wxy/miniconda3/lib/python3.10/site-packages/optuna/distributions.py:685: UserWarning: The distribution is specified by [0, 1.00001] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0, 1.0].
  warnings.warn(
K:  10
alpha:  0.45
lr:  0.00238955173918197
weight_decay:  5.7841573641693063e-05
dropout:  0.4
fix split and run 3 times
Data: Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], adj_t=[2708, 2708, nnz=10556])
num_train tensor(140)
num_noise 0
noise: tensor(0)
data feature 1433
ALTOPT(
  (lins): Sequential(
    (0): Linear(in_features=1433, out_features=64, bias=True)
    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.4, inplace=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=7, bias=True)
    (5): LogSoftmax(dim=-1)
  )
  (prop): Propagation(K=10, mode=None, lambda1=None, lambda2=None, L21=True, alpha=0.45)
  (gcn): GCN(
    (convs): ModuleList(
      (0): GCNConv(1433, 64)
      (1): GCNConv(64, 7)
    )
    (bns): ModuleList(
      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (output): LogSoftmax(dim=-1)
  )
)
propagate done
